vocabulary size: 226
n tunes: 4083
n train tunes: 3891.0
n validation tunes: 192.0
min, max length 55 822
Building the model
  number of parameters: 10384102
  layer output shapes:               #params:   output shape:
    InputLayer                       0          (32, None)
    EmbeddingLayer                   51076      (32, None, 226)
    InputLayer                       0          (32, None)
    GRULayer                         2465600    (32, None, 800)
    DropoutLayer                     0          (32, None, 800)
    GRULayer                         3843200    (32, None, 800)
    DropoutLayer                     0          (32, None, 800)
    GRULayer                         3843200    (32, None, 800)
    DropoutLayer                     0          (32, None, 800)
    ReshapeLayer                     0          (None, 800)
    DenseLayer                       181026     (None, 226)
Train model
Load metadata for resuming
setting learning rate to 0.0030000
7781/10943 (epoch 63.992) train_loss=455.67004395 time/batch=1.18s
7782/10943 (epoch 64.000) train_loss=353.04379272 time/batch=0.80s
7783/10943 (epoch 64.008) train_loss=790.32641602 time/batch=1.63s
7784/10943 (epoch 64.016) train_loss=620.18225098 time/batch=1.44s
7785/10943 (epoch 64.025) train_loss=160.96194458 time/batch=0.47s
7786/10943 (epoch 64.033) train_loss=235.60264587 time/batch=0.54s
7787/10943 (epoch 64.041) train_loss=341.88778687 time/batch=0.82s
7788/10943 (epoch 64.049) train_loss=98.98066711 time/batch=0.30s
7789/10943 (epoch 64.058) train_loss=373.60327148 time/batch=0.87s
7790/10943 (epoch 64.066) train_loss=759.91680908 time/batch=1.92s
7791/10943 (epoch 64.074) train_loss=879.57604980 time/batch=3.15s
7792/10943 (epoch 64.082) train_loss=290.59326172 time/batch=0.95s
7793/10943 (epoch 64.090) train_loss=279.08523560 time/batch=0.66s
7794/10943 (epoch 64.099) train_loss=217.98600769 time/batch=0.55s
7795/10943 (epoch 64.107) train_loss=315.82904053 time/batch=0.73s
7796/10943 (epoch 64.115) train_loss=423.46792603 time/batch=1.02s
7797/10943 (epoch 64.123) train_loss=371.45294189 time/batch=0.92s
7798/10943 (epoch 64.132) train_loss=177.30169678 time/batch=0.46s
7799/10943 (epoch 64.140) train_loss=142.14294434 time/batch=0.34s
7800/10943 (epoch 64.148) train_loss=186.94241333 time/batch=0.44s
7801/10943 (epoch 64.156) train_loss=305.58676147 time/batch=0.73s
7802/10943 (epoch 64.164) train_loss=403.97540283 time/batch=0.94s
7803/10943 (epoch 64.173) train_loss=161.99993896 time/batch=0.47s
7804/10943 (epoch 64.181) train_loss=442.77038574 time/batch=0.94s
7805/10943 (epoch 64.189) train_loss=212.93048096 time/batch=0.58s
7806/10943 (epoch 64.197) train_loss=185.54275513 time/batch=0.47s
7807/10943 (epoch 64.206) train_loss=393.44839478 time/batch=0.93s
7808/10943 (epoch 64.214) train_loss=374.80352783 time/batch=0.92s
7809/10943 (epoch 64.222) train_loss=591.25311279 time/batch=1.30s
7810/10943 (epoch 64.230) train_loss=467.59857178 time/batch=1.16s
7811/10943 (epoch 64.238) train_loss=162.90921021 time/batch=0.47s
7812/10943 (epoch 64.247) train_loss=301.92883301 time/batch=0.71s
7813/10943 (epoch 64.255) train_loss=455.71176147 time/batch=1.03s
7814/10943 (epoch 64.263) train_loss=248.08129883 time/batch=0.66s
7815/10943 (epoch 64.271) train_loss=112.01313782 time/batch=0.30s
7816/10943 (epoch 64.280) train_loss=546.23199463 time/batch=1.19s
7817/10943 (epoch 64.288) train_loss=354.18249512 time/batch=0.90s
7818/10943 (epoch 64.296) train_loss=484.45251465 time/batch=1.18s
7819/10943 (epoch 64.304) train_loss=311.93811035 time/batch=0.85s
7820/10943 (epoch 64.313) train_loss=267.55273438 time/batch=0.65s
7821/10943 (epoch 64.321) train_loss=520.82324219 time/batch=1.29s
7822/10943 (epoch 64.329) train_loss=411.27673340 time/batch=1.04s
7823/10943 (epoch 64.337) train_loss=203.08117676 time/batch=0.58s
7824/10943 (epoch 64.345) train_loss=264.13787842 time/batch=0.66s
7825/10943 (epoch 64.354) train_loss=393.40026855 time/batch=0.93s
7826/10943 (epoch 64.362) train_loss=515.36749268 time/batch=1.20s
7827/10943 (epoch 64.370) train_loss=150.67337036 time/batch=0.44s
7828/10943 (epoch 64.378) train_loss=307.03912354 time/batch=0.74s
7829/10943 (epoch 64.387) train_loss=399.20422363 time/batch=0.96s
7830/10943 (epoch 64.395) train_loss=461.56405640 time/batch=1.11s
7831/10943 (epoch 64.403) train_loss=144.09475708 time/batch=0.42s
7832/10943 (epoch 64.411) train_loss=332.07818604 time/batch=0.77s
7833/10943 (epoch 64.419) train_loss=158.80758667 time/batch=0.41s
7834/10943 (epoch 64.428) train_loss=285.90808105 time/batch=0.68s
7835/10943 (epoch 64.436) train_loss=178.91563416 time/batch=0.46s
7836/10943 (epoch 64.444) train_loss=331.12896729 time/batch=0.78s
7837/10943 (epoch 64.452) train_loss=384.21194458 time/batch=0.97s
7838/10943 (epoch 64.461) train_loss=313.99890137 time/batch=0.82s
7839/10943 (epoch 64.469) train_loss=233.56596375 time/batch=0.59s
7840/10943 (epoch 64.477) train_loss=211.50582886 time/batch=0.55s
7841/10943 (epoch 64.485) train_loss=121.13196564 time/batch=0.31s
7842/10943 (epoch 64.493) train_loss=233.68424988 time/batch=0.54s
7843/10943 (epoch 64.502) train_loss=140.59475708 time/batch=0.37s
7844/10943 (epoch 64.510) train_loss=157.76525879 time/batch=0.39s
7845/10943 (epoch 64.518) train_loss=240.08084106 time/batch=0.57s
7846/10943 (epoch 64.526) train_loss=467.15280151 time/batch=1.08s
7847/10943 (epoch 64.535) train_loss=200.63182068 time/batch=0.58s
7848/10943 (epoch 64.543) train_loss=334.24975586 time/batch=0.79s
7849/10943 (epoch 64.551) train_loss=190.45155334 time/batch=0.52s
7850/10943 (epoch 64.559) train_loss=278.92279053 time/batch=0.66s
7851/10943 (epoch 64.567) train_loss=309.41641235 time/batch=0.78s
7852/10943 (epoch 64.576) train_loss=314.03680420 time/batch=0.79s
7853/10943 (epoch 64.584) train_loss=336.36920166 time/batch=0.83s
7854/10943 (epoch 64.592) train_loss=237.25354004 time/batch=0.64s
7855/10943 (epoch 64.600) train_loss=117.48124695 time/batch=0.33s
7856/10943 (epoch 64.609) train_loss=264.90118408 time/batch=0.61s
7857/10943 (epoch 64.617) train_loss=340.62542725 time/batch=0.82s
7858/10943 (epoch 64.625) train_loss=378.15692139 time/batch=1.00s
7859/10943 (epoch 64.633) train_loss=195.83142090 time/batch=0.53s
7860/10943 (epoch 64.641) train_loss=313.70989990 time/batch=0.74s
7861/10943 (epoch 64.650) train_loss=342.36294556 time/batch=0.84s
7862/10943 (epoch 64.658) train_loss=292.81854248 time/batch=0.75s
7863/10943 (epoch 64.666) train_loss=485.54794312 time/batch=1.40s
7864/10943 (epoch 64.674) train_loss=207.24282837 time/batch=0.60s
7865/10943 (epoch 64.683) train_loss=248.59390259 time/batch=0.60s
7866/10943 (epoch 64.691) train_loss=351.13360596 time/batch=0.85s
7867/10943 (epoch 64.699) train_loss=164.37823486 time/batch=0.47s
7868/10943 (epoch 64.707) train_loss=270.84887695 time/batch=0.63s
7869/10943 (epoch 64.715) train_loss=248.03924561 time/batch=0.62s
7870/10943 (epoch 64.724) train_loss=227.77774048 time/batch=0.59s
7871/10943 (epoch 64.732) train_loss=225.67703247 time/batch=0.59s
7872/10943 (epoch 64.740) train_loss=259.34411621 time/batch=0.64s
7873/10943 (epoch 64.748) train_loss=155.93737793 time/batch=0.46s
7874/10943 (epoch 64.757) train_loss=173.14942932 time/batch=0.44s
7875/10943 (epoch 64.765) train_loss=140.33299255 time/batch=0.45s
7876/10943 (epoch 64.773) train_loss=235.12771606 time/batch=0.59s
7877/10943 (epoch 64.781) train_loss=291.16107178 time/batch=0.70s
7878/10943 (epoch 64.790) train_loss=198.35658264 time/batch=0.55s
7879/10943 (epoch 64.798) train_loss=196.56587219 time/batch=0.49s
7880/10943 (epoch 64.806) train_loss=203.54147339 time/batch=0.50s
7881/10943 (epoch 64.814) train_loss=299.42749023 time/batch=0.72s
7882/10943 (epoch 64.822) train_loss=122.92477417 time/batch=0.35s
7883/10943 (epoch 64.831) train_loss=349.93859863 time/batch=0.82s
7884/10943 (epoch 64.839) train_loss=229.33810425 time/batch=0.60s
7885/10943 (epoch 64.847) train_loss=168.08949280 time/batch=0.51s
7886/10943 (epoch 64.855) train_loss=229.24362183 time/batch=0.58s
7887/10943 (epoch 64.864) train_loss=210.95346069 time/batch=0.53s
7888/10943 (epoch 64.872) train_loss=269.29595947 time/batch=0.65s
7889/10943 (epoch 64.880) train_loss=170.83775330 time/batch=0.56s
7890/10943 (epoch 64.888) train_loss=307.60327148 time/batch=0.71s
7891/10943 (epoch 64.896) train_loss=253.23464966 time/batch=0.67s
7892/10943 (epoch 64.905) train_loss=267.27478027 time/batch=0.66s
7893/10943 (epoch 64.913) train_loss=372.20715332 time/batch=0.99s
7894/10943 (epoch 64.921) train_loss=232.98043823 time/batch=0.63s
7895/10943 (epoch 64.929) train_loss=311.70703125 time/batch=0.85s
7896/10943 (epoch 64.938) train_loss=244.84642029 time/batch=0.68s
7897/10943 (epoch 64.946) train_loss=296.77941895 time/batch=0.71s
7898/10943 (epoch 64.954) train_loss=299.83898926 time/batch=0.85s
7899/10943 (epoch 64.962) train_loss=257.37698364 time/batch=0.69s
7900/10943 (epoch 64.970) train_loss=289.54083252 time/batch=0.69s
7901/10943 (epoch 64.979) train_loss=277.34399414 time/batch=0.72s
7902/10943 (epoch 64.987) train_loss=160.24627686 time/batch=0.43s
7903/10943 (epoch 64.995) train_loss=267.89968872 time/batch=0.63s
7904/10943 (epoch 65.003) train_loss=419.22003174 time/batch=1.01s
7905/10943 (epoch 65.012) train_loss=510.99548340 time/batch=1.25s
7906/10943 (epoch 65.020) train_loss=959.37609863 time/batch=3.11s
7907/10943 (epoch 65.028) train_loss=608.76562500 time/batch=1.59s
7908/10943 (epoch 65.036) train_loss=317.38110352 time/batch=0.87s
7909/10943 (epoch 65.044) train_loss=442.08007812 time/batch=1.01s
7910/10943 (epoch 65.053) train_loss=304.31063843 time/batch=0.80s
7911/10943 (epoch 65.061) train_loss=325.72552490 time/batch=0.82s
7912/10943 (epoch 65.069) train_loss=196.81246948 time/batch=0.54s
7913/10943 (epoch 65.077) train_loss=712.42529297 time/batch=1.63s
7914/10943 (epoch 65.086) train_loss=281.50869751 time/batch=0.82s
7915/10943 (epoch 65.094) train_loss=463.58959961 time/batch=1.09s
7916/10943 (epoch 65.102) train_loss=97.13444519 time/batch=0.33s
7917/10943 (epoch 65.110) train_loss=348.66522217 time/batch=0.78s
7918/10943 (epoch 65.118) train_loss=653.27441406 time/batch=1.54s
7919/10943 (epoch 65.127) train_loss=238.57218933 time/batch=0.68s
7920/10943 (epoch 65.135) train_loss=313.84976196 time/batch=0.75s
7921/10943 (epoch 65.143) train_loss=558.14794922 time/batch=1.36s
7922/10943 (epoch 65.151) train_loss=148.08981323 time/batch=0.45s
7923/10943 (epoch 65.160) train_loss=182.85836792 time/batch=0.44s
7924/10943 (epoch 65.168) train_loss=234.58123779 time/batch=0.60s
7925/10943 (epoch 65.176) train_loss=455.32244873 time/batch=1.04s
7926/10943 (epoch 65.184) train_loss=182.62565613 time/batch=0.50s
7927/10943 (epoch 65.192) train_loss=275.76977539 time/batch=0.66s
7928/10943 (epoch 65.201) train_loss=124.04611206 time/batch=0.34s
7929/10943 (epoch 65.209) train_loss=391.96246338 time/batch=0.91s
7930/10943 (epoch 65.217) train_loss=344.40325928 time/batch=0.88s
7931/10943 (epoch 65.225) train_loss=483.90374756 time/batch=1.16s
7932/10943 (epoch 65.234) train_loss=322.15963745 time/batch=0.82s
7933/10943 (epoch 65.242) train_loss=232.71429443 time/batch=0.60s
7934/10943 (epoch 65.250) train_loss=186.64230347 time/batch=0.48s
7935/10943 (epoch 65.258) train_loss=265.04708862 time/batch=0.62s
7936/10943 (epoch 65.267) train_loss=202.17321777 time/batch=0.51s
7937/10943 (epoch 65.275) train_loss=297.65908813 time/batch=0.70s
7938/10943 (epoch 65.283) train_loss=358.16250610 time/batch=0.89s
7939/10943 (epoch 65.291) train_loss=124.56610107 time/batch=0.35s
7940/10943 (epoch 65.299) train_loss=334.10998535 time/batch=0.79s
7941/10943 (epoch 65.308) train_loss=510.01068115 time/batch=1.18s
7942/10943 (epoch 65.316) train_loss=429.17514038 time/batch=1.02s
7943/10943 (epoch 65.324) train_loss=124.42524719 time/batch=0.38s
7944/10943 (epoch 65.332) train_loss=320.51089478 time/batch=0.75s
7945/10943 (epoch 65.341) train_loss=360.89453125 time/batch=0.90s
7946/10943 (epoch 65.349) train_loss=140.07885742 time/batch=0.40s
7947/10943 (epoch 65.357) train_loss=306.65264893 time/batch=0.77s
7948/10943 (epoch 65.365) train_loss=178.27265930 time/batch=0.48s
7949/10943 (epoch 65.373) train_loss=365.39190674 time/batch=0.88s
7950/10943 (epoch 65.382) train_loss=348.29574585 time/batch=0.89s
7951/10943 (epoch 65.390) train_loss=128.60224915 time/batch=0.40s
7952/10943 (epoch 65.398) train_loss=466.06872559 time/batch=1.03s
7953/10943 (epoch 65.406) train_loss=281.98858643 time/batch=0.74s
7954/10943 (epoch 65.415) train_loss=150.65625000 time/batch=0.41s
7955/10943 (epoch 65.423) train_loss=299.49664307 time/batch=0.67s
7956/10943 (epoch 65.431) train_loss=266.47067261 time/batch=0.67s
7957/10943 (epoch 65.439) train_loss=110.78279114 time/batch=0.31s
7958/10943 (epoch 65.447) train_loss=452.50088501 time/batch=1.03s
7959/10943 (epoch 65.456) train_loss=432.14575195 time/batch=1.15s
7960/10943 (epoch 65.464) train_loss=142.21594238 time/batch=0.44s
7961/10943 (epoch 65.472) train_loss=372.81951904 time/batch=0.88s
7962/10943 (epoch 65.480) train_loss=312.15301514 time/batch=0.78s
7963/10943 (epoch 65.489) train_loss=232.38040161 time/batch=0.61s
7964/10943 (epoch 65.497) train_loss=163.00498962 time/batch=0.44s
7965/10943 (epoch 65.505) train_loss=562.92053223 time/batch=1.37s
7966/10943 (epoch 65.513) train_loss=217.22625732 time/batch=0.63s
7967/10943 (epoch 65.521) train_loss=474.97869873 time/batch=1.19s
7968/10943 (epoch 65.530) train_loss=232.32283020 time/batch=0.66s
7969/10943 (epoch 65.538) train_loss=263.63110352 time/batch=0.66s
7970/10943 (epoch 65.546) train_loss=136.78619385 time/batch=0.38s
7971/10943 (epoch 65.554) train_loss=215.83897400 time/batch=0.53s
7972/10943 (epoch 65.563) train_loss=250.35717773 time/batch=0.62s
7973/10943 (epoch 65.571) train_loss=158.52763367 time/batch=0.41s
7974/10943 (epoch 65.579) train_loss=192.08453369 time/batch=0.47s
7975/10943 (epoch 65.587) train_loss=285.25485229 time/batch=0.72s
7976/10943 (epoch 65.595) train_loss=275.36898804 time/batch=0.70s
7977/10943 (epoch 65.604) train_loss=226.21643066 time/batch=0.60s
7978/10943 (epoch 65.612) train_loss=214.21817017 time/batch=0.56s
7979/10943 (epoch 65.620) train_loss=288.02005005 time/batch=0.68s
7980/10943 (epoch 65.628) train_loss=351.96911621 time/batch=0.86s
7981/10943 (epoch 65.637) train_loss=195.88928223 time/batch=0.56s
7982/10943 (epoch 65.645) train_loss=285.47723389 time/batch=0.67s
7983/10943 (epoch 65.653) train_loss=203.88104248 time/batch=0.53s
7984/10943 (epoch 65.661) train_loss=201.32456970 time/batch=0.49s
7985/10943 (epoch 65.669) train_loss=294.42742920 time/batch=0.72s
7986/10943 (epoch 65.678) train_loss=237.09228516 time/batch=0.61s
7987/10943 (epoch 65.686) train_loss=387.51885986 time/batch=0.91s
7988/10943 (epoch 65.694) train_loss=183.02616882 time/batch=0.51s
7989/10943 (epoch 65.702) train_loss=242.66458130 time/batch=0.58s
7990/10943 (epoch 65.711) train_loss=255.10678101 time/batch=0.62s
7991/10943 (epoch 65.719) train_loss=191.01382446 time/batch=0.49s
7992/10943 (epoch 65.727) train_loss=393.14007568 time/batch=0.95s
7993/10943 (epoch 65.735) train_loss=302.85327148 time/batch=0.82s
7994/10943 (epoch 65.744) train_loss=298.52020264 time/batch=0.79s
7995/10943 (epoch 65.752) train_loss=161.21145630 time/batch=0.47s
7996/10943 (epoch 65.760) train_loss=252.43127441 time/batch=0.62s
7997/10943 (epoch 65.768) train_loss=185.31796265 time/batch=0.50s
7998/10943 (epoch 65.776) train_loss=134.81747437 time/batch=0.36s
7999/10943 (epoch 65.785) train_loss=267.76831055 time/batch=0.64s
Validating
    loss:	276.413439

8000/10943 (epoch 65.793) train_loss=239.91473389 time/batch=2.44s
8001/10943 (epoch 65.801) train_loss=395.76831055 time/batch=0.97s
8002/10943 (epoch 65.809) train_loss=156.51031494 time/batch=0.44s
8003/10943 (epoch 65.818) train_loss=229.92709351 time/batch=0.56s
8004/10943 (epoch 65.826) train_loss=211.06698608 time/batch=0.54s
8005/10943 (epoch 65.834) train_loss=177.65802002 time/batch=0.53s
8006/10943 (epoch 65.842) train_loss=265.73492432 time/batch=0.66s
8007/10943 (epoch 65.850) train_loss=196.47558594 time/batch=0.54s
8008/10943 (epoch 65.859) train_loss=270.47042847 time/batch=0.63s
8009/10943 (epoch 65.867) train_loss=276.92419434 time/batch=0.66s
8010/10943 (epoch 65.875) train_loss=296.10107422 time/batch=0.73s
8011/10943 (epoch 65.883) train_loss=196.33822632 time/batch=0.59s
8012/10943 (epoch 65.892) train_loss=238.68301392 time/batch=0.63s
8013/10943 (epoch 65.900) train_loss=390.71240234 time/batch=0.93s
8014/10943 (epoch 65.908) train_loss=310.80950928 time/batch=0.82s
8015/10943 (epoch 65.916) train_loss=310.48379517 time/batch=0.76s
8016/10943 (epoch 65.924) train_loss=338.26208496 time/batch=0.83s
8017/10943 (epoch 65.933) train_loss=272.38195801 time/batch=0.76s
8018/10943 (epoch 65.941) train_loss=327.85565186 time/batch=0.81s
8019/10943 (epoch 65.949) train_loss=220.72560120 time/batch=0.62s
8020/10943 (epoch 65.957) train_loss=372.44091797 time/batch=0.91s
8021/10943 (epoch 65.966) train_loss=332.85729980 time/batch=0.84s
8022/10943 (epoch 65.974) train_loss=289.23138428 time/batch=0.82s
setting learning rate to 0.0029100
  saved to metadata/gru_dropout-9_nov_folkwiki-20181207-173447_epoch21.pkl
8023/10943 (epoch 65.982) train_loss=299.75399780 time/batch=0.85s
8024/10943 (epoch 65.990) train_loss=304.11370850 time/batch=0.80s
8025/10943 (epoch 65.998) train_loss=737.27874756 time/batch=1.74s
8026/10943 (epoch 66.007) train_loss=173.80702209 time/batch=0.58s
8027/10943 (epoch 66.015) train_loss=198.35472107 time/batch=0.50s
8028/10943 (epoch 66.023) train_loss=219.21835327 time/batch=0.53s
8029/10943 (epoch 66.031) train_loss=426.21380615 time/batch=0.96s
8030/10943 (epoch 66.040) train_loss=230.51062012 time/batch=0.63s
8031/10943 (epoch 66.048) train_loss=466.10284424 time/batch=1.11s
8032/10943 (epoch 66.056) train_loss=187.73451233 time/batch=0.55s
8033/10943 (epoch 66.064) train_loss=912.08190918 time/batch=3.02s
8034/10943 (epoch 66.072) train_loss=446.45391846 time/batch=1.27s
8035/10943 (epoch 66.081) train_loss=434.37841797 time/batch=1.04s
8036/10943 (epoch 66.089) train_loss=251.90364075 time/batch=0.67s
8037/10943 (epoch 66.097) train_loss=560.76770020 time/batch=1.34s
8038/10943 (epoch 66.105) train_loss=438.31951904 time/batch=1.14s
8039/10943 (epoch 66.114) train_loss=588.46246338 time/batch=1.50s
8040/10943 (epoch 66.122) train_loss=192.70094299 time/batch=0.60s
8041/10943 (epoch 66.130) train_loss=159.06201172 time/batch=0.40s
8042/10943 (epoch 66.138) train_loss=546.77520752 time/batch=1.22s
8043/10943 (epoch 66.146) train_loss=311.30966187 time/batch=0.82s
8044/10943 (epoch 66.155) train_loss=495.19961548 time/batch=1.28s
8045/10943 (epoch 66.163) train_loss=337.94006348 time/batch=0.92s
8046/10943 (epoch 66.171) train_loss=173.29028320 time/batch=0.47s
8047/10943 (epoch 66.179) train_loss=369.17425537 time/batch=0.88s
8048/10943 (epoch 66.188) train_loss=235.33459473 time/batch=0.65s
8049/10943 (epoch 66.196) train_loss=301.58441162 time/batch=0.78s
8050/10943 (epoch 66.204) train_loss=153.27194214 time/batch=0.44s
8051/10943 (epoch 66.212) train_loss=613.90173340 time/batch=1.48s
8052/10943 (epoch 66.221) train_loss=217.23159790 time/batch=0.67s
8053/10943 (epoch 66.229) train_loss=310.11584473 time/batch=0.77s
8054/10943 (epoch 66.237) train_loss=479.78500366 time/batch=1.17s
8055/10943 (epoch 66.245) train_loss=445.94610596 time/batch=1.14s
8056/10943 (epoch 66.253) train_loss=390.53295898 time/batch=1.01s
8057/10943 (epoch 66.262) train_loss=388.01303101 time/batch=0.95s
8058/10943 (epoch 66.270) train_loss=258.69595337 time/batch=0.66s
8059/10943 (epoch 66.278) train_loss=292.89190674 time/batch=0.73s
8060/10943 (epoch 66.286) train_loss=148.13397217 time/batch=0.40s
8061/10943 (epoch 66.295) train_loss=140.12789917 time/batch=0.35s
8062/10943 (epoch 66.303) train_loss=512.30993652 time/batch=1.15s
8063/10943 (epoch 66.311) train_loss=228.47839355 time/batch=0.64s
8064/10943 (epoch 66.319) train_loss=141.81028748 time/batch=0.38s
8065/10943 (epoch 66.327) train_loss=265.54214478 time/batch=0.63s
8066/10943 (epoch 66.336) train_loss=116.02043152 time/batch=0.33s
8067/10943 (epoch 66.344) train_loss=110.67583466 time/batch=0.29s
8068/10943 (epoch 66.352) train_loss=230.09466553 time/batch=0.56s
8069/10943 (epoch 66.360) train_loss=287.95242310 time/batch=0.70s
8070/10943 (epoch 66.369) train_loss=267.77679443 time/batch=0.67s
8071/10943 (epoch 66.377) train_loss=283.77764893 time/batch=0.74s
8072/10943 (epoch 66.385) train_loss=128.60334778 time/batch=0.36s
8073/10943 (epoch 66.393) train_loss=98.69279480 time/batch=0.27s
8074/10943 (epoch 66.401) train_loss=203.91230774 time/batch=0.51s
8075/10943 (epoch 66.410) train_loss=450.58224487 time/batch=1.04s
8076/10943 (epoch 66.418) train_loss=112.17616272 time/batch=0.37s
8077/10943 (epoch 66.426) train_loss=277.50137329 time/batch=0.63s
8078/10943 (epoch 66.434) train_loss=439.25820923 time/batch=1.06s
8079/10943 (epoch 66.443) train_loss=273.78686523 time/batch=0.74s
8080/10943 (epoch 66.451) train_loss=297.24362183 time/batch=0.75s
8081/10943 (epoch 66.459) train_loss=192.44244385 time/batch=0.51s
8082/10943 (epoch 66.467) train_loss=403.61041260 time/batch=0.97s
8083/10943 (epoch 66.475) train_loss=291.42074585 time/batch=0.75s
8084/10943 (epoch 66.484) train_loss=199.30722046 time/batch=0.55s
8085/10943 (epoch 66.492) train_loss=133.29837036 time/batch=0.34s
8086/10943 (epoch 66.500) train_loss=243.20150757 time/batch=0.59s
8087/10943 (epoch 66.508) train_loss=266.42864990 time/batch=0.68s
8088/10943 (epoch 66.517) train_loss=338.92993164 time/batch=0.83s
8089/10943 (epoch 66.525) train_loss=203.91609192 time/batch=0.57s
8090/10943 (epoch 66.533) train_loss=158.28585815 time/batch=0.42s
8091/10943 (epoch 66.541) train_loss=206.23452759 time/batch=0.48s
8092/10943 (epoch 66.549) train_loss=310.39703369 time/batch=0.75s
8093/10943 (epoch 66.558) train_loss=363.17218018 time/batch=0.91s
8094/10943 (epoch 66.566) train_loss=151.08630371 time/batch=0.46s
8095/10943 (epoch 66.574) train_loss=121.47277069 time/batch=0.31s
8096/10943 (epoch 66.582) train_loss=224.31881714 time/batch=0.54s
8097/10943 (epoch 66.591) train_loss=356.16305542 time/batch=0.86s
8098/10943 (epoch 66.599) train_loss=153.44570923 time/batch=0.46s
8099/10943 (epoch 66.607) train_loss=394.44641113 time/batch=0.91s
8100/10943 (epoch 66.615) train_loss=192.79681396 time/batch=0.55s
8101/10943 (epoch 66.623) train_loss=270.71112061 time/batch=0.66s
8102/10943 (epoch 66.632) train_loss=190.12661743 time/batch=0.47s
8103/10943 (epoch 66.640) train_loss=215.48641968 time/batch=0.54s
8104/10943 (epoch 66.648) train_loss=333.97515869 time/batch=0.80s
8105/10943 (epoch 66.656) train_loss=233.79101562 time/batch=0.63s
8106/10943 (epoch 66.665) train_loss=174.25299072 time/batch=0.45s
8107/10943 (epoch 66.673) train_loss=197.32292175 time/batch=0.49s
8108/10943 (epoch 66.681) train_loss=316.63949585 time/batch=0.78s
8109/10943 (epoch 66.689) train_loss=341.90185547 time/batch=0.87s
8110/10943 (epoch 66.698) train_loss=423.95202637 time/batch=1.12s
8111/10943 (epoch 66.706) train_loss=321.71911621 time/batch=0.81s
8112/10943 (epoch 66.714) train_loss=137.27508545 time/batch=0.38s
8113/10943 (epoch 66.722) train_loss=294.98529053 time/batch=0.68s
8114/10943 (epoch 66.730) train_loss=171.16940308 time/batch=0.49s
8115/10943 (epoch 66.739) train_loss=208.45657349 time/batch=0.52s
8116/10943 (epoch 66.747) train_loss=313.33877563 time/batch=0.77s
8117/10943 (epoch 66.755) train_loss=177.93730164 time/batch=0.50s
8118/10943 (epoch 66.763) train_loss=156.78591919 time/batch=0.56s
8119/10943 (epoch 66.772) train_loss=284.54281616 time/batch=0.69s
8120/10943 (epoch 66.780) train_loss=254.34962463 time/batch=0.65s
8121/10943 (epoch 66.788) train_loss=236.56652832 time/batch=0.58s
8122/10943 (epoch 66.796) train_loss=347.83288574 time/batch=0.83s
8123/10943 (epoch 66.804) train_loss=264.33447266 time/batch=0.67s
8124/10943 (epoch 66.813) train_loss=372.27020264 time/batch=0.93s
8125/10943 (epoch 66.821) train_loss=239.75679016 time/batch=0.65s
8126/10943 (epoch 66.829) train_loss=293.44766235 time/batch=0.69s
8127/10943 (epoch 66.837) train_loss=360.16561890 time/batch=0.89s
8128/10943 (epoch 66.846) train_loss=336.14007568 time/batch=0.85s
8129/10943 (epoch 66.854) train_loss=238.47770691 time/batch=0.63s
8130/10943 (epoch 66.862) train_loss=215.06546021 time/batch=0.58s
8131/10943 (epoch 66.870) train_loss=324.29620361 time/batch=0.80s
8132/10943 (epoch 66.878) train_loss=244.84059143 time/batch=0.62s
8133/10943 (epoch 66.887) train_loss=235.28033447 time/batch=0.62s
8134/10943 (epoch 66.895) train_loss=254.15487671 time/batch=0.63s
8135/10943 (epoch 66.903) train_loss=328.81253052 time/batch=0.83s
8136/10943 (epoch 66.911) train_loss=349.10171509 time/batch=0.88s
8137/10943 (epoch 66.920) train_loss=268.95794678 time/batch=0.72s
8138/10943 (epoch 66.928) train_loss=235.60472107 time/batch=0.67s
8139/10943 (epoch 66.936) train_loss=363.76879883 time/batch=0.87s
8140/10943 (epoch 66.944) train_loss=299.13650513 time/batch=0.79s
8141/10943 (epoch 66.952) train_loss=273.67504883 time/batch=0.70s
8142/10943 (epoch 66.961) train_loss=302.50494385 time/batch=0.77s
8143/10943 (epoch 66.969) train_loss=271.73339844 time/batch=0.72s
setting learning rate to 0.0028227
8144/10943 (epoch 66.977) train_loss=379.54107666 time/batch=0.95s
8145/10943 (epoch 66.985) train_loss=697.21203613 time/batch=1.63s
8146/10943 (epoch 66.994) train_loss=225.41223145 time/batch=0.66s
8147/10943 (epoch 67.002) train_loss=373.46472168 time/batch=0.89s
8148/10943 (epoch 67.010) train_loss=560.85180664 time/batch=1.36s
8149/10943 (epoch 67.018) train_loss=312.03265381 time/batch=0.88s
8150/10943 (epoch 67.026) train_loss=391.22497559 time/batch=0.98s
8151/10943 (epoch 67.035) train_loss=455.43273926 time/batch=1.13s
8152/10943 (epoch 67.043) train_loss=572.46002197 time/batch=1.46s
8153/10943 (epoch 67.051) train_loss=500.96386719 time/batch=1.25s
8154/10943 (epoch 67.059) train_loss=638.74548340 time/batch=1.70s
8155/10943 (epoch 67.068) train_loss=458.98632812 time/batch=1.19s
8156/10943 (epoch 67.076) train_loss=399.69763184 time/batch=0.99s
8157/10943 (epoch 67.084) train_loss=934.21984863 time/batch=3.09s
8158/10943 (epoch 67.092) train_loss=572.66754150 time/batch=1.90s
8159/10943 (epoch 67.100) train_loss=195.00982666 time/batch=0.64s
8160/10943 (epoch 67.109) train_loss=339.26519775 time/batch=0.80s
8161/10943 (epoch 67.117) train_loss=411.73431396 time/batch=1.04s
8162/10943 (epoch 67.125) train_loss=131.12062073 time/batch=0.39s
8163/10943 (epoch 67.133) train_loss=197.79048157 time/batch=0.48s
8164/10943 (epoch 67.142) train_loss=149.98585510 time/batch=0.38s
8165/10943 (epoch 67.150) train_loss=427.36840820 time/batch=0.93s
8166/10943 (epoch 67.158) train_loss=294.17718506 time/batch=0.76s
8167/10943 (epoch 67.166) train_loss=285.08178711 time/batch=0.74s
8168/10943 (epoch 67.175) train_loss=202.23867798 time/batch=0.53s
8169/10943 (epoch 67.183) train_loss=490.11315918 time/batch=1.17s
8170/10943 (epoch 67.191) train_loss=270.97329712 time/batch=0.72s
8171/10943 (epoch 67.199) train_loss=155.55166626 time/batch=0.43s
8172/10943 (epoch 67.207) train_loss=302.98132324 time/batch=0.75s
8173/10943 (epoch 67.216) train_loss=112.45599365 time/batch=0.34s
8174/10943 (epoch 67.224) train_loss=200.05050659 time/batch=0.48s
8175/10943 (epoch 67.232) train_loss=145.24008179 time/batch=0.38s
8176/10943 (epoch 67.240) train_loss=488.05926514 time/batch=1.18s
8177/10943 (epoch 67.249) train_loss=433.78631592 time/batch=1.12s
8178/10943 (epoch 67.257) train_loss=98.98622131 time/batch=0.33s
8179/10943 (epoch 67.265) train_loss=441.65637207 time/batch=0.98s
8180/10943 (epoch 67.273) train_loss=369.51318359 time/batch=0.91s
8181/10943 (epoch 67.281) train_loss=363.57546997 time/batch=0.92s
8182/10943 (epoch 67.290) train_loss=453.31903076 time/batch=1.15s
8183/10943 (epoch 67.298) train_loss=162.11584473 time/batch=0.49s
8184/10943 (epoch 67.306) train_loss=215.90301514 time/batch=0.51s
8185/10943 (epoch 67.314) train_loss=139.54438782 time/batch=0.36s
8186/10943 (epoch 67.323) train_loss=179.38429260 time/batch=0.46s
8187/10943 (epoch 67.331) train_loss=215.93357849 time/batch=0.54s
8188/10943 (epoch 67.339) train_loss=210.86019897 time/batch=0.57s
8189/10943 (epoch 67.347) train_loss=170.73153687 time/batch=0.42s
8190/10943 (epoch 67.355) train_loss=453.14318848 time/batch=1.05s
8191/10943 (epoch 67.364) train_loss=336.71478271 time/batch=0.88s
8192/10943 (epoch 67.372) train_loss=300.68383789 time/batch=0.78s
8193/10943 (epoch 67.380) train_loss=259.17718506 time/batch=0.70s
8194/10943 (epoch 67.388) train_loss=142.67648315 time/batch=0.41s
8195/10943 (epoch 67.397) train_loss=224.46353149 time/batch=0.55s
8196/10943 (epoch 67.405) train_loss=393.70208740 time/batch=0.97s
8197/10943 (epoch 67.413) train_loss=168.64923096 time/batch=0.50s
8198/10943 (epoch 67.421) train_loss=310.44134521 time/batch=0.73s
8199/10943 (epoch 67.429) train_loss=226.90132141 time/batch=0.61s
8200/10943 (epoch 67.438) train_loss=131.91900635 time/batch=0.35s
8201/10943 (epoch 67.446) train_loss=410.58087158 time/batch=0.95s
8202/10943 (epoch 67.454) train_loss=201.64663696 time/batch=0.59s
8203/10943 (epoch 67.462) train_loss=361.06213379 time/batch=0.86s
8204/10943 (epoch 67.471) train_loss=349.12207031 time/batch=0.88s
8205/10943 (epoch 67.479) train_loss=119.88936615 time/batch=0.35s
8206/10943 (epoch 67.487) train_loss=195.57962036 time/batch=0.52s
8207/10943 (epoch 67.495) train_loss=269.93292236 time/batch=0.68s
8208/10943 (epoch 67.503) train_loss=317.45809937 time/batch=0.80s
8209/10943 (epoch 67.512) train_loss=145.62652588 time/batch=0.38s
8210/10943 (epoch 67.520) train_loss=285.70245361 time/batch=0.67s
8211/10943 (epoch 67.528) train_loss=120.28249359 time/batch=0.36s
8212/10943 (epoch 67.536) train_loss=334.98919678 time/batch=0.77s
8213/10943 (epoch 67.545) train_loss=272.25842285 time/batch=0.68s
8214/10943 (epoch 67.553) train_loss=325.11578369 time/batch=0.81s
8215/10943 (epoch 67.561) train_loss=186.75788879 time/batch=0.51s
8216/10943 (epoch 67.569) train_loss=265.17358398 time/batch=0.64s
8217/10943 (epoch 67.577) train_loss=263.68807983 time/batch=0.67s
8218/10943 (epoch 67.586) train_loss=303.41928101 time/batch=0.76s
8219/10943 (epoch 67.594) train_loss=309.64047241 time/batch=0.79s
8220/10943 (epoch 67.602) train_loss=330.85998535 time/batch=0.86s
8221/10943 (epoch 67.610) train_loss=361.94357300 time/batch=0.94s
8222/10943 (epoch 67.619) train_loss=353.68121338 time/batch=0.91s
8223/10943 (epoch 67.627) train_loss=267.82260132 time/batch=0.70s
8224/10943 (epoch 67.635) train_loss=265.33489990 time/batch=0.66s
8225/10943 (epoch 67.643) train_loss=310.00561523 time/batch=0.80s
8226/10943 (epoch 67.652) train_loss=300.09896851 time/batch=0.79s
8227/10943 (epoch 67.660) train_loss=342.80047607 time/batch=0.88s
8228/10943 (epoch 67.668) train_loss=290.96798706 time/batch=0.76s
8229/10943 (epoch 67.676) train_loss=225.69216919 time/batch=0.61s
8230/10943 (epoch 67.684) train_loss=223.33197021 time/batch=0.56s
8231/10943 (epoch 67.693) train_loss=196.87292480 time/batch=0.48s
8232/10943 (epoch 67.701) train_loss=114.72467041 time/batch=0.31s
8233/10943 (epoch 67.709) train_loss=284.33581543 time/batch=0.66s
8234/10943 (epoch 67.717) train_loss=220.85189819 time/batch=0.58s
8235/10943 (epoch 67.726) train_loss=277.97814941 time/batch=0.68s
8236/10943 (epoch 67.734) train_loss=305.09509277 time/batch=0.79s
8237/10943 (epoch 67.742) train_loss=232.35195923 time/batch=0.59s
8238/10943 (epoch 67.750) train_loss=228.15829468 time/batch=0.59s
8239/10943 (epoch 67.758) train_loss=238.44923401 time/batch=0.61s
8240/10943 (epoch 67.767) train_loss=296.85345459 time/batch=0.70s
8241/10943 (epoch 67.775) train_loss=318.84558105 time/batch=0.82s
8242/10943 (epoch 67.783) train_loss=195.39753723 time/batch=0.52s
8243/10943 (epoch 67.791) train_loss=195.82421875 time/batch=0.58s
8244/10943 (epoch 67.800) train_loss=247.57012939 time/batch=0.62s
8245/10943 (epoch 67.808) train_loss=159.33963013 time/batch=0.45s
8246/10943 (epoch 67.816) train_loss=288.18771362 time/batch=0.69s
8247/10943 (epoch 67.824) train_loss=308.42193604 time/batch=0.84s
8248/10943 (epoch 67.832) train_loss=259.11911011 time/batch=0.66s
8249/10943 (epoch 67.841) train_loss=172.33834839 time/batch=0.46s
8250/10943 (epoch 67.849) train_loss=172.00942993 time/batch=0.45s
8251/10943 (epoch 67.857) train_loss=234.58580017 time/batch=0.57s
8252/10943 (epoch 67.865) train_loss=126.59558105 time/batch=0.40s
8253/10943 (epoch 67.874) train_loss=155.19717407 time/batch=0.42s
8254/10943 (epoch 67.882) train_loss=324.98724365 time/batch=0.80s
8255/10943 (epoch 67.890) train_loss=302.83557129 time/batch=0.76s
8256/10943 (epoch 67.898) train_loss=253.08010864 time/batch=0.63s
8257/10943 (epoch 67.906) train_loss=236.00164795 time/batch=0.62s
8258/10943 (epoch 67.915) train_loss=236.51049805 time/batch=0.62s
8259/10943 (epoch 67.923) train_loss=258.60668945 time/batch=0.66s
8260/10943 (epoch 67.931) train_loss=233.81628418 time/batch=0.60s
8261/10943 (epoch 67.939) train_loss=189.45245361 time/batch=0.59s
8262/10943 (epoch 67.948) train_loss=237.11764526 time/batch=0.62s
8263/10943 (epoch 67.956) train_loss=276.69921875 time/batch=0.71s
8264/10943 (epoch 67.964) train_loss=251.12887573 time/batch=0.65s
setting learning rate to 0.0027380
  saved to metadata/gru_dropout-9_nov_folkwiki-20181207-173447_epoch23.pkl
8265/10943 (epoch 67.972) train_loss=408.65481567 time/batch=1.03s
8266/10943 (epoch 67.980) train_loss=564.84008789 time/batch=1.30s
8267/10943 (epoch 67.989) train_loss=216.50225830 time/batch=0.63s
8268/10943 (epoch 67.997) train_loss=102.72022247 time/batch=0.29s
8269/10943 (epoch 68.005) train_loss=768.83715820 time/batch=1.80s
8270/10943 (epoch 68.013) train_loss=310.86346436 time/batch=0.91s
8271/10943 (epoch 68.022) train_loss=258.20727539 time/batch=0.64s
8272/10943 (epoch 68.030) train_loss=228.81022644 time/batch=0.60s
8273/10943 (epoch 68.038) train_loss=297.13211060 time/batch=0.79s
8274/10943 (epoch 68.046) train_loss=531.28649902 time/batch=1.29s
8275/10943 (epoch 68.054) train_loss=413.73828125 time/batch=1.05s
8276/10943 (epoch 68.063) train_loss=158.19934082 time/batch=0.45s
8277/10943 (epoch 68.071) train_loss=211.85478210 time/batch=0.52s
8278/10943 (epoch 68.079) train_loss=209.58065796 time/batch=0.53s
8279/10943 (epoch 68.087) train_loss=874.61193848 time/batch=3.02s
8280/10943 (epoch 68.096) train_loss=522.07336426 time/batch=1.46s
8281/10943 (epoch 68.104) train_loss=478.56091309 time/batch=1.22s
8282/10943 (epoch 68.112) train_loss=622.91870117 time/batch=1.58s
8283/10943 (epoch 68.120) train_loss=474.31655884 time/batch=1.17s
8284/10943 (epoch 68.129) train_loss=232.98596191 time/batch=0.64s
8285/10943 (epoch 68.137) train_loss=134.45602417 time/batch=0.36s
8286/10943 (epoch 68.145) train_loss=507.45587158 time/batch=1.27s
8287/10943 (epoch 68.153) train_loss=389.20812988 time/batch=0.99s
8288/10943 (epoch 68.161) train_loss=396.49896240 time/batch=0.96s
8289/10943 (epoch 68.170) train_loss=253.92175293 time/batch=0.69s
8290/10943 (epoch 68.178) train_loss=120.11795044 time/batch=0.32s
8291/10943 (epoch 68.186) train_loss=296.50036621 time/batch=0.72s
8292/10943 (epoch 68.194) train_loss=430.33093262 time/batch=1.02s
8293/10943 (epoch 68.203) train_loss=377.99847412 time/batch=0.98s
8294/10943 (epoch 68.211) train_loss=465.43350220 time/batch=1.35s
8295/10943 (epoch 68.219) train_loss=434.46325684 time/batch=1.07s
8296/10943 (epoch 68.227) train_loss=342.37127686 time/batch=0.87s
8297/10943 (epoch 68.235) train_loss=123.55744934 time/batch=0.36s
8298/10943 (epoch 68.244) train_loss=293.89398193 time/batch=0.71s
8299/10943 (epoch 68.252) train_loss=291.79302979 time/batch=0.76s
8300/10943 (epoch 68.260) train_loss=433.83068848 time/batch=1.07s
8301/10943 (epoch 68.268) train_loss=341.23498535 time/batch=0.90s
8302/10943 (epoch 68.277) train_loss=221.32000732 time/batch=0.61s
8303/10943 (epoch 68.285) train_loss=157.76445007 time/batch=0.42s
8304/10943 (epoch 68.293) train_loss=431.16027832 time/batch=1.05s
8305/10943 (epoch 68.301) train_loss=116.29681396 time/batch=0.39s
8306/10943 (epoch 68.309) train_loss=384.71014404 time/batch=0.93s
8307/10943 (epoch 68.318) train_loss=208.98728943 time/batch=0.58s
8308/10943 (epoch 68.326) train_loss=328.46359253 time/batch=0.79s
8309/10943 (epoch 68.334) train_loss=147.86511230 time/batch=0.40s
8310/10943 (epoch 68.342) train_loss=354.66699219 time/batch=0.88s
8311/10943 (epoch 68.351) train_loss=149.10537720 time/batch=0.43s
8312/10943 (epoch 68.359) train_loss=193.11053467 time/batch=0.47s
8313/10943 (epoch 68.367) train_loss=98.07530212 time/batch=0.29s
8314/10943 (epoch 68.375) train_loss=179.71691895 time/batch=0.44s
8315/10943 (epoch 68.383) train_loss=260.40521240 time/batch=0.65s
8316/10943 (epoch 68.392) train_loss=533.16540527 time/batch=1.37s
8317/10943 (epoch 68.400) train_loss=444.29351807 time/batch=1.17s
8318/10943 (epoch 68.408) train_loss=267.84848022 time/batch=0.73s
8319/10943 (epoch 68.416) train_loss=330.79541016 time/batch=0.84s
8320/10943 (epoch 68.425) train_loss=127.17141724 time/batch=0.37s
8321/10943 (epoch 68.433) train_loss=298.02099609 time/batch=0.74s
8322/10943 (epoch 68.441) train_loss=169.04345703 time/batch=0.47s
8323/10943 (epoch 68.449) train_loss=273.40130615 time/batch=0.66s
8324/10943 (epoch 68.457) train_loss=291.48852539 time/batch=0.72s
8325/10943 (epoch 68.466) train_loss=354.79077148 time/batch=0.87s
8326/10943 (epoch 68.474) train_loss=308.55160522 time/batch=0.82s
8327/10943 (epoch 68.482) train_loss=354.98760986 time/batch=0.91s
8328/10943 (epoch 68.490) train_loss=269.74029541 time/batch=0.73s
8329/10943 (epoch 68.499) train_loss=308.33251953 time/batch=0.79s
8330/10943 (epoch 68.507) train_loss=290.31298828 time/batch=0.72s
8331/10943 (epoch 68.515) train_loss=187.87585449 time/batch=0.51s
8332/10943 (epoch 68.523) train_loss=149.39074707 time/batch=0.38s
8333/10943 (epoch 68.531) train_loss=189.99316406 time/batch=0.50s
8334/10943 (epoch 68.540) train_loss=169.55168152 time/batch=0.45s
8335/10943 (epoch 68.548) train_loss=402.78070068 time/batch=1.36s
8336/10943 (epoch 68.556) train_loss=325.67993164 time/batch=0.88s
8337/10943 (epoch 68.564) train_loss=355.22875977 time/batch=0.89s
8338/10943 (epoch 68.573) train_loss=263.32366943 time/batch=0.68s
8339/10943 (epoch 68.581) train_loss=304.17208862 time/batch=0.76s
8340/10943 (epoch 68.589) train_loss=259.37487793 time/batch=0.67s
8341/10943 (epoch 68.597) train_loss=168.20043945 time/batch=0.45s
8342/10943 (epoch 68.605) train_loss=143.77236938 time/batch=0.38s
8343/10943 (epoch 68.614) train_loss=128.53656006 time/batch=0.33s
8344/10943 (epoch 68.622) train_loss=231.16607666 time/batch=0.54s
8345/10943 (epoch 68.630) train_loss=289.77343750 time/batch=0.69s
8346/10943 (epoch 68.638) train_loss=329.89776611 time/batch=0.84s
8347/10943 (epoch 68.647) train_loss=280.54516602 time/batch=0.74s
8348/10943 (epoch 68.655) train_loss=183.13641357 time/batch=0.48s
8349/10943 (epoch 68.663) train_loss=133.41375732 time/batch=0.36s
8350/10943 (epoch 68.671) train_loss=166.21929932 time/batch=0.43s
8351/10943 (epoch 68.680) train_loss=255.39024353 time/batch=0.66s
8352/10943 (epoch 68.688) train_loss=191.33825684 time/batch=0.53s
8353/10943 (epoch 68.696) train_loss=153.05879211 time/batch=0.45s
8354/10943 (epoch 68.704) train_loss=307.87817383 time/batch=0.77s
8355/10943 (epoch 68.712) train_loss=244.30805969 time/batch=0.66s
8356/10943 (epoch 68.721) train_loss=361.93109131 time/batch=0.88s
8357/10943 (epoch 68.729) train_loss=311.63003540 time/batch=0.80s
8358/10943 (epoch 68.737) train_loss=224.61746216 time/batch=0.60s
8359/10943 (epoch 68.745) train_loss=229.89532471 time/batch=0.60s
8360/10943 (epoch 68.754) train_loss=227.79379272 time/batch=0.58s
8361/10943 (epoch 68.762) train_loss=164.32531738 time/batch=0.47s
8362/10943 (epoch 68.770) train_loss=222.15466309 time/batch=0.55s
8363/10943 (epoch 68.778) train_loss=219.41859436 time/batch=0.57s
8364/10943 (epoch 68.786) train_loss=298.67724609 time/batch=0.72s
8365/10943 (epoch 68.795) train_loss=383.73410034 time/batch=1.41s
8366/10943 (epoch 68.803) train_loss=203.14517212 time/batch=0.60s
8367/10943 (epoch 68.811) train_loss=191.22949219 time/batch=0.48s
8368/10943 (epoch 68.819) train_loss=239.12667847 time/batch=0.58s
8369/10943 (epoch 68.828) train_loss=181.20904541 time/batch=0.50s
8370/10943 (epoch 68.836) train_loss=239.02093506 time/batch=0.61s
8371/10943 (epoch 68.844) train_loss=308.21911621 time/batch=0.76s
8372/10943 (epoch 68.852) train_loss=207.20677185 time/batch=0.54s
8373/10943 (epoch 68.860) train_loss=208.57878113 time/batch=0.57s
8374/10943 (epoch 68.869) train_loss=256.49774170 time/batch=0.64s
8375/10943 (epoch 68.877) train_loss=294.47549438 time/batch=0.73s
8376/10943 (epoch 68.885) train_loss=258.11596680 time/batch=0.66s
8377/10943 (epoch 68.893) train_loss=276.81219482 time/batch=0.66s
8378/10943 (epoch 68.902) train_loss=272.77926636 time/batch=0.70s
8379/10943 (epoch 68.910) train_loss=282.22210693 time/batch=0.70s
8380/10943 (epoch 68.918) train_loss=230.20428467 time/batch=0.62s
8381/10943 (epoch 68.926) train_loss=226.36602783 time/batch=0.60s
8382/10943 (epoch 68.934) train_loss=333.53204346 time/batch=0.83s
8383/10943 (epoch 68.943) train_loss=254.00498962 time/batch=0.74s
8384/10943 (epoch 68.951) train_loss=322.97985840 time/batch=0.82s
8385/10943 (epoch 68.959) train_loss=285.52725220 time/batch=0.80s
setting learning rate to 0.0026559
8386/10943 (epoch 68.967) train_loss=449.33642578 time/batch=1.10s
8387/10943 (epoch 68.976) train_loss=459.21765137 time/batch=1.11s
8388/10943 (epoch 68.984) train_loss=201.10635376 time/batch=0.55s
8389/10943 (epoch 68.992) train_loss=526.54956055 time/batch=1.22s
8390/10943 (epoch 69.000) train_loss=584.68078613 time/batch=1.53s
8391/10943 (epoch 69.008) train_loss=333.41775513 time/batch=0.94s
8392/10943 (epoch 69.017) train_loss=368.02313232 time/batch=0.89s
8393/10943 (epoch 69.025) train_loss=195.87437439 time/batch=0.56s
8394/10943 (epoch 69.033) train_loss=421.84506226 time/batch=0.98s
8395/10943 (epoch 69.041) train_loss=469.89105225 time/batch=1.18s
8396/10943 (epoch 69.050) train_loss=344.02560425 time/batch=0.90s
8397/10943 (epoch 69.058) train_loss=142.90390015 time/batch=0.40s
8398/10943 (epoch 69.066) train_loss=705.34356689 time/batch=1.62s
8399/10943 (epoch 69.074) train_loss=159.72502136 time/batch=0.56s
8400/10943 (epoch 69.082) train_loss=181.44744873 time/batch=0.45s
8401/10943 (epoch 69.091) train_loss=563.38732910 time/batch=1.26s
8402/10943 (epoch 69.099) train_loss=183.04321289 time/batch=0.54s
8403/10943 (epoch 69.107) train_loss=871.88903809 time/batch=2.31s
8404/10943 (epoch 69.115) train_loss=270.06817627 time/batch=0.85s
8405/10943 (epoch 69.124) train_loss=331.07537842 time/batch=0.81s
8406/10943 (epoch 69.132) train_loss=404.37811279 time/batch=0.99s
8407/10943 (epoch 69.140) train_loss=265.99829102 time/batch=0.70s
8408/10943 (epoch 69.148) train_loss=98.88116455 time/batch=0.30s
8409/10943 (epoch 69.157) train_loss=233.94317627 time/batch=0.56s
8410/10943 (epoch 69.165) train_loss=140.02380371 time/batch=0.38s
8411/10943 (epoch 69.173) train_loss=373.48236084 time/batch=0.89s
8412/10943 (epoch 69.181) train_loss=404.35870361 time/batch=1.05s
8413/10943 (epoch 69.189) train_loss=127.45738220 time/batch=0.40s
8414/10943 (epoch 69.198) train_loss=225.88497925 time/batch=0.58s
8415/10943 (epoch 69.206) train_loss=336.25872803 time/batch=0.87s
8416/10943 (epoch 69.214) train_loss=295.88827515 time/batch=0.81s
8417/10943 (epoch 69.222) train_loss=509.62713623 time/batch=1.33s
8418/10943 (epoch 69.231) train_loss=267.65484619 time/batch=0.76s
8419/10943 (epoch 69.239) train_loss=285.15509033 time/batch=0.73s
8420/10943 (epoch 69.247) train_loss=356.07965088 time/batch=0.90s
8421/10943 (epoch 69.255) train_loss=180.90444946 time/batch=0.51s
8422/10943 (epoch 69.263) train_loss=532.60919189 time/batch=1.31s
8423/10943 (epoch 69.272) train_loss=142.62759399 time/batch=0.46s
8424/10943 (epoch 69.280) train_loss=525.12756348 time/batch=1.43s
8425/10943 (epoch 69.288) train_loss=434.46777344 time/batch=1.11s
8426/10943 (epoch 69.296) train_loss=421.62564087 time/batch=1.06s
8427/10943 (epoch 69.305) train_loss=383.10241699 time/batch=0.99s
8428/10943 (epoch 69.313) train_loss=204.18954468 time/batch=0.54s
8429/10943 (epoch 69.321) train_loss=351.75366211 time/batch=0.86s
8430/10943 (epoch 69.329) train_loss=389.05050659 time/batch=0.98s
8431/10943 (epoch 69.337) train_loss=303.62716675 time/batch=0.79s
8432/10943 (epoch 69.346) train_loss=358.91592407 time/batch=0.91s
8433/10943 (epoch 69.354) train_loss=249.38394165 time/batch=0.66s
8434/10943 (epoch 69.362) train_loss=473.88735962 time/batch=1.48s
8435/10943 (epoch 69.370) train_loss=132.98678589 time/batch=0.45s
8436/10943 (epoch 69.379) train_loss=403.73968506 time/batch=1.00s
8437/10943 (epoch 69.387) train_loss=146.22331238 time/batch=0.46s
8438/10943 (epoch 69.395) train_loss=165.53021240 time/batch=0.43s
8439/10943 (epoch 69.403) train_loss=251.22201538 time/batch=0.61s
8440/10943 (epoch 69.411) train_loss=531.27368164 time/batch=3.05s
8441/10943 (epoch 69.420) train_loss=240.37374878 time/batch=0.89s
8442/10943 (epoch 69.428) train_loss=283.14843750 time/batch=0.71s
8443/10943 (epoch 69.436) train_loss=326.55627441 time/batch=0.81s
8444/10943 (epoch 69.444) train_loss=302.21771240 time/batch=0.81s
8445/10943 (epoch 69.453) train_loss=181.36624146 time/batch=0.51s
8446/10943 (epoch 69.461) train_loss=176.62969971 time/batch=0.47s
8447/10943 (epoch 69.469) train_loss=224.03425598 time/batch=0.57s
8448/10943 (epoch 69.477) train_loss=115.33120728 time/batch=0.33s
8449/10943 (epoch 69.485) train_loss=209.12811279 time/batch=0.52s
8450/10943 (epoch 69.494) train_loss=258.63745117 time/batch=0.66s
8451/10943 (epoch 69.502) train_loss=194.52352905 time/batch=0.53s
8452/10943 (epoch 69.510) train_loss=152.32684326 time/batch=0.38s
8453/10943 (epoch 69.518) train_loss=212.51773071 time/batch=0.53s
8454/10943 (epoch 69.527) train_loss=206.47772217 time/batch=0.53s
8455/10943 (epoch 69.535) train_loss=120.06364441 time/batch=0.32s
8456/10943 (epoch 69.543) train_loss=228.37512207 time/batch=0.53s
8457/10943 (epoch 69.551) train_loss=173.93865967 time/batch=0.48s
8458/10943 (epoch 69.559) train_loss=337.49142456 time/batch=0.82s
8459/10943 (epoch 69.568) train_loss=158.80960083 time/batch=0.46s
8460/10943 (epoch 69.576) train_loss=305.80529785 time/batch=0.74s
8461/10943 (epoch 69.584) train_loss=169.88967896 time/batch=0.46s
8462/10943 (epoch 69.592) train_loss=102.42211151 time/batch=0.28s
8463/10943 (epoch 69.601) train_loss=309.13977051 time/batch=0.74s
8464/10943 (epoch 69.609) train_loss=159.85142517 time/batch=0.46s
8465/10943 (epoch 69.617) train_loss=304.60766602 time/batch=0.75s
8466/10943 (epoch 69.625) train_loss=272.86920166 time/batch=0.71s
8467/10943 (epoch 69.634) train_loss=225.14503479 time/batch=0.59s
8468/10943 (epoch 69.642) train_loss=393.39822388 time/batch=1.03s
8469/10943 (epoch 69.650) train_loss=275.07730103 time/batch=0.74s
8470/10943 (epoch 69.658) train_loss=375.27648926 time/batch=0.92s
8471/10943 (epoch 69.666) train_loss=186.95297241 time/batch=0.53s
8472/10943 (epoch 69.675) train_loss=142.87490845 time/batch=0.38s
8473/10943 (epoch 69.683) train_loss=323.99468994 time/batch=0.80s
8474/10943 (epoch 69.691) train_loss=260.54989624 time/batch=0.67s
8475/10943 (epoch 69.699) train_loss=128.97538757 time/batch=0.43s
8476/10943 (epoch 69.708) train_loss=219.75279236 time/batch=0.52s
8477/10943 (epoch 69.716) train_loss=298.95910645 time/batch=0.74s
8478/10943 (epoch 69.724) train_loss=268.58172607 time/batch=0.71s
8479/10943 (epoch 69.732) train_loss=329.45288086 time/batch=0.88s
8480/10943 (epoch 69.740) train_loss=283.59143066 time/batch=0.76s
8481/10943 (epoch 69.749) train_loss=223.08099365 time/batch=0.61s
8482/10943 (epoch 69.757) train_loss=215.32821655 time/batch=0.57s
8483/10943 (epoch 69.765) train_loss=189.98155212 time/batch=0.52s
8484/10943 (epoch 69.773) train_loss=147.20474243 time/batch=0.49s
8485/10943 (epoch 69.782) train_loss=194.91403198 time/batch=0.50s
8486/10943 (epoch 69.790) train_loss=241.06921387 time/batch=0.61s
8487/10943 (epoch 69.798) train_loss=325.34713745 time/batch=0.80s
8488/10943 (epoch 69.806) train_loss=233.38017273 time/batch=0.63s
8489/10943 (epoch 69.814) train_loss=312.60021973 time/batch=0.77s
8490/10943 (epoch 69.823) train_loss=311.40432739 time/batch=0.82s
8491/10943 (epoch 69.831) train_loss=230.85429382 time/batch=0.63s
8492/10943 (epoch 69.839) train_loss=268.96780396 time/batch=0.65s
8493/10943 (epoch 69.847) train_loss=273.85610962 time/batch=0.72s
8494/10943 (epoch 69.856) train_loss=254.82666016 time/batch=0.65s
8495/10943 (epoch 69.864) train_loss=226.48225403 time/batch=0.59s
8496/10943 (epoch 69.872) train_loss=269.83071899 time/batch=0.65s
8497/10943 (epoch 69.880) train_loss=295.81323242 time/batch=0.73s
8498/10943 (epoch 69.888) train_loss=224.30091858 time/batch=0.63s
8499/10943 (epoch 69.897) train_loss=234.49324036 time/batch=0.66s
8500/10943 (epoch 69.905) train_loss=258.25906372 time/batch=0.67s
8501/10943 (epoch 69.913) train_loss=297.61230469 time/batch=0.78s
8502/10943 (epoch 69.921) train_loss=257.47433472 time/batch=0.69s
8503/10943 (epoch 69.930) train_loss=296.91711426 time/batch=0.73s
8504/10943 (epoch 69.938) train_loss=301.17874146 time/batch=0.80s
8505/10943 (epoch 69.946) train_loss=291.54040527 time/batch=0.71s
8506/10943 (epoch 69.954) train_loss=301.42050171 time/batch=0.81s
setting learning rate to 0.0025762
  saved to metadata/gru_dropout-9_nov_folkwiki-20181207-173447_epoch25.pkl
8507/10943 (epoch 69.962) train_loss=472.35607910 time/batch=1.20s
8508/10943 (epoch 69.971) train_loss=394.82290649 time/batch=0.98s
8509/10943 (epoch 69.979) train_loss=439.43426514 time/batch=1.12s
8510/10943 (epoch 69.987) train_loss=850.14672852 time/batch=2.31s
8511/10943 (epoch 69.995) train_loss=652.83288574 time/batch=1.71s
8512/10943 (epoch 70.004) train_loss=761.19207764 time/batch=3.16s
8513/10943 (epoch 70.012) train_loss=262.96057129 time/batch=0.92s
8514/10943 (epoch 70.020) train_loss=159.45579529 time/batch=0.41s
8515/10943 (epoch 70.028) train_loss=236.73344421 time/batch=0.58s
8516/10943 (epoch 70.036) train_loss=550.72985840 time/batch=1.25s
8517/10943 (epoch 70.045) train_loss=257.85998535 time/batch=0.74s
8518/10943 (epoch 70.053) train_loss=552.40942383 time/batch=1.32s
8519/10943 (epoch 70.061) train_loss=181.90945435 time/batch=0.56s
8520/10943 (epoch 70.069) train_loss=208.10906982 time/batch=0.54s
8521/10943 (epoch 70.078) train_loss=189.75683594 time/batch=0.48s
8522/10943 (epoch 70.086) train_loss=107.08441925 time/batch=0.30s
8523/10943 (epoch 70.094) train_loss=90.98565674 time/batch=0.25s
8524/10943 (epoch 70.102) train_loss=423.25823975 time/batch=0.94s
8525/10943 (epoch 70.111) train_loss=467.76077271 time/batch=1.10s
8526/10943 (epoch 70.119) train_loss=129.08843994 time/batch=0.40s
8527/10943 (epoch 70.127) train_loss=287.71496582 time/batch=0.66s
8528/10943 (epoch 70.135) train_loss=358.27783203 time/batch=0.87s
8529/10943 (epoch 70.143) train_loss=301.86724854 time/batch=0.77s
8530/10943 (epoch 70.152) train_loss=203.45108032 time/batch=0.53s
8531/10943 (epoch 70.160) train_loss=171.44393921 time/batch=0.43s
8532/10943 (epoch 70.168) train_loss=161.45658875 time/batch=0.42s
8533/10943 (epoch 70.176) train_loss=195.37265015 time/batch=0.49s
8534/10943 (epoch 70.185) train_loss=262.21722412 time/batch=0.68s
8535/10943 (epoch 70.193) train_loss=189.60633850 time/batch=0.48s
8536/10943 (epoch 70.201) train_loss=144.24423218 time/batch=0.39s
8537/10943 (epoch 70.209) train_loss=358.41992188 time/batch=0.86s
8538/10943 (epoch 70.217) train_loss=217.01785278 time/batch=0.59s
8539/10943 (epoch 70.226) train_loss=303.28399658 time/batch=0.78s
8540/10943 (epoch 70.234) train_loss=553.89379883 time/batch=1.41s
8541/10943 (epoch 70.242) train_loss=423.79598999 time/batch=1.09s
8542/10943 (epoch 70.250) train_loss=510.14361572 time/batch=1.22s
8543/10943 (epoch 70.259) train_loss=126.01388550 time/batch=0.39s
8544/10943 (epoch 70.267) train_loss=438.10357666 time/batch=1.04s
8545/10943 (epoch 70.275) train_loss=288.14587402 time/batch=0.75s
8546/10943 (epoch 70.283) train_loss=150.34121704 time/batch=0.41s
8547/10943 (epoch 70.291) train_loss=206.33946228 time/batch=0.52s
8548/10943 (epoch 70.300) train_loss=148.17968750 time/batch=0.40s
8549/10943 (epoch 70.308) train_loss=276.76885986 time/batch=0.68s
8550/10943 (epoch 70.316) train_loss=459.71282959 time/batch=1.15s
8551/10943 (epoch 70.324) train_loss=264.55187988 time/batch=0.73s
8552/10943 (epoch 70.333) train_loss=120.84596252 time/batch=0.33s
8553/10943 (epoch 70.341) train_loss=403.45095825 time/batch=0.93s
8554/10943 (epoch 70.349) train_loss=308.53930664 time/batch=0.80s
8555/10943 (epoch 70.357) train_loss=255.86569214 time/batch=0.65s
8556/10943 (epoch 70.365) train_loss=154.37426758 time/batch=0.42s
8557/10943 (epoch 70.374) train_loss=268.68261719 time/batch=0.66s
8558/10943 (epoch 70.382) train_loss=358.77853394 time/batch=0.93s
8559/10943 (epoch 70.390) train_loss=356.90011597 time/batch=0.90s
8560/10943 (epoch 70.398) train_loss=292.00622559 time/batch=0.76s
8561/10943 (epoch 70.407) train_loss=186.77597046 time/batch=0.50s
8562/10943 (epoch 70.415) train_loss=465.19387817 time/batch=1.17s
8563/10943 (epoch 70.423) train_loss=362.96499634 time/batch=0.99s
8564/10943 (epoch 70.431) train_loss=215.78518677 time/batch=0.59s
8565/10943 (epoch 70.439) train_loss=289.67111206 time/batch=0.71s
8566/10943 (epoch 70.448) train_loss=323.17462158 time/batch=0.82s
8567/10943 (epoch 70.456) train_loss=284.44805908 time/batch=0.76s
8568/10943 (epoch 70.464) train_loss=444.28463745 time/batch=1.20s
8569/10943 (epoch 70.472) train_loss=168.91879272 time/batch=0.52s
8570/10943 (epoch 70.481) train_loss=287.09906006 time/batch=0.69s
8571/10943 (epoch 70.489) train_loss=282.12536621 time/batch=0.74s
8572/10943 (epoch 70.497) train_loss=230.93847656 time/batch=0.63s
8573/10943 (epoch 70.505) train_loss=168.89144897 time/batch=0.46s
8574/10943 (epoch 70.513) train_loss=120.50086212 time/batch=0.32s
8575/10943 (epoch 70.522) train_loss=225.24604797 time/batch=0.54s
8576/10943 (epoch 70.530) train_loss=236.59295654 time/batch=0.60s
8577/10943 (epoch 70.538) train_loss=187.85751343 time/batch=0.52s
8578/10943 (epoch 70.546) train_loss=310.17840576 time/batch=0.78s
8579/10943 (epoch 70.555) train_loss=262.21917725 time/batch=0.68s
8580/10943 (epoch 70.563) train_loss=436.76275635 time/batch=1.00s
8581/10943 (epoch 70.571) train_loss=168.20635986 time/batch=0.49s
8582/10943 (epoch 70.579) train_loss=333.74090576 time/batch=0.81s
8583/10943 (epoch 70.588) train_loss=354.22131348 time/batch=0.94s
8584/10943 (epoch 70.596) train_loss=296.04559326 time/batch=0.78s
8585/10943 (epoch 70.604) train_loss=194.05102539 time/batch=0.54s
8586/10943 (epoch 70.612) train_loss=369.11898804 time/batch=0.91s
8587/10943 (epoch 70.620) train_loss=121.29109955 time/batch=0.39s
8588/10943 (epoch 70.629) train_loss=262.40756226 time/batch=0.65s
8589/10943 (epoch 70.637) train_loss=220.69387817 time/batch=0.58s
8590/10943 (epoch 70.645) train_loss=373.08941650 time/batch=0.93s
8591/10943 (epoch 70.653) train_loss=187.59194946 time/batch=0.54s
8592/10943 (epoch 70.662) train_loss=381.15197754 time/batch=0.92s
8593/10943 (epoch 70.670) train_loss=346.96386719 time/batch=0.98s
8594/10943 (epoch 70.678) train_loss=196.04998779 time/batch=0.56s
8595/10943 (epoch 70.686) train_loss=406.63812256 time/batch=1.37s
8596/10943 (epoch 70.694) train_loss=226.23513794 time/batch=0.69s
8597/10943 (epoch 70.703) train_loss=334.98004150 time/batch=0.93s
8598/10943 (epoch 70.711) train_loss=231.94630432 time/batch=0.63s
8599/10943 (epoch 70.719) train_loss=293.90472412 time/batch=0.77s
8600/10943 (epoch 70.727) train_loss=268.67980957 time/batch=0.68s
8601/10943 (epoch 70.736) train_loss=261.75567627 time/batch=0.65s
8602/10943 (epoch 70.744) train_loss=295.35855103 time/batch=0.75s
8603/10943 (epoch 70.752) train_loss=305.74072266 time/batch=0.79s
8604/10943 (epoch 70.760) train_loss=237.74740601 time/batch=0.65s
8605/10943 (epoch 70.768) train_loss=218.39355469 time/batch=0.59s
8606/10943 (epoch 70.777) train_loss=141.62611389 time/batch=0.38s
8607/10943 (epoch 70.785) train_loss=219.52416992 time/batch=0.55s
8608/10943 (epoch 70.793) train_loss=324.39916992 time/batch=0.80s
8609/10943 (epoch 70.801) train_loss=146.07901001 time/batch=0.39s
8610/10943 (epoch 70.810) train_loss=328.23312378 time/batch=0.79s
8611/10943 (epoch 70.818) train_loss=303.16699219 time/batch=0.81s
8612/10943 (epoch 70.826) train_loss=261.81939697 time/batch=0.67s
8613/10943 (epoch 70.834) train_loss=257.33123779 time/batch=0.66s
8614/10943 (epoch 70.842) train_loss=302.20233154 time/batch=0.76s
8615/10943 (epoch 70.851) train_loss=302.99700928 time/batch=0.78s
8616/10943 (epoch 70.859) train_loss=338.32315063 time/batch=1.41s
8617/10943 (epoch 70.867) train_loss=201.63760376 time/batch=0.62s
8618/10943 (epoch 70.875) train_loss=136.93954468 time/batch=0.35s
8619/10943 (epoch 70.884) train_loss=264.70001221 time/batch=0.72s
8620/10943 (epoch 70.892) train_loss=235.74621582 time/batch=0.64s
8621/10943 (epoch 70.900) train_loss=234.96203613 time/batch=0.60s
8622/10943 (epoch 70.908) train_loss=145.12313843 time/batch=0.42s
8623/10943 (epoch 70.916) train_loss=229.50140381 time/batch=0.56s
8624/10943 (epoch 70.925) train_loss=240.21008301 time/batch=0.63s
8625/10943 (epoch 70.933) train_loss=224.85113525 time/batch=0.58s
8626/10943 (epoch 70.941) train_loss=327.79956055 time/batch=0.81s
8627/10943 (epoch 70.949) train_loss=306.10870361 time/batch=0.81s
setting learning rate to 0.0024989
8628/10943 (epoch 70.958) train_loss=526.47167969 time/batch=1.26s
8629/10943 (epoch 70.966) train_loss=333.71615601 time/batch=0.88s
8630/10943 (epoch 70.974) train_loss=152.70690918 time/batch=0.43s
8631/10943 (epoch 70.982) train_loss=235.00073242 time/batch=0.58s
8632/10943 (epoch 70.990) train_loss=367.68920898 time/batch=0.86s
8633/10943 (epoch 70.999) train_loss=573.48168945 time/batch=1.45s
8634/10943 (epoch 71.007) train_loss=564.07690430 time/batch=1.38s
8635/10943 (epoch 71.015) train_loss=191.18249512 time/batch=0.57s
8636/10943 (epoch 71.023) train_loss=116.89430237 time/batch=0.31s
8637/10943 (epoch 71.032) train_loss=236.99009705 time/batch=0.59s
8638/10943 (epoch 71.040) train_loss=618.55914307 time/batch=1.52s
8639/10943 (epoch 71.048) train_loss=160.94303894 time/batch=0.53s
8640/10943 (epoch 71.056) train_loss=348.65209961 time/batch=0.84s
8641/10943 (epoch 71.065) train_loss=139.39962769 time/batch=0.39s
8642/10943 (epoch 71.073) train_loss=166.49685669 time/batch=0.41s
8643/10943 (epoch 71.081) train_loss=159.91322327 time/batch=0.42s
8644/10943 (epoch 71.089) train_loss=129.05255127 time/batch=0.32s
8645/10943 (epoch 71.097) train_loss=243.72039795 time/batch=0.59s
8646/10943 (epoch 71.106) train_loss=526.07116699 time/batch=1.32s
8647/10943 (epoch 71.114) train_loss=934.57598877 time/batch=3.11s
8648/10943 (epoch 71.122) train_loss=330.01889038 time/batch=1.08s
8649/10943 (epoch 71.130) train_loss=469.44500732 time/batch=1.08s
8650/10943 (epoch 71.139) train_loss=422.00366211 time/batch=1.04s
8651/10943 (epoch 71.147) train_loss=143.59515381 time/batch=0.41s
8652/10943 (epoch 71.155) train_loss=188.27575684 time/batch=0.44s
8653/10943 (epoch 71.163) train_loss=353.22698975 time/batch=0.87s
8654/10943 (epoch 71.171) train_loss=170.38427734 time/batch=0.49s
8655/10943 (epoch 71.180) train_loss=93.27519226 time/batch=0.26s
8656/10943 (epoch 71.188) train_loss=224.57098389 time/batch=0.56s
8657/10943 (epoch 71.196) train_loss=298.33239746 time/batch=0.76s
8658/10943 (epoch 71.204) train_loss=266.57159424 time/batch=0.67s
8659/10943 (epoch 71.213) train_loss=135.47282410 time/batch=0.38s
8660/10943 (epoch 71.221) train_loss=301.59735107 time/batch=0.71s
8661/10943 (epoch 71.229) train_loss=691.35510254 time/batch=1.66s
8662/10943 (epoch 71.237) train_loss=231.81945801 time/batch=0.74s
8663/10943 (epoch 71.245) train_loss=268.97351074 time/batch=0.68s
8664/10943 (epoch 71.254) train_loss=465.45202637 time/batch=1.13s
8665/10943 (epoch 71.262) train_loss=309.01461792 time/batch=0.81s
8666/10943 (epoch 71.270) train_loss=295.96743774 time/batch=0.73s
8667/10943 (epoch 71.278) train_loss=191.87834167 time/batch=0.51s
8668/10943 (epoch 71.287) train_loss=432.92529297 time/batch=1.03s
8669/10943 (epoch 71.295) train_loss=293.06246948 time/batch=0.77s
8670/10943 (epoch 71.303) train_loss=245.97030640 time/batch=0.65s
8671/10943 (epoch 71.311) train_loss=208.87969971 time/batch=0.55s
8672/10943 (epoch 71.319) train_loss=425.65435791 time/batch=0.95s
8673/10943 (epoch 71.328) train_loss=270.23397827 time/batch=0.71s
8674/10943 (epoch 71.336) train_loss=250.59405518 time/batch=0.65s
8675/10943 (epoch 71.344) train_loss=187.95805359 time/batch=0.49s
8676/10943 (epoch 71.352) train_loss=345.53747559 time/batch=0.86s
8677/10943 (epoch 71.361) train_loss=270.26324463 time/batch=0.69s
8678/10943 (epoch 71.369) train_loss=382.76300049 time/batch=0.95s
8679/10943 (epoch 71.377) train_loss=231.10508728 time/batch=0.65s
8680/10943 (epoch 71.385) train_loss=284.16717529 time/batch=0.70s
8681/10943 (epoch 71.393) train_loss=284.94946289 time/batch=0.76s
8682/10943 (epoch 71.402) train_loss=391.80737305 time/batch=0.97s
8683/10943 (epoch 71.410) train_loss=207.47322083 time/batch=0.59s
8684/10943 (epoch 71.418) train_loss=284.96298218 time/batch=0.68s
8685/10943 (epoch 71.426) train_loss=260.07958984 time/batch=0.69s
8686/10943 (epoch 71.435) train_loss=414.29028320 time/batch=1.03s
8687/10943 (epoch 71.443) train_loss=309.44006348 time/batch=0.82s
8688/10943 (epoch 71.451) train_loss=272.61056519 time/batch=0.72s
8689/10943 (epoch 71.459) train_loss=185.28945923 time/batch=0.49s
8690/10943 (epoch 71.467) train_loss=199.68167114 time/batch=0.49s
8691/10943 (epoch 71.476) train_loss=218.66882324 time/batch=0.55s
8692/10943 (epoch 71.484) train_loss=429.18646240 time/batch=1.00s
8693/10943 (epoch 71.492) train_loss=196.75630188 time/batch=0.57s
8694/10943 (epoch 71.500) train_loss=131.30938721 time/batch=0.36s
8695/10943 (epoch 71.509) train_loss=380.86444092 time/batch=0.94s
8696/10943 (epoch 71.517) train_loss=484.00369263 time/batch=1.20s
8697/10943 (epoch 71.525) train_loss=216.18807983 time/batch=0.62s
8698/10943 (epoch 71.533) train_loss=474.02523804 time/batch=1.15s
8699/10943 (epoch 71.542) train_loss=361.96368408 time/batch=0.93s
8700/10943 (epoch 71.550) train_loss=269.10803223 time/batch=0.67s
8701/10943 (epoch 71.558) train_loss=312.06774902 time/batch=0.77s
8702/10943 (epoch 71.566) train_loss=196.68269348 time/batch=0.54s
8703/10943 (epoch 71.574) train_loss=131.11138916 time/batch=0.37s
8704/10943 (epoch 71.583) train_loss=251.11889648 time/batch=0.62s
8705/10943 (epoch 71.591) train_loss=214.82333374 time/batch=0.55s
8706/10943 (epoch 71.599) train_loss=337.46820068 time/batch=0.81s
8707/10943 (epoch 71.607) train_loss=334.78179932 time/batch=0.86s
8708/10943 (epoch 71.616) train_loss=373.38531494 time/batch=1.02s
8709/10943 (epoch 71.624) train_loss=227.71739197 time/batch=0.62s
8710/10943 (epoch 71.632) train_loss=158.25753784 time/batch=0.42s
8711/10943 (epoch 71.640) train_loss=230.79690552 time/batch=0.58s
8712/10943 (epoch 71.648) train_loss=391.84536743 time/batch=0.99s
8713/10943 (epoch 71.657) train_loss=282.85906982 time/batch=0.76s
8714/10943 (epoch 71.665) train_loss=146.11494446 time/batch=0.42s
8715/10943 (epoch 71.673) train_loss=143.11630249 time/batch=0.38s
8716/10943 (epoch 71.681) train_loss=178.82391357 time/batch=0.49s
8717/10943 (epoch 71.690) train_loss=305.65747070 time/batch=0.76s
8718/10943 (epoch 71.698) train_loss=158.29861450 time/batch=0.47s
8719/10943 (epoch 71.706) train_loss=462.77478027 time/batch=1.15s
8720/10943 (epoch 71.714) train_loss=218.79008484 time/batch=0.63s
8721/10943 (epoch 71.722) train_loss=333.55609131 time/batch=0.88s
8722/10943 (epoch 71.731) train_loss=334.10317993 time/batch=0.91s
8723/10943 (epoch 71.739) train_loss=374.85650635 time/batch=1.06s
8724/10943 (epoch 71.747) train_loss=261.75119019 time/batch=0.71s
8725/10943 (epoch 71.755) train_loss=109.78179932 time/batch=0.31s
8726/10943 (epoch 71.764) train_loss=114.16783142 time/batch=0.30s
8727/10943 (epoch 71.772) train_loss=281.01547241 time/batch=0.66s
8728/10943 (epoch 71.780) train_loss=293.38427734 time/batch=0.74s
8729/10943 (epoch 71.788) train_loss=318.39660645 time/batch=0.84s
8730/10943 (epoch 71.796) train_loss=251.80921936 time/batch=0.65s
8731/10943 (epoch 71.805) train_loss=291.48028564 time/batch=0.79s
8732/10943 (epoch 71.813) train_loss=398.13140869 time/batch=1.09s
8733/10943 (epoch 71.821) train_loss=196.94784546 time/batch=0.60s
8734/10943 (epoch 71.829) train_loss=313.76501465 time/batch=0.79s
8735/10943 (epoch 71.838) train_loss=307.80438232 time/batch=0.81s
8736/10943 (epoch 71.846) train_loss=290.61483765 time/batch=0.75s
8737/10943 (epoch 71.854) train_loss=144.38520813 time/batch=0.47s
8738/10943 (epoch 71.862) train_loss=305.53079224 time/batch=0.76s
8739/10943 (epoch 71.870) train_loss=268.92443848 time/batch=0.75s
8740/10943 (epoch 71.879) train_loss=262.31323242 time/batch=0.68s
8741/10943 (epoch 71.887) train_loss=199.57391357 time/batch=0.59s
8742/10943 (epoch 71.895) train_loss=326.27020264 time/batch=0.82s
8743/10943 (epoch 71.903) train_loss=232.31852722 time/batch=0.62s
8744/10943 (epoch 71.912) train_loss=167.98709106 time/batch=0.46s
8745/10943 (epoch 71.920) train_loss=240.17437744 time/batch=0.77s
8746/10943 (epoch 71.928) train_loss=219.53234863 time/batch=0.59s
8747/10943 (epoch 71.936) train_loss=220.39253235 time/batch=0.58s
8748/10943 (epoch 71.944) train_loss=257.97283936 time/batch=0.78s
setting learning rate to 0.0024239
  saved to metadata/gru_dropout-9_nov_folkwiki-20181207-173447_epoch27.pkl
8749/10943 (epoch 71.953) train_loss=153.55885315 time/batch=0.49s
8750/10943 (epoch 71.961) train_loss=525.50964355 time/batch=1.21s
8751/10943 (epoch 71.969) train_loss=379.56726074 time/batch=1.01s
8752/10943 (epoch 71.977) train_loss=342.86016846 time/batch=0.88s
8753/10943 (epoch 71.986) train_loss=101.78838348 time/batch=0.32s
8754/10943 (epoch 71.994) train_loss=934.58453369 time/batch=3.00s
8755/10943 (epoch 72.002) train_loss=481.38623047 time/batch=1.40s
8756/10943 (epoch 72.010) train_loss=299.15606689 time/batch=0.78s
8757/10943 (epoch 72.019) train_loss=212.22387695 time/batch=0.58s
8758/10943 (epoch 72.027) train_loss=503.74353027 time/batch=1.17s
8759/10943 (epoch 72.035) train_loss=306.92504883 time/batch=0.83s
8760/10943 (epoch 72.043) train_loss=577.00457764 time/batch=1.47s
8761/10943 (epoch 72.051) train_loss=303.75970459 time/batch=0.88s
8762/10943 (epoch 72.060) train_loss=694.15649414 time/batch=1.65s
8763/10943 (epoch 72.068) train_loss=334.13824463 time/batch=0.96s
8764/10943 (epoch 72.076) train_loss=582.42596436 time/batch=1.54s
8765/10943 (epoch 72.084) train_loss=191.13806152 time/batch=0.61s
8766/10943 (epoch 72.093) train_loss=301.98803711 time/batch=0.78s
8767/10943 (epoch 72.101) train_loss=287.43106079 time/batch=0.72s
8768/10943 (epoch 72.109) train_loss=318.75039673 time/batch=0.85s
8769/10943 (epoch 72.117) train_loss=102.80372620 time/batch=0.32s
8770/10943 (epoch 72.125) train_loss=256.93811035 time/batch=0.64s
8771/10943 (epoch 72.134) train_loss=391.50097656 time/batch=0.97s
8772/10943 (epoch 72.142) train_loss=301.41314697 time/batch=0.80s
8773/10943 (epoch 72.150) train_loss=116.82487488 time/batch=0.34s
8774/10943 (epoch 72.158) train_loss=320.08813477 time/batch=0.77s
8775/10943 (epoch 72.167) train_loss=258.90109253 time/batch=0.66s
8776/10943 (epoch 72.175) train_loss=450.54980469 time/batch=1.12s
8777/10943 (epoch 72.183) train_loss=271.81365967 time/batch=0.77s
8778/10943 (epoch 72.191) train_loss=530.82421875 time/batch=1.27s
8779/10943 (epoch 72.199) train_loss=416.30377197 time/batch=1.11s
8780/10943 (epoch 72.208) train_loss=139.07730103 time/batch=0.42s
8781/10943 (epoch 72.216) train_loss=428.57806396 time/batch=0.96s
8782/10943 (epoch 72.224) train_loss=252.32766724 time/batch=0.67s
8783/10943 (epoch 72.232) train_loss=539.70953369 time/batch=1.30s
8784/10943 (epoch 72.241) train_loss=387.10968018 time/batch=0.99s
8785/10943 (epoch 72.249) train_loss=204.25903320 time/batch=0.54s
8786/10943 (epoch 72.257) train_loss=470.04855347 time/batch=1.05s
8787/10943 (epoch 72.265) train_loss=461.42999268 time/batch=1.37s
8788/10943 (epoch 72.273) train_loss=126.61905670 time/batch=0.42s
8789/10943 (epoch 72.282) train_loss=439.46350098 time/batch=1.04s
8790/10943 (epoch 72.290) train_loss=387.51416016 time/batch=0.99s
8791/10943 (epoch 72.298) train_loss=386.24945068 time/batch=0.96s
8792/10943 (epoch 72.306) train_loss=208.99172974 time/batch=0.58s
8793/10943 (epoch 72.315) train_loss=297.34301758 time/batch=0.76s
8794/10943 (epoch 72.323) train_loss=212.86903381 time/batch=0.57s
8795/10943 (epoch 72.331) train_loss=115.12250519 time/batch=0.32s
8796/10943 (epoch 72.339) train_loss=417.96026611 time/batch=0.97s
8797/10943 (epoch 72.347) train_loss=269.32043457 time/batch=0.70s
8798/10943 (epoch 72.356) train_loss=192.09078979 time/batch=0.52s
8799/10943 (epoch 72.364) train_loss=367.40356445 time/batch=0.94s
8800/10943 (epoch 72.372) train_loss=277.53454590 time/batch=0.75s
8801/10943 (epoch 72.380) train_loss=393.71502686 time/batch=0.99s
8802/10943 (epoch 72.389) train_loss=192.91336060 time/batch=0.57s
8803/10943 (epoch 72.397) train_loss=176.38223267 time/batch=0.46s
8804/10943 (epoch 72.405) train_loss=155.81893921 time/batch=0.41s
8805/10943 (epoch 72.413) train_loss=307.01367188 time/batch=0.74s
8806/10943 (epoch 72.421) train_loss=157.63970947 time/batch=0.45s
8807/10943 (epoch 72.430) train_loss=352.83010864 time/batch=0.85s
8808/10943 (epoch 72.438) train_loss=261.78546143 time/batch=0.67s
8809/10943 (epoch 72.446) train_loss=163.34597778 time/batch=0.44s
8810/10943 (epoch 72.454) train_loss=169.57014465 time/batch=0.43s
8811/10943 (epoch 72.463) train_loss=141.45382690 time/batch=0.35s
8812/10943 (epoch 72.471) train_loss=282.00183105 time/batch=0.70s
8813/10943 (epoch 72.479) train_loss=123.07910919 time/batch=0.36s
8814/10943 (epoch 72.487) train_loss=188.53381348 time/batch=0.48s
8815/10943 (epoch 72.496) train_loss=349.84912109 time/batch=0.87s
8816/10943 (epoch 72.504) train_loss=332.10351562 time/batch=0.87s
8817/10943 (epoch 72.512) train_loss=239.35345459 time/batch=0.66s
8818/10943 (epoch 72.520) train_loss=251.59564209 time/batch=0.64s
8819/10943 (epoch 72.528) train_loss=265.09191895 time/batch=0.65s
8820/10943 (epoch 72.537) train_loss=163.10345459 time/batch=0.46s
8821/10943 (epoch 72.545) train_loss=257.04458618 time/batch=0.66s
8822/10943 (epoch 72.553) train_loss=221.72692871 time/batch=0.58s
8823/10943 (epoch 72.561) train_loss=341.16210938 time/batch=0.84s
8824/10943 (epoch 72.570) train_loss=140.31558228 time/batch=0.41s
8825/10943 (epoch 72.578) train_loss=412.02905273 time/batch=1.04s
8826/10943 (epoch 72.586) train_loss=224.50173950 time/batch=0.63s
8827/10943 (epoch 72.594) train_loss=361.93524170 time/batch=0.85s
8828/10943 (epoch 72.602) train_loss=223.19287109 time/batch=0.62s
8829/10943 (epoch 72.611) train_loss=187.90625000 time/batch=0.51s
8830/10943 (epoch 72.619) train_loss=148.77871704 time/batch=0.40s
8831/10943 (epoch 72.627) train_loss=346.30078125 time/batch=0.86s
8832/10943 (epoch 72.635) train_loss=289.86788940 time/batch=0.72s
8833/10943 (epoch 72.644) train_loss=226.19073486 time/batch=0.59s
8834/10943 (epoch 72.652) train_loss=291.47137451 time/batch=0.72s
8835/10943 (epoch 72.660) train_loss=297.34231567 time/batch=0.78s
8836/10943 (epoch 72.668) train_loss=291.61975098 time/batch=0.81s
8837/10943 (epoch 72.676) train_loss=255.53770447 time/batch=0.67s
8838/10943 (epoch 72.685) train_loss=207.76354980 time/batch=0.56s
8839/10943 (epoch 72.693) train_loss=137.41026306 time/batch=0.38s
8840/10943 (epoch 72.701) train_loss=266.65524292 time/batch=0.63s
8841/10943 (epoch 72.709) train_loss=264.19308472 time/batch=0.68s
8842/10943 (epoch 72.718) train_loss=305.66168213 time/batch=0.80s
8843/10943 (epoch 72.726) train_loss=294.32501221 time/batch=0.76s
8844/10943 (epoch 72.734) train_loss=296.72451782 time/batch=0.80s
8845/10943 (epoch 72.742) train_loss=238.10063171 time/batch=0.66s
8846/10943 (epoch 72.750) train_loss=152.57107544 time/batch=0.44s
8847/10943 (epoch 72.759) train_loss=159.71412659 time/batch=0.43s
8848/10943 (epoch 72.767) train_loss=127.67324829 time/batch=0.37s
8849/10943 (epoch 72.775) train_loss=183.24754333 time/batch=0.46s
8850/10943 (epoch 72.783) train_loss=232.69784546 time/batch=0.58s
8851/10943 (epoch 72.792) train_loss=284.81515503 time/batch=0.71s
8852/10943 (epoch 72.800) train_loss=292.77450562 time/batch=0.79s
8853/10943 (epoch 72.808) train_loss=194.18215942 time/batch=0.53s
8854/10943 (epoch 72.816) train_loss=318.14013672 time/batch=0.80s
8855/10943 (epoch 72.824) train_loss=221.98329163 time/batch=0.61s
8856/10943 (epoch 72.833) train_loss=238.14868164 time/batch=0.59s
8857/10943 (epoch 72.841) train_loss=181.52444458 time/batch=0.47s
8858/10943 (epoch 72.849) train_loss=229.27722168 time/batch=0.56s
8859/10943 (epoch 72.857) train_loss=217.73950195 time/batch=0.55s
8860/10943 (epoch 72.866) train_loss=197.38592529 time/batch=0.54s
8861/10943 (epoch 72.874) train_loss=171.83534241 time/batch=0.51s
8862/10943 (epoch 72.882) train_loss=227.44891357 time/batch=0.63s
8863/10943 (epoch 72.890) train_loss=335.84912109 time/batch=0.82s
8864/10943 (epoch 72.898) train_loss=319.76751709 time/batch=0.84s
8865/10943 (epoch 72.907) train_loss=275.64630127 time/batch=0.71s
8866/10943 (epoch 72.915) train_loss=226.24189758 time/batch=0.61s
8867/10943 (epoch 72.923) train_loss=233.41593933 time/batch=0.59s
8868/10943 (epoch 72.931) train_loss=258.47650146 time/batch=0.69s
8869/10943 (epoch 72.940) train_loss=234.86175537 time/batch=0.69s
setting learning rate to 0.0023512
8870/10943 (epoch 72.948) train_loss=334.99774170 time/batch=0.83s
8871/10943 (epoch 72.956) train_loss=144.11083984 time/batch=0.41s
8872/10943 (epoch 72.964) train_loss=303.48501587 time/batch=0.74s
8873/10943 (epoch 72.973) train_loss=187.19075012 time/batch=0.49s
8874/10943 (epoch 72.981) train_loss=442.64471436 time/batch=1.04s
8875/10943 (epoch 72.989) train_loss=324.35992432 time/batch=0.86s
8876/10943 (epoch 72.997) train_loss=566.03240967 time/batch=1.30s
8877/10943 (epoch 73.005) train_loss=822.30773926 time/batch=2.21s
8878/10943 (epoch 73.014) train_loss=479.27362061 time/batch=1.30s
8879/10943 (epoch 73.022) train_loss=497.78924561 time/batch=1.24s
8880/10943 (epoch 73.030) train_loss=551.39331055 time/batch=1.41s
8881/10943 (epoch 73.038) train_loss=703.43859863 time/batch=2.25s
8882/10943 (epoch 73.047) train_loss=225.92884827 time/batch=0.77s
8883/10943 (epoch 73.055) train_loss=437.31024170 time/batch=1.04s
8884/10943 (epoch 73.063) train_loss=452.79937744 time/batch=1.20s
8885/10943 (epoch 73.071) train_loss=404.96429443 time/batch=1.04s
8886/10943 (epoch 73.079) train_loss=302.47775269 time/batch=0.83s
8887/10943 (epoch 73.088) train_loss=713.56420898 time/batch=3.08s
8888/10943 (epoch 73.096) train_loss=169.80651855 time/batch=0.71s
8889/10943 (epoch 73.104) train_loss=104.50467682 time/batch=0.28s
8890/10943 (epoch 73.112) train_loss=189.25195312 time/batch=0.48s
8891/10943 (epoch 73.121) train_loss=300.61614990 time/batch=0.75s
8892/10943 (epoch 73.129) train_loss=341.06460571 time/batch=0.86s
8893/10943 (epoch 73.137) train_loss=261.32867432 time/batch=0.68s
8894/10943 (epoch 73.145) train_loss=116.66889954 time/batch=0.33s
8895/10943 (epoch 73.153) train_loss=517.89099121 time/batch=1.18s
8896/10943 (epoch 73.162) train_loss=189.47602844 time/batch=0.55s
8897/10943 (epoch 73.170) train_loss=109.01499939 time/batch=0.30s
8898/10943 (epoch 73.178) train_loss=329.83898926 time/batch=0.80s
8899/10943 (epoch 73.186) train_loss=280.64990234 time/batch=0.74s
8900/10943 (epoch 73.195) train_loss=381.73834229 time/batch=0.92s
8901/10943 (epoch 73.203) train_loss=267.18725586 time/batch=0.71s
8902/10943 (epoch 73.211) train_loss=155.20283508 time/batch=0.42s
8903/10943 (epoch 73.219) train_loss=274.14187622 time/batch=0.63s
8904/10943 (epoch 73.227) train_loss=219.75741577 time/batch=0.59s
8905/10943 (epoch 73.236) train_loss=297.46685791 time/batch=0.76s
8906/10943 (epoch 73.244) train_loss=301.23437500 time/batch=0.79s
8907/10943 (epoch 73.252) train_loss=433.79693604 time/batch=1.08s
8908/10943 (epoch 73.260) train_loss=343.69595337 time/batch=0.90s
8909/10943 (epoch 73.269) train_loss=279.84820557 time/batch=0.76s
8910/10943 (epoch 73.277) train_loss=358.57693481 time/batch=0.91s
8911/10943 (epoch 73.285) train_loss=124.17517090 time/batch=0.37s
8912/10943 (epoch 73.293) train_loss=157.06695557 time/batch=0.39s
8913/10943 (epoch 73.301) train_loss=170.27392578 time/batch=0.44s
8914/10943 (epoch 73.310) train_loss=236.94772339 time/batch=0.60s
8915/10943 (epoch 73.318) train_loss=408.17709351 time/batch=0.96s
8916/10943 (epoch 73.326) train_loss=331.25274658 time/batch=0.85s
8917/10943 (epoch 73.334) train_loss=189.24703979 time/batch=0.53s
8918/10943 (epoch 73.343) train_loss=339.31549072 time/batch=0.84s
8919/10943 (epoch 73.351) train_loss=411.89416504 time/batch=1.02s
8920/10943 (epoch 73.359) train_loss=234.21618652 time/batch=0.66s
8921/10943 (epoch 73.367) train_loss=256.47564697 time/batch=0.65s
8922/10943 (epoch 73.375) train_loss=153.54244995 time/batch=0.40s
8923/10943 (epoch 73.384) train_loss=356.75433350 time/batch=0.88s
8924/10943 (epoch 73.392) train_loss=297.42358398 time/batch=0.79s
8925/10943 (epoch 73.400) train_loss=526.32336426 time/batch=1.42s
8926/10943 (epoch 73.408) train_loss=295.11254883 time/batch=0.81s
8927/10943 (epoch 73.417) train_loss=129.41174316 time/batch=0.36s
8928/10943 (epoch 73.425) train_loss=356.96594238 time/batch=0.82s
8929/10943 (epoch 73.433) train_loss=115.19862366 time/batch=0.36s
8930/10943 (epoch 73.441) train_loss=184.69323730 time/batch=0.45s
8931/10943 (epoch 73.449) train_loss=260.47583008 time/batch=0.62s
8932/10943 (epoch 73.458) train_loss=236.26742554 time/batch=0.61s
8933/10943 (epoch 73.466) train_loss=358.97467041 time/batch=0.87s
8934/10943 (epoch 73.474) train_loss=143.00500488 time/batch=0.40s
8935/10943 (epoch 73.482) train_loss=194.03045654 time/batch=0.51s
8936/10943 (epoch 73.491) train_loss=380.33966064 time/batch=0.94s
8937/10943 (epoch 73.499) train_loss=257.23175049 time/batch=0.68s
8938/10943 (epoch 73.507) train_loss=170.08633423 time/batch=0.48s
8939/10943 (epoch 73.515) train_loss=205.17369080 time/batch=0.49s
8940/10943 (epoch 73.524) train_loss=264.36816406 time/batch=0.67s
8941/10943 (epoch 73.532) train_loss=122.31359863 time/batch=0.36s
8942/10943 (epoch 73.540) train_loss=328.32916260 time/batch=0.77s
8943/10943 (epoch 73.548) train_loss=229.33670044 time/batch=0.63s
8944/10943 (epoch 73.556) train_loss=190.35711670 time/batch=0.50s
8945/10943 (epoch 73.565) train_loss=317.05969238 time/batch=0.78s
8946/10943 (epoch 73.573) train_loss=235.84695435 time/batch=0.63s
8947/10943 (epoch 73.581) train_loss=280.58264160 time/batch=0.72s
8948/10943 (epoch 73.589) train_loss=165.91462708 time/batch=0.46s
8949/10943 (epoch 73.598) train_loss=441.77679443 time/batch=1.12s
8950/10943 (epoch 73.606) train_loss=298.73040771 time/batch=0.80s
8951/10943 (epoch 73.614) train_loss=341.58932495 time/batch=0.89s
8952/10943 (epoch 73.622) train_loss=395.32781982 time/batch=0.99s
8953/10943 (epoch 73.630) train_loss=260.81445312 time/batch=0.70s
8954/10943 (epoch 73.639) train_loss=428.85443115 time/batch=1.08s
8955/10943 (epoch 73.647) train_loss=219.60317993 time/batch=0.62s
8956/10943 (epoch 73.655) train_loss=191.11560059 time/batch=0.50s
8957/10943 (epoch 73.663) train_loss=303.20455933 time/batch=0.87s
8958/10943 (epoch 73.672) train_loss=224.28874207 time/batch=0.61s
8959/10943 (epoch 73.680) train_loss=378.20843506 time/batch=0.92s
8960/10943 (epoch 73.688) train_loss=304.40209961 time/batch=0.79s
8961/10943 (epoch 73.696) train_loss=400.78540039 time/batch=1.02s
8962/10943 (epoch 73.704) train_loss=299.64788818 time/batch=0.83s
8963/10943 (epoch 73.713) train_loss=304.82577515 time/batch=0.81s
8964/10943 (epoch 73.721) train_loss=149.89849854 time/batch=0.44s
8965/10943 (epoch 73.729) train_loss=140.64624023 time/batch=0.35s
8966/10943 (epoch 73.737) train_loss=213.23999023 time/batch=0.54s
8967/10943 (epoch 73.746) train_loss=283.77954102 time/batch=0.68s
8968/10943 (epoch 73.754) train_loss=233.59786987 time/batch=0.64s
8969/10943 (epoch 73.762) train_loss=265.96282959 time/batch=0.68s
8970/10943 (epoch 73.770) train_loss=245.39761353 time/batch=0.65s
8971/10943 (epoch 73.778) train_loss=289.50726318 time/batch=0.78s
8972/10943 (epoch 73.787) train_loss=231.03364563 time/batch=0.59s
8973/10943 (epoch 73.795) train_loss=170.81637573 time/batch=0.48s
8974/10943 (epoch 73.803) train_loss=283.13626099 time/batch=0.70s
8975/10943 (epoch 73.811) train_loss=130.77728271 time/batch=0.39s
8976/10943 (epoch 73.820) train_loss=209.92654419 time/batch=0.51s
8977/10943 (epoch 73.828) train_loss=206.33569336 time/batch=0.55s
8978/10943 (epoch 73.836) train_loss=246.46870422 time/batch=0.62s
8979/10943 (epoch 73.844) train_loss=224.82330322 time/batch=0.58s
8980/10943 (epoch 73.852) train_loss=228.90542603 time/batch=0.58s
8981/10943 (epoch 73.861) train_loss=143.67332458 time/batch=0.42s
8982/10943 (epoch 73.869) train_loss=196.78196716 time/batch=0.50s
8983/10943 (epoch 73.877) train_loss=209.74980164 time/batch=0.53s
8984/10943 (epoch 73.885) train_loss=178.74783325 time/batch=0.54s
8985/10943 (epoch 73.894) train_loss=256.85998535 time/batch=0.67s
8986/10943 (epoch 73.902) train_loss=293.34304810 time/batch=0.70s
8987/10943 (epoch 73.910) train_loss=264.76852417 time/batch=0.70s
8988/10943 (epoch 73.918) train_loss=284.14074707 time/batch=0.71s
8989/10943 (epoch 73.926) train_loss=231.75799561 time/batch=0.63s
8990/10943 (epoch 73.935) train_loss=210.24053955 time/batch=0.60s
setting learning rate to 0.0022807
  saved to metadata/gru_dropout-9_nov_folkwiki-20181207-173447_epoch29.pkl
8991/10943 (epoch 73.943) train_loss=428.10449219 time/batch=1.05s
8992/10943 (epoch 73.951) train_loss=495.88146973 time/batch=1.21s
8993/10943 (epoch 73.959) train_loss=186.30264282 time/batch=0.55s
8994/10943 (epoch 73.968) train_loss=251.40905762 time/batch=0.66s
8995/10943 (epoch 73.976) train_loss=165.73175049 time/batch=0.44s
8996/10943 (epoch 73.984) train_loss=515.88146973 time/batch=1.20s
8997/10943 (epoch 73.992) train_loss=264.13403320 time/batch=0.73s
8998/10943 (epoch 74.001) train_loss=379.16531372 time/batch=0.92s
8999/10943 (epoch 74.009) train_loss=116.79232788 time/batch=0.37s
Validating
    loss:	274.814059

9000/10943 (epoch 74.017) train_loss=238.29782104 time/batch=2.42s
9001/10943 (epoch 74.025) train_loss=459.82852173 time/batch=1.11s
9002/10943 (epoch 74.033) train_loss=708.07733154 time/batch=1.69s
9003/10943 (epoch 74.042) train_loss=283.67712402 time/batch=0.82s
9004/10943 (epoch 74.050) train_loss=356.24673462 time/batch=0.91s
9005/10943 (epoch 74.058) train_loss=136.92660522 time/batch=0.40s
9006/10943 (epoch 74.066) train_loss=385.75524902 time/batch=0.91s
9007/10943 (epoch 74.075) train_loss=121.55979919 time/batch=0.37s
9008/10943 (epoch 74.083) train_loss=127.80619812 time/batch=0.33s
9009/10943 (epoch 74.091) train_loss=138.49197388 time/batch=0.34s
9010/10943 (epoch 74.099) train_loss=393.27059937 time/batch=0.95s
9011/10943 (epoch 74.107) train_loss=430.26690674 time/batch=1.09s
9012/10943 (epoch 74.116) train_loss=356.31942749 time/batch=0.95s
9013/10943 (epoch 74.124) train_loss=325.76596069 time/batch=0.87s
9014/10943 (epoch 74.132) train_loss=339.86672974 time/batch=0.86s
9015/10943 (epoch 74.140) train_loss=760.61657715 time/batch=2.08s
9016/10943 (epoch 74.149) train_loss=157.01200867 time/batch=0.56s
9017/10943 (epoch 74.157) train_loss=93.49806976 time/batch=0.26s
9018/10943 (epoch 74.165) train_loss=293.04061890 time/batch=0.72s
9019/10943 (epoch 74.173) train_loss=541.02990723 time/batch=1.40s
9020/10943 (epoch 74.181) train_loss=206.02140808 time/batch=0.63s
9021/10943 (epoch 74.190) train_loss=220.71427917 time/batch=0.56s
9022/10943 (epoch 74.198) train_loss=122.56853485 time/batch=0.33s
9023/10943 (epoch 74.206) train_loss=772.63055420 time/batch=3.02s
9024/10943 (epoch 74.214) train_loss=492.38037109 time/batch=1.45s
9025/10943 (epoch 74.223) train_loss=381.15820312 time/batch=0.98s
9026/10943 (epoch 74.231) train_loss=354.82800293 time/batch=0.88s
9027/10943 (epoch 74.239) train_loss=265.97265625 time/batch=0.70s
9028/10943 (epoch 74.247) train_loss=255.79167175 time/batch=0.65s
9029/10943 (epoch 74.255) train_loss=227.80523682 time/batch=0.60s
9030/10943 (epoch 74.264) train_loss=338.18267822 time/batch=0.83s
9031/10943 (epoch 74.272) train_loss=423.46911621 time/batch=1.01s
9032/10943 (epoch 74.280) train_loss=110.15016937 time/batch=0.35s
9033/10943 (epoch 74.288) train_loss=570.80865479 time/batch=1.36s
9034/10943 (epoch 74.297) train_loss=443.28991699 time/batch=1.17s
9035/10943 (epoch 74.305) train_loss=165.87428284 time/batch=0.51s
9036/10943 (epoch 74.313) train_loss=344.64068604 time/batch=0.83s
9037/10943 (epoch 74.321) train_loss=322.18807983 time/batch=0.85s
9038/10943 (epoch 74.329) train_loss=135.02314758 time/batch=0.40s
9039/10943 (epoch 74.338) train_loss=195.55104065 time/batch=0.48s
9040/10943 (epoch 74.346) train_loss=266.11541748 time/batch=0.67s
9041/10943 (epoch 74.354) train_loss=145.85198975 time/batch=0.41s
9042/10943 (epoch 74.362) train_loss=307.19818115 time/batch=0.72s
9043/10943 (epoch 74.371) train_loss=260.16250610 time/batch=0.67s
9044/10943 (epoch 74.379) train_loss=293.61920166 time/batch=0.80s
9045/10943 (epoch 74.387) train_loss=237.24215698 time/batch=0.64s
9046/10943 (epoch 74.395) train_loss=281.52844238 time/batch=0.73s
9047/10943 (epoch 74.403) train_loss=415.30596924 time/batch=1.03s
9048/10943 (epoch 74.412) train_loss=172.42028809 time/batch=0.51s
9049/10943 (epoch 74.420) train_loss=179.65757751 time/batch=0.46s
9050/10943 (epoch 74.428) train_loss=301.93212891 time/batch=0.77s
9051/10943 (epoch 74.436) train_loss=224.32736206 time/batch=0.61s
9052/10943 (epoch 74.445) train_loss=216.87536621 time/batch=0.54s
9053/10943 (epoch 74.453) train_loss=307.30477905 time/batch=0.75s
9054/10943 (epoch 74.461) train_loss=465.48202515 time/batch=1.08s
9055/10943 (epoch 74.469) train_loss=230.66601562 time/batch=0.63s
9056/10943 (epoch 74.478) train_loss=433.57763672 time/batch=1.07s
9057/10943 (epoch 74.486) train_loss=209.88502502 time/batch=0.60s
9058/10943 (epoch 74.494) train_loss=297.35528564 time/batch=0.78s
9059/10943 (epoch 74.502) train_loss=376.01586914 time/batch=0.96s
9060/10943 (epoch 74.510) train_loss=280.89251709 time/batch=0.72s
9061/10943 (epoch 74.519) train_loss=278.47222900 time/batch=0.70s
9062/10943 (epoch 74.527) train_loss=505.72048950 time/batch=1.25s
9063/10943 (epoch 74.535) train_loss=291.36547852 time/batch=0.80s
9064/10943 (epoch 74.543) train_loss=156.74382019 time/batch=0.44s
9065/10943 (epoch 74.552) train_loss=326.99847412 time/batch=0.78s
9066/10943 (epoch 74.560) train_loss=218.39308167 time/batch=0.59s
9067/10943 (epoch 74.568) train_loss=256.48281860 time/batch=0.64s
9068/10943 (epoch 74.576) train_loss=357.19049072 time/batch=0.86s
9069/10943 (epoch 74.584) train_loss=241.36680603 time/batch=0.64s
9070/10943 (epoch 74.593) train_loss=332.64892578 time/batch=0.82s
9071/10943 (epoch 74.601) train_loss=251.52601624 time/batch=0.66s
9072/10943 (epoch 74.609) train_loss=122.58598328 time/batch=0.38s
9073/10943 (epoch 74.617) train_loss=302.39935303 time/batch=0.74s
9074/10943 (epoch 74.626) train_loss=373.58575439 time/batch=0.98s
9075/10943 (epoch 74.634) train_loss=194.73992920 time/batch=0.57s
9076/10943 (epoch 74.642) train_loss=357.97427368 time/batch=0.94s
9077/10943 (epoch 74.650) train_loss=163.77212524 time/batch=0.48s
9078/10943 (epoch 74.658) train_loss=197.06303406 time/batch=0.50s
9079/10943 (epoch 74.667) train_loss=277.36199951 time/batch=0.72s
9080/10943 (epoch 74.675) train_loss=300.04956055 time/batch=0.78s
9081/10943 (epoch 74.683) train_loss=287.22158813 time/batch=0.72s
9082/10943 (epoch 74.691) train_loss=202.37939453 time/batch=0.53s
9083/10943 (epoch 74.700) train_loss=306.59143066 time/batch=0.75s
9084/10943 (epoch 74.708) train_loss=215.02355957 time/batch=0.58s
9085/10943 (epoch 74.716) train_loss=268.80340576 time/batch=0.64s
9086/10943 (epoch 74.724) train_loss=193.52027893 time/batch=0.52s
9087/10943 (epoch 74.732) train_loss=261.86022949 time/batch=0.68s
9088/10943 (epoch 74.741) train_loss=265.46609497 time/batch=0.67s
9089/10943 (epoch 74.749) train_loss=230.69221497 time/batch=0.61s
9090/10943 (epoch 74.757) train_loss=145.23464966 time/batch=0.38s
9091/10943 (epoch 74.765) train_loss=299.83166504 time/batch=0.74s
9092/10943 (epoch 74.774) train_loss=162.30499268 time/batch=0.46s
9093/10943 (epoch 74.782) train_loss=289.69512939 time/batch=0.69s
9094/10943 (epoch 74.790) train_loss=322.04373169 time/batch=0.83s
9095/10943 (epoch 74.798) train_loss=195.39160156 time/batch=0.54s
9096/10943 (epoch 74.806) train_loss=147.76528931 time/batch=0.43s
9097/10943 (epoch 74.815) train_loss=247.53677368 time/batch=0.61s
9098/10943 (epoch 74.823) train_loss=319.66467285 time/batch=0.86s
9099/10943 (epoch 74.831) train_loss=217.51016235 time/batch=0.61s
9100/10943 (epoch 74.839) train_loss=286.46911621 time/batch=0.71s
9101/10943 (epoch 74.848) train_loss=223.55023193 time/batch=0.59s
9102/10943 (epoch 74.856) train_loss=176.73893738 time/batch=0.47s
9103/10943 (epoch 74.864) train_loss=309.23010254 time/batch=0.76s
9104/10943 (epoch 74.872) train_loss=277.55001831 time/batch=0.73s
9105/10943 (epoch 74.880) train_loss=212.62756348 time/batch=0.60s
9106/10943 (epoch 74.889) train_loss=176.69332886 time/batch=0.47s
9107/10943 (epoch 74.897) train_loss=229.22038269 time/batch=0.59s
9108/10943 (epoch 74.905) train_loss=225.10893250 time/batch=0.59s
9109/10943 (epoch 74.913) train_loss=187.93521118 time/batch=0.48s
9110/10943 (epoch 74.922) train_loss=222.93943787 time/batch=0.59s
9111/10943 (epoch 74.930) train_loss=244.95587158 time/batch=0.72s
setting learning rate to 0.0022123
9112/10943 (epoch 74.938) train_loss=355.98315430 time/batch=0.90s
9113/10943 (epoch 74.946) train_loss=348.04217529 time/batch=0.93s
9114/10943 (epoch 74.955) train_loss=291.77917480 time/batch=0.74s
9115/10943 (epoch 74.963) train_loss=552.50146484 time/batch=1.41s
9116/10943 (epoch 74.971) train_loss=641.06219482 time/batch=1.62s
9117/10943 (epoch 74.979) train_loss=98.24106598 time/batch=0.39s
9118/10943 (epoch 74.987) train_loss=734.13085938 time/batch=1.69s
9119/10943 (epoch 74.996) train_loss=580.14739990 time/batch=1.87s
9120/10943 (epoch 75.004) train_loss=463.00256348 time/batch=1.26s
9121/10943 (epoch 75.012) train_loss=283.25491333 time/batch=0.76s
9122/10943 (epoch 75.020) train_loss=327.67669678 time/batch=0.83s
9123/10943 (epoch 75.029) train_loss=181.70350647 time/batch=0.51s
9124/10943 (epoch 75.037) train_loss=166.78637695 time/batch=0.45s
9125/10943 (epoch 75.045) train_loss=427.12011719 time/batch=1.01s
9126/10943 (epoch 75.053) train_loss=869.17523193 time/batch=3.10s
9127/10943 (epoch 75.061) train_loss=529.99548340 time/batch=1.52s
9128/10943 (epoch 75.070) train_loss=332.74963379 time/batch=0.90s
9129/10943 (epoch 75.078) train_loss=190.34130859 time/batch=0.52s
9130/10943 (epoch 75.086) train_loss=192.64114380 time/batch=0.48s
9131/10943 (epoch 75.094) train_loss=106.42141724 time/batch=0.29s
9132/10943 (epoch 75.103) train_loss=169.33770752 time/batch=0.40s
9133/10943 (epoch 75.111) train_loss=389.67630005 time/batch=0.92s
9134/10943 (epoch 75.119) train_loss=162.95507812 time/batch=0.49s
9135/10943 (epoch 75.127) train_loss=153.49676514 time/batch=0.40s
9136/10943 (epoch 75.135) train_loss=207.57664490 time/batch=0.53s
9137/10943 (epoch 75.144) train_loss=417.76138306 time/batch=0.99s
9138/10943 (epoch 75.152) train_loss=386.87033081 time/batch=0.96s
9139/10943 (epoch 75.160) train_loss=260.58392334 time/batch=0.71s
9140/10943 (epoch 75.168) train_loss=136.34872437 time/batch=0.37s
9141/10943 (epoch 75.177) train_loss=113.81458282 time/batch=0.30s
9142/10943 (epoch 75.185) train_loss=417.37707520 time/batch=0.97s
9143/10943 (epoch 75.193) train_loss=268.04821777 time/batch=0.73s
9144/10943 (epoch 75.201) train_loss=298.19696045 time/batch=0.75s
9145/10943 (epoch 75.209) train_loss=196.97161865 time/batch=0.54s
9146/10943 (epoch 75.218) train_loss=437.13668823 time/batch=1.07s
9147/10943 (epoch 75.226) train_loss=195.73168945 time/batch=0.59s
9148/10943 (epoch 75.234) train_loss=286.87860107 time/batch=0.71s
9149/10943 (epoch 75.242) train_loss=460.84024048 time/batch=1.08s
9150/10943 (epoch 75.251) train_loss=128.94990540 time/batch=0.40s
9151/10943 (epoch 75.259) train_loss=158.58319092 time/batch=0.42s
9152/10943 (epoch 75.267) train_loss=358.35528564 time/batch=0.84s
9153/10943 (epoch 75.275) train_loss=159.07374573 time/batch=0.48s
9154/10943 (epoch 75.283) train_loss=397.31262207 time/batch=0.96s
9155/10943 (epoch 75.292) train_loss=510.68667603 time/batch=1.29s
9156/10943 (epoch 75.300) train_loss=194.08505249 time/batch=0.60s
9157/10943 (epoch 75.308) train_loss=225.87820435 time/batch=0.57s
9158/10943 (epoch 75.316) train_loss=299.97814941 time/batch=0.78s
9159/10943 (epoch 75.325) train_loss=220.87207031 time/batch=0.59s
9160/10943 (epoch 75.333) train_loss=195.71002197 time/batch=0.52s
9161/10943 (epoch 75.341) train_loss=254.57829285 time/batch=0.65s
9162/10943 (epoch 75.349) train_loss=278.21136475 time/batch=0.74s
9163/10943 (epoch 75.357) train_loss=201.30590820 time/batch=0.52s
9164/10943 (epoch 75.366) train_loss=254.91809082 time/batch=0.66s
9165/10943 (epoch 75.374) train_loss=375.11590576 time/batch=0.95s
9166/10943 (epoch 75.382) train_loss=297.29086304 time/batch=0.81s
9167/10943 (epoch 75.390) train_loss=172.17324829 time/batch=0.48s
9168/10943 (epoch 75.399) train_loss=210.56558228 time/batch=0.55s
9169/10943 (epoch 75.407) train_loss=230.63339233 time/batch=0.59s
9170/10943 (epoch 75.415) train_loss=306.18338013 time/batch=0.75s
9171/10943 (epoch 75.423) train_loss=332.09851074 time/batch=0.84s
9172/10943 (epoch 75.432) train_loss=428.34313965 time/batch=1.04s
9173/10943 (epoch 75.440) train_loss=172.93424988 time/batch=0.52s
9174/10943 (epoch 75.448) train_loss=158.44857788 time/batch=0.45s
9175/10943 (epoch 75.456) train_loss=255.82586670 time/batch=0.62s
9176/10943 (epoch 75.464) train_loss=510.51498413 time/batch=1.19s
9177/10943 (epoch 75.473) train_loss=470.67382812 time/batch=1.23s
9178/10943 (epoch 75.481) train_loss=240.79748535 time/batch=0.68s
9179/10943 (epoch 75.489) train_loss=138.89178467 time/batch=0.38s
9180/10943 (epoch 75.497) train_loss=362.91455078 time/batch=0.87s
9181/10943 (epoch 75.506) train_loss=282.36621094 time/batch=0.72s
9182/10943 (epoch 75.514) train_loss=115.51973724 time/batch=0.34s
9183/10943 (epoch 75.522) train_loss=432.30572510 time/batch=1.05s
9184/10943 (epoch 75.530) train_loss=209.88478088 time/batch=0.59s
9185/10943 (epoch 75.538) train_loss=149.80303955 time/batch=0.38s
9186/10943 (epoch 75.547) train_loss=279.22799683 time/batch=0.70s
9187/10943 (epoch 75.555) train_loss=296.53640747 time/batch=0.74s
9188/10943 (epoch 75.563) train_loss=224.51879883 time/batch=0.59s
9189/10943 (epoch 75.571) train_loss=299.80712891 time/batch=0.76s
9190/10943 (epoch 75.580) train_loss=299.46447754 time/batch=0.77s
9191/10943 (epoch 75.588) train_loss=233.02877808 time/batch=0.62s
9192/10943 (epoch 75.596) train_loss=340.08935547 time/batch=0.84s
9193/10943 (epoch 75.604) train_loss=257.10287476 time/batch=0.68s
9194/10943 (epoch 75.612) train_loss=143.11967468 time/batch=0.40s
9195/10943 (epoch 75.621) train_loss=329.34716797 time/batch=0.79s
9196/10943 (epoch 75.629) train_loss=204.75317383 time/batch=0.56s
9197/10943 (epoch 75.637) train_loss=256.00823975 time/batch=0.63s
9198/10943 (epoch 75.645) train_loss=384.33489990 time/batch=0.93s
9199/10943 (epoch 75.654) train_loss=129.43856812 time/batch=0.38s
9200/10943 (epoch 75.662) train_loss=232.78822327 time/batch=0.59s
9201/10943 (epoch 75.670) train_loss=295.92968750 time/batch=0.78s
9202/10943 (epoch 75.678) train_loss=224.57054138 time/batch=0.62s
9203/10943 (epoch 75.686) train_loss=120.10098267 time/batch=0.33s
9204/10943 (epoch 75.695) train_loss=350.62939453 time/batch=0.87s
9205/10943 (epoch 75.703) train_loss=266.75866699 time/batch=0.69s
9206/10943 (epoch 75.711) train_loss=283.29473877 time/batch=0.76s
9207/10943 (epoch 75.719) train_loss=317.08862305 time/batch=0.86s
9208/10943 (epoch 75.728) train_loss=215.15853882 time/batch=0.60s
9209/10943 (epoch 75.736) train_loss=338.78955078 time/batch=0.84s
9210/10943 (epoch 75.744) train_loss=185.41455078 time/batch=0.53s
9211/10943 (epoch 75.752) train_loss=264.00509644 time/batch=0.65s
9212/10943 (epoch 75.760) train_loss=140.93792725 time/batch=0.37s
9213/10943 (epoch 75.769) train_loss=253.57440186 time/batch=0.60s
9214/10943 (epoch 75.777) train_loss=267.19869995 time/batch=0.66s
9215/10943 (epoch 75.785) train_loss=260.32189941 time/batch=0.67s
9216/10943 (epoch 75.793) train_loss=240.54542542 time/batch=0.65s
9217/10943 (epoch 75.802) train_loss=256.87677002 time/batch=0.69s
9218/10943 (epoch 75.810) train_loss=335.43853760 time/batch=0.87s
9219/10943 (epoch 75.818) train_loss=197.21566772 time/batch=0.57s
9220/10943 (epoch 75.826) train_loss=378.05108643 time/batch=0.95s
9221/10943 (epoch 75.834) train_loss=219.86347961 time/batch=0.62s
9222/10943 (epoch 75.843) train_loss=316.31005859 time/batch=0.79s
9223/10943 (epoch 75.851) train_loss=320.06304932 time/batch=1.05s
9224/10943 (epoch 75.859) train_loss=303.46456909 time/batch=0.84s
9225/10943 (epoch 75.867) train_loss=206.75720215 time/batch=0.59s
9226/10943 (epoch 75.876) train_loss=225.23129272 time/batch=0.57s
9227/10943 (epoch 75.884) train_loss=307.57147217 time/batch=0.79s
9228/10943 (epoch 75.892) train_loss=293.14654541 time/batch=0.71s
9229/10943 (epoch 75.900) train_loss=294.89636230 time/batch=0.80s
9230/10943 (epoch 75.909) train_loss=170.44522095 time/batch=0.62s
9231/10943 (epoch 75.917) train_loss=223.31346130 time/batch=0.62s
9232/10943 (epoch 75.925) train_loss=245.56257629 time/batch=0.71s
setting learning rate to 0.0021459
  saved to metadata/gru_dropout-9_nov_folkwiki-20181207-173447_epoch31.pkl
9233/10943 (epoch 75.933) train_loss=459.85552979 time/batch=1.14s
9234/10943 (epoch 75.941) train_loss=546.74035645 time/batch=1.45s
9235/10943 (epoch 75.950) train_loss=424.63604736 time/batch=1.06s
9236/10943 (epoch 75.958) train_loss=555.23529053 time/batch=1.32s
9237/10943 (epoch 75.966) train_loss=917.48168945 time/batch=3.13s
9238/10943 (epoch 75.974) train_loss=191.10885620 time/batch=0.79s
9239/10943 (epoch 75.983) train_loss=215.08624268 time/batch=0.54s
9240/10943 (epoch 75.991) train_loss=93.91961670 time/batch=0.27s
9241/10943 (epoch 75.999) train_loss=460.46752930 time/batch=1.10s
9242/10943 (epoch 76.007) train_loss=158.58438110 time/batch=0.48s
9243/10943 (epoch 76.015) train_loss=294.23968506 time/batch=0.70s
9244/10943 (epoch 76.024) train_loss=293.73559570 time/batch=0.79s
9245/10943 (epoch 76.032) train_loss=688.05096436 time/batch=1.67s
9246/10943 (epoch 76.040) train_loss=140.37670898 time/batch=0.50s
9247/10943 (epoch 76.048) train_loss=191.20056152 time/batch=0.48s
9248/10943 (epoch 76.057) train_loss=171.76382446 time/batch=0.45s
9249/10943 (epoch 76.065) train_loss=481.68273926 time/batch=1.19s
9250/10943 (epoch 76.073) train_loss=605.94995117 time/batch=1.59s
9251/10943 (epoch 76.081) train_loss=147.35519409 time/batch=0.51s
9252/10943 (epoch 76.089) train_loss=428.53558350 time/batch=1.03s
9253/10943 (epoch 76.098) train_loss=149.32522583 time/batch=0.46s
9254/10943 (epoch 76.106) train_loss=189.03208923 time/batch=0.49s
9255/10943 (epoch 76.114) train_loss=296.70483398 time/batch=0.79s
9256/10943 (epoch 76.122) train_loss=223.79496765 time/batch=0.61s
9257/10943 (epoch 76.131) train_loss=298.38500977 time/batch=0.74s
9258/10943 (epoch 76.139) train_loss=548.64514160 time/batch=1.34s
9259/10943 (epoch 76.147) train_loss=369.81784058 time/batch=1.05s
9260/10943 (epoch 76.155) train_loss=424.89349365 time/batch=1.03s
9261/10943 (epoch 76.163) train_loss=267.54409790 time/batch=0.69s
9262/10943 (epoch 76.172) train_loss=135.17002869 time/batch=0.36s
9263/10943 (epoch 76.180) train_loss=428.26403809 time/batch=1.04s
9264/10943 (epoch 76.188) train_loss=229.10800171 time/batch=0.67s
9265/10943 (epoch 76.196) train_loss=377.71997070 time/batch=0.94s
9266/10943 (epoch 76.205) train_loss=107.89487457 time/batch=0.35s
9267/10943 (epoch 76.213) train_loss=113.51448059 time/batch=0.28s
9268/10943 (epoch 76.221) train_loss=164.68811035 time/batch=0.42s
9269/10943 (epoch 76.229) train_loss=191.54663086 time/batch=0.47s
9270/10943 (epoch 76.237) train_loss=168.45938110 time/batch=0.44s
9271/10943 (epoch 76.246) train_loss=176.40122986 time/batch=0.46s
9272/10943 (epoch 76.254) train_loss=445.76452637 time/batch=1.10s
9273/10943 (epoch 76.262) train_loss=189.07147217 time/batch=0.53s
9274/10943 (epoch 76.270) train_loss=119.71138763 time/batch=0.31s
9275/10943 (epoch 76.279) train_loss=124.19285583 time/batch=0.32s
9276/10943 (epoch 76.287) train_loss=391.52087402 time/batch=0.91s
9277/10943 (epoch 76.295) train_loss=214.74305725 time/batch=0.60s
9278/10943 (epoch 76.303) train_loss=149.49205017 time/batch=0.38s
9279/10943 (epoch 76.311) train_loss=168.80981445 time/batch=0.42s
9280/10943 (epoch 76.320) train_loss=140.90632629 time/batch=0.36s
9281/10943 (epoch 76.328) train_loss=293.54925537 time/batch=0.69s
9282/10943 (epoch 76.336) train_loss=260.51977539 time/batch=0.71s
9283/10943 (epoch 76.344) train_loss=303.54205322 time/batch=0.77s
9284/10943 (epoch 76.353) train_loss=408.85046387 time/batch=1.04s
9285/10943 (epoch 76.361) train_loss=260.15948486 time/batch=0.69s
9286/10943 (epoch 76.369) train_loss=179.91897583 time/batch=0.48s
9287/10943 (epoch 76.377) train_loss=244.27215576 time/batch=0.60s
9288/10943 (epoch 76.386) train_loss=191.62248230 time/batch=0.50s
9289/10943 (epoch 76.394) train_loss=218.94509888 time/batch=0.55s
9290/10943 (epoch 76.402) train_loss=469.77316284 time/batch=1.14s
9291/10943 (epoch 76.410) train_loss=207.08444214 time/batch=0.61s
9292/10943 (epoch 76.418) train_loss=293.26293945 time/batch=0.70s
9293/10943 (epoch 76.427) train_loss=322.46350098 time/batch=0.85s
9294/10943 (epoch 76.435) train_loss=119.99462891 time/batch=0.35s
9295/10943 (epoch 76.443) train_loss=254.61654663 time/batch=0.63s
9296/10943 (epoch 76.451) train_loss=279.90591431 time/batch=0.74s
9297/10943 (epoch 76.460) train_loss=342.91107178 time/batch=0.86s
9298/10943 (epoch 76.468) train_loss=295.38842773 time/batch=0.78s
9299/10943 (epoch 76.476) train_loss=137.29022217 time/batch=0.40s
9300/10943 (epoch 76.484) train_loss=127.99262238 time/batch=0.36s
9301/10943 (epoch 76.492) train_loss=167.34814453 time/batch=0.48s
9302/10943 (epoch 76.501) train_loss=150.57893372 time/batch=0.42s
9303/10943 (epoch 76.509) train_loss=193.38056946 time/batch=0.49s
9304/10943 (epoch 76.517) train_loss=260.62603760 time/batch=0.65s
9305/10943 (epoch 76.525) train_loss=232.97668457 time/batch=0.62s
9306/10943 (epoch 76.534) train_loss=291.54864502 time/batch=0.75s
9307/10943 (epoch 76.542) train_loss=195.28181458 time/batch=0.56s
9308/10943 (epoch 76.550) train_loss=348.33926392 time/batch=0.86s
9309/10943 (epoch 76.558) train_loss=332.04574585 time/batch=0.86s
9310/10943 (epoch 76.566) train_loss=253.37617493 time/batch=0.66s
9311/10943 (epoch 76.575) train_loss=277.05563354 time/batch=0.70s
9312/10943 (epoch 76.583) train_loss=209.77529907 time/batch=0.59s
9313/10943 (epoch 76.591) train_loss=353.91177368 time/batch=0.90s
9314/10943 (epoch 76.599) train_loss=382.69808960 time/batch=0.95s
9315/10943 (epoch 76.608) train_loss=450.35733032 time/batch=1.20s
9316/10943 (epoch 76.616) train_loss=328.58593750 time/batch=0.87s
9317/10943 (epoch 76.624) train_loss=238.48837280 time/batch=0.65s
9318/10943 (epoch 76.632) train_loss=469.12481689 time/batch=1.18s
9319/10943 (epoch 76.640) train_loss=264.03002930 time/batch=0.73s
9320/10943 (epoch 76.649) train_loss=366.09771729 time/batch=0.93s
9321/10943 (epoch 76.657) train_loss=311.62512207 time/batch=0.83s
9322/10943 (epoch 76.665) train_loss=304.71972656 time/batch=0.80s
9323/10943 (epoch 76.673) train_loss=257.55972290 time/batch=0.66s
9324/10943 (epoch 76.682) train_loss=229.55471802 time/batch=0.60s
9325/10943 (epoch 76.690) train_loss=229.95777893 time/batch=0.62s
9326/10943 (epoch 76.698) train_loss=357.68026733 time/batch=0.95s
9327/10943 (epoch 76.706) train_loss=354.67297363 time/batch=0.92s
9328/10943 (epoch 76.714) train_loss=294.12310791 time/batch=0.73s
9329/10943 (epoch 76.723) train_loss=258.03912354 time/batch=0.66s
9330/10943 (epoch 76.731) train_loss=362.34066772 time/batch=0.86s
9331/10943 (epoch 76.739) train_loss=207.47711182 time/batch=0.57s
9332/10943 (epoch 76.747) train_loss=266.46536255 time/batch=0.67s
9333/10943 (epoch 76.756) train_loss=305.44537354 time/batch=0.80s
9334/10943 (epoch 76.764) train_loss=319.23608398 time/batch=0.83s
9335/10943 (epoch 76.772) train_loss=298.98809814 time/batch=0.80s
9336/10943 (epoch 76.780) train_loss=282.17590332 time/batch=0.78s
9337/10943 (epoch 76.788) train_loss=323.38226318 time/batch=0.84s
9338/10943 (epoch 76.797) train_loss=224.25947571 time/batch=0.61s
9339/10943 (epoch 76.805) train_loss=220.54772949 time/batch=0.57s
9340/10943 (epoch 76.813) train_loss=332.21594238 time/batch=0.83s
9341/10943 (epoch 76.821) train_loss=301.13595581 time/batch=0.81s
9342/10943 (epoch 76.830) train_loss=203.98928833 time/batch=0.57s
9343/10943 (epoch 76.838) train_loss=231.52017212 time/batch=0.57s
9344/10943 (epoch 76.846) train_loss=346.22436523 time/batch=0.86s
9345/10943 (epoch 76.854) train_loss=236.84182739 time/batch=0.63s
9346/10943 (epoch 76.863) train_loss=303.74694824 time/batch=0.81s
9347/10943 (epoch 76.871) train_loss=265.87011719 time/batch=0.70s
9348/10943 (epoch 76.879) train_loss=269.47567749 time/batch=0.70s
9349/10943 (epoch 76.887) train_loss=279.00610352 time/batch=0.83s
9350/10943 (epoch 76.895) train_loss=226.85961914 time/batch=0.61s
9351/10943 (epoch 76.904) train_loss=248.48635864 time/batch=0.63s
9352/10943 (epoch 76.912) train_loss=284.04479980 time/batch=0.71s
9353/10943 (epoch 76.920) train_loss=219.71878052 time/batch=0.61s
setting learning rate to 0.0020815
9354/10943 (epoch 76.928) train_loss=161.52095032 time/batch=0.45s
9355/10943 (epoch 76.937) train_loss=300.98480225 time/batch=0.77s
9356/10943 (epoch 76.945) train_loss=688.82794189 time/batch=1.66s
9357/10943 (epoch 76.953) train_loss=279.68664551 time/batch=0.81s
9358/10943 (epoch 76.961) train_loss=420.45703125 time/batch=0.98s
9359/10943 (epoch 76.969) train_loss=130.64224243 time/batch=0.38s
9360/10943 (epoch 76.978) train_loss=545.57739258 time/batch=1.23s
9361/10943 (epoch 76.986) train_loss=459.35137939 time/batch=1.18s
9362/10943 (epoch 76.994) train_loss=108.92399597 time/batch=0.37s
9363/10943 (epoch 77.002) train_loss=121.25991821 time/batch=0.32s
9364/10943 (epoch 77.011) train_loss=168.20208740 time/batch=0.43s
9365/10943 (epoch 77.019) train_loss=327.45275879 time/batch=0.81s
9366/10943 (epoch 77.027) train_loss=704.86175537 time/batch=1.93s
9367/10943 (epoch 77.035) train_loss=584.80773926 time/batch=1.58s
9368/10943 (epoch 77.043) train_loss=269.43545532 time/batch=0.76s
9369/10943 (epoch 77.052) train_loss=576.44982910 time/batch=2.00s
9370/10943 (epoch 77.060) train_loss=495.05828857 time/batch=1.34s
9371/10943 (epoch 77.068) train_loss=259.33895874 time/batch=0.73s
9372/10943 (epoch 77.076) train_loss=249.76953125 time/batch=0.65s
9373/10943 (epoch 77.085) train_loss=106.84444427 time/batch=0.31s
9374/10943 (epoch 77.093) train_loss=148.94967651 time/batch=0.37s
9375/10943 (epoch 77.101) train_loss=255.39956665 time/batch=0.62s
9376/10943 (epoch 77.109) train_loss=166.93238831 time/batch=0.46s
9377/10943 (epoch 77.117) train_loss=439.81915283 time/batch=1.05s
9378/10943 (epoch 77.126) train_loss=145.36732483 time/batch=0.47s
9379/10943 (epoch 77.134) train_loss=427.02487183 time/batch=1.01s
9380/10943 (epoch 77.142) train_loss=489.20376587 time/batch=1.25s
9381/10943 (epoch 77.150) train_loss=116.92764282 time/batch=0.39s
9382/10943 (epoch 77.159) train_loss=283.23336792 time/batch=0.67s
9383/10943 (epoch 77.167) train_loss=194.40859985 time/batch=0.52s
9384/10943 (epoch 77.175) train_loss=329.06430054 time/batch=0.81s
9385/10943 (epoch 77.183) train_loss=387.06304932 time/batch=0.95s
9386/10943 (epoch 77.191) train_loss=754.37750244 time/batch=3.08s
9387/10943 (epoch 77.200) train_loss=257.13308716 time/batch=0.92s
9388/10943 (epoch 77.208) train_loss=148.66120911 time/batch=0.39s
9389/10943 (epoch 77.216) train_loss=300.00738525 time/batch=0.72s
9390/10943 (epoch 77.224) train_loss=346.85583496 time/batch=0.91s
9391/10943 (epoch 77.233) train_loss=280.08966064 time/batch=0.73s
9392/10943 (epoch 77.241) train_loss=326.91809082 time/batch=0.85s
9393/10943 (epoch 77.249) train_loss=182.00697327 time/batch=0.50s
9394/10943 (epoch 77.257) train_loss=241.43804932 time/batch=0.60s
9395/10943 (epoch 77.265) train_loss=260.19262695 time/batch=0.67s
9396/10943 (epoch 77.274) train_loss=438.01937866 time/batch=1.06s
9397/10943 (epoch 77.282) train_loss=462.85162354 time/batch=1.25s
9398/10943 (epoch 77.290) train_loss=447.11407471 time/batch=1.16s
9399/10943 (epoch 77.298) train_loss=222.08602905 time/batch=0.63s
9400/10943 (epoch 77.307) train_loss=155.92030334 time/batch=0.41s
9401/10943 (epoch 77.315) train_loss=265.94091797 time/batch=0.65s
9402/10943 (epoch 77.323) train_loss=134.68968201 time/batch=0.38s
9403/10943 (epoch 77.331) train_loss=354.68460083 time/batch=0.89s
9404/10943 (epoch 77.340) train_loss=334.02185059 time/batch=0.87s
9405/10943 (epoch 77.348) train_loss=137.13555908 time/batch=0.40s
9406/10943 (epoch 77.356) train_loss=170.84837341 time/batch=0.43s
9407/10943 (epoch 77.364) train_loss=193.86447144 time/batch=0.51s
9408/10943 (epoch 77.372) train_loss=321.74615479 time/batch=0.79s
9409/10943 (epoch 77.381) train_loss=231.66891479 time/batch=0.62s
9410/10943 (epoch 77.389) train_loss=192.83682251 time/batch=0.51s
9411/10943 (epoch 77.397) train_loss=395.11700439 time/batch=0.92s
9412/10943 (epoch 77.405) train_loss=296.75613403 time/batch=0.82s
9413/10943 (epoch 77.414) train_loss=278.98861694 time/batch=0.76s
9414/10943 (epoch 77.422) train_loss=190.03463745 time/batch=0.50s
9415/10943 (epoch 77.430) train_loss=349.48107910 time/batch=0.85s
9416/10943 (epoch 77.438) train_loss=154.24884033 time/batch=0.44s
9417/10943 (epoch 77.446) train_loss=177.14196777 time/batch=0.46s
9418/10943 (epoch 77.455) train_loss=317.12051392 time/batch=0.79s
9419/10943 (epoch 77.463) train_loss=312.98266602 time/batch=0.77s
9420/10943 (epoch 77.471) train_loss=375.11334229 time/batch=0.96s
9421/10943 (epoch 77.479) train_loss=421.33020020 time/batch=1.15s
9422/10943 (epoch 77.488) train_loss=236.59130859 time/batch=0.67s
9423/10943 (epoch 77.496) train_loss=211.05767822 time/batch=0.55s
9424/10943 (epoch 77.504) train_loss=202.56179810 time/batch=0.54s
9425/10943 (epoch 77.512) train_loss=174.09695435 time/batch=0.48s
9426/10943 (epoch 77.520) train_loss=415.01119995 time/batch=0.97s
9427/10943 (epoch 77.529) train_loss=355.60690308 time/batch=0.94s
9428/10943 (epoch 77.537) train_loss=308.31414795 time/batch=0.82s
9429/10943 (epoch 77.545) train_loss=129.63131714 time/batch=0.38s
9430/10943 (epoch 77.553) train_loss=224.82507324 time/batch=0.55s
9431/10943 (epoch 77.562) train_loss=186.81945801 time/batch=0.50s
9432/10943 (epoch 77.570) train_loss=281.01721191 time/batch=0.70s
9433/10943 (epoch 77.578) train_loss=208.59651184 time/batch=0.55s
9434/10943 (epoch 77.586) train_loss=191.00253296 time/batch=0.52s
9435/10943 (epoch 77.594) train_loss=164.27520752 time/batch=0.47s
9436/10943 (epoch 77.603) train_loss=202.85217285 time/batch=0.52s
9437/10943 (epoch 77.611) train_loss=103.85305786 time/batch=0.32s
9438/10943 (epoch 77.619) train_loss=265.04193115 time/batch=0.64s
9439/10943 (epoch 77.627) train_loss=300.99908447 time/batch=0.79s
9440/10943 (epoch 77.636) train_loss=222.88597107 time/batch=0.61s
9441/10943 (epoch 77.644) train_loss=290.16418457 time/batch=0.73s
9442/10943 (epoch 77.652) train_loss=266.05175781 time/batch=0.71s
9443/10943 (epoch 77.660) train_loss=277.51562500 time/batch=0.71s
9444/10943 (epoch 77.668) train_loss=363.23352051 time/batch=0.91s
9445/10943 (epoch 77.677) train_loss=323.09008789 time/batch=0.83s
9446/10943 (epoch 77.685) train_loss=377.48950195 time/batch=0.99s
9447/10943 (epoch 77.693) train_loss=247.84915161 time/batch=0.67s
9448/10943 (epoch 77.701) train_loss=143.55903625 time/batch=0.42s
9449/10943 (epoch 77.710) train_loss=223.59397888 time/batch=0.56s
9450/10943 (epoch 77.718) train_loss=403.97467041 time/batch=0.98s
9451/10943 (epoch 77.726) train_loss=301.74475098 time/batch=0.78s
9452/10943 (epoch 77.734) train_loss=291.05499268 time/batch=0.74s
9453/10943 (epoch 77.742) train_loss=222.25808716 time/batch=0.59s
9454/10943 (epoch 77.751) train_loss=223.50840759 time/batch=0.61s
9455/10943 (epoch 77.759) train_loss=285.66540527 time/batch=0.73s
9456/10943 (epoch 77.767) train_loss=228.24400330 time/batch=0.59s
9457/10943 (epoch 77.775) train_loss=345.15274048 time/batch=0.84s
9458/10943 (epoch 77.784) train_loss=241.18513489 time/batch=0.63s
9459/10943 (epoch 77.792) train_loss=304.42385864 time/batch=0.81s
9460/10943 (epoch 77.800) train_loss=223.86811829 time/batch=0.61s
9461/10943 (epoch 77.808) train_loss=266.10461426 time/batch=0.66s
9462/10943 (epoch 77.816) train_loss=179.46464539 time/batch=0.49s
9463/10943 (epoch 77.825) train_loss=306.43255615 time/batch=0.82s
9464/10943 (epoch 77.833) train_loss=262.32754517 time/batch=0.71s
9465/10943 (epoch 77.841) train_loss=170.47500610 time/batch=0.55s
9466/10943 (epoch 77.849) train_loss=367.31677246 time/batch=0.99s
9467/10943 (epoch 77.858) train_loss=253.48194885 time/batch=0.69s
9468/10943 (epoch 77.866) train_loss=211.43640137 time/batch=0.55s
9469/10943 (epoch 77.874) train_loss=343.45623779 time/batch=0.97s
9470/10943 (epoch 77.882) train_loss=225.79054260 time/batch=0.65s
9471/10943 (epoch 77.891) train_loss=291.24734497 time/batch=0.73s
9472/10943 (epoch 77.899) train_loss=293.23718262 time/batch=0.77s
9473/10943 (epoch 77.907) train_loss=218.38757324 time/batch=0.64s
9474/10943 (epoch 77.915) train_loss=248.11422729 time/batch=0.76s
setting learning rate to 0.0020191
  saved to metadata/gru_dropout-9_nov_folkwiki-20181207-173447_epoch33.pkl
9475/10943 (epoch 77.923) train_loss=512.49938965 time/batch=1.30s
9476/10943 (epoch 77.932) train_loss=798.93402100 time/batch=2.18s
9477/10943 (epoch 77.940) train_loss=98.01337433 time/batch=0.45s
9478/10943 (epoch 77.948) train_loss=109.69642639 time/batch=0.28s
9479/10943 (epoch 77.956) train_loss=298.88412476 time/batch=0.73s
9480/10943 (epoch 77.965) train_loss=194.45477295 time/batch=0.53s
9481/10943 (epoch 77.973) train_loss=156.92539978 time/batch=0.40s
9482/10943 (epoch 77.981) train_loss=547.98822021 time/batch=1.24s
9483/10943 (epoch 77.989) train_loss=417.02194214 time/batch=1.03s
9484/10943 (epoch 77.997) train_loss=454.70703125 time/batch=1.16s
9485/10943 (epoch 78.006) train_loss=299.72595215 time/batch=0.85s
9486/10943 (epoch 78.014) train_loss=640.79046631 time/batch=1.56s
9487/10943 (epoch 78.022) train_loss=235.69833374 time/batch=0.71s
9488/10943 (epoch 78.030) train_loss=375.82006836 time/batch=0.94s
9489/10943 (epoch 78.039) train_loss=255.73757935 time/batch=0.68s
9490/10943 (epoch 78.047) train_loss=287.10510254 time/batch=0.72s
9491/10943 (epoch 78.055) train_loss=303.54278564 time/batch=0.81s
9492/10943 (epoch 78.063) train_loss=450.54412842 time/batch=1.09s
9493/10943 (epoch 78.071) train_loss=141.59036255 time/batch=0.43s
9494/10943 (epoch 78.080) train_loss=288.02429199 time/batch=0.68s
9495/10943 (epoch 78.088) train_loss=318.36816406 time/batch=0.81s
9496/10943 (epoch 78.096) train_loss=140.55339050 time/batch=0.42s
9497/10943 (epoch 78.104) train_loss=263.10961914 time/batch=0.63s
9498/10943 (epoch 78.113) train_loss=194.55250549 time/batch=0.53s
9499/10943 (epoch 78.121) train_loss=551.26568604 time/batch=1.34s
9500/10943 (epoch 78.129) train_loss=272.41079712 time/batch=0.81s
9501/10943 (epoch 78.137) train_loss=304.27474976 time/batch=0.80s
9502/10943 (epoch 78.145) train_loss=395.70382690 time/batch=0.96s
9503/10943 (epoch 78.154) train_loss=703.07611084 time/batch=2.30s
9504/10943 (epoch 78.162) train_loss=193.23101807 time/batch=0.65s
9505/10943 (epoch 78.170) train_loss=521.88623047 time/batch=1.27s
9506/10943 (epoch 78.178) train_loss=165.39422607 time/batch=0.53s
9507/10943 (epoch 78.187) train_loss=114.56282043 time/batch=0.31s
9508/10943 (epoch 78.195) train_loss=425.58078003 time/batch=1.03s
9509/10943 (epoch 78.203) train_loss=383.45153809 time/batch=1.02s
9510/10943 (epoch 78.211) train_loss=288.54492188 time/batch=0.75s
9511/10943 (epoch 78.219) train_loss=481.42666626 time/batch=1.18s
9512/10943 (epoch 78.228) train_loss=420.30023193 time/batch=1.08s
9513/10943 (epoch 78.236) train_loss=425.40826416 time/batch=1.04s
9514/10943 (epoch 78.244) train_loss=136.36541748 time/batch=0.41s
9515/10943 (epoch 78.252) train_loss=151.40144348 time/batch=0.37s
9516/10943 (epoch 78.261) train_loss=456.71438599 time/batch=1.10s
9517/10943 (epoch 78.269) train_loss=343.04321289 time/batch=0.90s
9518/10943 (epoch 78.277) train_loss=133.22474670 time/batch=0.39s
9519/10943 (epoch 78.285) train_loss=189.51528931 time/batch=0.49s
9520/10943 (epoch 78.293) train_loss=261.11279297 time/batch=0.66s
9521/10943 (epoch 78.302) train_loss=579.11181641 time/batch=3.06s
9522/10943 (epoch 78.310) train_loss=285.78942871 time/batch=0.96s
9523/10943 (epoch 78.318) train_loss=253.64097595 time/batch=0.65s
9524/10943 (epoch 78.326) train_loss=205.59524536 time/batch=0.55s
9525/10943 (epoch 78.335) train_loss=269.24725342 time/batch=0.67s
9526/10943 (epoch 78.343) train_loss=216.69134521 time/batch=0.55s
9527/10943 (epoch 78.351) train_loss=235.09523010 time/batch=0.61s
9528/10943 (epoch 78.359) train_loss=355.58325195 time/batch=0.89s
9529/10943 (epoch 78.368) train_loss=223.34793091 time/batch=0.61s
9530/10943 (epoch 78.376) train_loss=169.56312561 time/batch=0.43s
9531/10943 (epoch 78.384) train_loss=225.62756348 time/batch=0.59s
9532/10943 (epoch 78.392) train_loss=230.66102600 time/batch=0.61s
9533/10943 (epoch 78.400) train_loss=136.12857056 time/batch=0.37s
9534/10943 (epoch 78.409) train_loss=298.28219604 time/batch=0.73s
9535/10943 (epoch 78.417) train_loss=237.80397034 time/batch=0.63s
9536/10943 (epoch 78.425) train_loss=295.63809204 time/batch=0.74s
9537/10943 (epoch 78.433) train_loss=247.19641113 time/batch=0.65s
9538/10943 (epoch 78.442) train_loss=392.40521240 time/batch=0.97s
9539/10943 (epoch 78.450) train_loss=299.18881226 time/batch=0.84s
9540/10943 (epoch 78.458) train_loss=220.02812195 time/batch=0.62s
9541/10943 (epoch 78.466) train_loss=148.96722412 time/batch=0.41s
9542/10943 (epoch 78.474) train_loss=152.72624207 time/batch=0.41s
9543/10943 (epoch 78.483) train_loss=259.23141479 time/batch=0.65s
9544/10943 (epoch 78.491) train_loss=329.03240967 time/batch=0.83s
9545/10943 (epoch 78.499) train_loss=263.27401733 time/batch=0.68s
9546/10943 (epoch 78.507) train_loss=429.95187378 time/batch=1.06s
9547/10943 (epoch 78.516) train_loss=226.47624207 time/batch=0.67s
9548/10943 (epoch 78.524) train_loss=211.25941467 time/batch=0.56s
9549/10943 (epoch 78.532) train_loss=120.33517456 time/batch=0.33s
9550/10943 (epoch 78.540) train_loss=358.77728271 time/batch=0.85s
9551/10943 (epoch 78.548) train_loss=299.84924316 time/batch=0.79s
9552/10943 (epoch 78.557) train_loss=192.72323608 time/batch=0.55s
9553/10943 (epoch 78.565) train_loss=345.52651978 time/batch=0.85s
9554/10943 (epoch 78.573) train_loss=204.57861328 time/batch=0.57s
9555/10943 (epoch 78.581) train_loss=325.64636230 time/batch=0.81s
9556/10943 (epoch 78.590) train_loss=216.51419067 time/batch=0.60s
9557/10943 (epoch 78.598) train_loss=169.32409668 time/batch=0.46s
9558/10943 (epoch 78.606) train_loss=257.05389404 time/batch=0.65s
9559/10943 (epoch 78.614) train_loss=256.19018555 time/batch=0.64s
9560/10943 (epoch 78.622) train_loss=129.49438477 time/batch=0.39s
9561/10943 (epoch 78.631) train_loss=182.12521362 time/batch=0.46s
9562/10943 (epoch 78.639) train_loss=174.69606018 time/batch=0.46s
9563/10943 (epoch 78.647) train_loss=294.49761963 time/batch=0.76s
9564/10943 (epoch 78.655) train_loss=336.02874756 time/batch=0.87s
9565/10943 (epoch 78.664) train_loss=337.53192139 time/batch=0.89s
9566/10943 (epoch 78.672) train_loss=120.43801880 time/batch=0.36s
9567/10943 (epoch 78.680) train_loss=325.85943604 time/batch=0.79s
9568/10943 (epoch 78.688) train_loss=142.99819946 time/batch=0.46s
9569/10943 (epoch 78.696) train_loss=230.78520203 time/batch=0.55s
9570/10943 (epoch 78.705) train_loss=365.09259033 time/batch=0.88s
9571/10943 (epoch 78.713) train_loss=363.38485718 time/batch=0.95s
9572/10943 (epoch 78.721) train_loss=384.59863281 time/batch=1.10s
9573/10943 (epoch 78.729) train_loss=281.61157227 time/batch=0.73s
9574/10943 (epoch 78.738) train_loss=394.41424561 time/batch=1.09s
9575/10943 (epoch 78.746) train_loss=305.86676025 time/batch=0.85s
9576/10943 (epoch 78.754) train_loss=292.66351318 time/batch=0.75s
9577/10943 (epoch 78.762) train_loss=219.04798889 time/batch=0.59s
9578/10943 (epoch 78.770) train_loss=231.69029236 time/batch=0.59s
9579/10943 (epoch 78.779) train_loss=237.97975159 time/batch=0.62s
9580/10943 (epoch 78.787) train_loss=320.83538818 time/batch=0.81s
9581/10943 (epoch 78.795) train_loss=209.59664917 time/batch=0.59s
9582/10943 (epoch 78.803) train_loss=260.45025635 time/batch=0.69s
9583/10943 (epoch 78.812) train_loss=184.41555786 time/batch=0.50s
9584/10943 (epoch 78.820) train_loss=161.95541382 time/batch=0.44s
9585/10943 (epoch 78.828) train_loss=311.50866699 time/batch=0.78s
9586/10943 (epoch 78.836) train_loss=262.55340576 time/batch=0.71s
9587/10943 (epoch 78.845) train_loss=197.66253662 time/batch=0.50s
9588/10943 (epoch 78.853) train_loss=226.77259827 time/batch=0.57s
9589/10943 (epoch 78.861) train_loss=284.77392578 time/batch=0.73s
9590/10943 (epoch 78.869) train_loss=216.54249573 time/batch=0.60s
9591/10943 (epoch 78.877) train_loss=317.00659180 time/batch=0.80s
9592/10943 (epoch 78.886) train_loss=166.41197205 time/batch=0.49s
9593/10943 (epoch 78.894) train_loss=191.00382996 time/batch=0.48s
9594/10943 (epoch 78.902) train_loss=274.69085693 time/batch=0.68s
9595/10943 (epoch 78.910) train_loss=261.69879150 time/batch=0.74s
setting learning rate to 0.0019585
9596/10943 (epoch 78.919) train_loss=388.93164062 time/batch=0.95s
9597/10943 (epoch 78.927) train_loss=690.48608398 time/batch=1.68s
9598/10943 (epoch 78.935) train_loss=437.33703613 time/batch=1.19s
9599/10943 (epoch 78.943) train_loss=916.63232422 time/batch=3.10s
9600/10943 (epoch 78.951) train_loss=259.16873169 time/batch=0.92s
9601/10943 (epoch 78.960) train_loss=540.18823242 time/batch=1.26s
9602/10943 (epoch 78.968) train_loss=576.23132324 time/batch=1.53s
9603/10943 (epoch 78.976) train_loss=113.03079987 time/batch=0.41s
9604/10943 (epoch 78.984) train_loss=266.58544922 time/batch=0.64s
9605/10943 (epoch 78.993) train_loss=120.06075287 time/batch=0.33s
9606/10943 (epoch 79.001) train_loss=237.21472168 time/batch=0.59s
9607/10943 (epoch 79.009) train_loss=408.51263428 time/batch=1.03s
9608/10943 (epoch 79.017) train_loss=257.66552734 time/batch=0.74s
9609/10943 (epoch 79.025) train_loss=124.59959412 time/batch=0.35s
9610/10943 (epoch 79.034) train_loss=258.77746582 time/batch=0.65s
9611/10943 (epoch 79.042) train_loss=357.24597168 time/batch=0.86s
9612/10943 (epoch 79.050) train_loss=294.38912964 time/batch=0.77s
9613/10943 (epoch 79.058) train_loss=329.37698364 time/batch=0.86s
9614/10943 (epoch 79.067) train_loss=451.74273682 time/batch=1.15s
9615/10943 (epoch 79.075) train_loss=422.09555054 time/batch=1.09s
9616/10943 (epoch 79.083) train_loss=155.06857300 time/batch=0.47s
9617/10943 (epoch 79.091) train_loss=487.35226440 time/batch=1.19s
9618/10943 (epoch 79.099) train_loss=259.26080322 time/batch=0.72s
9619/10943 (epoch 79.108) train_loss=584.04425049 time/batch=1.50s
9620/10943 (epoch 79.116) train_loss=188.82675171 time/batch=0.60s
9621/10943 (epoch 79.124) train_loss=279.73184204 time/batch=0.67s
9622/10943 (epoch 79.132) train_loss=492.55657959 time/batch=1.18s
9623/10943 (epoch 79.141) train_loss=290.79400635 time/batch=0.76s
9624/10943 (epoch 79.149) train_loss=110.85534668 time/batch=0.34s
9625/10943 (epoch 79.157) train_loss=131.88182068 time/batch=0.33s
9626/10943 (epoch 79.165) train_loss=450.73162842 time/batch=1.09s
9627/10943 (epoch 79.173) train_loss=157.94276428 time/batch=0.49s
9628/10943 (epoch 79.182) train_loss=548.33612061 time/batch=1.49s
9629/10943 (epoch 79.190) train_loss=238.07185364 time/batch=0.70s
9630/10943 (epoch 79.198) train_loss=383.14535522 time/batch=0.94s
9631/10943 (epoch 79.206) train_loss=300.02780151 time/batch=0.84s
9632/10943 (epoch 79.215) train_loss=212.23619080 time/batch=0.58s
9633/10943 (epoch 79.223) train_loss=186.10897827 time/batch=0.48s
9634/10943 (epoch 79.231) train_loss=289.16119385 time/batch=0.71s
9635/10943 (epoch 79.239) train_loss=424.24725342 time/batch=1.06s
9636/10943 (epoch 79.247) train_loss=267.80844116 time/batch=0.74s
9637/10943 (epoch 79.256) train_loss=465.21673584 time/batch=1.15s
9638/10943 (epoch 79.264) train_loss=172.93395996 time/batch=0.51s
9639/10943 (epoch 79.272) train_loss=96.59653473 time/batch=0.31s
9640/10943 (epoch 79.280) train_loss=292.32965088 time/batch=0.72s
9641/10943 (epoch 79.289) train_loss=223.64373779 time/batch=0.61s
9642/10943 (epoch 79.297) train_loss=113.73710632 time/batch=0.33s
9643/10943 (epoch 79.305) train_loss=339.85345459 time/batch=0.80s
9644/10943 (epoch 79.313) train_loss=280.72235107 time/batch=0.73s
9645/10943 (epoch 79.322) train_loss=379.61877441 time/batch=0.97s
9646/10943 (epoch 79.330) train_loss=163.08421326 time/batch=0.47s
9647/10943 (epoch 79.338) train_loss=240.87907410 time/batch=0.60s
9648/10943 (epoch 79.346) train_loss=165.15979004 time/batch=0.46s
9649/10943 (epoch 79.354) train_loss=352.55126953 time/batch=0.87s
9650/10943 (epoch 79.363) train_loss=297.68887329 time/batch=0.81s
9651/10943 (epoch 79.371) train_loss=257.29953003 time/batch=0.66s
9652/10943 (epoch 79.379) train_loss=290.88168335 time/batch=0.71s
9653/10943 (epoch 79.387) train_loss=194.78805542 time/batch=0.53s
9654/10943 (epoch 79.396) train_loss=142.89254761 time/batch=0.39s
9655/10943 (epoch 79.404) train_loss=166.19769287 time/batch=0.43s
9656/10943 (epoch 79.412) train_loss=249.02578735 time/batch=0.60s
9657/10943 (epoch 79.420) train_loss=356.94866943 time/batch=0.91s
9658/10943 (epoch 79.428) train_loss=336.91790771 time/batch=0.86s
9659/10943 (epoch 79.437) train_loss=430.97479248 time/batch=1.02s
9660/10943 (epoch 79.445) train_loss=314.19891357 time/batch=0.87s
9661/10943 (epoch 79.453) train_loss=221.30087280 time/batch=0.59s
9662/10943 (epoch 79.461) train_loss=328.18041992 time/batch=0.79s
9663/10943 (epoch 79.470) train_loss=134.48937988 time/batch=0.40s
9664/10943 (epoch 79.478) train_loss=371.21102905 time/batch=0.93s
9665/10943 (epoch 79.486) train_loss=175.06838989 time/batch=0.51s
9666/10943 (epoch 79.494) train_loss=237.07723999 time/batch=0.59s
9667/10943 (epoch 79.502) train_loss=139.87922668 time/batch=0.36s
9668/10943 (epoch 79.511) train_loss=207.22184753 time/batch=0.51s
9669/10943 (epoch 79.519) train_loss=431.89746094 time/batch=1.20s
9670/10943 (epoch 79.527) train_loss=223.45358276 time/batch=0.65s
9671/10943 (epoch 79.535) train_loss=207.35232544 time/batch=0.54s
9672/10943 (epoch 79.544) train_loss=224.64393616 time/batch=0.61s
9673/10943 (epoch 79.552) train_loss=192.39633179 time/batch=0.53s
9674/10943 (epoch 79.560) train_loss=270.57128906 time/batch=0.69s
9675/10943 (epoch 79.568) train_loss=277.59637451 time/batch=0.73s
9676/10943 (epoch 79.576) train_loss=210.07955933 time/batch=0.58s
9677/10943 (epoch 79.585) train_loss=256.49380493 time/batch=0.64s
9678/10943 (epoch 79.593) train_loss=321.70071411 time/batch=0.81s
9679/10943 (epoch 79.601) train_loss=180.08224487 time/batch=0.49s
9680/10943 (epoch 79.609) train_loss=144.90716553 time/batch=0.37s
9681/10943 (epoch 79.618) train_loss=179.89350891 time/batch=0.47s
9682/10943 (epoch 79.626) train_loss=304.01235962 time/batch=0.77s
9683/10943 (epoch 79.634) train_loss=279.47726440 time/batch=0.75s
9684/10943 (epoch 79.642) train_loss=300.61254883 time/batch=0.78s
9685/10943 (epoch 79.650) train_loss=268.34252930 time/batch=0.68s
9686/10943 (epoch 79.659) train_loss=278.66790771 time/batch=0.75s
9687/10943 (epoch 79.667) train_loss=201.57315063 time/batch=0.52s
9688/10943 (epoch 79.675) train_loss=280.03741455 time/batch=0.71s
9689/10943 (epoch 79.683) train_loss=152.34474182 time/batch=0.42s
9690/10943 (epoch 79.692) train_loss=229.69461060 time/batch=0.57s
9691/10943 (epoch 79.700) train_loss=406.88067627 time/batch=0.97s
9692/10943 (epoch 79.708) train_loss=251.05218506 time/batch=0.70s
9693/10943 (epoch 79.716) train_loss=225.63545227 time/batch=0.60s
9694/10943 (epoch 79.724) train_loss=193.52038574 time/batch=0.49s
9695/10943 (epoch 79.733) train_loss=345.44519043 time/batch=0.86s
9696/10943 (epoch 79.741) train_loss=208.24224854 time/batch=0.57s
9697/10943 (epoch 79.749) train_loss=302.92364502 time/batch=0.77s
9698/10943 (epoch 79.757) train_loss=361.04663086 time/batch=0.93s
9699/10943 (epoch 79.766) train_loss=345.74468994 time/batch=0.91s
9700/10943 (epoch 79.774) train_loss=312.32690430 time/batch=0.84s
9701/10943 (epoch 79.782) train_loss=352.83279419 time/batch=0.93s
9702/10943 (epoch 79.790) train_loss=136.19836426 time/batch=0.41s
9703/10943 (epoch 79.799) train_loss=300.55703735 time/batch=0.72s
9704/10943 (epoch 79.807) train_loss=327.96420288 time/batch=0.86s
9705/10943 (epoch 79.815) train_loss=153.59809875 time/batch=0.46s
9706/10943 (epoch 79.823) train_loss=191.10720825 time/batch=0.50s
9707/10943 (epoch 79.831) train_loss=232.96150208 time/batch=0.60s
9708/10943 (epoch 79.840) train_loss=293.81762695 time/batch=0.79s
9709/10943 (epoch 79.848) train_loss=335.85284424 time/batch=0.98s
9710/10943 (epoch 79.856) train_loss=217.53399658 time/batch=0.70s
9711/10943 (epoch 79.864) train_loss=225.61340332 time/batch=0.59s
9712/10943 (epoch 79.873) train_loss=305.02511597 time/batch=0.77s
9713/10943 (epoch 79.881) train_loss=175.52517700 time/batch=0.55s
9714/10943 (epoch 79.889) train_loss=255.97418213 time/batch=0.65s
9715/10943 (epoch 79.897) train_loss=225.58892822 time/batch=0.58s
9716/10943 (epoch 79.905) train_loss=245.39465332 time/batch=0.73s
setting learning rate to 0.0018998
  saved to metadata/gru_dropout-9_nov_folkwiki-20181207-173447_epoch35.pkl
9717/10943 (epoch 79.914) train_loss=255.79858398 time/batch=0.75s
9718/10943 (epoch 79.922) train_loss=209.01522827 time/batch=0.59s
9719/10943 (epoch 79.930) train_loss=552.75732422 time/batch=1.27s
9720/10943 (epoch 79.938) train_loss=916.97058105 time/batch=3.12s
9721/10943 (epoch 79.947) train_loss=443.20333862 time/batch=1.37s
9722/10943 (epoch 79.955) train_loss=687.39318848 time/batch=1.70s
9723/10943 (epoch 79.963) train_loss=400.18884277 time/batch=1.07s
9724/10943 (epoch 79.971) train_loss=264.52893066 time/batch=0.69s
9725/10943 (epoch 79.979) train_loss=105.36372375 time/batch=0.30s
9726/10943 (epoch 79.988) train_loss=542.47387695 time/batch=1.29s
9727/10943 (epoch 79.996) train_loss=374.88116455 time/batch=1.02s
9728/10943 (epoch 80.004) train_loss=99.67337036 time/batch=0.34s
9729/10943 (epoch 80.012) train_loss=166.00198364 time/batch=0.43s
9730/10943 (epoch 80.021) train_loss=450.21875000 time/batch=1.10s
9731/10943 (epoch 80.029) train_loss=355.97854614 time/batch=0.95s
9732/10943 (epoch 80.037) train_loss=603.11218262 time/batch=1.52s
9733/10943 (epoch 80.045) train_loss=417.26589966 time/batch=1.12s
9734/10943 (epoch 80.053) train_loss=295.57156372 time/batch=0.82s
9735/10943 (epoch 80.062) train_loss=165.59877014 time/batch=0.47s
9736/10943 (epoch 80.070) train_loss=259.37664795 time/batch=0.64s
9737/10943 (epoch 80.078) train_loss=451.88037109 time/batch=1.14s
9738/10943 (epoch 80.086) train_loss=278.58810425 time/batch=0.77s
9739/10943 (epoch 80.095) train_loss=546.55468750 time/batch=1.66s
9740/10943 (epoch 80.103) train_loss=123.91272736 time/batch=0.44s
9741/10943 (epoch 80.111) train_loss=167.09863281 time/batch=0.41s
9742/10943 (epoch 80.119) train_loss=250.55198669 time/batch=0.63s
9743/10943 (epoch 80.127) train_loss=358.72192383 time/batch=0.88s
9744/10943 (epoch 80.136) train_loss=333.21243286 time/batch=0.87s
9745/10943 (epoch 80.144) train_loss=248.89088440 time/batch=0.66s
9746/10943 (epoch 80.152) train_loss=385.23800659 time/batch=0.98s
9747/10943 (epoch 80.160) train_loss=446.45886230 time/batch=1.11s
9748/10943 (epoch 80.169) train_loss=168.12268066 time/batch=0.51s
9749/10943 (epoch 80.177) train_loss=183.75083923 time/batch=0.46s
9750/10943 (epoch 80.185) train_loss=501.62475586 time/batch=1.16s
9751/10943 (epoch 80.193) train_loss=326.71398926 time/batch=0.90s
9752/10943 (epoch 80.201) train_loss=217.48516846 time/batch=0.60s
9753/10943 (epoch 80.210) train_loss=136.59664917 time/batch=0.35s
9754/10943 (epoch 80.218) train_loss=254.76899719 time/batch=0.66s
9755/10943 (epoch 80.226) train_loss=188.27482605 time/batch=0.49s
9756/10943 (epoch 80.234) train_loss=296.30120850 time/batch=0.77s
9757/10943 (epoch 80.243) train_loss=224.20384216 time/batch=0.64s
9758/10943 (epoch 80.251) train_loss=375.29760742 time/batch=0.94s
9759/10943 (epoch 80.259) train_loss=278.77569580 time/batch=0.74s
9760/10943 (epoch 80.267) train_loss=245.84149170 time/batch=0.64s
9761/10943 (epoch 80.276) train_loss=210.80677795 time/batch=0.58s
9762/10943 (epoch 80.284) train_loss=452.97113037 time/batch=1.12s
9763/10943 (epoch 80.292) train_loss=288.83505249 time/batch=0.78s
9764/10943 (epoch 80.300) train_loss=297.43911743 time/batch=0.78s
9765/10943 (epoch 80.308) train_loss=141.78302002 time/batch=0.39s
9766/10943 (epoch 80.317) train_loss=438.31164551 time/batch=1.16s
9767/10943 (epoch 80.325) train_loss=423.17150879 time/batch=1.06s
9768/10943 (epoch 80.333) train_loss=287.60662842 time/batch=0.77s
9769/10943 (epoch 80.341) train_loss=432.11679077 time/batch=1.19s
9770/10943 (epoch 80.350) train_loss=157.03408813 time/batch=0.48s
9771/10943 (epoch 80.358) train_loss=190.98458862 time/batch=0.48s
9772/10943 (epoch 80.366) train_loss=186.60644531 time/batch=0.49s
9773/10943 (epoch 80.374) train_loss=237.36450195 time/batch=0.61s
9774/10943 (epoch 80.382) train_loss=474.77093506 time/batch=1.22s
9775/10943 (epoch 80.391) train_loss=310.11358643 time/batch=0.84s
9776/10943 (epoch 80.399) train_loss=223.31838989 time/batch=0.62s
9777/10943 (epoch 80.407) train_loss=392.79992676 time/batch=0.92s
9778/10943 (epoch 80.415) train_loss=189.86877441 time/batch=0.55s
9779/10943 (epoch 80.424) train_loss=261.18017578 time/batch=0.62s
9780/10943 (epoch 80.432) train_loss=258.48876953 time/batch=0.67s
9781/10943 (epoch 80.440) train_loss=163.57147217 time/batch=0.46s
9782/10943 (epoch 80.448) train_loss=363.35214233 time/batch=0.85s
9783/10943 (epoch 80.456) train_loss=205.03335571 time/batch=0.59s
9784/10943 (epoch 80.465) train_loss=174.07086182 time/batch=0.46s
9785/10943 (epoch 80.473) train_loss=254.10804749 time/batch=0.63s
9786/10943 (epoch 80.481) train_loss=192.61898804 time/batch=0.54s
9787/10943 (epoch 80.489) train_loss=113.94283295 time/batch=0.32s
9788/10943 (epoch 80.498) train_loss=343.29464722 time/batch=0.86s
9789/10943 (epoch 80.506) train_loss=269.33776855 time/batch=0.71s
9790/10943 (epoch 80.514) train_loss=139.02542114 time/batch=0.38s
9791/10943 (epoch 80.522) train_loss=296.27117920 time/batch=0.73s
9792/10943 (epoch 80.530) train_loss=275.42401123 time/batch=0.71s
9793/10943 (epoch 80.539) train_loss=299.46554565 time/batch=0.80s
9794/10943 (epoch 80.547) train_loss=331.24420166 time/batch=0.89s
9795/10943 (epoch 80.555) train_loss=200.80654907 time/batch=0.57s
9796/10943 (epoch 80.563) train_loss=235.19078064 time/batch=0.59s
9797/10943 (epoch 80.572) train_loss=198.69271851 time/batch=0.51s
9798/10943 (epoch 80.580) train_loss=143.39657593 time/batch=0.38s
9799/10943 (epoch 80.588) train_loss=211.08926392 time/batch=0.52s
9800/10943 (epoch 80.596) train_loss=221.10182190 time/batch=0.57s
9801/10943 (epoch 80.604) train_loss=128.62188721 time/batch=0.33s
9802/10943 (epoch 80.613) train_loss=120.48281860 time/batch=0.35s
9803/10943 (epoch 80.621) train_loss=234.84339905 time/batch=0.58s
9804/10943 (epoch 80.629) train_loss=117.23946381 time/batch=0.38s
9805/10943 (epoch 80.637) train_loss=194.45558167 time/batch=0.48s
9806/10943 (epoch 80.646) train_loss=365.51165771 time/batch=0.94s
9807/10943 (epoch 80.654) train_loss=156.03987122 time/batch=0.45s
9808/10943 (epoch 80.662) train_loss=228.03042603 time/batch=0.55s
9809/10943 (epoch 80.670) train_loss=232.39363098 time/batch=0.59s
9810/10943 (epoch 80.678) train_loss=324.33044434 time/batch=0.80s
9811/10943 (epoch 80.687) train_loss=148.84082031 time/batch=0.44s
9812/10943 (epoch 80.695) train_loss=297.84796143 time/batch=0.72s
9813/10943 (epoch 80.703) train_loss=280.55767822 time/batch=0.72s
9814/10943 (epoch 80.711) train_loss=235.20977783 time/batch=0.63s
9815/10943 (epoch 80.720) train_loss=348.96469116 time/batch=0.91s
9816/10943 (epoch 80.728) train_loss=206.46179199 time/batch=0.57s
9817/10943 (epoch 80.736) train_loss=317.23248291 time/batch=0.80s
9818/10943 (epoch 80.744) train_loss=225.83111572 time/batch=0.63s
9819/10943 (epoch 80.753) train_loss=230.20980835 time/batch=0.62s
9820/10943 (epoch 80.761) train_loss=148.69366455 time/batch=0.38s
9821/10943 (epoch 80.769) train_loss=296.18902588 time/batch=0.73s
9822/10943 (epoch 80.777) train_loss=334.88937378 time/batch=0.84s
9823/10943 (epoch 80.785) train_loss=328.63772583 time/batch=0.87s
9824/10943 (epoch 80.794) train_loss=276.92730713 time/batch=0.72s
9825/10943 (epoch 80.802) train_loss=148.33035278 time/batch=0.47s
9826/10943 (epoch 80.810) train_loss=275.55993652 time/batch=0.72s
9827/10943 (epoch 80.818) train_loss=306.49703979 time/batch=0.80s
9828/10943 (epoch 80.827) train_loss=303.28582764 time/batch=0.80s
9829/10943 (epoch 80.835) train_loss=323.94506836 time/batch=0.83s
9830/10943 (epoch 80.843) train_loss=267.93896484 time/batch=0.69s
9831/10943 (epoch 80.851) train_loss=217.13114929 time/batch=0.58s
9832/10943 (epoch 80.859) train_loss=252.99769592 time/batch=0.67s
9833/10943 (epoch 80.868) train_loss=219.22866821 time/batch=0.68s
9834/10943 (epoch 80.876) train_loss=223.92234802 time/batch=0.70s
9835/10943 (epoch 80.884) train_loss=299.26339722 time/batch=0.78s
9836/10943 (epoch 80.892) train_loss=328.25631714 time/batch=0.84s
9837/10943 (epoch 80.901) train_loss=278.07147217 time/batch=0.82s
setting learning rate to 0.0018428
9838/10943 (epoch 80.909) train_loss=170.27737427 time/batch=0.48s
9839/10943 (epoch 80.917) train_loss=321.62551880 time/batch=0.78s
9840/10943 (epoch 80.925) train_loss=353.96453857 time/batch=0.88s
9841/10943 (epoch 80.933) train_loss=125.32859802 time/batch=0.38s
9842/10943 (epoch 80.942) train_loss=462.24255371 time/batch=1.04s
9843/10943 (epoch 80.950) train_loss=320.78363037 time/batch=0.89s
9844/10943 (epoch 80.958) train_loss=499.56134033 time/batch=1.24s
9845/10943 (epoch 80.966) train_loss=922.64758301 time/batch=3.10s
9846/10943 (epoch 80.975) train_loss=187.49650574 time/batch=0.75s
9847/10943 (epoch 80.983) train_loss=287.41766357 time/batch=0.69s
9848/10943 (epoch 80.991) train_loss=170.34977722 time/batch=0.47s
9849/10943 (epoch 80.999) train_loss=444.64257812 time/batch=1.09s
9850/10943 (epoch 81.007) train_loss=203.12631226 time/batch=0.56s
9851/10943 (epoch 81.016) train_loss=626.34582520 time/batch=1.52s
9852/10943 (epoch 81.024) train_loss=229.98030090 time/batch=0.68s
9853/10943 (epoch 81.032) train_loss=288.44232178 time/batch=0.73s
9854/10943 (epoch 81.040) train_loss=291.66033936 time/batch=0.75s
9855/10943 (epoch 81.049) train_loss=551.59686279 time/batch=1.37s
9856/10943 (epoch 81.057) train_loss=276.50067139 time/batch=0.81s
9857/10943 (epoch 81.065) train_loss=546.74584961 time/batch=1.30s
9858/10943 (epoch 81.073) train_loss=229.13369751 time/batch=0.69s
9859/10943 (epoch 81.081) train_loss=265.71960449 time/batch=0.65s
9860/10943 (epoch 81.090) train_loss=432.25335693 time/batch=1.08s
9861/10943 (epoch 81.098) train_loss=421.49035645 time/batch=1.02s
9862/10943 (epoch 81.106) train_loss=262.39422607 time/batch=0.71s
9863/10943 (epoch 81.114) train_loss=117.43872070 time/batch=0.32s
9864/10943 (epoch 81.123) train_loss=258.11694336 time/batch=0.63s
9865/10943 (epoch 81.131) train_loss=409.48306274 time/batch=1.03s
9866/10943 (epoch 81.139) train_loss=282.24295044 time/batch=0.74s
9867/10943 (epoch 81.147) train_loss=141.80110168 time/batch=0.38s
9868/10943 (epoch 81.155) train_loss=213.42477417 time/batch=0.53s
9869/10943 (epoch 81.164) train_loss=136.01167297 time/batch=0.38s
9870/10943 (epoch 81.172) train_loss=249.74526978 time/batch=0.61s
9871/10943 (epoch 81.180) train_loss=243.69207764 time/batch=0.63s
9872/10943 (epoch 81.188) train_loss=332.95483398 time/batch=0.83s
9873/10943 (epoch 81.197) train_loss=355.68591309 time/batch=0.91s
9874/10943 (epoch 81.205) train_loss=117.97080994 time/batch=0.36s
9875/10943 (epoch 81.213) train_loss=341.69720459 time/batch=0.81s
9876/10943 (epoch 81.221) train_loss=588.33703613 time/batch=1.60s
9877/10943 (epoch 81.230) train_loss=137.18426514 time/batch=0.47s
9878/10943 (epoch 81.238) train_loss=191.89636230 time/batch=0.50s
9879/10943 (epoch 81.246) train_loss=432.58734131 time/batch=1.08s
9880/10943 (epoch 81.254) train_loss=354.92694092 time/batch=0.97s
9881/10943 (epoch 81.262) train_loss=109.31002045 time/batch=0.36s
9882/10943 (epoch 81.271) train_loss=346.90386963 time/batch=0.88s
9883/10943 (epoch 81.279) train_loss=197.40274048 time/batch=0.55s
9884/10943 (epoch 81.287) train_loss=153.63293457 time/batch=0.41s
9885/10943 (epoch 81.295) train_loss=170.24989319 time/batch=0.42s
9886/10943 (epoch 81.304) train_loss=384.87625122 time/batch=0.95s
9887/10943 (epoch 81.312) train_loss=274.48687744 time/batch=0.75s
9888/10943 (epoch 81.320) train_loss=343.74484253 time/batch=0.88s
9889/10943 (epoch 81.328) train_loss=337.20742798 time/batch=0.88s
9890/10943 (epoch 81.336) train_loss=209.12756348 time/batch=0.59s
9891/10943 (epoch 81.345) train_loss=300.41293335 time/batch=0.74s
9892/10943 (epoch 81.353) train_loss=105.37967682 time/batch=0.34s
9893/10943 (epoch 81.361) train_loss=374.42614746 time/batch=0.92s
9894/10943 (epoch 81.369) train_loss=194.14120483 time/batch=0.54s
9895/10943 (epoch 81.378) train_loss=129.67909241 time/batch=0.33s
9896/10943 (epoch 81.386) train_loss=382.28857422 time/batch=0.91s
9897/10943 (epoch 81.394) train_loss=521.37707520 time/batch=1.26s
9898/10943 (epoch 81.402) train_loss=215.16719055 time/batch=0.62s
9899/10943 (epoch 81.410) train_loss=425.97753906 time/batch=0.98s
9900/10943 (epoch 81.419) train_loss=298.75048828 time/batch=0.83s
9901/10943 (epoch 81.427) train_loss=326.29022217 time/batch=0.84s
9902/10943 (epoch 81.435) train_loss=254.77098083 time/batch=0.70s
9903/10943 (epoch 81.443) train_loss=452.81784058 time/batch=1.12s
9904/10943 (epoch 81.452) train_loss=298.07260132 time/batch=0.85s
9905/10943 (epoch 81.460) train_loss=208.05862427 time/batch=0.56s
9906/10943 (epoch 81.468) train_loss=293.84130859 time/batch=0.77s
9907/10943 (epoch 81.476) train_loss=439.77267456 time/batch=1.16s
9908/10943 (epoch 81.484) train_loss=236.07479858 time/batch=0.67s
9909/10943 (epoch 81.493) train_loss=303.85369873 time/batch=0.75s
9910/10943 (epoch 81.501) train_loss=134.64538574 time/batch=0.40s
9911/10943 (epoch 81.509) train_loss=322.01547241 time/batch=0.78s
9912/10943 (epoch 81.517) train_loss=605.22918701 time/batch=1.66s
9913/10943 (epoch 81.526) train_loss=304.88021851 time/batch=0.91s
9914/10943 (epoch 81.534) train_loss=251.99215698 time/batch=0.66s
9915/10943 (epoch 81.542) train_loss=199.02226257 time/batch=0.55s
9916/10943 (epoch 81.550) train_loss=325.89202881 time/batch=0.83s
9917/10943 (epoch 81.558) train_loss=372.98168945 time/batch=0.94s
9918/10943 (epoch 81.567) train_loss=196.35076904 time/batch=0.57s
9919/10943 (epoch 81.575) train_loss=138.04594421 time/batch=0.39s
9920/10943 (epoch 81.583) train_loss=154.57147217 time/batch=0.38s
9921/10943 (epoch 81.591) train_loss=276.86294556 time/batch=0.70s
9922/10943 (epoch 81.600) train_loss=388.41577148 time/batch=0.95s
9923/10943 (epoch 81.608) train_loss=212.62838745 time/batch=0.60s
9924/10943 (epoch 81.616) train_loss=249.02130127 time/batch=0.62s
9925/10943 (epoch 81.624) train_loss=230.22148132 time/batch=0.58s
9926/10943 (epoch 81.632) train_loss=233.56033325 time/batch=0.60s
9927/10943 (epoch 81.641) train_loss=116.37070465 time/batch=0.38s
9928/10943 (epoch 81.649) train_loss=221.09048462 time/batch=0.55s
9929/10943 (epoch 81.657) train_loss=191.14462280 time/batch=0.49s
9930/10943 (epoch 81.665) train_loss=235.18653870 time/batch=0.60s
9931/10943 (epoch 81.674) train_loss=149.29629517 time/batch=0.41s
9932/10943 (epoch 81.682) train_loss=260.02111816 time/batch=0.66s
9933/10943 (epoch 81.690) train_loss=300.56872559 time/batch=0.77s
9934/10943 (epoch 81.698) train_loss=233.51486206 time/batch=0.62s
9935/10943 (epoch 81.707) train_loss=210.61930847 time/batch=0.57s
9936/10943 (epoch 81.715) train_loss=176.17903137 time/batch=0.46s
9937/10943 (epoch 81.723) train_loss=222.54566956 time/batch=0.58s
9938/10943 (epoch 81.731) train_loss=144.64759827 time/batch=0.43s
9939/10943 (epoch 81.739) train_loss=161.53627014 time/batch=0.42s
9940/10943 (epoch 81.748) train_loss=179.46353149 time/batch=0.46s
9941/10943 (epoch 81.756) train_loss=386.63763428 time/batch=1.13s
9942/10943 (epoch 81.764) train_loss=207.31436157 time/batch=0.65s
9943/10943 (epoch 81.772) train_loss=319.99417114 time/batch=0.90s
9944/10943 (epoch 81.781) train_loss=286.69323730 time/batch=0.78s
9945/10943 (epoch 81.789) train_loss=266.65625000 time/batch=0.70s
9946/10943 (epoch 81.797) train_loss=266.27905273 time/batch=0.66s
9947/10943 (epoch 81.805) train_loss=324.90368652 time/batch=1.64s
9948/10943 (epoch 81.813) train_loss=229.98167419 time/batch=0.71s
9949/10943 (epoch 81.822) train_loss=216.39773560 time/batch=0.59s
9950/10943 (epoch 81.830) train_loss=303.76757812 time/batch=0.76s
9951/10943 (epoch 81.838) train_loss=286.23483276 time/batch=0.71s
9952/10943 (epoch 81.846) train_loss=184.92504883 time/batch=0.51s
9953/10943 (epoch 81.855) train_loss=259.28503418 time/batch=0.63s
9954/10943 (epoch 81.863) train_loss=271.16342163 time/batch=0.69s
9955/10943 (epoch 81.871) train_loss=182.83694458 time/batch=0.63s
9956/10943 (epoch 81.879) train_loss=251.57336426 time/batch=0.66s
9957/10943 (epoch 81.887) train_loss=299.73849487 time/batch=0.78s
9958/10943 (epoch 81.896) train_loss=267.37261963 time/batch=0.71s
setting learning rate to 0.0017875
  saved to metadata/gru_dropout-9_nov_folkwiki-20181207-173447_epoch37.pkl
9959/10943 (epoch 81.904) train_loss=298.14083862 time/batch=0.86s
9960/10943 (epoch 81.912) train_loss=554.80664062 time/batch=1.35s
9961/10943 (epoch 81.920) train_loss=330.44390869 time/batch=0.87s
9962/10943 (epoch 81.929) train_loss=447.71109009 time/batch=1.12s
9963/10943 (epoch 81.937) train_loss=583.95153809 time/batch=1.51s
9964/10943 (epoch 81.945) train_loss=416.52294922 time/batch=1.13s
9965/10943 (epoch 81.953) train_loss=259.42898560 time/batch=0.70s
9966/10943 (epoch 81.961) train_loss=508.56295776 time/batch=1.24s
9967/10943 (epoch 81.970) train_loss=416.05142212 time/batch=1.10s
9968/10943 (epoch 81.978) train_loss=432.29513550 time/batch=1.09s
9969/10943 (epoch 81.986) train_loss=172.24610901 time/batch=0.52s
9970/10943 (epoch 81.994) train_loss=485.71435547 time/batch=1.21s
9971/10943 (epoch 82.003) train_loss=154.36279297 time/batch=0.48s
9972/10943 (epoch 82.011) train_loss=542.42004395 time/batch=1.32s
9973/10943 (epoch 82.019) train_loss=737.80310059 time/batch=2.01s
9974/10943 (epoch 82.027) train_loss=439.41543579 time/batch=1.23s
9975/10943 (epoch 82.035) train_loss=215.07875061 time/batch=0.61s
9976/10943 (epoch 82.044) train_loss=337.98645020 time/batch=0.84s
9977/10943 (epoch 82.052) train_loss=291.80877686 time/batch=0.78s
9978/10943 (epoch 82.060) train_loss=123.77957916 time/batch=0.35s
9979/10943 (epoch 82.068) train_loss=173.94248962 time/batch=0.44s
9980/10943 (epoch 82.077) train_loss=164.33081055 time/batch=0.43s
9981/10943 (epoch 82.085) train_loss=421.76718140 time/batch=0.94s
9982/10943 (epoch 82.093) train_loss=257.38696289 time/batch=0.69s
9983/10943 (epoch 82.101) train_loss=432.49636841 time/batch=1.06s
9984/10943 (epoch 82.109) train_loss=522.58959961 time/batch=1.53s
9985/10943 (epoch 82.118) train_loss=381.09802246 time/batch=1.04s
9986/10943 (epoch 82.126) train_loss=659.10461426 time/batch=2.07s
9987/10943 (epoch 82.134) train_loss=95.95526123 time/batch=0.44s
9988/10943 (epoch 82.142) train_loss=111.36080933 time/batch=0.29s
9989/10943 (epoch 82.151) train_loss=304.34738159 time/batch=0.73s
9990/10943 (epoch 82.159) train_loss=222.11492920 time/batch=0.62s
9991/10943 (epoch 82.167) train_loss=334.78161621 time/batch=0.82s
9992/10943 (epoch 82.175) train_loss=206.25906372 time/batch=0.59s
9993/10943 (epoch 82.184) train_loss=349.03555298 time/batch=0.89s
9994/10943 (epoch 82.192) train_loss=116.65586853 time/batch=0.35s
9995/10943 (epoch 82.200) train_loss=468.17218018 time/batch=1.10s
9996/10943 (epoch 82.208) train_loss=240.86868286 time/batch=0.68s
9997/10943 (epoch 82.216) train_loss=166.90991211 time/batch=0.46s
9998/10943 (epoch 82.225) train_loss=332.82250977 time/batch=0.82s
9999/10943 (epoch 82.233) train_loss=132.32183838 time/batch=0.39s
Validating
    loss:	274.497484

10000/10943 (epoch 82.241) train_loss=191.12033081 time/batch=2.15s
10001/10943 (epoch 82.249) train_loss=351.66482544 time/batch=0.85s
10002/10943 (epoch 82.258) train_loss=267.03698730 time/batch=0.71s
10003/10943 (epoch 82.266) train_loss=373.73742676 time/batch=0.98s
10004/10943 (epoch 82.274) train_loss=500.75366211 time/batch=2.17s
10005/10943 (epoch 82.282) train_loss=258.29901123 time/batch=0.84s
10006/10943 (epoch 82.290) train_loss=277.14950562 time/batch=0.74s
10007/10943 (epoch 82.299) train_loss=232.74224854 time/batch=0.62s
10008/10943 (epoch 82.307) train_loss=296.05026245 time/batch=0.77s
10009/10943 (epoch 82.315) train_loss=138.82902527 time/batch=0.40s
10010/10943 (epoch 82.323) train_loss=180.12425232 time/batch=0.45s
10011/10943 (epoch 82.332) train_loss=287.54702759 time/batch=0.68s
10012/10943 (epoch 82.340) train_loss=210.27294922 time/batch=0.54s
10013/10943 (epoch 82.348) train_loss=249.06320190 time/batch=0.63s
10014/10943 (epoch 82.356) train_loss=111.64527893 time/batch=0.33s
10015/10943 (epoch 82.364) train_loss=388.69494629 time/batch=0.91s
10016/10943 (epoch 82.373) train_loss=145.18579102 time/batch=0.44s
10017/10943 (epoch 82.381) train_loss=266.91333008 time/batch=0.63s
10018/10943 (epoch 82.389) train_loss=260.56652832 time/batch=0.68s
10019/10943 (epoch 82.397) train_loss=211.81091309 time/batch=0.56s
10020/10943 (epoch 82.406) train_loss=148.64260864 time/batch=0.40s
10021/10943 (epoch 82.414) train_loss=263.01940918 time/batch=0.64s
10022/10943 (epoch 82.422) train_loss=335.01727295 time/batch=0.81s
10023/10943 (epoch 82.430) train_loss=379.70834351 time/batch=0.97s
10024/10943 (epoch 82.438) train_loss=390.34704590 time/batch=1.01s
10025/10943 (epoch 82.447) train_loss=228.59503174 time/batch=0.65s
10026/10943 (epoch 82.455) train_loss=250.09225464 time/batch=0.63s
10027/10943 (epoch 82.463) train_loss=129.09672546 time/batch=0.37s
10028/10943 (epoch 82.471) train_loss=173.30599976 time/batch=0.44s
10029/10943 (epoch 82.480) train_loss=302.94198608 time/batch=0.75s
10030/10943 (epoch 82.488) train_loss=295.40753174 time/batch=0.81s
10031/10943 (epoch 82.496) train_loss=303.72302246 time/batch=0.78s
10032/10943 (epoch 82.504) train_loss=244.92591858 time/batch=0.64s
10033/10943 (epoch 82.512) train_loss=351.86853027 time/batch=0.90s
10034/10943 (epoch 82.521) train_loss=192.74314880 time/batch=0.55s
10035/10943 (epoch 82.529) train_loss=592.31469727 time/batch=3.03s
10036/10943 (epoch 82.537) train_loss=261.93768311 time/batch=0.95s
10037/10943 (epoch 82.545) train_loss=318.66711426 time/batch=0.82s
10038/10943 (epoch 82.554) train_loss=284.26873779 time/batch=0.74s
10039/10943 (epoch 82.562) train_loss=129.42863464 time/batch=0.37s
10040/10943 (epoch 82.570) train_loss=194.95046997 time/batch=0.50s
10041/10943 (epoch 82.578) train_loss=306.07714844 time/batch=0.79s
10042/10943 (epoch 82.586) train_loss=147.18237305 time/batch=0.44s
10043/10943 (epoch 82.595) train_loss=345.08062744 time/batch=0.82s
10044/10943 (epoch 82.603) train_loss=299.92120361 time/batch=0.80s
10045/10943 (epoch 82.611) train_loss=229.45932007 time/batch=0.63s
10046/10943 (epoch 82.619) train_loss=206.24525452 time/batch=0.54s
10047/10943 (epoch 82.628) train_loss=142.57864380 time/batch=0.41s
10048/10943 (epoch 82.636) train_loss=217.44778442 time/batch=0.55s
10049/10943 (epoch 82.644) train_loss=168.87474060 time/batch=0.47s
10050/10943 (epoch 82.652) train_loss=315.28131104 time/batch=0.81s
10051/10943 (epoch 82.660) train_loss=312.71386719 time/batch=0.83s
10052/10943 (epoch 82.669) train_loss=357.97906494 time/batch=0.93s
10053/10943 (epoch 82.677) train_loss=201.69979858 time/batch=0.55s
10054/10943 (epoch 82.685) train_loss=320.00952148 time/batch=0.84s
10055/10943 (epoch 82.693) train_loss=228.96504211 time/batch=0.64s
10056/10943 (epoch 82.702) train_loss=151.87596130 time/batch=0.42s
10057/10943 (epoch 82.710) train_loss=237.86346436 time/batch=0.59s
10058/10943 (epoch 82.718) train_loss=196.52676392 time/batch=0.55s
10059/10943 (epoch 82.726) train_loss=259.80575562 time/batch=0.66s
10060/10943 (epoch 82.735) train_loss=190.29479980 time/batch=0.50s
10061/10943 (epoch 82.743) train_loss=177.81594849 time/batch=0.47s
10062/10943 (epoch 82.751) train_loss=295.16577148 time/batch=0.73s
10063/10943 (epoch 82.759) train_loss=185.21630859 time/batch=0.51s
10064/10943 (epoch 82.767) train_loss=160.03504944 time/batch=0.46s
10065/10943 (epoch 82.776) train_loss=228.56953430 time/batch=0.60s
10066/10943 (epoch 82.784) train_loss=229.96154785 time/batch=0.58s
10067/10943 (epoch 82.792) train_loss=220.45246887 time/batch=0.58s
10068/10943 (epoch 82.800) train_loss=227.32382202 time/batch=0.61s
10069/10943 (epoch 82.809) train_loss=289.21582031 time/batch=0.72s
10070/10943 (epoch 82.817) train_loss=289.86962891 time/batch=0.76s
10071/10943 (epoch 82.825) train_loss=249.65921021 time/batch=0.66s
10072/10943 (epoch 82.833) train_loss=279.87756348 time/batch=0.69s
10073/10943 (epoch 82.841) train_loss=281.33557129 time/batch=0.70s
10074/10943 (epoch 82.850) train_loss=320.22473145 time/batch=0.91s
10075/10943 (epoch 82.858) train_loss=299.44808960 time/batch=0.81s
10076/10943 (epoch 82.866) train_loss=219.68707275 time/batch=0.58s
10077/10943 (epoch 82.874) train_loss=209.31059265 time/batch=0.58s
10078/10943 (epoch 82.883) train_loss=281.74151611 time/batch=0.70s
10079/10943 (epoch 82.891) train_loss=193.47012329 time/batch=0.70s
setting learning rate to 0.0017339
10080/10943 (epoch 82.899) train_loss=557.14123535 time/batch=1.42s
10081/10943 (epoch 82.907) train_loss=162.20678711 time/batch=0.52s
10082/10943 (epoch 82.915) train_loss=116.08974457 time/batch=0.31s
10083/10943 (epoch 82.924) train_loss=412.34063721 time/batch=0.99s
10084/10943 (epoch 82.932) train_loss=579.30468750 time/batch=1.50s
10085/10943 (epoch 82.940) train_loss=285.49340820 time/batch=0.83s
10086/10943 (epoch 82.948) train_loss=203.08502197 time/batch=0.56s
10087/10943 (epoch 82.957) train_loss=193.47015381 time/batch=0.51s
10088/10943 (epoch 82.965) train_loss=267.34078979 time/batch=0.67s
10089/10943 (epoch 82.973) train_loss=321.00915527 time/batch=0.84s
10090/10943 (epoch 82.981) train_loss=482.80078125 time/batch=1.20s
10091/10943 (epoch 82.989) train_loss=575.38891602 time/batch=1.55s
10092/10943 (epoch 82.998) train_loss=903.11517334 time/batch=3.14s
10093/10943 (epoch 83.006) train_loss=352.81042480 time/batch=1.20s
10094/10943 (epoch 83.014) train_loss=304.56924438 time/batch=0.82s
10095/10943 (epoch 83.022) train_loss=341.65319824 time/batch=0.88s
10096/10943 (epoch 83.031) train_loss=455.62518311 time/batch=1.14s
10097/10943 (epoch 83.039) train_loss=489.19155884 time/batch=1.24s
10098/10943 (epoch 83.047) train_loss=257.09106445 time/batch=0.73s
10099/10943 (epoch 83.055) train_loss=680.58026123 time/batch=1.66s
10100/10943 (epoch 83.063) train_loss=415.18084717 time/batch=1.11s
10101/10943 (epoch 83.072) train_loss=147.96984863 time/batch=0.45s
10102/10943 (epoch 83.080) train_loss=420.10943604 time/batch=0.98s
10103/10943 (epoch 83.088) train_loss=168.51754761 time/batch=0.49s
10104/10943 (epoch 83.096) train_loss=390.59890747 time/batch=0.91s
10105/10943 (epoch 83.105) train_loss=427.37207031 time/batch=1.09s
10106/10943 (epoch 83.113) train_loss=249.62274170 time/batch=0.68s
10107/10943 (epoch 83.121) train_loss=350.87976074 time/batch=0.85s
10108/10943 (epoch 83.129) train_loss=277.64080811 time/batch=0.74s
10109/10943 (epoch 83.137) train_loss=151.99652100 time/batch=0.44s
10110/10943 (epoch 83.146) train_loss=91.53535461 time/batch=0.26s
10111/10943 (epoch 83.154) train_loss=178.28695679 time/batch=0.45s
10112/10943 (epoch 83.162) train_loss=168.82250977 time/batch=0.43s
10113/10943 (epoch 83.170) train_loss=440.55935669 time/batch=1.06s
10114/10943 (epoch 83.179) train_loss=533.43652344 time/batch=1.30s
10115/10943 (epoch 83.187) train_loss=462.27923584 time/batch=1.28s
10116/10943 (epoch 83.195) train_loss=180.87438965 time/batch=0.54s
10117/10943 (epoch 83.203) train_loss=454.48171997 time/batch=1.04s
10118/10943 (epoch 83.212) train_loss=352.56433105 time/batch=0.94s
10119/10943 (epoch 83.220) train_loss=247.35934448 time/batch=0.68s
10120/10943 (epoch 83.228) train_loss=114.99018860 time/batch=0.32s
10121/10943 (epoch 83.236) train_loss=320.40112305 time/batch=0.78s
10122/10943 (epoch 83.244) train_loss=375.62243652 time/batch=0.95s
10123/10943 (epoch 83.253) train_loss=108.89756775 time/batch=0.36s
10124/10943 (epoch 83.261) train_loss=367.78448486 time/batch=0.91s
10125/10943 (epoch 83.269) train_loss=262.27209473 time/batch=0.70s
10126/10943 (epoch 83.277) train_loss=221.21217346 time/batch=0.59s
10127/10943 (epoch 83.286) train_loss=282.12768555 time/batch=0.69s
10128/10943 (epoch 83.294) train_loss=159.14685059 time/batch=0.46s
10129/10943 (epoch 83.302) train_loss=124.83613586 time/batch=0.33s
10130/10943 (epoch 83.310) train_loss=460.89059448 time/batch=1.48s
10131/10943 (epoch 83.318) train_loss=289.57690430 time/batch=0.83s
10132/10943 (epoch 83.327) train_loss=284.39886475 time/batch=0.72s
10133/10943 (epoch 83.335) train_loss=263.36618042 time/batch=0.67s
10134/10943 (epoch 83.343) train_loss=135.88873291 time/batch=0.37s
10135/10943 (epoch 83.351) train_loss=121.97842407 time/batch=0.31s
10136/10943 (epoch 83.360) train_loss=268.06820679 time/batch=0.65s
10137/10943 (epoch 83.368) train_loss=341.05020142 time/batch=0.87s
10138/10943 (epoch 83.376) train_loss=335.27108765 time/batch=0.86s
10139/10943 (epoch 83.384) train_loss=374.96206665 time/batch=0.97s
10140/10943 (epoch 83.392) train_loss=232.32406616 time/batch=0.65s
10141/10943 (epoch 83.401) train_loss=380.25848389 time/batch=0.95s
10142/10943 (epoch 83.409) train_loss=297.95855713 time/batch=0.80s
10143/10943 (epoch 83.417) train_loss=325.33630371 time/batch=0.88s
10144/10943 (epoch 83.425) train_loss=227.66780090 time/batch=0.63s
10145/10943 (epoch 83.434) train_loss=309.50006104 time/batch=0.76s
10146/10943 (epoch 83.442) train_loss=356.90985107 time/batch=0.89s
10147/10943 (epoch 83.450) train_loss=259.20080566 time/batch=0.72s
10148/10943 (epoch 83.458) train_loss=193.17117310 time/batch=0.50s
10149/10943 (epoch 83.466) train_loss=308.97009277 time/batch=0.74s
10150/10943 (epoch 83.475) train_loss=211.60592651 time/batch=0.58s
10151/10943 (epoch 83.483) train_loss=183.91461182 time/batch=0.49s
10152/10943 (epoch 83.491) train_loss=236.24328613 time/batch=0.59s
10153/10943 (epoch 83.499) train_loss=287.66558838 time/batch=0.73s
10154/10943 (epoch 83.508) train_loss=177.58009338 time/batch=0.48s
10155/10943 (epoch 83.516) train_loss=217.43136597 time/batch=0.54s
10156/10943 (epoch 83.524) train_loss=293.46472168 time/batch=0.77s
10157/10943 (epoch 83.532) train_loss=212.74291992 time/batch=0.59s
10158/10943 (epoch 83.540) train_loss=176.67706299 time/batch=0.47s
10159/10943 (epoch 83.549) train_loss=235.05963135 time/batch=0.59s
10160/10943 (epoch 83.557) train_loss=259.05438232 time/batch=0.67s
10161/10943 (epoch 83.565) train_loss=292.45150757 time/batch=0.80s
10162/10943 (epoch 83.573) train_loss=223.03564453 time/batch=0.60s
10163/10943 (epoch 83.582) train_loss=221.39367676 time/batch=0.58s
10164/10943 (epoch 83.590) train_loss=238.19462585 time/batch=0.60s
10165/10943 (epoch 83.598) train_loss=192.43762207 time/batch=0.53s
10166/10943 (epoch 83.606) train_loss=415.95953369 time/batch=0.97s
10167/10943 (epoch 83.614) train_loss=208.40829468 time/batch=0.58s
10168/10943 (epoch 83.623) train_loss=155.54428101 time/batch=0.44s
10169/10943 (epoch 83.631) train_loss=194.60888672 time/batch=0.49s
10170/10943 (epoch 83.639) train_loss=346.90994263 time/batch=0.96s
10171/10943 (epoch 83.647) train_loss=269.39334106 time/batch=0.72s
10172/10943 (epoch 83.656) train_loss=209.98912048 time/batch=0.55s
10173/10943 (epoch 83.664) train_loss=252.42526245 time/batch=0.62s
10174/10943 (epoch 83.672) train_loss=221.85426331 time/batch=0.59s
10175/10943 (epoch 83.680) train_loss=225.35447693 time/batch=0.61s
10176/10943 (epoch 83.689) train_loss=135.11520386 time/batch=0.37s
10177/10943 (epoch 83.697) train_loss=305.58068848 time/batch=0.76s
10178/10943 (epoch 83.705) train_loss=237.75976562 time/batch=0.64s
10179/10943 (epoch 83.713) train_loss=152.16847229 time/batch=0.40s
10180/10943 (epoch 83.721) train_loss=301.03173828 time/batch=0.72s
10181/10943 (epoch 83.730) train_loss=140.05490112 time/batch=0.41s
10182/10943 (epoch 83.738) train_loss=282.98693848 time/batch=0.72s
10183/10943 (epoch 83.746) train_loss=132.91650391 time/batch=0.39s
10184/10943 (epoch 83.754) train_loss=290.61456299 time/batch=0.68s
10185/10943 (epoch 83.763) train_loss=142.61199951 time/batch=0.46s
10186/10943 (epoch 83.771) train_loss=208.17927551 time/batch=0.54s
10187/10943 (epoch 83.779) train_loss=294.22094727 time/batch=0.74s
10188/10943 (epoch 83.787) train_loss=335.39935303 time/batch=0.83s
10189/10943 (epoch 83.795) train_loss=192.00906372 time/batch=0.54s
10190/10943 (epoch 83.804) train_loss=333.48474121 time/batch=0.80s
10191/10943 (epoch 83.812) train_loss=300.16043091 time/batch=0.81s
10192/10943 (epoch 83.820) train_loss=310.99432373 time/batch=0.82s
10193/10943 (epoch 83.828) train_loss=276.13287354 time/batch=0.78s
10194/10943 (epoch 83.837) train_loss=292.00283813 time/batch=0.82s
10195/10943 (epoch 83.845) train_loss=157.76300049 time/batch=0.47s
10196/10943 (epoch 83.853) train_loss=196.83319092 time/batch=0.49s
10197/10943 (epoch 83.861) train_loss=227.73381042 time/batch=0.56s
10198/10943 (epoch 83.869) train_loss=262.64566040 time/batch=0.68s
10199/10943 (epoch 83.878) train_loss=219.38551331 time/batch=0.63s
10200/10943 (epoch 83.886) train_loss=262.44799805 time/batch=0.65s
setting learning rate to 0.0016818
  saved to metadata/gru_dropout-9_nov_folkwiki-20181207-173447_epoch39.pkl
10201/10943 (epoch 83.894) train_loss=664.47546387 time/batch=1.63s
10202/10943 (epoch 83.902) train_loss=189.20460510 time/batch=0.61s
10203/10943 (epoch 83.911) train_loss=294.21249390 time/batch=0.75s
10204/10943 (epoch 83.919) train_loss=474.45007324 time/batch=1.18s
10205/10943 (epoch 83.927) train_loss=150.78797913 time/batch=0.46s
10206/10943 (epoch 83.935) train_loss=553.59979248 time/batch=1.26s
10207/10943 (epoch 83.943) train_loss=446.49816895 time/batch=1.18s
10208/10943 (epoch 83.952) train_loss=276.89862061 time/batch=0.77s
10209/10943 (epoch 83.960) train_loss=355.68624878 time/batch=0.93s
10210/10943 (epoch 83.968) train_loss=341.95288086 time/batch=0.88s
10211/10943 (epoch 83.976) train_loss=445.37670898 time/batch=1.09s
10212/10943 (epoch 83.985) train_loss=189.48561096 time/batch=0.55s
10213/10943 (epoch 83.993) train_loss=320.80749512 time/batch=0.79s
10214/10943 (epoch 84.001) train_loss=288.39648438 time/batch=0.73s
10215/10943 (epoch 84.009) train_loss=444.88195801 time/batch=1.08s
10216/10943 (epoch 84.017) train_loss=135.13366699 time/batch=0.42s
10217/10943 (epoch 84.026) train_loss=622.33355713 time/batch=1.57s
10218/10943 (epoch 84.034) train_loss=235.48603821 time/batch=0.72s
10219/10943 (epoch 84.042) train_loss=337.30892944 time/batch=0.82s
10220/10943 (epoch 84.050) train_loss=136.10870361 time/batch=0.39s
10221/10943 (epoch 84.059) train_loss=260.35925293 time/batch=0.62s
10222/10943 (epoch 84.067) train_loss=253.73069763 time/batch=0.66s
10223/10943 (epoch 84.075) train_loss=247.67501831 time/batch=0.63s
10224/10943 (epoch 84.083) train_loss=142.12246704 time/batch=0.39s
10225/10943 (epoch 84.091) train_loss=405.94989014 time/batch=1.00s
10226/10943 (epoch 84.100) train_loss=544.16210938 time/batch=1.36s
10227/10943 (epoch 84.108) train_loss=397.65527344 time/batch=1.01s
10228/10943 (epoch 84.116) train_loss=457.10119629 time/batch=1.16s
10229/10943 (epoch 84.124) train_loss=298.50616455 time/batch=0.83s
10230/10943 (epoch 84.133) train_loss=901.90063477 time/batch=3.07s
10231/10943 (epoch 84.141) train_loss=148.48907471 time/batch=0.69s
10232/10943 (epoch 84.149) train_loss=172.32620239 time/batch=0.41s
10233/10943 (epoch 84.157) train_loss=347.64611816 time/batch=0.84s
10234/10943 (epoch 84.166) train_loss=383.28518677 time/batch=1.01s
10235/10943 (epoch 84.174) train_loss=300.47116089 time/batch=0.79s
10236/10943 (epoch 84.182) train_loss=414.40814209 time/batch=1.15s
10237/10943 (epoch 84.190) train_loss=269.37905884 time/batch=0.72s
10238/10943 (epoch 84.198) train_loss=509.06903076 time/batch=1.34s
10239/10943 (epoch 84.207) train_loss=106.88755798 time/batch=0.38s
10240/10943 (epoch 84.215) train_loss=169.20571899 time/batch=0.44s
10241/10943 (epoch 84.223) train_loss=235.60504150 time/batch=0.58s
10242/10943 (epoch 84.231) train_loss=417.16494751 time/batch=1.00s
10243/10943 (epoch 84.240) train_loss=309.73147583 time/batch=0.82s
10244/10943 (epoch 84.248) train_loss=296.28674316 time/batch=0.80s
10245/10943 (epoch 84.256) train_loss=367.97235107 time/batch=0.95s
10246/10943 (epoch 84.264) train_loss=124.47439575 time/batch=0.37s
10247/10943 (epoch 84.272) train_loss=175.15441895 time/batch=0.44s
10248/10943 (epoch 84.281) train_loss=357.42578125 time/batch=0.84s
10249/10943 (epoch 84.289) train_loss=305.60797119 time/batch=0.83s
10250/10943 (epoch 84.297) train_loss=261.72668457 time/batch=0.69s
10251/10943 (epoch 84.305) train_loss=250.99958801 time/batch=0.64s
10252/10943 (epoch 84.314) train_loss=180.71125793 time/batch=0.48s
10253/10943 (epoch 84.322) train_loss=224.97344971 time/batch=0.56s
10254/10943 (epoch 84.330) train_loss=237.47222900 time/batch=0.62s
10255/10943 (epoch 84.338) train_loss=190.37207031 time/batch=0.52s
10256/10943 (epoch 84.346) train_loss=348.79876709 time/batch=0.87s
10257/10943 (epoch 84.355) train_loss=140.89743042 time/batch=0.44s
10258/10943 (epoch 84.363) train_loss=262.17205811 time/batch=0.63s
10259/10943 (epoch 84.371) train_loss=129.41343689 time/batch=0.38s
10260/10943 (epoch 84.379) train_loss=150.16932678 time/batch=0.38s
10261/10943 (epoch 84.388) train_loss=290.88574219 time/batch=0.77s
10262/10943 (epoch 84.396) train_loss=280.90481567 time/batch=0.75s
10263/10943 (epoch 84.404) train_loss=275.56790161 time/batch=0.73s
10264/10943 (epoch 84.412) train_loss=256.95452881 time/batch=0.65s
10265/10943 (epoch 84.420) train_loss=165.59196472 time/batch=0.45s
10266/10943 (epoch 84.429) train_loss=286.13381958 time/batch=0.71s
10267/10943 (epoch 84.437) train_loss=333.29431152 time/batch=0.86s
10268/10943 (epoch 84.445) train_loss=212.51354980 time/batch=0.59s
10269/10943 (epoch 84.453) train_loss=507.53561401 time/batch=1.59s
10270/10943 (epoch 84.462) train_loss=223.86686707 time/batch=0.69s
10271/10943 (epoch 84.470) train_loss=281.74438477 time/batch=0.71s
10272/10943 (epoch 84.478) train_loss=226.98753357 time/batch=0.58s
10273/10943 (epoch 84.486) train_loss=370.83367920 time/batch=0.94s
10274/10943 (epoch 84.494) train_loss=283.57220459 time/batch=0.77s
10275/10943 (epoch 84.503) train_loss=234.36488342 time/batch=0.62s
10276/10943 (epoch 84.511) train_loss=335.42004395 time/batch=0.88s
10277/10943 (epoch 84.519) train_loss=400.66845703 time/batch=0.99s
10278/10943 (epoch 84.527) train_loss=97.73381042 time/batch=0.35s
10279/10943 (epoch 84.536) train_loss=299.76556396 time/batch=0.75s
10280/10943 (epoch 84.544) train_loss=511.00494385 time/batch=1.68s
10281/10943 (epoch 84.552) train_loss=411.75372314 time/batch=1.09s
10282/10943 (epoch 84.560) train_loss=278.67431641 time/batch=0.74s
10283/10943 (epoch 84.568) train_loss=152.95407104 time/batch=0.43s
10284/10943 (epoch 84.577) train_loss=234.32942200 time/batch=0.59s
10285/10943 (epoch 84.585) train_loss=156.03739929 time/batch=0.42s
10286/10943 (epoch 84.593) train_loss=327.56433105 time/batch=0.87s
10287/10943 (epoch 84.601) train_loss=121.65955353 time/batch=0.38s
10288/10943 (epoch 84.610) train_loss=127.36198425 time/batch=0.35s
10289/10943 (epoch 84.618) train_loss=288.61511230 time/batch=0.71s
10290/10943 (epoch 84.626) train_loss=220.92242432 time/batch=0.60s
10291/10943 (epoch 84.634) train_loss=179.19400024 time/batch=0.48s
10292/10943 (epoch 84.643) train_loss=193.85763550 time/batch=0.50s
10293/10943 (epoch 84.651) train_loss=262.93762207 time/batch=0.65s
10294/10943 (epoch 84.659) train_loss=207.00585938 time/batch=0.57s
10295/10943 (epoch 84.667) train_loss=204.51167297 time/batch=0.53s
10296/10943 (epoch 84.675) train_loss=172.00358582 time/batch=0.46s
10297/10943 (epoch 84.684) train_loss=205.47431946 time/batch=0.52s
10298/10943 (epoch 84.692) train_loss=296.97155762 time/batch=0.74s
10299/10943 (epoch 84.700) train_loss=332.90817261 time/batch=0.82s
10300/10943 (epoch 84.708) train_loss=269.13555908 time/batch=0.70s
10301/10943 (epoch 84.717) train_loss=301.58178711 time/batch=0.79s
10302/10943 (epoch 84.725) train_loss=245.12684631 time/batch=0.69s
10303/10943 (epoch 84.733) train_loss=198.58157349 time/batch=0.55s
10304/10943 (epoch 84.741) train_loss=290.41934204 time/batch=0.73s
10305/10943 (epoch 84.749) train_loss=187.54675293 time/batch=0.51s
10306/10943 (epoch 84.758) train_loss=295.99908447 time/batch=0.77s
10307/10943 (epoch 84.766) train_loss=192.96455383 time/batch=0.53s
10308/10943 (epoch 84.774) train_loss=252.26770020 time/batch=0.66s
10309/10943 (epoch 84.782) train_loss=260.74578857 time/batch=0.69s
10310/10943 (epoch 84.791) train_loss=207.58389282 time/batch=0.55s
10311/10943 (epoch 84.799) train_loss=318.65380859 time/batch=0.81s
10312/10943 (epoch 84.807) train_loss=225.95851135 time/batch=0.60s
10313/10943 (epoch 84.815) train_loss=406.54641724 time/batch=0.99s
10314/10943 (epoch 84.823) train_loss=208.20802307 time/batch=0.62s
10315/10943 (epoch 84.832) train_loss=228.44947815 time/batch=0.62s
10316/10943 (epoch 84.840) train_loss=114.18716431 time/batch=0.32s
10317/10943 (epoch 84.848) train_loss=325.91921997 time/batch=0.87s
10318/10943 (epoch 84.856) train_loss=297.58456421 time/batch=0.85s
10319/10943 (epoch 84.865) train_loss=163.98056030 time/batch=0.60s
10320/10943 (epoch 84.873) train_loss=238.67622375 time/batch=0.68s
10321/10943 (epoch 84.881) train_loss=222.96163940 time/batch=0.60s
setting learning rate to 0.0016314
10322/10943 (epoch 84.889) train_loss=218.77781677 time/batch=0.58s
10323/10943 (epoch 84.897) train_loss=144.66494751 time/batch=0.39s
10324/10943 (epoch 84.906) train_loss=426.36526489 time/batch=0.96s
10325/10943 (epoch 84.914) train_loss=460.35595703 time/batch=1.16s
10326/10943 (epoch 84.922) train_loss=309.68200684 time/batch=0.81s
10327/10943 (epoch 84.930) train_loss=93.02131653 time/batch=0.30s
10328/10943 (epoch 84.939) train_loss=461.76751709 time/batch=1.03s
10329/10943 (epoch 84.947) train_loss=545.23004150 time/batch=1.44s
10330/10943 (epoch 84.955) train_loss=125.03025818 time/batch=0.40s
10331/10943 (epoch 84.963) train_loss=379.18511963 time/batch=0.91s
10332/10943 (epoch 84.971) train_loss=714.28350830 time/batch=1.77s
10333/10943 (epoch 84.980) train_loss=638.51660156 time/batch=1.67s
10334/10943 (epoch 84.988) train_loss=544.85076904 time/batch=1.37s
10335/10943 (epoch 84.996) train_loss=479.72906494 time/batch=1.23s
10336/10943 (epoch 85.004) train_loss=438.69696045 time/batch=1.14s
10337/10943 (epoch 85.013) train_loss=429.08447266 time/batch=1.15s
10338/10943 (epoch 85.021) train_loss=383.97576904 time/batch=0.99s
10339/10943 (epoch 85.029) train_loss=345.27236938 time/batch=0.95s
10340/10943 (epoch 85.037) train_loss=850.86444092 time/batch=3.09s
10341/10943 (epoch 85.045) train_loss=437.62915039 time/batch=1.38s
10342/10943 (epoch 85.054) train_loss=152.08520508 time/batch=0.44s
10343/10943 (epoch 85.062) train_loss=259.06359863 time/batch=0.64s
10344/10943 (epoch 85.070) train_loss=161.52705383 time/batch=0.46s
10345/10943 (epoch 85.078) train_loss=189.14245605 time/batch=0.45s
10346/10943 (epoch 85.087) train_loss=320.63702393 time/batch=0.83s
10347/10943 (epoch 85.095) train_loss=130.83996582 time/batch=0.39s
10348/10943 (epoch 85.103) train_loss=172.19375610 time/batch=0.43s
10349/10943 (epoch 85.111) train_loss=260.79519653 time/batch=0.67s
10350/10943 (epoch 85.120) train_loss=262.14050293 time/batch=0.67s
10351/10943 (epoch 85.128) train_loss=284.90609741 time/batch=0.78s
10352/10943 (epoch 85.136) train_loss=348.49392700 time/batch=0.91s
10353/10943 (epoch 85.144) train_loss=227.75494385 time/batch=0.62s
10354/10943 (epoch 85.152) train_loss=281.12039185 time/batch=0.73s
10355/10943 (epoch 85.161) train_loss=154.99150085 time/batch=0.44s
10356/10943 (epoch 85.169) train_loss=425.42803955 time/batch=1.13s
10357/10943 (epoch 85.177) train_loss=227.12672424 time/batch=0.66s
10358/10943 (epoch 85.185) train_loss=111.31027985 time/batch=0.30s
10359/10943 (epoch 85.194) train_loss=302.82928467 time/batch=0.75s
10360/10943 (epoch 85.202) train_loss=205.94590759 time/batch=0.56s
10361/10943 (epoch 85.210) train_loss=379.67401123 time/batch=0.93s
10362/10943 (epoch 85.218) train_loss=172.20999146 time/batch=0.48s
10363/10943 (epoch 85.226) train_loss=263.02590942 time/batch=0.65s
10364/10943 (epoch 85.235) train_loss=542.65447998 time/batch=1.32s
10365/10943 (epoch 85.243) train_loss=263.97760010 time/batch=0.75s
10366/10943 (epoch 85.251) train_loss=383.79470825 time/batch=0.93s
10367/10943 (epoch 85.259) train_loss=307.59521484 time/batch=0.83s
10368/10943 (epoch 85.268) train_loss=421.18811035 time/batch=1.03s
10369/10943 (epoch 85.276) train_loss=360.71899414 time/batch=0.96s
10370/10943 (epoch 85.284) train_loss=118.08135986 time/batch=0.37s
10371/10943 (epoch 85.292) train_loss=148.83932495 time/batch=0.38s
10372/10943 (epoch 85.300) train_loss=490.25921631 time/batch=1.30s
10373/10943 (epoch 85.309) train_loss=322.12982178 time/batch=0.90s
10374/10943 (epoch 85.317) train_loss=288.66131592 time/batch=0.76s
10375/10943 (epoch 85.325) train_loss=352.10577393 time/batch=0.87s
10376/10943 (epoch 85.333) train_loss=264.35955811 time/batch=0.67s
10377/10943 (epoch 85.342) train_loss=169.82824707 time/batch=0.46s
10378/10943 (epoch 85.350) train_loss=209.08334351 time/batch=0.51s
10379/10943 (epoch 85.358) train_loss=171.85354614 time/batch=0.46s
10380/10943 (epoch 85.366) train_loss=141.04721069 time/batch=0.36s
10381/10943 (epoch 85.374) train_loss=267.31262207 time/batch=0.68s
10382/10943 (epoch 85.383) train_loss=292.62268066 time/batch=0.72s
10383/10943 (epoch 85.391) train_loss=198.14846802 time/batch=0.54s
10384/10943 (epoch 85.399) train_loss=344.23513794 time/batch=0.85s
10385/10943 (epoch 85.407) train_loss=346.04693604 time/batch=0.88s
10386/10943 (epoch 85.416) train_loss=206.97799683 time/batch=0.58s
10387/10943 (epoch 85.424) train_loss=276.74542236 time/batch=0.69s
10388/10943 (epoch 85.432) train_loss=212.07249451 time/batch=0.57s
10389/10943 (epoch 85.440) train_loss=253.97544861 time/batch=0.64s
10390/10943 (epoch 85.448) train_loss=280.80303955 time/batch=0.71s
10391/10943 (epoch 85.457) train_loss=209.55297852 time/batch=0.57s
10392/10943 (epoch 85.465) train_loss=264.70605469 time/batch=0.64s
10393/10943 (epoch 85.473) train_loss=254.53576660 time/batch=0.64s
10394/10943 (epoch 85.481) train_loss=184.67593384 time/batch=0.49s
10395/10943 (epoch 85.490) train_loss=289.89105225 time/batch=0.69s
10396/10943 (epoch 85.498) train_loss=303.24166870 time/batch=0.76s
10397/10943 (epoch 85.506) train_loss=311.96618652 time/batch=0.83s
10398/10943 (epoch 85.514) train_loss=212.16549683 time/batch=0.59s
10399/10943 (epoch 85.522) train_loss=166.80511475 time/batch=0.47s
10400/10943 (epoch 85.531) train_loss=192.71066284 time/batch=0.49s
10401/10943 (epoch 85.539) train_loss=285.80422974 time/batch=0.72s
10402/10943 (epoch 85.547) train_loss=112.43643188 time/batch=0.34s
10403/10943 (epoch 85.555) train_loss=290.67828369 time/batch=0.68s
10404/10943 (epoch 85.564) train_loss=392.09231567 time/batch=0.99s
10405/10943 (epoch 85.572) train_loss=129.72773743 time/batch=0.39s
10406/10943 (epoch 85.580) train_loss=162.93750000 time/batch=0.45s
10407/10943 (epoch 85.588) train_loss=422.20043945 time/batch=0.95s
10408/10943 (epoch 85.597) train_loss=269.21984863 time/batch=0.72s
10409/10943 (epoch 85.605) train_loss=224.07778931 time/batch=0.60s
10410/10943 (epoch 85.613) train_loss=296.91082764 time/batch=0.75s
10411/10943 (epoch 85.621) train_loss=178.32269287 time/batch=0.50s
10412/10943 (epoch 85.629) train_loss=389.65618896 time/batch=1.16s
10413/10943 (epoch 85.638) train_loss=229.12556458 time/batch=0.68s
10414/10943 (epoch 85.646) train_loss=272.76412964 time/batch=0.72s
10415/10943 (epoch 85.654) train_loss=336.53375244 time/batch=0.86s
10416/10943 (epoch 85.662) train_loss=133.26431274 time/batch=0.39s
10417/10943 (epoch 85.671) train_loss=237.87065125 time/batch=0.59s
10418/10943 (epoch 85.679) train_loss=372.15649414 time/batch=1.18s
10419/10943 (epoch 85.687) train_loss=174.89437866 time/batch=0.56s
10420/10943 (epoch 85.695) train_loss=225.07232666 time/batch=0.57s
10421/10943 (epoch 85.703) train_loss=233.91271973 time/batch=0.62s
10422/10943 (epoch 85.712) train_loss=204.09249878 time/batch=0.51s
10423/10943 (epoch 85.720) train_loss=169.00537109 time/batch=0.48s
10424/10943 (epoch 85.728) train_loss=291.24060059 time/batch=0.75s
10425/10943 (epoch 85.736) train_loss=236.12879944 time/batch=0.62s
10426/10943 (epoch 85.745) train_loss=306.50579834 time/batch=0.77s
10427/10943 (epoch 85.753) train_loss=300.09423828 time/batch=0.81s
10428/10943 (epoch 85.761) train_loss=268.69354248 time/batch=0.76s
10429/10943 (epoch 85.769) train_loss=332.54321289 time/batch=0.83s
10430/10943 (epoch 85.777) train_loss=191.89727783 time/batch=0.55s
10431/10943 (epoch 85.786) train_loss=326.41305542 time/batch=0.81s
10432/10943 (epoch 85.794) train_loss=194.96846008 time/batch=0.54s
10433/10943 (epoch 85.802) train_loss=312.51132202 time/batch=0.79s
10434/10943 (epoch 85.810) train_loss=137.63540649 time/batch=0.40s
10435/10943 (epoch 85.819) train_loss=235.07604980 time/batch=0.58s
10436/10943 (epoch 85.827) train_loss=227.25952148 time/batch=0.57s
10437/10943 (epoch 85.835) train_loss=301.71508789 time/batch=0.78s
10438/10943 (epoch 85.843) train_loss=235.97789001 time/batch=0.64s
10439/10943 (epoch 85.851) train_loss=229.45037842 time/batch=0.58s
10440/10943 (epoch 85.860) train_loss=214.12161255 time/batch=0.62s
10441/10943 (epoch 85.868) train_loss=268.26535034 time/batch=0.78s
10442/10943 (epoch 85.876) train_loss=247.01988220 time/batch=0.66s
setting learning rate to 0.0015824
  saved to metadata/gru_dropout-9_nov_folkwiki-20181207-173447_epoch41.pkl
10443/10943 (epoch 85.884) train_loss=540.09704590 time/batch=1.32s
10444/10943 (epoch 85.893) train_loss=918.85205078 time/batch=3.14s
10445/10943 (epoch 85.901) train_loss=439.59057617 time/batch=1.29s
10446/10943 (epoch 85.909) train_loss=127.67439270 time/batch=0.40s
10447/10943 (epoch 85.917) train_loss=207.42413330 time/batch=0.50s
10448/10943 (epoch 85.925) train_loss=335.64550781 time/batch=0.82s
10449/10943 (epoch 85.934) train_loss=390.70568848 time/batch=1.00s
10450/10943 (epoch 85.942) train_loss=460.98013306 time/batch=1.17s
10451/10943 (epoch 85.950) train_loss=104.64134216 time/batch=0.35s
10452/10943 (epoch 85.958) train_loss=399.84045410 time/batch=0.90s
10453/10943 (epoch 85.967) train_loss=153.47573853 time/batch=0.47s
10454/10943 (epoch 85.975) train_loss=348.20794678 time/batch=0.87s
10455/10943 (epoch 85.983) train_loss=287.37295532 time/batch=0.76s
10456/10943 (epoch 85.991) train_loss=456.45367432 time/batch=1.08s
10457/10943 (epoch 85.999) train_loss=296.98785400 time/batch=0.80s
10458/10943 (epoch 86.008) train_loss=223.53195190 time/batch=0.61s
10459/10943 (epoch 86.016) train_loss=261.07699585 time/batch=0.66s
10460/10943 (epoch 86.024) train_loss=352.72070312 time/batch=0.87s
10461/10943 (epoch 86.032) train_loss=155.13769531 time/batch=0.44s
10462/10943 (epoch 86.041) train_loss=506.76495361 time/batch=1.14s
10463/10943 (epoch 86.049) train_loss=547.35168457 time/batch=1.42s
10464/10943 (epoch 86.057) train_loss=237.81854248 time/batch=0.71s
10465/10943 (epoch 86.065) train_loss=329.35449219 time/batch=0.83s
10466/10943 (epoch 86.074) train_loss=692.42022705 time/batch=1.66s
10467/10943 (epoch 86.082) train_loss=186.11911011 time/batch=0.60s
10468/10943 (epoch 86.090) train_loss=608.46105957 time/batch=1.49s
10469/10943 (epoch 86.098) train_loss=501.89080811 time/batch=1.36s
10470/10943 (epoch 86.106) train_loss=248.26383972 time/batch=0.70s
10471/10943 (epoch 86.115) train_loss=222.46289062 time/batch=0.59s
10472/10943 (epoch 86.123) train_loss=166.95393372 time/batch=0.43s
10473/10943 (epoch 86.131) train_loss=483.98089600 time/batch=1.24s
10474/10943 (epoch 86.139) train_loss=238.27436829 time/batch=0.69s
10475/10943 (epoch 86.148) train_loss=504.45489502 time/batch=1.40s
10476/10943 (epoch 86.156) train_loss=409.03149414 time/batch=1.11s
10477/10943 (epoch 86.164) train_loss=202.22888184 time/batch=0.56s
10478/10943 (epoch 86.172) train_loss=436.27850342 time/batch=1.08s
10479/10943 (epoch 86.180) train_loss=291.36383057 time/batch=0.82s
10480/10943 (epoch 86.189) train_loss=162.17677307 time/batch=0.47s
10481/10943 (epoch 86.197) train_loss=344.69488525 time/batch=0.85s
10482/10943 (epoch 86.205) train_loss=222.40307617 time/batch=0.62s
10483/10943 (epoch 86.213) train_loss=433.26861572 time/batch=1.05s
10484/10943 (epoch 86.222) train_loss=193.55194092 time/batch=0.56s
10485/10943 (epoch 86.230) train_loss=417.19378662 time/batch=0.97s
10486/10943 (epoch 86.238) train_loss=121.94734955 time/batch=0.38s
10487/10943 (epoch 86.246) train_loss=297.24856567 time/batch=0.72s
10488/10943 (epoch 86.254) train_loss=133.13945007 time/batch=0.38s
10489/10943 (epoch 86.263) train_loss=444.28723145 time/batch=1.03s
10490/10943 (epoch 86.271) train_loss=296.27545166 time/batch=0.84s
10491/10943 (epoch 86.279) train_loss=373.01690674 time/batch=0.95s
10492/10943 (epoch 86.287) train_loss=302.47631836 time/batch=0.82s
10493/10943 (epoch 86.296) train_loss=282.02310181 time/batch=0.76s
10494/10943 (epoch 86.304) train_loss=232.04272461 time/batch=0.61s
10495/10943 (epoch 86.312) train_loss=256.81869507 time/batch=0.66s
10496/10943 (epoch 86.320) train_loss=206.69422913 time/batch=0.56s
10497/10943 (epoch 86.328) train_loss=202.55172729 time/batch=0.52s
10498/10943 (epoch 86.337) train_loss=209.90106201 time/batch=0.55s
10499/10943 (epoch 86.345) train_loss=283.12060547 time/batch=0.71s
10500/10943 (epoch 86.353) train_loss=281.40802002 time/batch=0.71s
10501/10943 (epoch 86.361) train_loss=144.74496460 time/batch=0.40s
10502/10943 (epoch 86.370) train_loss=261.99734497 time/batch=0.65s
10503/10943 (epoch 86.378) train_loss=303.83709717 time/batch=0.77s
10504/10943 (epoch 86.386) train_loss=322.55224609 time/batch=0.85s
10505/10943 (epoch 86.394) train_loss=362.55709839 time/batch=0.94s
10506/10943 (epoch 86.402) train_loss=194.87927246 time/batch=0.56s
10507/10943 (epoch 86.411) train_loss=374.63836670 time/batch=0.91s
10508/10943 (epoch 86.419) train_loss=109.76800537 time/batch=0.35s
10509/10943 (epoch 86.427) train_loss=136.75134277 time/batch=0.33s
10510/10943 (epoch 86.435) train_loss=162.04724121 time/batch=0.42s
10511/10943 (epoch 86.444) train_loss=300.39871216 time/batch=0.74s
10512/10943 (epoch 86.452) train_loss=234.19981384 time/batch=0.63s
10513/10943 (epoch 86.460) train_loss=382.30282593 time/batch=0.95s
10514/10943 (epoch 86.468) train_loss=121.76994324 time/batch=0.36s
10515/10943 (epoch 86.476) train_loss=288.25677490 time/batch=0.71s
10516/10943 (epoch 86.485) train_loss=190.79545593 time/batch=0.53s
10517/10943 (epoch 86.493) train_loss=355.97055054 time/batch=0.92s
10518/10943 (epoch 86.501) train_loss=203.34375000 time/batch=0.59s
10519/10943 (epoch 86.509) train_loss=277.63665771 time/batch=0.70s
10520/10943 (epoch 86.518) train_loss=235.54135132 time/batch=0.64s
10521/10943 (epoch 86.526) train_loss=305.99014282 time/batch=0.78s
10522/10943 (epoch 86.534) train_loss=364.42926025 time/batch=0.97s
10523/10943 (epoch 86.542) train_loss=270.27416992 time/batch=0.70s
10524/10943 (epoch 86.551) train_loss=268.73809814 time/batch=0.66s
10525/10943 (epoch 86.559) train_loss=260.22793579 time/batch=0.66s
10526/10943 (epoch 86.567) train_loss=169.45498657 time/batch=0.47s
10527/10943 (epoch 86.575) train_loss=191.26538086 time/batch=0.47s
10528/10943 (epoch 86.583) train_loss=141.18069458 time/batch=0.36s
10529/10943 (epoch 86.592) train_loss=322.59197998 time/batch=0.81s
10530/10943 (epoch 86.600) train_loss=124.31791687 time/batch=0.40s
10531/10943 (epoch 86.608) train_loss=177.67851257 time/batch=0.46s
10532/10943 (epoch 86.616) train_loss=250.35159302 time/batch=0.62s
10533/10943 (epoch 86.625) train_loss=216.30996704 time/batch=0.59s
10534/10943 (epoch 86.633) train_loss=301.31390381 time/batch=0.78s
10535/10943 (epoch 86.641) train_loss=218.74200439 time/batch=0.58s
10536/10943 (epoch 86.649) train_loss=214.37820435 time/batch=0.56s
10537/10943 (epoch 86.657) train_loss=340.49905396 time/batch=0.84s
10538/10943 (epoch 86.666) train_loss=265.31530762 time/batch=0.70s
10539/10943 (epoch 86.674) train_loss=342.38507080 time/batch=0.86s
10540/10943 (epoch 86.682) train_loss=191.16543579 time/batch=0.51s
10541/10943 (epoch 86.690) train_loss=110.96951294 time/batch=0.36s
10542/10943 (epoch 86.699) train_loss=329.27014160 time/batch=0.84s
10543/10943 (epoch 86.707) train_loss=310.51132202 time/batch=0.83s
10544/10943 (epoch 86.715) train_loss=285.27401733 time/batch=0.75s
10545/10943 (epoch 86.723) train_loss=232.21035767 time/batch=0.64s
10546/10943 (epoch 86.731) train_loss=257.30270386 time/batch=0.64s
10547/10943 (epoch 86.740) train_loss=235.05830383 time/batch=0.61s
10548/10943 (epoch 86.748) train_loss=222.94059753 time/batch=0.59s
10549/10943 (epoch 86.756) train_loss=187.24853516 time/batch=0.49s
10550/10943 (epoch 86.764) train_loss=252.76925659 time/batch=0.64s
10551/10943 (epoch 86.773) train_loss=148.91885376 time/batch=0.40s
10552/10943 (epoch 86.781) train_loss=305.89276123 time/batch=0.76s
10553/10943 (epoch 86.789) train_loss=190.12838745 time/batch=0.59s
10554/10943 (epoch 86.797) train_loss=282.95874023 time/batch=0.72s
10555/10943 (epoch 86.805) train_loss=175.18107605 time/batch=0.59s
10556/10943 (epoch 86.814) train_loss=309.71322632 time/batch=0.79s
10557/10943 (epoch 86.822) train_loss=306.94445801 time/batch=0.82s
10558/10943 (epoch 86.830) train_loss=147.06500244 time/batch=0.44s
10559/10943 (epoch 86.838) train_loss=296.51654053 time/batch=0.67s
10560/10943 (epoch 86.847) train_loss=164.06085205 time/batch=0.57s
10561/10943 (epoch 86.855) train_loss=254.21600342 time/batch=0.66s
10562/10943 (epoch 86.863) train_loss=219.87101746 time/batch=0.57s
10563/10943 (epoch 86.871) train_loss=248.49066162 time/batch=0.68s
setting learning rate to 0.0015350
10564/10943 (epoch 86.879) train_loss=349.13122559 time/batch=0.91s
10565/10943 (epoch 86.888) train_loss=454.01696777 time/batch=1.11s
10566/10943 (epoch 86.896) train_loss=743.83911133 time/batch=1.92s
10567/10943 (epoch 86.904) train_loss=301.78558350 time/batch=0.90s
10568/10943 (epoch 86.912) train_loss=359.09069824 time/batch=0.89s
10569/10943 (epoch 86.921) train_loss=509.88510132 time/batch=1.26s
10570/10943 (epoch 86.929) train_loss=563.97302246 time/batch=1.37s
10571/10943 (epoch 86.937) train_loss=482.04592896 time/batch=1.23s
10572/10943 (epoch 86.945) train_loss=546.57885742 time/batch=1.40s
10573/10943 (epoch 86.953) train_loss=302.86206055 time/batch=0.86s
10574/10943 (epoch 86.962) train_loss=106.46515656 time/batch=0.32s
10575/10943 (epoch 86.970) train_loss=426.39105225 time/batch=1.02s
10576/10943 (epoch 86.978) train_loss=457.77893066 time/batch=1.18s
10577/10943 (epoch 86.986) train_loss=571.74176025 time/batch=1.53s
10578/10943 (epoch 86.995) train_loss=393.06433105 time/batch=1.07s
10579/10943 (epoch 87.003) train_loss=503.24978638 time/batch=1.22s
10580/10943 (epoch 87.011) train_loss=269.90283203 time/batch=0.71s
10581/10943 (epoch 87.019) train_loss=155.74996948 time/batch=0.43s
10582/10943 (epoch 87.027) train_loss=138.35351562 time/batch=0.36s
10583/10943 (epoch 87.036) train_loss=259.80581665 time/batch=0.62s
10584/10943 (epoch 87.044) train_loss=860.48181152 time/batch=3.06s
10585/10943 (epoch 87.052) train_loss=137.49130249 time/batch=0.64s
10586/10943 (epoch 87.060) train_loss=284.67996216 time/batch=0.66s
10587/10943 (epoch 87.069) train_loss=142.36734009 time/batch=0.37s
10588/10943 (epoch 87.077) train_loss=374.61267090 time/batch=0.92s
10589/10943 (epoch 87.085) train_loss=187.97802734 time/batch=0.53s
10590/10943 (epoch 87.093) train_loss=249.17524719 time/batch=0.63s
10591/10943 (epoch 87.102) train_loss=257.90380859 time/batch=0.67s
10592/10943 (epoch 87.110) train_loss=535.09106445 time/batch=1.53s
10593/10943 (epoch 87.118) train_loss=374.07324219 time/batch=1.06s
10594/10943 (epoch 87.126) train_loss=337.72082520 time/batch=0.89s
10595/10943 (epoch 87.134) train_loss=259.33642578 time/batch=0.70s
10596/10943 (epoch 87.143) train_loss=277.23001099 time/batch=0.73s
10597/10943 (epoch 87.151) train_loss=221.71560669 time/batch=0.58s
10598/10943 (epoch 87.159) train_loss=272.86358643 time/batch=0.69s
10599/10943 (epoch 87.167) train_loss=437.55438232 time/batch=1.09s
10600/10943 (epoch 87.176) train_loss=338.09863281 time/batch=0.88s
10601/10943 (epoch 87.184) train_loss=221.91442871 time/batch=0.62s
10602/10943 (epoch 87.192) train_loss=260.11666870 time/batch=0.66s
10603/10943 (epoch 87.200) train_loss=196.65396118 time/batch=0.50s
10604/10943 (epoch 87.208) train_loss=119.17991638 time/batch=0.31s
10605/10943 (epoch 87.217) train_loss=164.11706543 time/batch=0.41s
10606/10943 (epoch 87.225) train_loss=289.31970215 time/batch=0.71s
10607/10943 (epoch 87.233) train_loss=441.99707031 time/batch=1.11s
10608/10943 (epoch 87.241) train_loss=196.14865112 time/batch=0.58s
10609/10943 (epoch 87.250) train_loss=185.30371094 time/batch=0.48s
10610/10943 (epoch 87.258) train_loss=155.98056030 time/batch=0.41s
10611/10943 (epoch 87.266) train_loss=264.68194580 time/batch=0.66s
10612/10943 (epoch 87.274) train_loss=225.70208740 time/batch=0.60s
10613/10943 (epoch 87.282) train_loss=169.14613342 time/batch=0.45s
10614/10943 (epoch 87.291) train_loss=226.97895813 time/batch=0.55s
10615/10943 (epoch 87.299) train_loss=379.18194580 time/batch=0.91s
10616/10943 (epoch 87.307) train_loss=411.65258789 time/batch=1.01s
10617/10943 (epoch 87.315) train_loss=263.02505493 time/batch=0.73s
10618/10943 (epoch 87.324) train_loss=422.41888428 time/batch=1.00s
10619/10943 (epoch 87.332) train_loss=214.17243958 time/batch=0.61s
10620/10943 (epoch 87.340) train_loss=194.08178711 time/batch=0.52s
10621/10943 (epoch 87.348) train_loss=298.60513306 time/batch=0.76s
10622/10943 (epoch 87.356) train_loss=170.76844788 time/batch=0.48s
10623/10943 (epoch 87.365) train_loss=298.89254761 time/batch=0.77s
10624/10943 (epoch 87.373) train_loss=107.74781799 time/batch=0.34s
10625/10943 (epoch 87.381) train_loss=298.10910034 time/batch=0.73s
10626/10943 (epoch 87.389) train_loss=295.51928711 time/batch=0.76s
10627/10943 (epoch 87.398) train_loss=320.65762329 time/batch=0.82s
10628/10943 (epoch 87.406) train_loss=307.96310425 time/batch=0.77s
10629/10943 (epoch 87.414) train_loss=117.19247437 time/batch=0.34s
10630/10943 (epoch 87.422) train_loss=410.93859863 time/batch=0.96s
10631/10943 (epoch 87.430) train_loss=184.28213501 time/batch=0.53s
10632/10943 (epoch 87.439) train_loss=407.91241455 time/batch=0.99s
10633/10943 (epoch 87.447) train_loss=314.33166504 time/batch=0.85s
10634/10943 (epoch 87.455) train_loss=289.30484009 time/batch=0.72s
10635/10943 (epoch 87.463) train_loss=138.12179565 time/batch=0.40s
10636/10943 (epoch 87.472) train_loss=106.45575714 time/batch=0.31s
10637/10943 (epoch 87.480) train_loss=193.50396729 time/batch=0.48s
10638/10943 (epoch 87.488) train_loss=216.61763000 time/batch=0.58s
10639/10943 (epoch 87.496) train_loss=369.11151123 time/batch=0.91s
10640/10943 (epoch 87.504) train_loss=224.40397644 time/batch=0.62s
10641/10943 (epoch 87.513) train_loss=375.56164551 time/batch=0.92s
10642/10943 (epoch 87.521) train_loss=264.98309326 time/batch=0.72s
10643/10943 (epoch 87.529) train_loss=258.38504028 time/batch=0.66s
10644/10943 (epoch 87.537) train_loss=131.31845093 time/batch=0.37s
10645/10943 (epoch 87.546) train_loss=179.06361389 time/batch=0.44s
10646/10943 (epoch 87.554) train_loss=167.66534424 time/batch=0.42s
10647/10943 (epoch 87.562) train_loss=265.52435303 time/batch=0.66s
10648/10943 (epoch 87.570) train_loss=128.01000977 time/batch=0.37s
10649/10943 (epoch 87.579) train_loss=237.40242004 time/batch=0.59s
10650/10943 (epoch 87.587) train_loss=359.02508545 time/batch=0.86s
10651/10943 (epoch 87.595) train_loss=237.45779419 time/batch=0.65s
10652/10943 (epoch 87.603) train_loss=274.70550537 time/batch=0.73s
10653/10943 (epoch 87.611) train_loss=173.99108887 time/batch=0.48s
10654/10943 (epoch 87.620) train_loss=253.67997742 time/batch=0.61s
10655/10943 (epoch 87.628) train_loss=225.78707886 time/batch=0.62s
10656/10943 (epoch 87.636) train_loss=167.21896362 time/batch=0.47s
10657/10943 (epoch 87.644) train_loss=342.00921631 time/batch=0.83s
10658/10943 (epoch 87.653) train_loss=196.60763550 time/batch=0.54s
10659/10943 (epoch 87.661) train_loss=283.25335693 time/batch=0.70s
10660/10943 (epoch 87.669) train_loss=230.28788757 time/batch=0.62s
10661/10943 (epoch 87.677) train_loss=285.55249023 time/batch=0.71s
10662/10943 (epoch 87.685) train_loss=230.16897583 time/batch=0.61s
10663/10943 (epoch 87.694) train_loss=190.33305359 time/batch=0.53s
10664/10943 (epoch 87.702) train_loss=297.13272095 time/batch=0.76s
10665/10943 (epoch 87.710) train_loss=254.04919434 time/batch=0.68s
10666/10943 (epoch 87.718) train_loss=210.71762085 time/batch=0.55s
10667/10943 (epoch 87.727) train_loss=290.24197388 time/batch=0.76s
10668/10943 (epoch 87.735) train_loss=205.79325867 time/batch=0.58s
10669/10943 (epoch 87.743) train_loss=143.37724304 time/batch=0.39s
10670/10943 (epoch 87.751) train_loss=336.18493652 time/batch=0.80s
10671/10943 (epoch 87.759) train_loss=214.20063782 time/batch=0.59s
10672/10943 (epoch 87.768) train_loss=296.76248169 time/batch=0.78s
10673/10943 (epoch 87.776) train_loss=228.37016296 time/batch=0.62s
10674/10943 (epoch 87.784) train_loss=336.82888794 time/batch=0.88s
10675/10943 (epoch 87.792) train_loss=303.90036011 time/batch=0.82s
10676/10943 (epoch 87.801) train_loss=151.94125366 time/batch=0.41s
10677/10943 (epoch 87.809) train_loss=158.76745605 time/batch=0.51s
10678/10943 (epoch 87.817) train_loss=326.06805420 time/batch=0.79s
10679/10943 (epoch 87.825) train_loss=325.69595337 time/batch=0.85s
10680/10943 (epoch 87.833) train_loss=300.45056152 time/batch=0.82s
10681/10943 (epoch 87.842) train_loss=326.39657593 time/batch=0.85s
10682/10943 (epoch 87.850) train_loss=206.76394653 time/batch=0.61s
10683/10943 (epoch 87.858) train_loss=228.36120605 time/batch=0.59s
10684/10943 (epoch 87.866) train_loss=238.79167175 time/batch=0.62s
setting learning rate to 0.0014889
  saved to metadata/gru_dropout-9_nov_folkwiki-20181207-173447_epoch43.pkl
10685/10943 (epoch 87.875) train_loss=150.77676392 time/batch=0.48s
10686/10943 (epoch 87.883) train_loss=335.54837036 time/batch=0.80s
10687/10943 (epoch 87.891) train_loss=554.26025391 time/batch=1.33s
10688/10943 (epoch 87.899) train_loss=912.35217285 time/batch=3.13s
10689/10943 (epoch 87.907) train_loss=596.04565430 time/batch=1.72s
10690/10943 (epoch 87.916) train_loss=428.46228027 time/batch=1.06s
10691/10943 (epoch 87.924) train_loss=120.67518616 time/batch=0.36s
10692/10943 (epoch 87.932) train_loss=492.76440430 time/batch=1.16s
10693/10943 (epoch 87.940) train_loss=534.64770508 time/batch=1.52s
10694/10943 (epoch 87.949) train_loss=168.31649780 time/batch=0.57s
10695/10943 (epoch 87.957) train_loss=411.11343384 time/batch=1.00s
10696/10943 (epoch 87.965) train_loss=96.57471466 time/batch=0.33s
10697/10943 (epoch 87.973) train_loss=489.40350342 time/batch=1.13s
10698/10943 (epoch 87.981) train_loss=350.25024414 time/batch=0.92s
10699/10943 (epoch 87.990) train_loss=461.45251465 time/batch=1.16s
10700/10943 (epoch 87.998) train_loss=148.20010376 time/batch=0.45s
10701/10943 (epoch 88.006) train_loss=164.61889648 time/batch=0.42s
10702/10943 (epoch 88.014) train_loss=408.25579834 time/batch=0.97s
10703/10943 (epoch 88.023) train_loss=268.36083984 time/batch=0.75s
10704/10943 (epoch 88.031) train_loss=682.06622314 time/batch=1.65s
10705/10943 (epoch 88.039) train_loss=270.68087769 time/batch=0.81s
10706/10943 (epoch 88.047) train_loss=123.17287445 time/batch=0.34s
10707/10943 (epoch 88.056) train_loss=211.24887085 time/batch=0.53s
10708/10943 (epoch 88.064) train_loss=343.62823486 time/batch=0.85s
10709/10943 (epoch 88.072) train_loss=188.45254517 time/batch=0.52s
10710/10943 (epoch 88.080) train_loss=256.35961914 time/batch=0.66s
10711/10943 (epoch 88.088) train_loss=382.43716431 time/batch=0.93s
10712/10943 (epoch 88.097) train_loss=372.92050171 time/batch=0.98s
10713/10943 (epoch 88.105) train_loss=105.89898682 time/batch=0.35s
10714/10943 (epoch 88.113) train_loss=445.76763916 time/batch=1.04s
10715/10943 (epoch 88.121) train_loss=279.10833740 time/batch=0.75s
10716/10943 (epoch 88.130) train_loss=198.25030518 time/batch=0.53s
10717/10943 (epoch 88.138) train_loss=350.38665771 time/batch=0.87s
10718/10943 (epoch 88.146) train_loss=377.20336914 time/batch=0.99s
10719/10943 (epoch 88.154) train_loss=196.15982056 time/batch=0.58s
10720/10943 (epoch 88.162) train_loss=446.84912109 time/batch=1.07s
10721/10943 (epoch 88.171) train_loss=299.59497070 time/batch=0.80s
10722/10943 (epoch 88.179) train_loss=594.95617676 time/batch=1.53s
10723/10943 (epoch 88.187) train_loss=447.52301025 time/batch=1.21s
10724/10943 (epoch 88.195) train_loss=292.81381226 time/batch=0.78s
10725/10943 (epoch 88.204) train_loss=192.30616760 time/batch=0.54s
10726/10943 (epoch 88.212) train_loss=205.72354126 time/batch=0.54s
10727/10943 (epoch 88.220) train_loss=424.33398438 time/batch=1.13s
10728/10943 (epoch 88.228) train_loss=154.97238159 time/batch=0.48s
10729/10943 (epoch 88.236) train_loss=297.40081787 time/batch=0.75s
10730/10943 (epoch 88.245) train_loss=255.14825439 time/batch=0.68s
10731/10943 (epoch 88.253) train_loss=115.44885254 time/batch=0.34s
10732/10943 (epoch 88.261) train_loss=220.47067261 time/batch=0.56s
10733/10943 (epoch 88.269) train_loss=317.48760986 time/batch=0.82s
10734/10943 (epoch 88.278) train_loss=313.37509155 time/batch=0.83s
10735/10943 (epoch 88.286) train_loss=350.38034058 time/batch=0.89s
10736/10943 (epoch 88.294) train_loss=328.62011719 time/batch=0.85s
10737/10943 (epoch 88.302) train_loss=298.22842407 time/batch=0.76s
10738/10943 (epoch 88.310) train_loss=292.23635864 time/batch=0.80s
10739/10943 (epoch 88.319) train_loss=156.09146118 time/batch=0.45s
10740/10943 (epoch 88.327) train_loss=298.55212402 time/batch=0.77s
10741/10943 (epoch 88.335) train_loss=118.79071045 time/batch=0.36s
10742/10943 (epoch 88.343) train_loss=232.37754822 time/batch=0.57s
10743/10943 (epoch 88.352) train_loss=176.57723999 time/batch=0.48s
10744/10943 (epoch 88.360) train_loss=236.98765564 time/batch=0.60s
10745/10943 (epoch 88.368) train_loss=220.62051392 time/batch=0.59s
10746/10943 (epoch 88.376) train_loss=183.19491577 time/batch=0.49s
10747/10943 (epoch 88.384) train_loss=306.45709229 time/batch=0.75s
10748/10943 (epoch 88.393) train_loss=314.92407227 time/batch=0.84s
10749/10943 (epoch 88.401) train_loss=140.89140320 time/batch=0.42s
10750/10943 (epoch 88.409) train_loss=190.93911743 time/batch=0.47s
10751/10943 (epoch 88.417) train_loss=257.01766968 time/batch=0.65s
10752/10943 (epoch 88.426) train_loss=144.50250244 time/batch=0.40s
10753/10943 (epoch 88.434) train_loss=305.99035645 time/batch=0.73s
10754/10943 (epoch 88.442) train_loss=356.08093262 time/batch=0.93s
10755/10943 (epoch 88.450) train_loss=434.19326782 time/batch=1.03s
10756/10943 (epoch 88.458) train_loss=385.59970093 time/batch=1.03s
10757/10943 (epoch 88.467) train_loss=279.90267944 time/batch=0.77s
10758/10943 (epoch 88.475) train_loss=433.80471802 time/batch=1.18s
10759/10943 (epoch 88.483) train_loss=385.06024170 time/batch=1.27s
10760/10943 (epoch 88.491) train_loss=295.28076172 time/batch=0.83s
10761/10943 (epoch 88.500) train_loss=296.76831055 time/batch=0.78s
10762/10943 (epoch 88.508) train_loss=227.14616394 time/batch=0.63s
10763/10943 (epoch 88.516) train_loss=172.98506165 time/batch=0.45s
10764/10943 (epoch 88.524) train_loss=187.19107056 time/batch=0.45s
10765/10943 (epoch 88.533) train_loss=136.72644043 time/batch=0.34s
10766/10943 (epoch 88.541) train_loss=274.00610352 time/batch=0.62s
10767/10943 (epoch 88.549) train_loss=239.52812195 time/batch=0.63s
10768/10943 (epoch 88.557) train_loss=250.74324036 time/batch=0.63s
10769/10943 (epoch 88.565) train_loss=296.90338135 time/batch=0.79s
10770/10943 (epoch 88.574) train_loss=269.57794189 time/batch=0.71s
10771/10943 (epoch 88.582) train_loss=282.74597168 time/batch=0.73s
10772/10943 (epoch 88.590) train_loss=178.74461365 time/batch=0.52s
10773/10943 (epoch 88.598) train_loss=330.89398193 time/batch=0.81s
10774/10943 (epoch 88.607) train_loss=126.96875763 time/batch=0.37s
10775/10943 (epoch 88.615) train_loss=219.51644897 time/batch=0.51s
10776/10943 (epoch 88.623) train_loss=244.28161621 time/batch=0.62s
10777/10943 (epoch 88.631) train_loss=202.25712585 time/batch=0.54s
10778/10943 (epoch 88.639) train_loss=201.58148193 time/batch=0.54s
10779/10943 (epoch 88.648) train_loss=354.05606079 time/batch=0.87s
10780/10943 (epoch 88.656) train_loss=183.57513428 time/batch=0.53s
10781/10943 (epoch 88.664) train_loss=335.07220459 time/batch=0.83s
10782/10943 (epoch 88.672) train_loss=233.92095947 time/batch=0.64s
10783/10943 (epoch 88.681) train_loss=143.55854797 time/batch=0.36s
10784/10943 (epoch 88.689) train_loss=256.05285645 time/batch=0.61s
10785/10943 (epoch 88.697) train_loss=321.65301514 time/batch=0.84s
10786/10943 (epoch 88.705) train_loss=197.73284912 time/batch=0.53s
10787/10943 (epoch 88.713) train_loss=285.15209961 time/batch=0.68s
10788/10943 (epoch 88.722) train_loss=280.27096558 time/batch=0.76s
10789/10943 (epoch 88.730) train_loss=222.97534180 time/batch=0.60s
10790/10943 (epoch 88.738) train_loss=282.11389160 time/batch=0.69s
10791/10943 (epoch 88.746) train_loss=198.41920471 time/batch=0.57s
10792/10943 (epoch 88.755) train_loss=222.47898865 time/batch=0.58s
10793/10943 (epoch 88.763) train_loss=298.14382935 time/batch=0.78s
10794/10943 (epoch 88.771) train_loss=252.94754028 time/batch=0.71s
10795/10943 (epoch 88.779) train_loss=290.31579590 time/batch=0.73s
10796/10943 (epoch 88.787) train_loss=255.85028076 time/batch=0.66s
10797/10943 (epoch 88.796) train_loss=265.22235107 time/batch=0.72s
10798/10943 (epoch 88.804) train_loss=291.23242188 time/batch=0.86s
10799/10943 (epoch 88.812) train_loss=224.55210876 time/batch=0.60s
10800/10943 (epoch 88.820) train_loss=150.87414551 time/batch=0.55s
10801/10943 (epoch 88.829) train_loss=245.62622070 time/batch=0.64s
10802/10943 (epoch 88.837) train_loss=222.32022095 time/batch=0.57s
10803/10943 (epoch 88.845) train_loss=217.44625854 time/batch=0.58s
10804/10943 (epoch 88.853) train_loss=172.21798706 time/batch=0.59s
10805/10943 (epoch 88.861) train_loss=232.47042847 time/batch=0.59s
setting learning rate to 0.0014443
10806/10943 (epoch 88.870) train_loss=162.84724426 time/batch=0.45s
10807/10943 (epoch 88.878) train_loss=130.60794067 time/batch=0.33s
10808/10943 (epoch 88.886) train_loss=320.75549316 time/batch=0.78s
10809/10943 (epoch 88.894) train_loss=416.70788574 time/batch=1.04s
10810/10943 (epoch 88.903) train_loss=295.24169922 time/batch=0.80s
10811/10943 (epoch 88.911) train_loss=339.64916992 time/batch=0.87s
10812/10943 (epoch 88.919) train_loss=289.40106201 time/batch=0.72s
10813/10943 (epoch 88.927) train_loss=166.94131470 time/batch=0.45s
10814/10943 (epoch 88.935) train_loss=928.42608643 time/batch=3.02s
10815/10943 (epoch 88.944) train_loss=659.85681152 time/batch=1.83s
10816/10943 (epoch 88.952) train_loss=155.15286255 time/batch=0.51s
10817/10943 (epoch 88.960) train_loss=371.53576660 time/batch=0.88s
10818/10943 (epoch 88.968) train_loss=138.77066040 time/batch=0.40s
10819/10943 (epoch 88.977) train_loss=523.11242676 time/batch=1.21s
10820/10943 (epoch 88.985) train_loss=430.48992920 time/batch=1.13s
10821/10943 (epoch 88.993) train_loss=618.66497803 time/batch=1.65s
10822/10943 (epoch 89.001) train_loss=322.94012451 time/batch=0.95s
10823/10943 (epoch 89.010) train_loss=352.83618164 time/batch=0.92s
10824/10943 (epoch 89.018) train_loss=156.81483459 time/batch=0.45s
10825/10943 (epoch 89.026) train_loss=283.80865479 time/batch=0.68s
10826/10943 (epoch 89.034) train_loss=448.85488892 time/batch=1.11s
10827/10943 (epoch 89.042) train_loss=121.21074677 time/batch=0.38s
10828/10943 (epoch 89.051) train_loss=371.68353271 time/batch=0.83s
10829/10943 (epoch 89.059) train_loss=300.37939453 time/batch=0.82s
10830/10943 (epoch 89.067) train_loss=395.64031982 time/batch=1.00s
10831/10943 (epoch 89.075) train_loss=578.39794922 time/batch=1.69s
10832/10943 (epoch 89.084) train_loss=234.01461792 time/batch=0.70s
10833/10943 (epoch 89.092) train_loss=94.80714417 time/batch=0.28s
10834/10943 (epoch 89.100) train_loss=141.50260925 time/batch=0.37s
10835/10943 (epoch 89.108) train_loss=233.91384888 time/batch=0.58s
10836/10943 (epoch 89.116) train_loss=216.81240845 time/batch=0.57s
10837/10943 (epoch 89.125) train_loss=107.21577454 time/batch=0.29s
10838/10943 (epoch 89.133) train_loss=331.26019287 time/batch=0.78s
10839/10943 (epoch 89.141) train_loss=466.96636963 time/batch=1.16s
10840/10943 (epoch 89.149) train_loss=385.39489746 time/batch=1.00s
10841/10943 (epoch 89.158) train_loss=185.28758240 time/batch=0.52s
10842/10943 (epoch 89.166) train_loss=376.51174927 time/batch=0.93s
10843/10943 (epoch 89.174) train_loss=437.42593384 time/batch=1.19s
10844/10943 (epoch 89.182) train_loss=131.49708557 time/batch=0.41s
10845/10943 (epoch 89.190) train_loss=153.02728271 time/batch=0.40s
10846/10943 (epoch 89.199) train_loss=254.47460938 time/batch=0.65s
10847/10943 (epoch 89.207) train_loss=222.87834167 time/batch=0.59s
10848/10943 (epoch 89.215) train_loss=303.02349854 time/batch=0.75s
10849/10943 (epoch 89.223) train_loss=355.09396362 time/batch=0.90s
10850/10943 (epoch 89.232) train_loss=196.04943848 time/batch=0.57s
10851/10943 (epoch 89.240) train_loss=439.44042969 time/batch=1.05s
10852/10943 (epoch 89.248) train_loss=194.37776184 time/batch=0.57s
10853/10943 (epoch 89.256) train_loss=204.36572266 time/batch=0.53s
10854/10943 (epoch 89.264) train_loss=299.55828857 time/batch=0.74s
10855/10943 (epoch 89.273) train_loss=296.36022949 time/batch=0.79s
10856/10943 (epoch 89.281) train_loss=531.93054199 time/batch=1.28s
10857/10943 (epoch 89.289) train_loss=546.16381836 time/batch=1.38s
10858/10943 (epoch 89.297) train_loss=317.70855713 time/batch=0.88s
10859/10943 (epoch 89.306) train_loss=301.36895752 time/batch=0.79s
10860/10943 (epoch 89.314) train_loss=297.04617310 time/batch=0.78s
10861/10943 (epoch 89.322) train_loss=297.25384521 time/batch=0.82s
10862/10943 (epoch 89.330) train_loss=192.88558960 time/batch=0.52s
10863/10943 (epoch 89.338) train_loss=428.67565918 time/batch=0.97s
10864/10943 (epoch 89.347) train_loss=234.45971680 time/batch=0.65s
10865/10943 (epoch 89.355) train_loss=502.80273438 time/batch=1.16s
10866/10943 (epoch 89.363) train_loss=167.65277100 time/batch=0.51s
10867/10943 (epoch 89.371) train_loss=167.67198181 time/batch=0.44s
10868/10943 (epoch 89.380) train_loss=289.20199585 time/batch=0.75s
10869/10943 (epoch 89.388) train_loss=441.57690430 time/batch=1.20s
10870/10943 (epoch 89.396) train_loss=266.73059082 time/batch=0.74s
10871/10943 (epoch 89.404) train_loss=380.54403687 time/batch=0.93s
10872/10943 (epoch 89.412) train_loss=143.71464539 time/batch=0.41s
10873/10943 (epoch 89.421) train_loss=264.91210938 time/batch=0.64s
10874/10943 (epoch 89.429) train_loss=241.35250854 time/batch=0.62s
10875/10943 (epoch 89.437) train_loss=264.66058350 time/batch=0.70s
10876/10943 (epoch 89.445) train_loss=330.48632812 time/batch=0.83s
10877/10943 (epoch 89.454) train_loss=224.55926514 time/batch=0.64s
10878/10943 (epoch 89.462) train_loss=325.17218018 time/batch=0.83s
10879/10943 (epoch 89.470) train_loss=282.30355835 time/batch=0.72s
10880/10943 (epoch 89.478) train_loss=284.19793701 time/batch=0.73s
10881/10943 (epoch 89.487) train_loss=235.17318726 time/batch=0.61s
10882/10943 (epoch 89.495) train_loss=282.12310791 time/batch=0.77s
10883/10943 (epoch 89.503) train_loss=242.73959351 time/batch=0.64s
10884/10943 (epoch 89.511) train_loss=117.99072266 time/batch=0.34s
10885/10943 (epoch 89.519) train_loss=114.69160461 time/batch=0.34s
10886/10943 (epoch 89.528) train_loss=121.94914246 time/batch=0.35s
10887/10943 (epoch 89.536) train_loss=352.71096802 time/batch=0.84s
10888/10943 (epoch 89.544) train_loss=187.59564209 time/batch=0.53s
10889/10943 (epoch 89.552) train_loss=293.52679443 time/batch=0.70s
10890/10943 (epoch 89.561) train_loss=297.91113281 time/batch=0.79s
10891/10943 (epoch 89.569) train_loss=152.75891113 time/batch=0.44s
10892/10943 (epoch 89.577) train_loss=209.28955078 time/batch=0.52s
10893/10943 (epoch 89.585) train_loss=213.47216797 time/batch=0.54s
10894/10943 (epoch 89.593) train_loss=173.58007812 time/batch=0.45s
10895/10943 (epoch 89.602) train_loss=229.38919067 time/batch=0.58s
10896/10943 (epoch 89.610) train_loss=335.61880493 time/batch=0.85s
10897/10943 (epoch 89.618) train_loss=253.53126526 time/batch=0.67s
10898/10943 (epoch 89.626) train_loss=261.51950073 time/batch=0.64s
10899/10943 (epoch 89.635) train_loss=324.53723145 time/batch=0.85s
10900/10943 (epoch 89.643) train_loss=179.33493042 time/batch=0.50s
10901/10943 (epoch 89.651) train_loss=209.94436646 time/batch=0.54s
10902/10943 (epoch 89.659) train_loss=325.96862793 time/batch=0.87s
10903/10943 (epoch 89.667) train_loss=203.88775635 time/batch=0.61s
10904/10943 (epoch 89.676) train_loss=175.51133728 time/batch=0.48s
10905/10943 (epoch 89.684) train_loss=198.29876709 time/batch=0.49s
10906/10943 (epoch 89.692) train_loss=176.77937317 time/batch=0.47s
10907/10943 (epoch 89.700) train_loss=247.16934204 time/batch=0.61s
10908/10943 (epoch 89.709) train_loss=386.18737793 time/batch=0.99s
10909/10943 (epoch 89.717) train_loss=293.23553467 time/batch=0.77s
10910/10943 (epoch 89.725) train_loss=271.50811768 time/batch=0.70s
10911/10943 (epoch 89.733) train_loss=223.73431396 time/batch=0.59s
10912/10943 (epoch 89.741) train_loss=219.61535645 time/batch=0.57s
10913/10943 (epoch 89.750) train_loss=170.37432861 time/batch=0.48s
10914/10943 (epoch 89.758) train_loss=258.97445679 time/batch=0.64s
10915/10943 (epoch 89.766) train_loss=274.03271484 time/batch=0.73s
10916/10943 (epoch 89.774) train_loss=309.56399536 time/batch=0.90s
10917/10943 (epoch 89.783) train_loss=220.20640564 time/batch=0.63s
10918/10943 (epoch 89.791) train_loss=260.89236450 time/batch=0.72s
10919/10943 (epoch 89.799) train_loss=238.96037292 time/batch=0.65s
10920/10943 (epoch 89.807) train_loss=336.32797241 time/batch=1.00s
10921/10943 (epoch 89.815) train_loss=220.70188904 time/batch=0.63s
10922/10943 (epoch 89.824) train_loss=191.49917603 time/batch=0.51s
10923/10943 (epoch 89.832) train_loss=406.90722656 time/batch=0.98s
10924/10943 (epoch 89.840) train_loss=216.07579041 time/batch=0.63s
10925/10943 (epoch 89.848) train_loss=264.80877686 time/batch=0.65s
10926/10943 (epoch 89.857) train_loss=260.32885742 time/batch=0.67s
setting learning rate to 0.0014009
  saved to metadata/gru_dropout-9_nov_folkwiki-20181207-173447_epoch45.pkl
10927/10943 (epoch 89.865) train_loss=649.17065430 time/batch=1.65s
10928/10943 (epoch 89.873) train_loss=224.75018311 time/batch=0.70s
10929/10943 (epoch 89.881) train_loss=547.03149414 time/batch=1.25s
10930/10943 (epoch 89.889) train_loss=616.42883301 time/batch=1.66s
10931/10943 (epoch 89.898) train_loss=121.88880920 time/batch=0.44s
10932/10943 (epoch 89.906) train_loss=95.89765930 time/batch=0.26s
10933/10943 (epoch 89.914) train_loss=387.35839844 time/batch=0.95s
10934/10943 (epoch 89.922) train_loss=545.47711182 time/batch=1.38s
10935/10943 (epoch 89.931) train_loss=432.04296875 time/batch=1.06s
10936/10943 (epoch 89.939) train_loss=336.19763184 time/batch=0.87s
10937/10943 (epoch 89.947) train_loss=157.56500244 time/batch=0.46s
10938/10943 (epoch 89.955) train_loss=234.51300049 time/batch=0.58s
10939/10943 (epoch 89.964) train_loss=920.29296875 time/batch=3.05s
10940/10943 (epoch 89.972) train_loss=297.02526855 time/batch=1.00s
10941/10943 (epoch 89.980) train_loss=326.27566528 time/batch=0.82s
10942/10943 (epoch 89.988) train_loss=133.56646729 time/batch=0.38s
10943/10943 (epoch 89.996) train_loss=125.08876038 time/batch=0.33s
10944/10943 (epoch 90.005) train_loss=213.61791992 time/batch=0.53s
10945/10943 (epoch 90.013) train_loss=378.78546143 time/batch=0.95s
10946/10943 (epoch 90.021) train_loss=106.64935303 time/batch=0.35s
10947/10943 (epoch 90.029) train_loss=332.61804199 time/batch=0.79s
10948/10943 (epoch 90.038) train_loss=119.88876343 time/batch=0.35s
10949/10943 (epoch 90.046) train_loss=226.07009888 time/batch=0.53s
10950/10943 (epoch 90.054) train_loss=350.17248535 time/batch=0.90s
10951/10943 (epoch 90.062) train_loss=244.77644348 time/batch=0.67s
10952/10943 (epoch 90.070) train_loss=475.78173828 time/batch=1.16s
10953/10943 (epoch 90.079) train_loss=285.07800293 time/batch=0.78s
10954/10943 (epoch 90.087) train_loss=381.57659912 time/batch=0.92s
10955/10943 (epoch 90.095) train_loss=222.20210266 time/batch=0.63s
10956/10943 (epoch 90.103) train_loss=318.27331543 time/batch=0.79s
10957/10943 (epoch 90.112) train_loss=457.83312988 time/batch=1.14s
10958/10943 (epoch 90.120) train_loss=186.05227661 time/batch=0.54s
10959/10943 (epoch 90.128) train_loss=438.29644775 time/batch=1.04s
10960/10943 (epoch 90.136) train_loss=134.36032104 time/batch=0.43s
10961/10943 (epoch 90.144) train_loss=261.37176514 time/batch=0.65s
10962/10943 (epoch 90.153) train_loss=143.67230225 time/batch=0.40s
10963/10943 (epoch 90.161) train_loss=192.97451782 time/batch=0.50s
10964/10943 (epoch 90.169) train_loss=438.42767334 time/batch=1.07s
10965/10943 (epoch 90.177) train_loss=530.37976074 time/batch=1.40s
10966/10943 (epoch 90.186) train_loss=267.68643188 time/batch=0.77s
10967/10943 (epoch 90.194) train_loss=208.53578186 time/batch=0.56s
10968/10943 (epoch 90.202) train_loss=232.76394653 time/batch=0.59s
10969/10943 (epoch 90.210) train_loss=323.21276855 time/batch=0.82s
10970/10943 (epoch 90.218) train_loss=262.52468872 time/batch=0.71s
10971/10943 (epoch 90.227) train_loss=147.41522217 time/batch=0.42s
10972/10943 (epoch 90.235) train_loss=110.91656494 time/batch=0.31s
10973/10943 (epoch 90.243) train_loss=297.61267090 time/batch=0.72s
10974/10943 (epoch 90.251) train_loss=233.89926147 time/batch=0.64s
10975/10943 (epoch 90.260) train_loss=139.09103394 time/batch=0.40s
10976/10943 (epoch 90.268) train_loss=241.58529663 time/batch=0.59s
10977/10943 (epoch 90.276) train_loss=214.02626038 time/batch=0.54s
10978/10943 (epoch 90.284) train_loss=368.66278076 time/batch=0.85s
10979/10943 (epoch 90.292) train_loss=185.03724670 time/batch=0.51s
10980/10943 (epoch 90.301) train_loss=259.89334106 time/batch=0.65s
10981/10943 (epoch 90.309) train_loss=354.58715820 time/batch=0.88s
10982/10943 (epoch 90.317) train_loss=569.77148438 time/batch=1.68s
10983/10943 (epoch 90.325) train_loss=293.19555664 time/batch=0.91s
10984/10943 (epoch 90.334) train_loss=388.87069702 time/batch=1.01s
10985/10943 (epoch 90.342) train_loss=164.47518921 time/batch=0.49s
10986/10943 (epoch 90.350) train_loss=229.47283936 time/batch=0.59s
10987/10943 (epoch 90.358) train_loss=298.56353760 time/batch=0.76s
10988/10943 (epoch 90.366) train_loss=427.62597656 time/batch=1.05s
10989/10943 (epoch 90.375) train_loss=264.24829102 time/batch=0.71s
10990/10943 (epoch 90.383) train_loss=280.06634521 time/batch=0.74s
10991/10943 (epoch 90.391) train_loss=208.45938110 time/batch=0.58s
10992/10943 (epoch 90.399) train_loss=189.46075439 time/batch=0.52s
10993/10943 (epoch 90.408) train_loss=156.71948242 time/batch=0.40s
10994/10943 (epoch 90.416) train_loss=280.67486572 time/batch=0.68s
10995/10943 (epoch 90.424) train_loss=131.46994019 time/batch=0.37s
10996/10943 (epoch 90.432) train_loss=154.06527710 time/batch=0.40s
10997/10943 (epoch 90.441) train_loss=165.82369995 time/batch=0.43s
10998/10943 (epoch 90.449) train_loss=300.67922974 time/batch=0.72s
10999/10943 (epoch 90.457) train_loss=198.18316650 time/batch=0.55s
Validating
    loss:	274.410578

11000/10943 (epoch 90.465) train_loss=183.95507812 time/batch=2.31s
11001/10943 (epoch 90.473) train_loss=139.41661072 time/batch=0.35s
11002/10943 (epoch 90.482) train_loss=168.64489746 time/batch=0.43s
11003/10943 (epoch 90.490) train_loss=313.97082520 time/batch=0.80s
11004/10943 (epoch 90.498) train_loss=332.44821167 time/batch=0.87s
11005/10943 (epoch 90.506) train_loss=310.08856201 time/batch=0.79s
11006/10943 (epoch 90.515) train_loss=302.52825928 time/batch=0.79s
11007/10943 (epoch 90.523) train_loss=422.01528931 time/batch=1.03s
11008/10943 (epoch 90.531) train_loss=480.26177979 time/batch=1.21s
11009/10943 (epoch 90.539) train_loss=194.06385803 time/batch=0.59s
11010/10943 (epoch 90.547) train_loss=403.11431885 time/batch=1.00s
11011/10943 (epoch 90.556) train_loss=405.03741455 time/batch=1.10s
11012/10943 (epoch 90.564) train_loss=230.44023132 time/batch=0.62s
11013/10943 (epoch 90.572) train_loss=234.82255554 time/batch=0.61s
11014/10943 (epoch 90.580) train_loss=172.55671692 time/batch=0.46s
11015/10943 (epoch 90.589) train_loss=385.94430542 time/batch=0.90s
11016/10943 (epoch 90.597) train_loss=270.24200439 time/batch=0.69s
11017/10943 (epoch 90.605) train_loss=273.00842285 time/batch=0.69s
11018/10943 (epoch 90.613) train_loss=228.38269043 time/batch=0.59s
11019/10943 (epoch 90.621) train_loss=322.79129028 time/batch=0.84s
11020/10943 (epoch 90.630) train_loss=244.92779541 time/batch=0.66s
11021/10943 (epoch 90.638) train_loss=263.29052734 time/batch=0.65s
11022/10943 (epoch 90.646) train_loss=334.79333496 time/batch=0.86s
11023/10943 (epoch 90.654) train_loss=408.61614990 time/batch=1.10s
11024/10943 (epoch 90.663) train_loss=409.65777588 time/batch=1.22s
11025/10943 (epoch 90.671) train_loss=310.47302246 time/batch=0.85s
11026/10943 (epoch 90.679) train_loss=230.69869995 time/batch=0.64s
11027/10943 (epoch 90.687) train_loss=167.25619507 time/batch=0.47s
11028/10943 (epoch 90.695) train_loss=188.84164429 time/batch=0.48s
11029/10943 (epoch 90.704) train_loss=298.20025635 time/batch=0.70s
11030/10943 (epoch 90.712) train_loss=253.08926392 time/batch=0.66s
11031/10943 (epoch 90.720) train_loss=207.06085205 time/batch=0.55s
11032/10943 (epoch 90.728) train_loss=268.59976196 time/batch=0.69s
11033/10943 (epoch 90.737) train_loss=187.07031250 time/batch=0.49s
11034/10943 (epoch 90.745) train_loss=203.05549622 time/batch=0.48s
11035/10943 (epoch 90.753) train_loss=258.43170166 time/batch=0.68s
11036/10943 (epoch 90.761) train_loss=175.22492981 time/batch=0.55s
11037/10943 (epoch 90.769) train_loss=293.76260376 time/batch=0.69s
11038/10943 (epoch 90.778) train_loss=218.94224548 time/batch=0.59s
11039/10943 (epoch 90.786) train_loss=352.02880859 time/batch=0.87s
11040/10943 (epoch 90.794) train_loss=274.18432617 time/batch=0.74s
11041/10943 (epoch 90.802) train_loss=250.07751465 time/batch=0.65s
11042/10943 (epoch 90.811) train_loss=305.88452148 time/batch=0.77s
11043/10943 (epoch 90.819) train_loss=301.52142334 time/batch=0.90s
11044/10943 (epoch 90.827) train_loss=299.24246216 time/batch=0.82s
11045/10943 (epoch 90.835) train_loss=280.21151733 time/batch=0.75s
11046/10943 (epoch 90.843) train_loss=296.39782715 time/batch=0.79s
11047/10943 (epoch 90.852) train_loss=227.20932007 time/batch=0.75s
setting learning rate to 0.0013589
11048/10943 (epoch 90.860) train_loss=422.04187012 time/batch=1.00s
11049/10943 (epoch 90.868) train_loss=379.96722412 time/batch=0.96s
11050/10943 (epoch 90.876) train_loss=914.59765625 time/batch=3.06s
11051/10943 (epoch 90.885) train_loss=201.94386292 time/batch=0.77s
11052/10943 (epoch 90.893) train_loss=296.25817871 time/batch=0.73s
11053/10943 (epoch 90.901) train_loss=210.84484863 time/batch=0.56s
11054/10943 (epoch 90.909) train_loss=446.19842529 time/batch=1.08s
11055/10943 (epoch 90.918) train_loss=540.13543701 time/batch=1.39s
11056/10943 (epoch 90.926) train_loss=453.87896729 time/batch=1.15s
11057/10943 (epoch 90.934) train_loss=376.63903809 time/batch=0.99s
11058/10943 (epoch 90.942) train_loss=218.12063599 time/batch=0.60s
11059/10943 (epoch 90.950) train_loss=329.85534668 time/batch=0.82s
11060/10943 (epoch 90.959) train_loss=288.44531250 time/batch=0.72s
11061/10943 (epoch 90.967) train_loss=297.05725098 time/batch=0.79s
11062/10943 (epoch 90.975) train_loss=355.90917969 time/batch=0.89s
11063/10943 (epoch 90.983) train_loss=295.40789795 time/batch=0.79s
11064/10943 (epoch 90.992) train_loss=381.39672852 time/batch=0.96s
11065/10943 (epoch 91.000) train_loss=182.69311523 time/batch=0.53s
11066/10943 (epoch 91.008) train_loss=282.06329346 time/batch=0.74s
11067/10943 (epoch 91.016) train_loss=607.07312012 time/batch=1.50s
11068/10943 (epoch 91.024) train_loss=228.04251099 time/batch=0.70s
11069/10943 (epoch 91.033) train_loss=280.07299805 time/batch=0.70s
11070/10943 (epoch 91.041) train_loss=294.17376709 time/batch=0.81s
11071/10943 (epoch 91.049) train_loss=204.13195801 time/batch=0.57s
11072/10943 (epoch 91.057) train_loss=458.66827393 time/batch=1.12s
11073/10943 (epoch 91.066) train_loss=221.06420898 time/batch=0.64s
11074/10943 (epoch 91.074) train_loss=397.32775879 time/batch=0.95s
11075/10943 (epoch 91.082) train_loss=255.10906982 time/batch=0.70s
11076/10943 (epoch 91.090) train_loss=260.01525879 time/batch=0.64s
11077/10943 (epoch 91.098) train_loss=155.58697510 time/batch=0.43s
11078/10943 (epoch 91.107) train_loss=400.34979248 time/batch=0.94s
11079/10943 (epoch 91.115) train_loss=502.48956299 time/batch=1.22s
11080/10943 (epoch 91.123) train_loss=334.68408203 time/batch=0.88s
11081/10943 (epoch 91.131) train_loss=399.41961670 time/batch=1.00s
11082/10943 (epoch 91.140) train_loss=213.08865356 time/batch=0.60s
11083/10943 (epoch 91.148) train_loss=209.07290649 time/batch=0.53s
11084/10943 (epoch 91.156) train_loss=107.85807800 time/batch=0.29s
11085/10943 (epoch 91.164) train_loss=221.91088867 time/batch=0.56s
11086/10943 (epoch 91.172) train_loss=326.02416992 time/batch=0.84s
11087/10943 (epoch 91.181) train_loss=410.48025513 time/batch=1.07s
11088/10943 (epoch 91.189) train_loss=94.63977814 time/batch=0.33s
11089/10943 (epoch 91.197) train_loss=152.39718628 time/batch=0.39s
11090/10943 (epoch 91.205) train_loss=230.76704407 time/batch=0.57s
11091/10943 (epoch 91.214) train_loss=126.80843353 time/batch=0.35s
11092/10943 (epoch 91.222) train_loss=453.98339844 time/batch=1.11s
11093/10943 (epoch 91.230) train_loss=274.36624146 time/batch=0.72s
11094/10943 (epoch 91.238) train_loss=115.22926331 time/batch=0.33s
11095/10943 (epoch 91.246) train_loss=610.17956543 time/batch=1.53s
11096/10943 (epoch 91.255) train_loss=244.78981018 time/batch=0.71s
11097/10943 (epoch 91.263) train_loss=349.75109863 time/batch=0.89s
11098/10943 (epoch 91.271) train_loss=120.85684204 time/batch=0.37s
11099/10943 (epoch 91.279) train_loss=307.18551636 time/batch=0.76s
11100/10943 (epoch 91.288) train_loss=550.55682373 time/batch=1.28s
11101/10943 (epoch 91.296) train_loss=357.86889648 time/batch=0.93s
11102/10943 (epoch 91.304) train_loss=164.34346008 time/batch=0.48s
11103/10943 (epoch 91.312) train_loss=140.30146790 time/batch=0.35s
11104/10943 (epoch 91.320) train_loss=186.09069824 time/batch=0.46s
11105/10943 (epoch 91.329) train_loss=188.50964355 time/batch=0.49s
11106/10943 (epoch 91.337) train_loss=234.71910095 time/batch=0.60s
11107/10943 (epoch 91.345) train_loss=640.13342285 time/batch=1.64s
11108/10943 (epoch 91.353) train_loss=170.43458557 time/batch=0.58s
11109/10943 (epoch 91.362) train_loss=488.99520874 time/batch=1.18s
11110/10943 (epoch 91.370) train_loss=366.60540771 time/batch=0.99s
11111/10943 (epoch 91.378) train_loss=299.01028442 time/batch=0.80s
11112/10943 (epoch 91.386) train_loss=279.66744995 time/batch=0.73s
11113/10943 (epoch 91.395) train_loss=346.58886719 time/batch=0.88s
11114/10943 (epoch 91.403) train_loss=306.01766968 time/batch=0.79s
11115/10943 (epoch 91.411) train_loss=170.63452148 time/batch=0.48s
11116/10943 (epoch 91.419) train_loss=262.27557373 time/batch=0.64s
11117/10943 (epoch 91.427) train_loss=261.84277344 time/batch=0.70s
11118/10943 (epoch 91.436) train_loss=443.78668213 time/batch=1.15s
11119/10943 (epoch 91.444) train_loss=373.48034668 time/batch=1.04s
11120/10943 (epoch 91.452) train_loss=425.31561279 time/batch=1.07s
11121/10943 (epoch 91.460) train_loss=205.14056396 time/batch=0.56s
11122/10943 (epoch 91.469) train_loss=220.69714355 time/batch=0.56s
11123/10943 (epoch 91.477) train_loss=336.62060547 time/batch=0.83s
11124/10943 (epoch 91.485) train_loss=294.94619751 time/batch=0.75s
11125/10943 (epoch 91.493) train_loss=190.35949707 time/batch=0.53s
11126/10943 (epoch 91.501) train_loss=292.23181152 time/batch=0.76s
11127/10943 (epoch 91.510) train_loss=329.24005127 time/batch=0.87s
11128/10943 (epoch 91.518) train_loss=233.32208252 time/batch=0.60s
11129/10943 (epoch 91.526) train_loss=230.51791382 time/batch=0.60s
11130/10943 (epoch 91.534) train_loss=136.17364502 time/batch=0.38s
11131/10943 (epoch 91.543) train_loss=299.48120117 time/batch=0.76s
11132/10943 (epoch 91.551) train_loss=252.11372375 time/batch=0.65s
11133/10943 (epoch 91.559) train_loss=117.14561462 time/batch=0.33s
11134/10943 (epoch 91.567) train_loss=280.94854736 time/batch=0.69s
11135/10943 (epoch 91.575) train_loss=257.43457031 time/batch=0.65s
11136/10943 (epoch 91.584) train_loss=211.89736938 time/batch=0.57s
11137/10943 (epoch 91.592) train_loss=289.07714844 time/batch=0.75s
11138/10943 (epoch 91.600) train_loss=325.86041260 time/batch=0.83s
11139/10943 (epoch 91.608) train_loss=189.99923706 time/batch=0.50s
11140/10943 (epoch 91.617) train_loss=317.37219238 time/batch=0.81s
11141/10943 (epoch 91.625) train_loss=193.34860229 time/batch=0.55s
11142/10943 (epoch 91.633) train_loss=132.16604614 time/batch=0.35s
11143/10943 (epoch 91.641) train_loss=275.18609619 time/batch=0.70s
11144/10943 (epoch 91.649) train_loss=228.75189209 time/batch=0.62s
11145/10943 (epoch 91.658) train_loss=139.48463440 time/batch=0.40s
11146/10943 (epoch 91.666) train_loss=150.47944641 time/batch=0.38s
11147/10943 (epoch 91.674) train_loss=191.97140503 time/batch=0.50s
11148/10943 (epoch 91.682) train_loss=261.82379150 time/batch=0.67s
11149/10943 (epoch 91.691) train_loss=258.96386719 time/batch=0.68s
11150/10943 (epoch 91.699) train_loss=307.52026367 time/batch=0.79s
11151/10943 (epoch 91.707) train_loss=227.75082397 time/batch=0.64s
11152/10943 (epoch 91.715) train_loss=255.11293030 time/batch=0.64s
11153/10943 (epoch 91.723) train_loss=257.81002808 time/batch=0.67s
11154/10943 (epoch 91.732) train_loss=142.18809509 time/batch=0.37s
11155/10943 (epoch 91.740) train_loss=136.23077393 time/batch=0.34s
11156/10943 (epoch 91.748) train_loss=225.48095703 time/batch=0.55s
11157/10943 (epoch 91.756) train_loss=150.28710938 time/batch=0.42s
11158/10943 (epoch 91.765) train_loss=328.18292236 time/batch=0.78s
11159/10943 (epoch 91.773) train_loss=269.32156372 time/batch=0.70s
11160/10943 (epoch 91.781) train_loss=169.84657288 time/batch=0.47s
11161/10943 (epoch 91.789) train_loss=333.27310181 time/batch=0.97s
11162/10943 (epoch 91.797) train_loss=200.51766968 time/batch=0.61s
11163/10943 (epoch 91.806) train_loss=276.27859497 time/batch=0.70s
11164/10943 (epoch 91.814) train_loss=241.86878967 time/batch=0.64s
11165/10943 (epoch 91.822) train_loss=293.45391846 time/batch=0.81s
11166/10943 (epoch 91.830) train_loss=186.42092896 time/batch=0.65s
11167/10943 (epoch 91.839) train_loss=162.75189209 time/batch=0.44s
11168/10943 (epoch 91.847) train_loss=235.99896240 time/batch=0.66s
setting learning rate to 0.0013181
  saved to metadata/gru_dropout-9_nov_folkwiki-20181207-173447_epoch47.pkl
11169/10943 (epoch 91.855) train_loss=134.96899414 time/batch=0.44s
11170/10943 (epoch 91.863) train_loss=452.03857422 time/batch=1.07s
11171/10943 (epoch 91.871) train_loss=124.54824829 time/batch=0.39s
11172/10943 (epoch 91.880) train_loss=435.24642944 time/batch=1.02s
11173/10943 (epoch 91.888) train_loss=224.06704712 time/batch=0.64s
11174/10943 (epoch 91.896) train_loss=230.52883911 time/batch=0.60s
11175/10943 (epoch 91.904) train_loss=549.33862305 time/batch=1.41s
11176/10943 (epoch 91.913) train_loss=306.19338989 time/batch=0.88s
11177/10943 (epoch 91.921) train_loss=394.36093140 time/batch=0.96s
11178/10943 (epoch 91.929) train_loss=376.52807617 time/batch=0.97s
11179/10943 (epoch 91.937) train_loss=454.72738647 time/batch=1.16s
11180/10943 (epoch 91.946) train_loss=247.42916870 time/batch=0.68s
11181/10943 (epoch 91.954) train_loss=499.56753540 time/batch=1.17s
11182/10943 (epoch 91.962) train_loss=557.13891602 time/batch=1.34s
11183/10943 (epoch 91.970) train_loss=599.83679199 time/batch=1.58s
11184/10943 (epoch 91.978) train_loss=386.74536133 time/batch=1.06s
11185/10943 (epoch 91.987) train_loss=412.71539307 time/batch=1.07s
11186/10943 (epoch 91.995) train_loss=578.11798096 time/batch=1.58s
11187/10943 (epoch 92.003) train_loss=111.06814575 time/batch=0.41s
11188/10943 (epoch 92.011) train_loss=746.65936279 time/batch=1.84s
11189/10943 (epoch 92.020) train_loss=141.34774780 time/batch=0.53s
11190/10943 (epoch 92.028) train_loss=262.07165527 time/batch=0.64s
11191/10943 (epoch 92.036) train_loss=167.58322144 time/batch=0.46s
11192/10943 (epoch 92.044) train_loss=838.95251465 time/batch=3.04s
11193/10943 (epoch 92.052) train_loss=301.47619629 time/batch=0.98s
11194/10943 (epoch 92.061) train_loss=209.61853027 time/batch=0.56s
11195/10943 (epoch 92.069) train_loss=273.10717773 time/batch=0.67s
11196/10943 (epoch 92.077) train_loss=295.30627441 time/batch=0.78s
11197/10943 (epoch 92.085) train_loss=389.82348633 time/batch=1.00s
11198/10943 (epoch 92.094) train_loss=133.16166687 time/batch=0.41s
11199/10943 (epoch 92.102) train_loss=297.13842773 time/batch=0.72s
11200/10943 (epoch 92.110) train_loss=147.06129456 time/batch=0.42s
11201/10943 (epoch 92.118) train_loss=289.03918457 time/batch=0.70s
11202/10943 (epoch 92.126) train_loss=194.18583679 time/batch=0.55s
11203/10943 (epoch 92.135) train_loss=141.92971802 time/batch=0.37s
11204/10943 (epoch 92.143) train_loss=246.59077454 time/batch=0.62s
11205/10943 (epoch 92.151) train_loss=208.71484375 time/batch=0.53s
11206/10943 (epoch 92.159) train_loss=99.59092712 time/batch=0.30s
11207/10943 (epoch 92.168) train_loss=358.76953125 time/batch=0.86s
11208/10943 (epoch 92.176) train_loss=424.95837402 time/batch=1.00s
11209/10943 (epoch 92.184) train_loss=168.12097168 time/batch=0.49s
11210/10943 (epoch 92.192) train_loss=220.37959290 time/batch=0.56s
11211/10943 (epoch 92.200) train_loss=170.05966187 time/batch=0.46s
11212/10943 (epoch 92.209) train_loss=144.26066589 time/batch=0.38s
11213/10943 (epoch 92.217) train_loss=456.09503174 time/batch=1.03s
11214/10943 (epoch 92.225) train_loss=156.48625183 time/batch=0.47s
11215/10943 (epoch 92.233) train_loss=215.14389038 time/batch=0.54s
11216/10943 (epoch 92.242) train_loss=234.35906982 time/batch=0.61s
11217/10943 (epoch 92.250) train_loss=135.84783936 time/batch=0.37s
11218/10943 (epoch 92.258) train_loss=492.04656982 time/batch=1.17s
11219/10943 (epoch 92.266) train_loss=327.30303955 time/batch=0.88s
11220/10943 (epoch 92.274) train_loss=331.07995605 time/batch=0.86s
11221/10943 (epoch 92.283) train_loss=208.51730347 time/batch=0.58s
11222/10943 (epoch 92.291) train_loss=108.64035797 time/batch=0.31s
11223/10943 (epoch 92.299) train_loss=345.56405640 time/batch=0.82s
11224/10943 (epoch 92.307) train_loss=321.84179688 time/batch=0.84s
11225/10943 (epoch 92.316) train_loss=175.77264404 time/batch=0.49s
11226/10943 (epoch 92.324) train_loss=334.02621460 time/batch=0.80s
11227/10943 (epoch 92.332) train_loss=389.00347900 time/batch=1.01s
11228/10943 (epoch 92.340) train_loss=272.37747192 time/batch=0.72s
11229/10943 (epoch 92.348) train_loss=465.68502808 time/batch=1.22s
11230/10943 (epoch 92.357) train_loss=272.63049316 time/batch=0.72s
11231/10943 (epoch 92.365) train_loss=212.88581848 time/batch=0.57s
11232/10943 (epoch 92.373) train_loss=300.39093018 time/batch=0.80s
11233/10943 (epoch 92.381) train_loss=432.14767456 time/batch=1.09s
11234/10943 (epoch 92.390) train_loss=207.94981384 time/batch=0.59s
11235/10943 (epoch 92.398) train_loss=341.62884521 time/batch=0.84s
11236/10943 (epoch 92.406) train_loss=189.07722473 time/batch=0.52s
11237/10943 (epoch 92.414) train_loss=301.79879761 time/batch=0.75s
11238/10943 (epoch 92.423) train_loss=397.54318237 time/batch=1.01s
11239/10943 (epoch 92.431) train_loss=231.72103882 time/batch=0.63s
11240/10943 (epoch 92.439) train_loss=257.67492676 time/batch=0.64s
11241/10943 (epoch 92.447) train_loss=157.69659424 time/batch=0.44s
11242/10943 (epoch 92.455) train_loss=197.72143555 time/batch=0.49s
11243/10943 (epoch 92.464) train_loss=354.09429932 time/batch=0.89s
11244/10943 (epoch 92.472) train_loss=188.53878784 time/batch=0.53s
11245/10943 (epoch 92.480) train_loss=320.11083984 time/batch=0.80s
11246/10943 (epoch 92.488) train_loss=294.06738281 time/batch=0.78s
11247/10943 (epoch 92.497) train_loss=117.29217529 time/batch=0.34s
11248/10943 (epoch 92.505) train_loss=198.20492554 time/batch=0.49s
11249/10943 (epoch 92.513) train_loss=146.44792175 time/batch=0.40s
11250/10943 (epoch 92.521) train_loss=289.65655518 time/batch=0.71s
11251/10943 (epoch 92.529) train_loss=195.91543579 time/batch=0.52s
11252/10943 (epoch 92.538) train_loss=222.46408081 time/batch=0.59s
11253/10943 (epoch 92.546) train_loss=270.17730713 time/batch=0.71s
11254/10943 (epoch 92.554) train_loss=244.68762207 time/batch=0.63s
11255/10943 (epoch 92.562) train_loss=256.76974487 time/batch=0.63s
11256/10943 (epoch 92.571) train_loss=259.68884277 time/batch=0.67s
11257/10943 (epoch 92.579) train_loss=192.20944214 time/batch=0.58s
11258/10943 (epoch 92.587) train_loss=187.31498718 time/batch=0.50s
11259/10943 (epoch 92.595) train_loss=282.62420654 time/batch=0.69s
11260/10943 (epoch 92.603) train_loss=412.07244873 time/batch=1.00s
11261/10943 (epoch 92.612) train_loss=304.62387085 time/batch=0.81s
11262/10943 (epoch 92.620) train_loss=269.10852051 time/batch=0.71s
11263/10943 (epoch 92.628) train_loss=301.48791504 time/batch=0.77s
11264/10943 (epoch 92.636) train_loss=230.17623901 time/batch=0.64s
11265/10943 (epoch 92.645) train_loss=174.31472778 time/batch=0.47s
11266/10943 (epoch 92.653) train_loss=351.15960693 time/batch=0.85s
11267/10943 (epoch 92.661) train_loss=330.05593872 time/batch=0.86s
11268/10943 (epoch 92.669) train_loss=251.54098511 time/batch=0.70s
11269/10943 (epoch 92.677) train_loss=284.81756592 time/batch=0.74s
11270/10943 (epoch 92.686) train_loss=350.52676392 time/batch=0.92s
11271/10943 (epoch 92.694) train_loss=364.42047119 time/batch=0.89s
11272/10943 (epoch 92.702) train_loss=186.25936890 time/batch=0.51s
11273/10943 (epoch 92.710) train_loss=234.31564331 time/batch=0.56s
11274/10943 (epoch 92.719) train_loss=233.19682312 time/batch=0.60s
11275/10943 (epoch 92.727) train_loss=200.82521057 time/batch=0.56s
11276/10943 (epoch 92.735) train_loss=161.26104736 time/batch=0.47s
11277/10943 (epoch 92.743) train_loss=307.04754639 time/batch=0.81s
11278/10943 (epoch 92.751) train_loss=233.95173645 time/batch=0.67s
11279/10943 (epoch 92.760) train_loss=123.57380676 time/batch=0.35s
11280/10943 (epoch 92.768) train_loss=285.34188843 time/batch=0.69s
11281/10943 (epoch 92.776) train_loss=258.80960083 time/batch=0.68s
11282/10943 (epoch 92.784) train_loss=215.82391357 time/batch=0.60s
11283/10943 (epoch 92.793) train_loss=282.45480347 time/batch=0.70s
11284/10943 (epoch 92.801) train_loss=310.37451172 time/batch=0.79s
11285/10943 (epoch 92.809) train_loss=259.78353882 time/batch=0.67s
11286/10943 (epoch 92.817) train_loss=289.48242188 time/batch=0.75s
11287/10943 (epoch 92.825) train_loss=299.97027588 time/batch=0.81s
11288/10943 (epoch 92.834) train_loss=250.08387756 time/batch=0.73s
11289/10943 (epoch 92.842) train_loss=290.53756714 time/batch=0.80s
setting learning rate to 0.0012786
11290/10943 (epoch 92.850) train_loss=515.70428467 time/batch=1.25s
11291/10943 (epoch 92.858) train_loss=637.67303467 time/batch=1.60s
11292/10943 (epoch 92.867) train_loss=301.74658203 time/batch=0.87s
11293/10943 (epoch 92.875) train_loss=334.01000977 time/batch=0.84s
11294/10943 (epoch 92.883) train_loss=99.22901917 time/batch=0.31s
11295/10943 (epoch 92.891) train_loss=502.70458984 time/batch=1.19s
11296/10943 (epoch 92.900) train_loss=472.98266602 time/batch=1.22s
11297/10943 (epoch 92.908) train_loss=360.37612915 time/batch=0.95s
11298/10943 (epoch 92.916) train_loss=718.42987061 time/batch=1.75s
11299/10943 (epoch 92.924) train_loss=890.31787109 time/batch=3.17s
11300/10943 (epoch 92.932) train_loss=202.57742310 time/batch=0.81s
11301/10943 (epoch 92.941) train_loss=558.20324707 time/batch=1.27s
11302/10943 (epoch 92.949) train_loss=217.02105713 time/batch=0.66s
11303/10943 (epoch 92.957) train_loss=116.60574341 time/batch=0.33s
11304/10943 (epoch 92.965) train_loss=545.52923584 time/batch=1.36s
11305/10943 (epoch 92.974) train_loss=152.71882629 time/batch=0.48s
11306/10943 (epoch 92.982) train_loss=369.56011963 time/batch=0.89s
11307/10943 (epoch 92.990) train_loss=410.23156738 time/batch=1.02s
11308/10943 (epoch 92.998) train_loss=215.36830139 time/batch=0.59s
11309/10943 (epoch 93.006) train_loss=143.61836243 time/batch=0.36s
11310/10943 (epoch 93.015) train_loss=110.49812317 time/batch=0.28s
11311/10943 (epoch 93.023) train_loss=194.84820557 time/batch=0.48s
11312/10943 (epoch 93.031) train_loss=356.29391479 time/batch=0.88s
11313/10943 (epoch 93.039) train_loss=156.92317200 time/batch=0.45s
11314/10943 (epoch 93.048) train_loss=298.01940918 time/batch=0.72s
11315/10943 (epoch 93.056) train_loss=411.74957275 time/batch=0.98s
11316/10943 (epoch 93.064) train_loss=187.38058472 time/batch=0.52s
11317/10943 (epoch 93.072) train_loss=402.81259155 time/batch=0.94s
11318/10943 (epoch 93.080) train_loss=387.20269775 time/batch=0.99s
11319/10943 (epoch 93.089) train_loss=166.00953674 time/batch=0.49s
11320/10943 (epoch 93.097) train_loss=202.34066772 time/batch=0.54s
11321/10943 (epoch 93.105) train_loss=533.82873535 time/batch=1.31s
11322/10943 (epoch 93.113) train_loss=218.70771790 time/batch=0.64s
11323/10943 (epoch 93.122) train_loss=393.47961426 time/batch=0.92s
11324/10943 (epoch 93.130) train_loss=296.07333374 time/batch=0.75s
11325/10943 (epoch 93.138) train_loss=456.16293335 time/batch=1.09s
11326/10943 (epoch 93.146) train_loss=450.31475830 time/batch=1.15s
11327/10943 (epoch 93.154) train_loss=476.45166016 time/batch=1.17s
11328/10943 (epoch 93.163) train_loss=226.48454285 time/batch=0.64s
11329/10943 (epoch 93.171) train_loss=285.44335938 time/batch=0.74s
11330/10943 (epoch 93.179) train_loss=428.49813843 time/batch=1.01s
11331/10943 (epoch 93.187) train_loss=320.98632812 time/batch=0.86s
11332/10943 (epoch 93.196) train_loss=341.64956665 time/batch=0.87s
11333/10943 (epoch 93.204) train_loss=355.91699219 time/batch=0.92s
11334/10943 (epoch 93.212) train_loss=436.77648926 time/batch=1.08s
11335/10943 (epoch 93.220) train_loss=209.48196411 time/batch=0.56s
11336/10943 (epoch 93.228) train_loss=114.44277191 time/batch=0.31s
11337/10943 (epoch 93.237) train_loss=257.81726074 time/batch=0.60s
11338/10943 (epoch 93.245) train_loss=307.01251221 time/batch=0.78s
11339/10943 (epoch 93.253) train_loss=409.76229858 time/batch=1.04s
11340/10943 (epoch 93.261) train_loss=375.82504272 time/batch=0.97s
11341/10943 (epoch 93.270) train_loss=159.88323975 time/batch=0.46s
11342/10943 (epoch 93.278) train_loss=285.82452393 time/batch=0.69s
11343/10943 (epoch 93.286) train_loss=236.91571045 time/batch=0.63s
11344/10943 (epoch 93.294) train_loss=271.72821045 time/batch=0.67s
11345/10943 (epoch 93.302) train_loss=326.58062744 time/batch=0.85s
11346/10943 (epoch 93.311) train_loss=300.55596924 time/batch=0.75s
11347/10943 (epoch 93.319) train_loss=228.37106323 time/batch=0.59s
11348/10943 (epoch 93.327) train_loss=342.56991577 time/batch=0.84s
11349/10943 (epoch 93.335) train_loss=147.60641479 time/batch=0.43s
11350/10943 (epoch 93.344) train_loss=167.91702271 time/batch=0.43s
11351/10943 (epoch 93.352) train_loss=177.74296570 time/batch=0.43s
11352/10943 (epoch 93.360) train_loss=303.10589600 time/batch=0.75s
11353/10943 (epoch 93.368) train_loss=155.16577148 time/batch=0.45s
11354/10943 (epoch 93.377) train_loss=269.67529297 time/batch=0.65s
11355/10943 (epoch 93.385) train_loss=448.37695312 time/batch=1.06s
11356/10943 (epoch 93.393) train_loss=287.39331055 time/batch=0.75s
11357/10943 (epoch 93.401) train_loss=312.23474121 time/batch=0.81s
11358/10943 (epoch 93.409) train_loss=203.92330933 time/batch=0.56s
11359/10943 (epoch 93.418) train_loss=129.40408325 time/batch=0.33s
11360/10943 (epoch 93.426) train_loss=290.40313721 time/batch=0.72s
11361/10943 (epoch 93.434) train_loss=220.13378906 time/batch=0.57s
11362/10943 (epoch 93.442) train_loss=122.62622070 time/batch=0.32s
11363/10943 (epoch 93.451) train_loss=311.59326172 time/batch=0.73s
11364/10943 (epoch 93.459) train_loss=141.07962036 time/batch=0.40s
11365/10943 (epoch 93.467) train_loss=233.86666870 time/batch=0.58s
11366/10943 (epoch 93.475) train_loss=195.18049622 time/batch=0.51s
11367/10943 (epoch 93.483) train_loss=182.51449585 time/batch=0.47s
11368/10943 (epoch 93.492) train_loss=346.68722534 time/batch=0.83s
11369/10943 (epoch 93.500) train_loss=233.22125244 time/batch=0.62s
11370/10943 (epoch 93.508) train_loss=263.25067139 time/batch=0.66s
11371/10943 (epoch 93.516) train_loss=301.63021851 time/batch=0.79s
11372/10943 (epoch 93.525) train_loss=306.06570435 time/batch=0.76s
11373/10943 (epoch 93.533) train_loss=192.47470093 time/batch=0.51s
11374/10943 (epoch 93.541) train_loss=377.62713623 time/batch=0.95s
11375/10943 (epoch 93.549) train_loss=233.27902222 time/batch=0.66s
11376/10943 (epoch 93.557) train_loss=286.98565674 time/batch=0.70s
11377/10943 (epoch 93.566) train_loss=276.42999268 time/batch=0.70s
11378/10943 (epoch 93.574) train_loss=254.09544373 time/batch=0.65s
11379/10943 (epoch 93.582) train_loss=212.82772827 time/batch=0.56s
11380/10943 (epoch 93.590) train_loss=299.64102173 time/batch=0.77s
11381/10943 (epoch 93.599) train_loss=138.29052734 time/batch=0.39s
11382/10943 (epoch 93.607) train_loss=129.11750793 time/batch=0.33s
11383/10943 (epoch 93.615) train_loss=150.36672974 time/batch=0.39s
11384/10943 (epoch 93.623) train_loss=366.51162720 time/batch=0.83s
11385/10943 (epoch 93.631) train_loss=330.38217163 time/batch=0.83s
11386/10943 (epoch 93.640) train_loss=232.92684937 time/batch=0.61s
11387/10943 (epoch 93.648) train_loss=172.34207153 time/batch=0.45s
11388/10943 (epoch 93.656) train_loss=269.23223877 time/batch=0.64s
11389/10943 (epoch 93.664) train_loss=240.66476440 time/batch=0.63s
11390/10943 (epoch 93.673) train_loss=159.08784485 time/batch=0.46s
11391/10943 (epoch 93.681) train_loss=220.49485779 time/batch=0.57s
11392/10943 (epoch 93.689) train_loss=250.23245239 time/batch=0.63s
11393/10943 (epoch 93.697) train_loss=253.81713867 time/batch=0.63s
11394/10943 (epoch 93.705) train_loss=194.27876282 time/batch=0.52s
11395/10943 (epoch 93.714) train_loss=239.43899536 time/batch=0.61s
11396/10943 (epoch 93.722) train_loss=268.39764404 time/batch=0.65s
11397/10943 (epoch 93.730) train_loss=188.11231995 time/batch=0.49s
11398/10943 (epoch 93.738) train_loss=300.41415405 time/batch=0.76s
11399/10943 (epoch 93.747) train_loss=265.88079834 time/batch=0.68s
11400/10943 (epoch 93.755) train_loss=307.47064209 time/batch=0.79s
11401/10943 (epoch 93.763) train_loss=268.29211426 time/batch=0.70s
11402/10943 (epoch 93.771) train_loss=202.46798706 time/batch=0.58s
11403/10943 (epoch 93.779) train_loss=313.09783936 time/batch=0.79s
11404/10943 (epoch 93.788) train_loss=257.87771606 time/batch=0.69s
11405/10943 (epoch 93.796) train_loss=295.62817383 time/batch=0.82s
11406/10943 (epoch 93.804) train_loss=329.52770996 time/batch=0.84s
11407/10943 (epoch 93.812) train_loss=224.52896118 time/batch=0.63s
11408/10943 (epoch 93.821) train_loss=244.46588135 time/batch=0.66s
11409/10943 (epoch 93.829) train_loss=269.80450439 time/batch=0.69s
11410/10943 (epoch 93.837) train_loss=260.99795532 time/batch=0.70s
setting learning rate to 0.0012402
  saved to metadata/gru_dropout-9_nov_folkwiki-20181207-173447_epoch49.pkl
11411/10943 (epoch 93.845) train_loss=190.49832153 time/batch=0.58s
11412/10943 (epoch 93.854) train_loss=336.54534912 time/batch=0.81s
11413/10943 (epoch 93.862) train_loss=358.15499878 time/batch=0.91s
11414/10943 (epoch 93.870) train_loss=796.94824219 time/batch=2.07s
11415/10943 (epoch 93.878) train_loss=166.13122559 time/batch=0.60s
11416/10943 (epoch 93.886) train_loss=112.44062805 time/batch=0.28s
11417/10943 (epoch 93.895) train_loss=559.95898438 time/batch=1.22s
11418/10943 (epoch 93.903) train_loss=138.57736206 time/batch=0.43s
11419/10943 (epoch 93.911) train_loss=388.30749512 time/batch=0.89s
11420/10943 (epoch 93.919) train_loss=260.95220947 time/batch=0.70s
11421/10943 (epoch 93.928) train_loss=150.45228577 time/batch=0.40s
11422/10943 (epoch 93.936) train_loss=440.63348389 time/batch=1.02s
11423/10943 (epoch 93.944) train_loss=592.87530518 time/batch=1.50s
11424/10943 (epoch 93.952) train_loss=290.10382080 time/batch=0.80s
11425/10943 (epoch 93.960) train_loss=458.25640869 time/batch=1.12s
11426/10943 (epoch 93.969) train_loss=521.72863770 time/batch=1.32s
11427/10943 (epoch 93.977) train_loss=428.00814819 time/batch=1.08s
11428/10943 (epoch 93.985) train_loss=228.16430664 time/batch=0.62s
11429/10943 (epoch 93.993) train_loss=300.74511719 time/batch=0.79s
11430/10943 (epoch 94.002) train_loss=285.85278320 time/batch=0.76s
11431/10943 (epoch 94.010) train_loss=352.54132080 time/batch=0.88s
11432/10943 (epoch 94.018) train_loss=450.69323730 time/batch=1.09s
11433/10943 (epoch 94.026) train_loss=198.28115845 time/batch=0.57s
11434/10943 (epoch 94.034) train_loss=629.47741699 time/batch=1.53s
11435/10943 (epoch 94.043) train_loss=316.41717529 time/batch=0.91s
11436/10943 (epoch 94.051) train_loss=444.27905273 time/batch=1.10s
11437/10943 (epoch 94.059) train_loss=149.84942627 time/batch=0.45s
11438/10943 (epoch 94.067) train_loss=313.07757568 time/batch=0.72s
11439/10943 (epoch 94.076) train_loss=261.65020752 time/batch=0.65s
11440/10943 (epoch 94.084) train_loss=274.80889893 time/batch=0.68s
11441/10943 (epoch 94.092) train_loss=297.98580933 time/batch=0.72s
11442/10943 (epoch 94.100) train_loss=302.28579712 time/batch=0.78s
11443/10943 (epoch 94.108) train_loss=119.46997833 time/batch=0.34s
11444/10943 (epoch 94.117) train_loss=284.78787231 time/batch=0.69s
11445/10943 (epoch 94.125) train_loss=289.23828125 time/batch=0.74s
11446/10943 (epoch 94.133) train_loss=345.86926270 time/batch=0.86s
11447/10943 (epoch 94.141) train_loss=214.27722168 time/batch=0.59s
11448/10943 (epoch 94.150) train_loss=163.16571045 time/batch=0.44s
11449/10943 (epoch 94.158) train_loss=543.09472656 time/batch=1.30s
11450/10943 (epoch 94.166) train_loss=451.48931885 time/batch=1.18s
11451/10943 (epoch 94.174) train_loss=456.96325684 time/batch=1.18s
11452/10943 (epoch 94.182) train_loss=174.44111633 time/batch=0.49s
11453/10943 (epoch 94.191) train_loss=493.29040527 time/batch=1.14s
11454/10943 (epoch 94.199) train_loss=120.16427612 time/batch=0.40s
11455/10943 (epoch 94.207) train_loss=197.01007080 time/batch=0.48s
11456/10943 (epoch 94.215) train_loss=391.61968994 time/batch=0.93s
11457/10943 (epoch 94.224) train_loss=233.95811462 time/batch=0.64s
11458/10943 (epoch 94.232) train_loss=239.07861328 time/batch=0.61s
11459/10943 (epoch 94.240) train_loss=310.98840332 time/batch=0.75s
11460/10943 (epoch 94.248) train_loss=420.24371338 time/batch=1.00s
11461/10943 (epoch 94.256) train_loss=401.39935303 time/batch=1.01s
11462/10943 (epoch 94.265) train_loss=226.19024658 time/batch=0.62s
11463/10943 (epoch 94.273) train_loss=194.40408325 time/batch=0.53s
11464/10943 (epoch 94.281) train_loss=158.10090637 time/batch=0.43s
11465/10943 (epoch 94.289) train_loss=340.42153931 time/batch=0.80s
11466/10943 (epoch 94.298) train_loss=211.48052979 time/batch=0.58s
11467/10943 (epoch 94.306) train_loss=187.67257690 time/batch=0.48s
11468/10943 (epoch 94.314) train_loss=815.37487793 time/batch=3.03s
11469/10943 (epoch 94.322) train_loss=270.53356934 time/batch=0.93s
11470/10943 (epoch 94.331) train_loss=324.50842285 time/batch=0.84s
11471/10943 (epoch 94.339) train_loss=229.40786743 time/batch=0.62s
11472/10943 (epoch 94.347) train_loss=380.58258057 time/batch=0.94s
11473/10943 (epoch 94.355) train_loss=144.18572998 time/batch=0.41s
11474/10943 (epoch 94.363) train_loss=474.05029297 time/batch=1.14s
11475/10943 (epoch 94.372) train_loss=269.95690918 time/batch=0.72s
11476/10943 (epoch 94.380) train_loss=359.99536133 time/batch=0.92s
11477/10943 (epoch 94.388) train_loss=202.56539917 time/batch=0.56s
11478/10943 (epoch 94.396) train_loss=337.53192139 time/batch=0.82s
11479/10943 (epoch 94.405) train_loss=231.03289795 time/batch=0.63s
11480/10943 (epoch 94.413) train_loss=274.24935913 time/batch=0.71s
11481/10943 (epoch 94.421) train_loss=321.72338867 time/batch=0.85s
11482/10943 (epoch 94.429) train_loss=157.20538330 time/batch=0.44s
11483/10943 (epoch 94.437) train_loss=222.22225952 time/batch=0.56s
11484/10943 (epoch 94.446) train_loss=93.60668182 time/batch=0.28s
11485/10943 (epoch 94.454) train_loss=296.42724609 time/batch=0.73s
11486/10943 (epoch 94.462) train_loss=268.29321289 time/batch=0.68s
11487/10943 (epoch 94.470) train_loss=368.20452881 time/batch=0.88s
11488/10943 (epoch 94.479) train_loss=176.31010437 time/batch=0.48s
11489/10943 (epoch 94.487) train_loss=205.01062012 time/batch=0.53s
11490/10943 (epoch 94.495) train_loss=180.67114258 time/batch=0.49s
11491/10943 (epoch 94.503) train_loss=258.50115967 time/batch=0.66s
11492/10943 (epoch 94.511) train_loss=265.32330322 time/batch=0.68s
11493/10943 (epoch 94.520) train_loss=400.30212402 time/batch=0.93s
11494/10943 (epoch 94.528) train_loss=296.89050293 time/batch=0.78s
11495/10943 (epoch 94.536) train_loss=350.04577637 time/batch=0.91s
11496/10943 (epoch 94.544) train_loss=300.96377563 time/batch=0.81s
11497/10943 (epoch 94.553) train_loss=268.58239746 time/batch=0.71s
11498/10943 (epoch 94.561) train_loss=249.25759888 time/batch=0.64s
11499/10943 (epoch 94.569) train_loss=253.80456543 time/batch=0.63s
11500/10943 (epoch 94.577) train_loss=122.11437225 time/batch=0.34s
11501/10943 (epoch 94.585) train_loss=262.40814209 time/batch=0.62s
11502/10943 (epoch 94.594) train_loss=306.25872803 time/batch=0.79s
11503/10943 (epoch 94.602) train_loss=141.08110046 time/batch=0.40s
11504/10943 (epoch 94.610) train_loss=229.01544189 time/batch=0.59s
11505/10943 (epoch 94.618) train_loss=223.69993591 time/batch=0.57s
11506/10943 (epoch 94.627) train_loss=212.81353760 time/batch=0.54s
11507/10943 (epoch 94.635) train_loss=157.29089355 time/batch=0.44s
11508/10943 (epoch 94.643) train_loss=257.54089355 time/batch=0.66s
11509/10943 (epoch 94.651) train_loss=232.66316223 time/batch=0.62s
11510/10943 (epoch 94.659) train_loss=181.19998169 time/batch=0.48s
11511/10943 (epoch 94.668) train_loss=123.36241150 time/batch=0.32s
11512/10943 (epoch 94.676) train_loss=203.40100098 time/batch=0.49s
11513/10943 (epoch 94.684) train_loss=230.81269836 time/batch=0.55s
11514/10943 (epoch 94.692) train_loss=191.68235779 time/batch=0.48s
11515/10943 (epoch 94.701) train_loss=330.02917480 time/batch=0.78s
11516/10943 (epoch 94.709) train_loss=196.94833374 time/batch=0.56s
11517/10943 (epoch 94.717) train_loss=360.48303223 time/batch=0.94s
11518/10943 (epoch 94.725) train_loss=294.56042480 time/batch=0.81s
11519/10943 (epoch 94.733) train_loss=330.14697266 time/batch=0.83s
11520/10943 (epoch 94.742) train_loss=248.89869690 time/batch=0.64s
11521/10943 (epoch 94.750) train_loss=166.19476318 time/batch=0.47s
11522/10943 (epoch 94.758) train_loss=298.47518921 time/batch=0.76s
11523/10943 (epoch 94.766) train_loss=289.20397949 time/batch=0.72s
11524/10943 (epoch 94.775) train_loss=200.49102783 time/batch=0.56s
11525/10943 (epoch 94.783) train_loss=309.57019043 time/batch=0.78s
11526/10943 (epoch 94.791) train_loss=287.37570190 time/batch=0.71s
11527/10943 (epoch 94.799) train_loss=224.40521240 time/batch=0.61s
11528/10943 (epoch 94.808) train_loss=132.53222656 time/batch=0.38s
11529/10943 (epoch 94.816) train_loss=158.74427795 time/batch=0.57s
11530/10943 (epoch 94.824) train_loss=253.09617615 time/batch=0.70s
11531/10943 (epoch 94.832) train_loss=266.89956665 time/batch=0.79s
setting learning rate to 0.0012030
11532/10943 (epoch 94.840) train_loss=546.01733398 time/batch=1.29s
11533/10943 (epoch 94.849) train_loss=362.04916382 time/batch=0.98s
11534/10943 (epoch 94.857) train_loss=390.39434814 time/batch=0.94s
11535/10943 (epoch 94.865) train_loss=549.33117676 time/batch=1.38s
11536/10943 (epoch 94.873) train_loss=302.91186523 time/batch=0.85s
11537/10943 (epoch 94.882) train_loss=344.55413818 time/batch=0.92s
11538/10943 (epoch 94.890) train_loss=613.18652344 time/batch=1.55s
11539/10943 (epoch 94.898) train_loss=432.32153320 time/batch=1.15s
11540/10943 (epoch 94.906) train_loss=198.71185303 time/batch=0.59s
11541/10943 (epoch 94.914) train_loss=199.64727783 time/batch=0.51s
11542/10943 (epoch 94.923) train_loss=470.83654785 time/batch=1.14s
11543/10943 (epoch 94.931) train_loss=151.83772278 time/batch=0.44s
11544/10943 (epoch 94.939) train_loss=228.13157654 time/batch=0.58s
11545/10943 (epoch 94.947) train_loss=306.17877197 time/batch=0.76s
11546/10943 (epoch 94.956) train_loss=233.96186829 time/batch=0.62s
11547/10943 (epoch 94.964) train_loss=383.92837524 time/batch=0.92s
11548/10943 (epoch 94.972) train_loss=105.75767517 time/batch=0.32s
11549/10943 (epoch 94.980) train_loss=821.28820801 time/batch=2.12s
11550/10943 (epoch 94.988) train_loss=293.74035645 time/batch=0.88s
11551/10943 (epoch 94.997) train_loss=807.48229980 time/batch=3.05s
11552/10943 (epoch 95.005) train_loss=484.01525879 time/batch=1.43s
11553/10943 (epoch 95.013) train_loss=340.29159546 time/batch=0.89s
11554/10943 (epoch 95.021) train_loss=498.71905518 time/batch=1.21s
11555/10943 (epoch 95.030) train_loss=418.51666260 time/batch=1.05s
11556/10943 (epoch 95.038) train_loss=545.71820068 time/batch=1.41s
11557/10943 (epoch 95.046) train_loss=219.88650513 time/batch=0.66s
11558/10943 (epoch 95.054) train_loss=454.79675293 time/batch=1.06s
11559/10943 (epoch 95.062) train_loss=205.85620117 time/batch=0.59s
11560/10943 (epoch 95.071) train_loss=424.18035889 time/batch=0.96s
11561/10943 (epoch 95.079) train_loss=157.81132507 time/batch=0.46s
11562/10943 (epoch 95.087) train_loss=443.62115479 time/batch=1.06s
11563/10943 (epoch 95.095) train_loss=431.32305908 time/batch=1.05s
11564/10943 (epoch 95.104) train_loss=221.93936157 time/batch=0.62s
11565/10943 (epoch 95.112) train_loss=272.93115234 time/batch=0.65s
11566/10943 (epoch 95.120) train_loss=288.34289551 time/batch=0.71s
11567/10943 (epoch 95.128) train_loss=136.78475952 time/batch=0.40s
11568/10943 (epoch 95.136) train_loss=98.35618591 time/batch=0.28s
11569/10943 (epoch 95.145) train_loss=346.96136475 time/batch=0.82s
11570/10943 (epoch 95.153) train_loss=328.00311279 time/batch=0.83s
11571/10943 (epoch 95.161) train_loss=327.83984375 time/batch=0.87s
11572/10943 (epoch 95.169) train_loss=489.66290283 time/batch=1.42s
11573/10943 (epoch 95.178) train_loss=252.09080505 time/batch=0.73s
11574/10943 (epoch 95.186) train_loss=117.43508911 time/batch=0.33s
11575/10943 (epoch 95.194) train_loss=256.26800537 time/batch=0.60s
11576/10943 (epoch 95.202) train_loss=447.09298706 time/batch=1.09s
11577/10943 (epoch 95.210) train_loss=122.80420685 time/batch=0.38s
11578/10943 (epoch 95.219) train_loss=326.34020996 time/batch=0.78s
11579/10943 (epoch 95.227) train_loss=215.21456909 time/batch=0.58s
11580/10943 (epoch 95.235) train_loss=190.43925476 time/batch=0.48s
11581/10943 (epoch 95.243) train_loss=169.50277710 time/batch=0.42s
11582/10943 (epoch 95.252) train_loss=227.60723877 time/batch=0.56s
11583/10943 (epoch 95.260) train_loss=384.40747070 time/batch=1.01s
11584/10943 (epoch 95.268) train_loss=377.76849365 time/batch=0.99s
11585/10943 (epoch 95.276) train_loss=265.86346436 time/batch=0.70s
11586/10943 (epoch 95.285) train_loss=118.54800415 time/batch=0.33s
11587/10943 (epoch 95.293) train_loss=140.13279724 time/batch=0.34s
11588/10943 (epoch 95.301) train_loss=357.72503662 time/batch=0.83s
11589/10943 (epoch 95.309) train_loss=355.59017944 time/batch=0.91s
11590/10943 (epoch 95.317) train_loss=290.73309326 time/batch=0.78s
11591/10943 (epoch 95.326) train_loss=360.08538818 time/batch=0.90s
11592/10943 (epoch 95.334) train_loss=199.00698853 time/batch=0.54s
11593/10943 (epoch 95.342) train_loss=141.71273804 time/batch=0.38s
11594/10943 (epoch 95.350) train_loss=170.77917480 time/batch=0.44s
11595/10943 (epoch 95.359) train_loss=395.74041748 time/batch=0.93s
11596/10943 (epoch 95.367) train_loss=328.60238647 time/batch=0.85s
11597/10943 (epoch 95.375) train_loss=346.74816895 time/batch=0.87s
11598/10943 (epoch 95.383) train_loss=249.35162354 time/batch=0.65s
11599/10943 (epoch 95.391) train_loss=389.11135864 time/batch=1.02s
11600/10943 (epoch 95.400) train_loss=282.15216064 time/batch=0.77s
11601/10943 (epoch 95.408) train_loss=128.65600586 time/batch=0.36s
11602/10943 (epoch 95.416) train_loss=266.56085205 time/batch=0.65s
11603/10943 (epoch 95.424) train_loss=153.94390869 time/batch=0.44s
11604/10943 (epoch 95.433) train_loss=197.72509766 time/batch=0.51s
11605/10943 (epoch 95.441) train_loss=226.64949036 time/batch=0.57s
11606/10943 (epoch 95.449) train_loss=209.69648743 time/batch=0.55s
11607/10943 (epoch 95.457) train_loss=300.39166260 time/batch=0.78s
11608/10943 (epoch 95.465) train_loss=157.15692139 time/batch=0.46s
11609/10943 (epoch 95.474) train_loss=157.63085938 time/batch=0.42s
11610/10943 (epoch 95.482) train_loss=282.04687500 time/batch=0.70s
11611/10943 (epoch 95.490) train_loss=294.94262695 time/batch=0.73s
11612/10943 (epoch 95.498) train_loss=302.34405518 time/batch=0.81s
11613/10943 (epoch 95.507) train_loss=230.90019226 time/batch=0.62s
11614/10943 (epoch 95.515) train_loss=223.41487122 time/batch=0.58s
11615/10943 (epoch 95.523) train_loss=253.85937500 time/batch=0.64s
11616/10943 (epoch 95.531) train_loss=309.31961060 time/batch=0.77s
11617/10943 (epoch 95.539) train_loss=165.48150635 time/batch=0.47s
11618/10943 (epoch 95.548) train_loss=326.84143066 time/batch=0.81s
11619/10943 (epoch 95.556) train_loss=291.03527832 time/batch=0.76s
11620/10943 (epoch 95.564) train_loss=311.45828247 time/batch=0.81s
11621/10943 (epoch 95.572) train_loss=184.09698486 time/batch=0.50s
11622/10943 (epoch 95.581) train_loss=307.43444824 time/batch=0.79s
11623/10943 (epoch 95.589) train_loss=237.79666138 time/batch=0.65s
11624/10943 (epoch 95.597) train_loss=228.61236572 time/batch=0.58s
11625/10943 (epoch 95.605) train_loss=303.76110840 time/batch=0.78s
11626/10943 (epoch 95.613) train_loss=260.30612183 time/batch=0.70s
11627/10943 (epoch 95.622) train_loss=169.92630005 time/batch=0.47s
11628/10943 (epoch 95.630) train_loss=147.24984741 time/batch=0.42s
11629/10943 (epoch 95.638) train_loss=205.18023682 time/batch=0.52s
11630/10943 (epoch 95.646) train_loss=187.66574097 time/batch=0.48s
11631/10943 (epoch 95.655) train_loss=223.41879272 time/batch=0.58s
11632/10943 (epoch 95.663) train_loss=295.03805542 time/batch=0.78s
11633/10943 (epoch 95.671) train_loss=268.43829346 time/batch=0.69s
11634/10943 (epoch 95.679) train_loss=277.99267578 time/batch=0.70s
11635/10943 (epoch 95.687) train_loss=188.79804993 time/batch=0.49s
11636/10943 (epoch 95.696) train_loss=237.78645325 time/batch=0.60s
11637/10943 (epoch 95.704) train_loss=272.23858643 time/batch=0.68s
11638/10943 (epoch 95.712) train_loss=302.17785645 time/batch=0.77s
11639/10943 (epoch 95.720) train_loss=301.33764648 time/batch=0.80s
11640/10943 (epoch 95.729) train_loss=202.02049255 time/batch=0.56s
11641/10943 (epoch 95.737) train_loss=277.79925537 time/batch=0.69s
11642/10943 (epoch 95.745) train_loss=193.02841187 time/batch=0.52s
11643/10943 (epoch 95.753) train_loss=125.23476410 time/batch=0.34s
11644/10943 (epoch 95.762) train_loss=220.25808716 time/batch=0.55s
11645/10943 (epoch 95.770) train_loss=257.94656372 time/batch=0.66s
11646/10943 (epoch 95.778) train_loss=284.96472168 time/batch=0.72s
11647/10943 (epoch 95.786) train_loss=141.44198608 time/batch=0.46s
11648/10943 (epoch 95.794) train_loss=255.36849976 time/batch=0.63s
11649/10943 (epoch 95.803) train_loss=251.45791626 time/batch=0.68s
11650/10943 (epoch 95.811) train_loss=274.26773071 time/batch=0.78s
11651/10943 (epoch 95.819) train_loss=196.26391602 time/batch=0.62s
11652/10943 (epoch 95.827) train_loss=232.41693115 time/batch=0.61s
setting learning rate to 0.0011669
  saved to metadata/gru_dropout-9_nov_folkwiki-20181207-173447_epoch51.pkl
11653/10943 (epoch 95.836) train_loss=647.68658447 time/batch=1.63s
11654/10943 (epoch 95.844) train_loss=146.49819946 time/batch=0.49s
11655/10943 (epoch 95.852) train_loss=269.54086304 time/batch=0.63s
11656/10943 (epoch 95.860) train_loss=222.96499634 time/batch=0.58s
11657/10943 (epoch 95.868) train_loss=108.99511719 time/batch=0.30s
11658/10943 (epoch 95.877) train_loss=189.81221008 time/batch=0.46s
11659/10943 (epoch 95.885) train_loss=361.45880127 time/batch=0.88s
11660/10943 (epoch 95.893) train_loss=477.62530518 time/batch=1.19s
11661/10943 (epoch 95.901) train_loss=220.94955444 time/batch=0.64s
11662/10943 (epoch 95.910) train_loss=555.28381348 time/batch=1.39s
11663/10943 (epoch 95.918) train_loss=350.95263672 time/batch=0.99s
11664/10943 (epoch 95.926) train_loss=459.00506592 time/batch=1.11s
11665/10943 (epoch 95.934) train_loss=322.86871338 time/batch=0.88s
11666/10943 (epoch 95.942) train_loss=445.72521973 time/batch=1.12s
11667/10943 (epoch 95.951) train_loss=519.76428223 time/batch=1.28s
11668/10943 (epoch 95.959) train_loss=131.33697510 time/batch=0.42s
11669/10943 (epoch 95.967) train_loss=337.46380615 time/batch=0.81s
11670/10943 (epoch 95.975) train_loss=251.44808960 time/batch=0.67s
11671/10943 (epoch 95.984) train_loss=282.34533691 time/batch=0.74s
11672/10943 (epoch 95.992) train_loss=386.12930298 time/batch=0.96s
11673/10943 (epoch 96.000) train_loss=438.17675781 time/batch=1.14s
11674/10943 (epoch 96.008) train_loss=301.16113281 time/batch=0.83s
11675/10943 (epoch 96.016) train_loss=252.70828247 time/batch=0.65s
11676/10943 (epoch 96.025) train_loss=256.70434570 time/batch=0.63s
11677/10943 (epoch 96.033) train_loss=420.70199585 time/batch=1.01s
11678/10943 (epoch 96.041) train_loss=173.52566528 time/batch=0.51s
11679/10943 (epoch 96.049) train_loss=482.00537109 time/batch=1.15s
11680/10943 (epoch 96.058) train_loss=440.78448486 time/batch=1.17s
11681/10943 (epoch 96.066) train_loss=156.50775146 time/batch=0.48s
11682/10943 (epoch 96.074) train_loss=140.29855347 time/batch=0.38s
11683/10943 (epoch 96.082) train_loss=555.37597656 time/batch=1.27s
11684/10943 (epoch 96.090) train_loss=194.48442078 time/batch=0.58s
11685/10943 (epoch 96.099) train_loss=336.51849365 time/batch=0.83s
11686/10943 (epoch 96.107) train_loss=164.25772095 time/batch=0.47s
11687/10943 (epoch 96.115) train_loss=224.52169800 time/batch=0.56s
11688/10943 (epoch 96.123) train_loss=382.82232666 time/batch=0.92s
11689/10943 (epoch 96.132) train_loss=418.78540039 time/batch=1.05s
11690/10943 (epoch 96.140) train_loss=627.34033203 time/batch=1.63s
11691/10943 (epoch 96.148) train_loss=309.13412476 time/batch=0.91s
11692/10943 (epoch 96.156) train_loss=351.72579956 time/batch=0.89s
11693/10943 (epoch 96.164) train_loss=776.60351562 time/batch=2.08s
11694/10943 (epoch 96.173) train_loss=154.88046265 time/batch=0.56s
11695/10943 (epoch 96.181) train_loss=291.14245605 time/batch=0.67s
11696/10943 (epoch 96.189) train_loss=302.77410889 time/batch=0.80s
11697/10943 (epoch 96.197) train_loss=236.80364990 time/batch=0.64s
11698/10943 (epoch 96.206) train_loss=368.87948608 time/batch=0.86s
11699/10943 (epoch 96.214) train_loss=323.44250488 time/batch=0.84s
11700/10943 (epoch 96.222) train_loss=201.42092896 time/batch=0.53s
11701/10943 (epoch 96.230) train_loss=193.17143250 time/batch=0.52s
11702/10943 (epoch 96.238) train_loss=265.91363525 time/batch=0.64s
11703/10943 (epoch 96.247) train_loss=364.65411377 time/batch=0.91s
11704/10943 (epoch 96.255) train_loss=107.48237610 time/batch=0.35s
11705/10943 (epoch 96.263) train_loss=420.56552124 time/batch=1.00s
11706/10943 (epoch 96.271) train_loss=201.52136230 time/batch=0.59s
11707/10943 (epoch 96.280) train_loss=447.27047729 time/batch=1.17s
11708/10943 (epoch 96.288) train_loss=331.78591919 time/batch=0.92s
11709/10943 (epoch 96.296) train_loss=121.74832153 time/batch=0.36s
11710/10943 (epoch 96.304) train_loss=284.14154053 time/batch=0.68s
11711/10943 (epoch 96.313) train_loss=412.50842285 time/batch=0.98s
11712/10943 (epoch 96.321) train_loss=143.35406494 time/batch=0.42s
11713/10943 (epoch 96.329) train_loss=190.04606628 time/batch=0.49s
11714/10943 (epoch 96.337) train_loss=185.99365234 time/batch=0.46s
11715/10943 (epoch 96.345) train_loss=223.61949158 time/batch=0.57s
11716/10943 (epoch 96.354) train_loss=394.63986206 time/batch=0.93s
11717/10943 (epoch 96.362) train_loss=184.60452271 time/batch=0.52s
11718/10943 (epoch 96.370) train_loss=332.05499268 time/batch=0.81s
11719/10943 (epoch 96.378) train_loss=371.47076416 time/batch=0.98s
11720/10943 (epoch 96.387) train_loss=150.32521057 time/batch=0.46s
11721/10943 (epoch 96.395) train_loss=218.26983643 time/batch=0.52s
11722/10943 (epoch 96.403) train_loss=124.97535706 time/batch=0.34s
11723/10943 (epoch 96.411) train_loss=578.32318115 time/batch=2.24s
11724/10943 (epoch 96.419) train_loss=163.97587585 time/batch=0.61s
11725/10943 (epoch 96.428) train_loss=287.11254883 time/batch=0.71s
11726/10943 (epoch 96.436) train_loss=231.52188110 time/batch=0.59s
11727/10943 (epoch 96.444) train_loss=351.90832520 time/batch=0.95s
11728/10943 (epoch 96.452) train_loss=267.66381836 time/batch=0.70s
11729/10943 (epoch 96.461) train_loss=265.88311768 time/batch=0.66s
11730/10943 (epoch 96.469) train_loss=110.68676758 time/batch=0.32s
11731/10943 (epoch 96.477) train_loss=264.27825928 time/batch=0.63s
11732/10943 (epoch 96.485) train_loss=305.70135498 time/batch=0.77s
11733/10943 (epoch 96.493) train_loss=262.94213867 time/batch=0.70s
11734/10943 (epoch 96.502) train_loss=212.89370728 time/batch=0.56s
11735/10943 (epoch 96.510) train_loss=234.34539795 time/batch=0.60s
11736/10943 (epoch 96.518) train_loss=115.64447021 time/batch=0.33s
11737/10943 (epoch 96.526) train_loss=294.03033447 time/batch=0.71s
11738/10943 (epoch 96.535) train_loss=254.87716675 time/batch=0.68s
11739/10943 (epoch 96.543) train_loss=176.11100769 time/batch=0.48s
11740/10943 (epoch 96.551) train_loss=199.72843933 time/batch=0.49s
11741/10943 (epoch 96.559) train_loss=277.62252808 time/batch=0.69s
11742/10943 (epoch 96.567) train_loss=231.01281738 time/batch=0.62s
11743/10943 (epoch 96.576) train_loss=142.70689392 time/batch=0.42s
11744/10943 (epoch 96.584) train_loss=288.53915405 time/batch=0.67s
11745/10943 (epoch 96.592) train_loss=203.13825989 time/batch=0.56s
11746/10943 (epoch 96.600) train_loss=223.78779602 time/batch=0.59s
11747/10943 (epoch 96.609) train_loss=239.11723328 time/batch=0.61s
11748/10943 (epoch 96.617) train_loss=127.42570496 time/batch=0.36s
11749/10943 (epoch 96.625) train_loss=192.63250732 time/batch=0.46s
11750/10943 (epoch 96.633) train_loss=299.17504883 time/batch=0.77s
11751/10943 (epoch 96.641) train_loss=176.17669678 time/batch=0.46s
11752/10943 (epoch 96.650) train_loss=195.22146606 time/batch=0.53s
11753/10943 (epoch 96.658) train_loss=241.79504395 time/batch=0.62s
11754/10943 (epoch 96.666) train_loss=262.51922607 time/batch=0.67s
11755/10943 (epoch 96.674) train_loss=475.63034058 time/batch=3.06s
11756/10943 (epoch 96.683) train_loss=297.35070801 time/batch=0.98s
11757/10943 (epoch 96.691) train_loss=310.88494873 time/batch=0.81s
11758/10943 (epoch 96.699) train_loss=158.02278137 time/batch=0.47s
11759/10943 (epoch 96.707) train_loss=293.94253540 time/batch=0.69s
11760/10943 (epoch 96.715) train_loss=310.18695068 time/batch=0.75s
11761/10943 (epoch 96.724) train_loss=306.67150879 time/batch=0.78s
11762/10943 (epoch 96.732) train_loss=211.78250122 time/batch=0.57s
11763/10943 (epoch 96.740) train_loss=268.16210938 time/batch=0.67s
11764/10943 (epoch 96.748) train_loss=289.84078979 time/batch=0.78s
11765/10943 (epoch 96.757) train_loss=317.74716187 time/batch=0.83s
11766/10943 (epoch 96.765) train_loss=267.95089722 time/batch=0.74s
11767/10943 (epoch 96.773) train_loss=321.13110352 time/batch=0.81s
11768/10943 (epoch 96.781) train_loss=279.18035889 time/batch=0.77s
11769/10943 (epoch 96.790) train_loss=231.99337769 time/batch=0.61s
11770/10943 (epoch 96.798) train_loss=252.89025879 time/batch=0.75s
11771/10943 (epoch 96.806) train_loss=188.37686157 time/batch=0.58s
11772/10943 (epoch 96.814) train_loss=234.85205078 time/batch=0.60s
11773/10943 (epoch 96.822) train_loss=275.09774780 time/batch=0.77s
setting learning rate to 0.0011319
11774/10943 (epoch 96.831) train_loss=191.85113525 time/batch=0.52s
11775/10943 (epoch 96.839) train_loss=655.39953613 time/batch=1.55s
11776/10943 (epoch 96.847) train_loss=923.18847656 time/batch=3.16s
11777/10943 (epoch 96.855) train_loss=113.90290070 time/batch=0.59s
11778/10943 (epoch 96.864) train_loss=140.98980713 time/batch=0.34s
11779/10943 (epoch 96.872) train_loss=360.91876221 time/batch=0.88s
11780/10943 (epoch 96.880) train_loss=610.54467773 time/batch=1.61s
11781/10943 (epoch 96.888) train_loss=357.36630249 time/batch=0.99s
11782/10943 (epoch 96.896) train_loss=267.00823975 time/batch=0.69s
11783/10943 (epoch 96.905) train_loss=375.42889404 time/batch=0.95s
11784/10943 (epoch 96.913) train_loss=200.40715027 time/batch=0.55s
11785/10943 (epoch 96.921) train_loss=113.51488495 time/batch=0.30s
11786/10943 (epoch 96.929) train_loss=393.84216309 time/batch=0.94s
11787/10943 (epoch 96.938) train_loss=512.62829590 time/batch=1.27s
11788/10943 (epoch 96.946) train_loss=369.31399536 time/batch=0.93s
11789/10943 (epoch 96.954) train_loss=551.93872070 time/batch=1.37s
11790/10943 (epoch 96.962) train_loss=236.82301331 time/batch=0.68s
11791/10943 (epoch 96.970) train_loss=195.54843140 time/batch=0.53s
11792/10943 (epoch 96.979) train_loss=295.02581787 time/batch=0.77s
11793/10943 (epoch 96.987) train_loss=430.71936035 time/batch=1.07s
11794/10943 (epoch 96.995) train_loss=284.48828125 time/batch=0.78s
11795/10943 (epoch 97.003) train_loss=220.99618530 time/batch=0.58s
11796/10943 (epoch 97.012) train_loss=99.85794067 time/batch=0.31s
11797/10943 (epoch 97.020) train_loss=167.52075195 time/batch=0.40s
11798/10943 (epoch 97.028) train_loss=300.30886841 time/batch=0.75s
11799/10943 (epoch 97.036) train_loss=157.23049927 time/batch=0.43s
11800/10943 (epoch 97.044) train_loss=549.58880615 time/batch=1.25s
11801/10943 (epoch 97.053) train_loss=294.30078125 time/batch=0.80s
11802/10943 (epoch 97.061) train_loss=141.88787842 time/batch=0.39s
11803/10943 (epoch 97.069) train_loss=316.44665527 time/batch=0.77s
11804/10943 (epoch 97.077) train_loss=438.12805176 time/batch=1.08s
11805/10943 (epoch 97.086) train_loss=534.69586182 time/batch=1.65s
11806/10943 (epoch 97.094) train_loss=342.20422363 time/batch=0.95s
11807/10943 (epoch 97.102) train_loss=258.43048096 time/batch=0.69s
11808/10943 (epoch 97.110) train_loss=339.29211426 time/batch=0.87s
11809/10943 (epoch 97.118) train_loss=261.70468140 time/batch=0.66s
11810/10943 (epoch 97.127) train_loss=128.00808716 time/batch=0.35s
11811/10943 (epoch 97.135) train_loss=328.63531494 time/batch=0.81s
11812/10943 (epoch 97.143) train_loss=260.73419189 time/batch=0.70s
11813/10943 (epoch 97.151) train_loss=457.67333984 time/batch=1.08s
11814/10943 (epoch 97.160) train_loss=145.76968384 time/batch=0.44s
11815/10943 (epoch 97.168) train_loss=437.94564819 time/batch=1.07s
11816/10943 (epoch 97.176) train_loss=295.54290771 time/batch=0.74s
11817/10943 (epoch 97.184) train_loss=157.27690125 time/batch=0.44s
11818/10943 (epoch 97.192) train_loss=181.56604004 time/batch=0.46s
11819/10943 (epoch 97.201) train_loss=415.75433350 time/batch=0.94s
11820/10943 (epoch 97.209) train_loss=194.87617493 time/batch=0.57s
11821/10943 (epoch 97.217) train_loss=237.23957825 time/batch=0.59s
11822/10943 (epoch 97.225) train_loss=170.82852173 time/batch=0.45s
11823/10943 (epoch 97.234) train_loss=467.70248413 time/batch=1.14s
11824/10943 (epoch 97.242) train_loss=493.05572510 time/batch=1.22s
11825/10943 (epoch 97.250) train_loss=211.57022095 time/batch=0.62s
11826/10943 (epoch 97.258) train_loss=288.22674561 time/batch=0.69s
11827/10943 (epoch 97.267) train_loss=221.93748474 time/batch=0.59s
11828/10943 (epoch 97.275) train_loss=269.26745605 time/batch=0.69s
11829/10943 (epoch 97.283) train_loss=430.64831543 time/batch=1.01s
11830/10943 (epoch 97.291) train_loss=253.37718201 time/batch=0.67s
11831/10943 (epoch 97.299) train_loss=162.91683960 time/batch=0.46s
11832/10943 (epoch 97.308) train_loss=114.07843781 time/batch=0.31s
11833/10943 (epoch 97.316) train_loss=216.60818481 time/batch=0.55s
11834/10943 (epoch 97.324) train_loss=397.98107910 time/batch=0.95s
11835/10943 (epoch 97.332) train_loss=512.19897461 time/batch=1.69s
11836/10943 (epoch 97.341) train_loss=197.78160095 time/batch=0.61s
11837/10943 (epoch 97.349) train_loss=197.11590576 time/batch=0.50s
11838/10943 (epoch 97.357) train_loss=269.02355957 time/batch=0.70s
11839/10943 (epoch 97.365) train_loss=117.58811951 time/batch=0.34s
11840/10943 (epoch 97.373) train_loss=334.30966187 time/batch=0.78s
11841/10943 (epoch 97.382) train_loss=184.71801758 time/batch=0.51s
11842/10943 (epoch 97.390) train_loss=286.26794434 time/batch=0.69s
11843/10943 (epoch 97.398) train_loss=142.79986572 time/batch=0.42s
11844/10943 (epoch 97.406) train_loss=148.34155273 time/batch=0.38s
11845/10943 (epoch 97.415) train_loss=403.18206787 time/batch=1.06s
11846/10943 (epoch 97.423) train_loss=345.25125122 time/batch=0.90s
11847/10943 (epoch 97.431) train_loss=186.00462341 time/batch=0.52s
11848/10943 (epoch 97.439) train_loss=290.63439941 time/batch=0.72s
11849/10943 (epoch 97.447) train_loss=228.30456543 time/batch=0.59s
11850/10943 (epoch 97.456) train_loss=350.27056885 time/batch=0.87s
11851/10943 (epoch 97.464) train_loss=267.94976807 time/batch=0.71s
11852/10943 (epoch 97.472) train_loss=351.81091309 time/batch=0.89s
11853/10943 (epoch 97.480) train_loss=175.87120056 time/batch=0.50s
11854/10943 (epoch 97.489) train_loss=128.29730225 time/batch=0.33s
11855/10943 (epoch 97.497) train_loss=280.06793213 time/batch=0.69s
11856/10943 (epoch 97.505) train_loss=299.41137695 time/batch=0.77s
11857/10943 (epoch 97.513) train_loss=337.35375977 time/batch=0.91s
11858/10943 (epoch 97.521) train_loss=135.43417358 time/batch=0.41s
11859/10943 (epoch 97.530) train_loss=151.55917358 time/batch=0.40s
11860/10943 (epoch 97.538) train_loss=407.85342407 time/batch=0.97s
11861/10943 (epoch 97.546) train_loss=323.26687622 time/batch=0.85s
11862/10943 (epoch 97.554) train_loss=202.08721924 time/batch=0.56s
11863/10943 (epoch 97.563) train_loss=303.55203247 time/batch=0.75s
11864/10943 (epoch 97.571) train_loss=210.12498474 time/batch=0.58s
11865/10943 (epoch 97.579) train_loss=294.61242676 time/batch=0.75s
11866/10943 (epoch 97.587) train_loss=178.59228516 time/batch=0.51s
11867/10943 (epoch 97.595) train_loss=223.96418762 time/batch=0.57s
11868/10943 (epoch 97.604) train_loss=381.03576660 time/batch=0.95s
11869/10943 (epoch 97.612) train_loss=226.55519104 time/batch=0.61s
11870/10943 (epoch 97.620) train_loss=305.74319458 time/batch=0.77s
11871/10943 (epoch 97.628) train_loss=264.67910767 time/batch=0.68s
11872/10943 (epoch 97.637) train_loss=363.27746582 time/batch=0.92s
11873/10943 (epoch 97.645) train_loss=185.43334961 time/batch=0.55s
11874/10943 (epoch 97.653) train_loss=200.46615601 time/batch=0.52s
11875/10943 (epoch 97.661) train_loss=251.92240906 time/batch=0.63s
11876/10943 (epoch 97.669) train_loss=302.27117920 time/batch=0.80s
11877/10943 (epoch 97.678) train_loss=254.56512451 time/batch=0.67s
11878/10943 (epoch 97.686) train_loss=250.15322876 time/batch=0.63s
11879/10943 (epoch 97.694) train_loss=264.41967773 time/batch=0.72s
11880/10943 (epoch 97.702) train_loss=288.29672241 time/batch=0.74s
11881/10943 (epoch 97.711) train_loss=216.38821411 time/batch=0.60s
11882/10943 (epoch 97.719) train_loss=239.10748291 time/batch=0.61s
11883/10943 (epoch 97.727) train_loss=234.94961548 time/batch=0.62s
11884/10943 (epoch 97.735) train_loss=247.34735107 time/batch=0.65s
11885/10943 (epoch 97.744) train_loss=297.83062744 time/batch=0.79s
11886/10943 (epoch 97.752) train_loss=234.83468628 time/batch=0.64s
11887/10943 (epoch 97.760) train_loss=242.77691650 time/batch=0.61s
11888/10943 (epoch 97.768) train_loss=306.60278320 time/batch=0.78s
11889/10943 (epoch 97.776) train_loss=215.39456177 time/batch=0.58s
11890/10943 (epoch 97.785) train_loss=293.15057373 time/batch=0.75s
11891/10943 (epoch 97.793) train_loss=229.41799927 time/batch=0.67s
11892/10943 (epoch 97.801) train_loss=319.05072021 time/batch=0.81s
11893/10943 (epoch 97.809) train_loss=292.89657593 time/batch=0.81s
11894/10943 (epoch 97.818) train_loss=253.23484802 time/batch=0.67s
setting learning rate to 0.0010980
  saved to metadata/gru_dropout-9_nov_folkwiki-20181207-173447_epoch53.pkl
11895/10943 (epoch 97.826) train_loss=488.14343262 time/batch=1.26s
11896/10943 (epoch 97.834) train_loss=145.99542236 time/batch=0.44s
11897/10943 (epoch 97.842) train_loss=155.61495972 time/batch=0.39s
11898/10943 (epoch 97.850) train_loss=646.07739258 time/batch=1.55s
11899/10943 (epoch 97.859) train_loss=353.19714355 time/batch=1.01s
11900/10943 (epoch 97.867) train_loss=543.35583496 time/batch=1.29s
11901/10943 (epoch 97.875) train_loss=391.88940430 time/batch=1.00s
11902/10943 (epoch 97.883) train_loss=193.57385254 time/batch=0.50s
11903/10943 (epoch 97.892) train_loss=550.81262207 time/batch=1.31s
11904/10943 (epoch 97.900) train_loss=506.70748901 time/batch=1.41s
11905/10943 (epoch 97.908) train_loss=421.86776733 time/batch=1.07s
11906/10943 (epoch 97.916) train_loss=322.13586426 time/batch=0.85s
11907/10943 (epoch 97.924) train_loss=107.67572021 time/batch=0.33s
11908/10943 (epoch 97.933) train_loss=465.74032593 time/batch=1.30s
11909/10943 (epoch 97.941) train_loss=208.12652588 time/batch=0.63s
11910/10943 (epoch 97.949) train_loss=353.93548584 time/batch=0.86s
11911/10943 (epoch 97.957) train_loss=545.07751465 time/batch=1.42s
11912/10943 (epoch 97.966) train_loss=235.39067078 time/batch=0.70s
11913/10943 (epoch 97.974) train_loss=236.86451721 time/batch=0.60s
11914/10943 (epoch 97.982) train_loss=706.34405518 time/batch=1.82s
11915/10943 (epoch 97.990) train_loss=330.12359619 time/batch=0.98s
11916/10943 (epoch 97.998) train_loss=303.84185791 time/batch=0.81s
11917/10943 (epoch 98.007) train_loss=206.69583130 time/batch=0.56s
11918/10943 (epoch 98.015) train_loss=130.57713318 time/batch=0.34s
11919/10943 (epoch 98.023) train_loss=183.85818481 time/batch=0.46s
11920/10943 (epoch 98.031) train_loss=239.58819580 time/batch=0.60s
11921/10943 (epoch 98.040) train_loss=172.10961914 time/batch=0.44s
11922/10943 (epoch 98.048) train_loss=361.07684326 time/batch=0.84s
11923/10943 (epoch 98.056) train_loss=155.68341064 time/batch=0.47s
11924/10943 (epoch 98.064) train_loss=848.52770996 time/batch=3.01s
11925/10943 (epoch 98.072) train_loss=339.68615723 time/batch=1.13s
11926/10943 (epoch 98.081) train_loss=290.05963135 time/batch=0.73s
11927/10943 (epoch 98.089) train_loss=264.70874023 time/batch=0.68s
11928/10943 (epoch 98.097) train_loss=289.43923950 time/batch=0.70s
11929/10943 (epoch 98.105) train_loss=195.97891235 time/batch=0.53s
11930/10943 (epoch 98.114) train_loss=254.44036865 time/batch=0.66s
11931/10943 (epoch 98.122) train_loss=254.41725159 time/batch=0.66s
11932/10943 (epoch 98.130) train_loss=298.08587646 time/batch=0.77s
11933/10943 (epoch 98.138) train_loss=418.22131348 time/batch=1.02s
11934/10943 (epoch 98.146) train_loss=103.07022095 time/batch=0.36s
11935/10943 (epoch 98.155) train_loss=293.32272339 time/batch=0.74s
11936/10943 (epoch 98.163) train_loss=182.20410156 time/batch=0.50s
11937/10943 (epoch 98.171) train_loss=266.31954956 time/batch=0.66s
11938/10943 (epoch 98.179) train_loss=167.98770142 time/batch=0.48s
11939/10943 (epoch 98.188) train_loss=293.11337280 time/batch=0.73s
11940/10943 (epoch 98.196) train_loss=201.44027710 time/batch=0.53s
11941/10943 (epoch 98.204) train_loss=243.66578674 time/batch=0.61s
11942/10943 (epoch 98.212) train_loss=308.88168335 time/batch=0.76s
11943/10943 (epoch 98.221) train_loss=264.55969238 time/batch=0.67s
11944/10943 (epoch 98.229) train_loss=211.95797729 time/batch=0.55s
11945/10943 (epoch 98.237) train_loss=287.43939209 time/batch=0.70s
11946/10943 (epoch 98.245) train_loss=428.50927734 time/batch=1.04s
11947/10943 (epoch 98.253) train_loss=443.17132568 time/batch=1.11s
11948/10943 (epoch 98.262) train_loss=180.93086243 time/batch=0.54s
11949/10943 (epoch 98.270) train_loss=300.14245605 time/batch=0.77s
11950/10943 (epoch 98.278) train_loss=442.93005371 time/batch=1.12s
11951/10943 (epoch 98.286) train_loss=422.45410156 time/batch=1.02s
11952/10943 (epoch 98.295) train_loss=224.95199585 time/batch=0.63s
11953/10943 (epoch 98.303) train_loss=160.10293579 time/batch=0.42s
11954/10943 (epoch 98.311) train_loss=226.02917480 time/batch=0.57s
11955/10943 (epoch 98.319) train_loss=202.05215454 time/batch=0.50s
11956/10943 (epoch 98.327) train_loss=376.64672852 time/batch=0.93s
11957/10943 (epoch 98.336) train_loss=379.33721924 time/batch=1.00s
11958/10943 (epoch 98.344) train_loss=200.07420349 time/batch=0.59s
11959/10943 (epoch 98.352) train_loss=364.70721436 time/batch=0.90s
11960/10943 (epoch 98.360) train_loss=232.73300171 time/batch=0.63s
11961/10943 (epoch 98.369) train_loss=181.59942627 time/batch=0.48s
11962/10943 (epoch 98.377) train_loss=210.60461426 time/batch=0.54s
11963/10943 (epoch 98.385) train_loss=214.22802734 time/batch=0.57s
11964/10943 (epoch 98.393) train_loss=287.85009766 time/batch=0.73s
11965/10943 (epoch 98.401) train_loss=274.52905273 time/batch=0.72s
11966/10943 (epoch 98.410) train_loss=161.83193970 time/batch=0.46s
11967/10943 (epoch 98.418) train_loss=349.87042236 time/batch=0.83s
11968/10943 (epoch 98.426) train_loss=221.13070679 time/batch=0.60s
11969/10943 (epoch 98.434) train_loss=267.41076660 time/batch=0.65s
11970/10943 (epoch 98.443) train_loss=446.64602661 time/batch=1.08s
11971/10943 (epoch 98.451) train_loss=439.92895508 time/batch=1.15s
11972/10943 (epoch 98.459) train_loss=151.89883423 time/batch=0.46s
11973/10943 (epoch 98.467) train_loss=331.14224243 time/batch=0.85s
11974/10943 (epoch 98.475) train_loss=188.24755859 time/batch=0.54s
11975/10943 (epoch 98.484) train_loss=141.15780640 time/batch=0.37s
11976/10943 (epoch 98.492) train_loss=115.85121155 time/batch=0.31s
11977/10943 (epoch 98.500) train_loss=292.78726196 time/batch=0.74s
11978/10943 (epoch 98.508) train_loss=396.93420410 time/batch=0.99s
11979/10943 (epoch 98.517) train_loss=395.70709229 time/batch=1.04s
11980/10943 (epoch 98.525) train_loss=340.79208374 time/batch=0.92s
11981/10943 (epoch 98.533) train_loss=289.79968262 time/batch=0.75s
11982/10943 (epoch 98.541) train_loss=228.13397217 time/batch=0.60s
11983/10943 (epoch 98.549) train_loss=301.18585205 time/batch=0.76s
11984/10943 (epoch 98.558) train_loss=288.58804321 time/batch=0.74s
11985/10943 (epoch 98.566) train_loss=289.21130371 time/batch=0.76s
11986/10943 (epoch 98.574) train_loss=275.26657104 time/batch=0.73s
11987/10943 (epoch 98.582) train_loss=139.43710327 time/batch=0.41s
11988/10943 (epoch 98.591) train_loss=263.90667725 time/batch=0.64s
11989/10943 (epoch 98.599) train_loss=228.39208984 time/batch=0.62s
11990/10943 (epoch 98.607) train_loss=241.76132202 time/batch=0.63s
11991/10943 (epoch 98.615) train_loss=266.02462769 time/batch=0.69s
11992/10943 (epoch 98.623) train_loss=367.10467529 time/batch=1.12s
11993/10943 (epoch 98.632) train_loss=318.59667969 time/batch=0.87s
11994/10943 (epoch 98.640) train_loss=238.46089172 time/batch=0.60s
11995/10943 (epoch 98.648) train_loss=133.93821716 time/batch=0.38s
11996/10943 (epoch 98.656) train_loss=225.78897095 time/batch=0.58s
11997/10943 (epoch 98.665) train_loss=253.07417297 time/batch=0.63s
11998/10943 (epoch 98.673) train_loss=109.24546051 time/batch=0.32s
11999/10943 (epoch 98.681) train_loss=319.91076660 time/batch=0.78s
Validating
    loss:	278.696340

12000/10943 (epoch 98.689) train_loss=262.80596924 time/batch=2.53s
12001/10943 (epoch 98.698) train_loss=222.12170410 time/batch=0.59s
12002/10943 (epoch 98.706) train_loss=329.46929932 time/batch=0.82s
12003/10943 (epoch 98.714) train_loss=311.12533569 time/batch=0.81s
12004/10943 (epoch 98.722) train_loss=288.56237793 time/batch=0.79s
12005/10943 (epoch 98.730) train_loss=329.22760010 time/batch=0.82s
12006/10943 (epoch 98.739) train_loss=260.95681763 time/batch=0.71s
12007/10943 (epoch 98.747) train_loss=349.25506592 time/batch=1.13s
12008/10943 (epoch 98.755) train_loss=252.87356567 time/batch=0.70s
12009/10943 (epoch 98.763) train_loss=128.69213867 time/batch=0.34s
12010/10943 (epoch 98.772) train_loss=181.79225159 time/batch=0.46s
12011/10943 (epoch 98.780) train_loss=194.39991760 time/batch=0.49s
12012/10943 (epoch 98.788) train_loss=121.79773712 time/batch=0.37s
12013/10943 (epoch 98.796) train_loss=151.21777344 time/batch=0.49s
12014/10943 (epoch 98.804) train_loss=156.30224609 time/batch=0.51s
12015/10943 (epoch 98.813) train_loss=267.87908936 time/batch=0.71s
setting learning rate to 0.0010650
12016/10943 (epoch 98.821) train_loss=177.99189758 time/batch=0.48s
12017/10943 (epoch 98.829) train_loss=466.81225586 time/batch=1.10s
12018/10943 (epoch 98.837) train_loss=161.06805420 time/batch=0.48s
12019/10943 (epoch 98.846) train_loss=295.19555664 time/batch=0.72s
12020/10943 (epoch 98.854) train_loss=225.75610352 time/batch=0.60s
12021/10943 (epoch 98.862) train_loss=287.18417358 time/batch=0.72s
12022/10943 (epoch 98.870) train_loss=292.50363159 time/batch=0.73s
12023/10943 (epoch 98.878) train_loss=683.94427490 time/batch=1.65s
12024/10943 (epoch 98.887) train_loss=552.89880371 time/batch=1.46s
12025/10943 (epoch 98.895) train_loss=110.80564117 time/batch=0.38s
12026/10943 (epoch 98.903) train_loss=434.25305176 time/batch=0.96s
12027/10943 (epoch 98.911) train_loss=259.45129395 time/batch=0.69s
12028/10943 (epoch 98.920) train_loss=457.66653442 time/batch=1.07s
12029/10943 (epoch 98.928) train_loss=430.25933838 time/batch=1.09s
12030/10943 (epoch 98.936) train_loss=380.91735840 time/batch=1.01s
12031/10943 (epoch 98.944) train_loss=560.11804199 time/batch=1.39s
12032/10943 (epoch 98.952) train_loss=428.06768799 time/batch=1.16s
12033/10943 (epoch 98.961) train_loss=923.30895996 time/batch=3.09s
12034/10943 (epoch 98.969) train_loss=270.10327148 time/batch=0.94s
12035/10943 (epoch 98.977) train_loss=604.50415039 time/batch=1.64s
12036/10943 (epoch 98.985) train_loss=419.77673340 time/batch=1.13s
12037/10943 (epoch 98.994) train_loss=171.74322510 time/batch=0.49s
12038/10943 (epoch 99.002) train_loss=494.23150635 time/batch=1.19s
12039/10943 (epoch 99.010) train_loss=545.18591309 time/batch=1.70s
12040/10943 (epoch 99.018) train_loss=377.74328613 time/batch=1.07s
12041/10943 (epoch 99.026) train_loss=499.63690186 time/batch=1.22s
12042/10943 (epoch 99.035) train_loss=305.52352905 time/batch=0.81s
12043/10943 (epoch 99.043) train_loss=144.69152832 time/batch=0.42s
12044/10943 (epoch 99.051) train_loss=275.42431641 time/batch=0.68s
12045/10943 (epoch 99.059) train_loss=294.57464600 time/batch=0.79s
12046/10943 (epoch 99.068) train_loss=356.72091675 time/batch=0.90s
12047/10943 (epoch 99.076) train_loss=234.45158386 time/batch=0.60s
12048/10943 (epoch 99.084) train_loss=446.89361572 time/batch=1.13s
12049/10943 (epoch 99.092) train_loss=234.94818115 time/batch=0.67s
12050/10943 (epoch 99.100) train_loss=149.87263489 time/batch=0.39s
12051/10943 (epoch 99.109) train_loss=441.52990723 time/batch=1.11s
12052/10943 (epoch 99.117) train_loss=291.26651001 time/batch=0.77s
12053/10943 (epoch 99.125) train_loss=323.81109619 time/batch=0.81s
12054/10943 (epoch 99.133) train_loss=278.95788574 time/batch=0.75s
12055/10943 (epoch 99.142) train_loss=266.57098389 time/batch=0.70s
12056/10943 (epoch 99.150) train_loss=187.84368896 time/batch=0.49s
12057/10943 (epoch 99.158) train_loss=93.50474548 time/batch=0.29s
12058/10943 (epoch 99.166) train_loss=356.95126343 time/batch=0.82s
12059/10943 (epoch 99.175) train_loss=401.77563477 time/batch=0.99s
12060/10943 (epoch 99.183) train_loss=301.62475586 time/batch=0.80s
12061/10943 (epoch 99.191) train_loss=115.70639801 time/batch=0.35s
12062/10943 (epoch 99.199) train_loss=121.64111328 time/batch=0.29s
12063/10943 (epoch 99.207) train_loss=137.56039429 time/batch=0.35s
12064/10943 (epoch 99.216) train_loss=140.34819031 time/batch=0.34s
12065/10943 (epoch 99.224) train_loss=247.05036926 time/batch=0.59s
12066/10943 (epoch 99.232) train_loss=184.52432251 time/batch=0.48s
12067/10943 (epoch 99.240) train_loss=289.97515869 time/batch=0.67s
12068/10943 (epoch 99.249) train_loss=281.06628418 time/batch=0.70s
12069/10943 (epoch 99.257) train_loss=237.28359985 time/batch=0.62s
12070/10943 (epoch 99.265) train_loss=128.11709595 time/batch=0.34s
12071/10943 (epoch 99.273) train_loss=174.82603455 time/batch=0.45s
12072/10943 (epoch 99.281) train_loss=269.79968262 time/batch=0.71s
12073/10943 (epoch 99.290) train_loss=156.80587769 time/batch=0.43s
12074/10943 (epoch 99.298) train_loss=263.20355225 time/batch=0.63s
12075/10943 (epoch 99.306) train_loss=237.37591553 time/batch=0.62s
12076/10943 (epoch 99.314) train_loss=343.33160400 time/batch=0.84s
12077/10943 (epoch 99.323) train_loss=385.41839600 time/batch=0.95s
12078/10943 (epoch 99.331) train_loss=213.86213684 time/batch=0.58s
12079/10943 (epoch 99.339) train_loss=229.60784912 time/batch=0.61s
12080/10943 (epoch 99.347) train_loss=306.95153809 time/batch=0.79s
12081/10943 (epoch 99.355) train_loss=170.05305481 time/batch=0.48s
12082/10943 (epoch 99.364) train_loss=325.37139893 time/batch=0.82s
12083/10943 (epoch 99.372) train_loss=199.61029053 time/batch=0.56s
12084/10943 (epoch 99.380) train_loss=196.07794189 time/batch=0.49s
12085/10943 (epoch 99.388) train_loss=331.55340576 time/batch=0.80s
12086/10943 (epoch 99.397) train_loss=329.77856445 time/batch=0.85s
12087/10943 (epoch 99.405) train_loss=221.19195557 time/batch=0.60s
12088/10943 (epoch 99.413) train_loss=256.69622803 time/batch=0.64s
12089/10943 (epoch 99.421) train_loss=289.34844971 time/batch=0.74s
12090/10943 (epoch 99.429) train_loss=352.05328369 time/batch=0.88s
12091/10943 (epoch 99.438) train_loss=155.28405762 time/batch=0.46s
12092/10943 (epoch 99.446) train_loss=214.06872559 time/batch=0.52s
12093/10943 (epoch 99.454) train_loss=114.42737579 time/batch=0.32s
12094/10943 (epoch 99.462) train_loss=262.54687500 time/batch=0.66s
12095/10943 (epoch 99.471) train_loss=183.76748657 time/batch=0.49s
12096/10943 (epoch 99.479) train_loss=230.68719482 time/batch=0.60s
12097/10943 (epoch 99.487) train_loss=272.96328735 time/batch=0.73s
12098/10943 (epoch 99.495) train_loss=357.08645630 time/batch=0.90s
12099/10943 (epoch 99.503) train_loss=246.51783752 time/batch=0.67s
12100/10943 (epoch 99.512) train_loss=436.37655640 time/batch=1.19s
12101/10943 (epoch 99.520) train_loss=153.89642334 time/batch=0.51s
12102/10943 (epoch 99.528) train_loss=228.83126831 time/batch=0.57s
12103/10943 (epoch 99.536) train_loss=198.41586304 time/batch=0.51s
12104/10943 (epoch 99.545) train_loss=193.34136963 time/batch=0.51s
12105/10943 (epoch 99.553) train_loss=300.72412109 time/batch=0.76s
12106/10943 (epoch 99.561) train_loss=300.49090576 time/batch=0.82s
12107/10943 (epoch 99.569) train_loss=351.89602661 time/batch=0.91s
12108/10943 (epoch 99.577) train_loss=224.10821533 time/batch=0.62s
12109/10943 (epoch 99.586) train_loss=216.73434448 time/batch=0.56s
12110/10943 (epoch 99.594) train_loss=128.98547363 time/batch=0.34s
12111/10943 (epoch 99.602) train_loss=133.80358887 time/batch=0.34s
12112/10943 (epoch 99.610) train_loss=255.02954102 time/batch=0.61s
12113/10943 (epoch 99.619) train_loss=228.14114380 time/batch=0.59s
12114/10943 (epoch 99.627) train_loss=212.24575806 time/batch=0.55s
12115/10943 (epoch 99.635) train_loss=168.23156738 time/batch=0.49s
12116/10943 (epoch 99.643) train_loss=334.52008057 time/batch=0.88s
12117/10943 (epoch 99.652) train_loss=225.97407532 time/batch=0.63s
12118/10943 (epoch 99.660) train_loss=206.59729004 time/batch=0.53s
12119/10943 (epoch 99.668) train_loss=393.24713135 time/batch=0.91s
12120/10943 (epoch 99.676) train_loss=157.56161499 time/batch=0.53s
12121/10943 (epoch 99.684) train_loss=262.88409424 time/batch=0.66s
12122/10943 (epoch 99.693) train_loss=264.17803955 time/batch=0.65s
12123/10943 (epoch 99.701) train_loss=303.67581177 time/batch=0.79s
12124/10943 (epoch 99.709) train_loss=314.29315186 time/batch=0.83s
12125/10943 (epoch 99.717) train_loss=309.50836182 time/batch=0.78s
12126/10943 (epoch 99.726) train_loss=293.36950684 time/batch=0.79s
12127/10943 (epoch 99.734) train_loss=337.32476807 time/batch=0.92s
12128/10943 (epoch 99.742) train_loss=259.21188354 time/batch=0.70s
12129/10943 (epoch 99.750) train_loss=392.21588135 time/batch=0.97s
12130/10943 (epoch 99.758) train_loss=294.19799805 time/batch=0.84s
12131/10943 (epoch 99.767) train_loss=274.31527710 time/batch=0.82s
12132/10943 (epoch 99.775) train_loss=338.17224121 time/batch=0.93s
12133/10943 (epoch 99.783) train_loss=199.27761841 time/batch=0.52s
12134/10943 (epoch 99.791) train_loss=194.29364014 time/batch=0.52s
12135/10943 (epoch 99.800) train_loss=240.78779602 time/batch=0.64s
12136/10943 (epoch 99.808) train_loss=192.14907837 time/batch=0.57s
setting learning rate to 0.0010331
  saved to metadata/gru_dropout-9_nov_folkwiki-20181207-173447_epoch55.pkl
12137/10943 (epoch 99.816) train_loss=299.47155762 time/batch=0.85s
12138/10943 (epoch 99.824) train_loss=303.74499512 time/batch=0.81s
12139/10943 (epoch 99.832) train_loss=351.64813232 time/batch=0.91s
12140/10943 (epoch 99.841) train_loss=320.93450928 time/batch=0.86s
12141/10943 (epoch 99.849) train_loss=429.37908936 time/batch=1.01s
12142/10943 (epoch 99.857) train_loss=851.56579590 time/batch=2.37s
12143/10943 (epoch 99.865) train_loss=184.72523499 time/batch=0.67s
12144/10943 (epoch 99.874) train_loss=222.63591003 time/batch=0.56s
12145/10943 (epoch 99.882) train_loss=392.24240112 time/batch=0.92s
12146/10943 (epoch 99.890) train_loss=290.45639038 time/batch=0.77s
12147/10943 (epoch 99.898) train_loss=233.38410950 time/batch=0.63s
12148/10943 (epoch 99.906) train_loss=258.90484619 time/batch=0.68s
12149/10943 (epoch 99.915) train_loss=429.71542358 time/batch=1.01s
12150/10943 (epoch 99.923) train_loss=386.53063965 time/batch=1.05s
12151/10943 (epoch 99.931) train_loss=365.29986572 time/batch=0.91s
12152/10943 (epoch 99.939) train_loss=342.99188232 time/batch=0.88s
12153/10943 (epoch 99.948) train_loss=551.82983398 time/batch=1.33s
12154/10943 (epoch 99.956) train_loss=428.34420776 time/batch=1.12s
12155/10943 (epoch 99.964) train_loss=517.14025879 time/batch=1.28s
12156/10943 (epoch 99.972) train_loss=248.99858093 time/batch=0.70s
12157/10943 (epoch 99.980) train_loss=94.94577026 time/batch=0.28s
12158/10943 (epoch 99.989) train_loss=444.77423096 time/batch=1.05s
12159/10943 (epoch 99.997) train_loss=320.23837280 time/batch=0.86s
12160/10943 (epoch 100.005) train_loss=385.37609863 time/batch=0.98s
12161/10943 (epoch 100.013) train_loss=232.49151611 time/batch=0.62s
12162/10943 (epoch 100.022) train_loss=581.70977783 time/batch=1.47s
12163/10943 (epoch 100.030) train_loss=310.21166992 time/batch=0.86s
12164/10943 (epoch 100.038) train_loss=260.02780151 time/batch=0.69s
12165/10943 (epoch 100.046) train_loss=223.31747437 time/batch=0.59s
12166/10943 (epoch 100.054) train_loss=314.36187744 time/batch=0.80s
12167/10943 (epoch 100.063) train_loss=491.36120605 time/batch=1.19s
12168/10943 (epoch 100.071) train_loss=182.82968140 time/batch=0.54s
12169/10943 (epoch 100.079) train_loss=121.82923126 time/batch=0.30s
12170/10943 (epoch 100.087) train_loss=133.16369629 time/batch=0.33s
12171/10943 (epoch 100.096) train_loss=154.83283997 time/batch=0.39s
12172/10943 (epoch 100.104) train_loss=207.31166077 time/batch=0.52s
12173/10943 (epoch 100.112) train_loss=335.93563843 time/batch=0.83s
12174/10943 (epoch 100.120) train_loss=144.78347778 time/batch=0.40s
12175/10943 (epoch 100.129) train_loss=212.84207153 time/batch=0.52s
12176/10943 (epoch 100.137) train_loss=126.56130981 time/batch=0.35s
12177/10943 (epoch 100.145) train_loss=150.11410522 time/batch=0.37s
12178/10943 (epoch 100.153) train_loss=422.00546265 time/batch=0.94s
12179/10943 (epoch 100.161) train_loss=266.72943115 time/batch=0.71s
12180/10943 (epoch 100.170) train_loss=459.15496826 time/batch=1.13s
12181/10943 (epoch 100.178) train_loss=366.79223633 time/batch=0.97s
12182/10943 (epoch 100.186) train_loss=382.01232910 time/batch=1.05s
12183/10943 (epoch 100.194) train_loss=385.06781006 time/batch=0.98s
12184/10943 (epoch 100.203) train_loss=286.76751709 time/batch=0.75s
12185/10943 (epoch 100.211) train_loss=174.44224548 time/batch=0.49s
12186/10943 (epoch 100.219) train_loss=162.05709839 time/batch=0.42s
12187/10943 (epoch 100.227) train_loss=108.63616943 time/batch=0.28s
12188/10943 (epoch 100.235) train_loss=218.81478882 time/batch=0.54s
12189/10943 (epoch 100.244) train_loss=254.48075867 time/batch=0.67s
12190/10943 (epoch 100.252) train_loss=544.52117920 time/batch=1.35s
12191/10943 (epoch 100.260) train_loss=161.25509644 time/batch=0.51s
12192/10943 (epoch 100.268) train_loss=265.51123047 time/batch=0.62s
12193/10943 (epoch 100.277) train_loss=766.06146240 time/batch=3.07s
12194/10943 (epoch 100.285) train_loss=199.98736572 time/batch=0.82s
12195/10943 (epoch 100.293) train_loss=299.17858887 time/batch=0.73s
12196/10943 (epoch 100.301) train_loss=170.49154663 time/batch=0.49s
12197/10943 (epoch 100.309) train_loss=359.63281250 time/batch=0.86s
12198/10943 (epoch 100.318) train_loss=139.97192383 time/batch=0.40s
12199/10943 (epoch 100.326) train_loss=302.43142700 time/batch=0.75s
12200/10943 (epoch 100.334) train_loss=511.94134521 time/batch=1.37s
12201/10943 (epoch 100.342) train_loss=137.32377625 time/batch=0.46s
12202/10943 (epoch 100.351) train_loss=515.09716797 time/batch=1.48s
12203/10943 (epoch 100.359) train_loss=463.42993164 time/batch=1.16s
12204/10943 (epoch 100.367) train_loss=233.22683716 time/batch=0.65s
12205/10943 (epoch 100.375) train_loss=263.06335449 time/batch=0.65s
12206/10943 (epoch 100.383) train_loss=219.36936951 time/batch=0.60s
12207/10943 (epoch 100.392) train_loss=243.56317139 time/batch=0.62s
12208/10943 (epoch 100.400) train_loss=143.44207764 time/batch=0.41s
12209/10943 (epoch 100.408) train_loss=199.25843811 time/batch=0.50s
12210/10943 (epoch 100.416) train_loss=434.98388672 time/batch=1.07s
12211/10943 (epoch 100.425) train_loss=220.40406799 time/batch=0.63s
12212/10943 (epoch 100.433) train_loss=191.53274536 time/batch=0.48s
12213/10943 (epoch 100.441) train_loss=339.12075806 time/batch=0.86s
12214/10943 (epoch 100.449) train_loss=268.55535889 time/batch=0.67s
12215/10943 (epoch 100.457) train_loss=188.56546021 time/batch=0.52s
12216/10943 (epoch 100.466) train_loss=284.71258545 time/batch=0.68s
12217/10943 (epoch 100.474) train_loss=284.84536743 time/batch=0.74s
12218/10943 (epoch 100.482) train_loss=116.39903259 time/batch=0.34s
12219/10943 (epoch 100.490) train_loss=269.06231689 time/batch=0.65s
12220/10943 (epoch 100.499) train_loss=144.54774475 time/batch=0.41s
12221/10943 (epoch 100.507) train_loss=282.82000732 time/batch=0.71s
12222/10943 (epoch 100.515) train_loss=372.56143188 time/batch=1.03s
12223/10943 (epoch 100.523) train_loss=349.30078125 time/batch=0.92s
12224/10943 (epoch 100.531) train_loss=294.21267700 time/batch=0.78s
12225/10943 (epoch 100.540) train_loss=219.65158081 time/batch=0.59s
12226/10943 (epoch 100.548) train_loss=295.96289062 time/batch=0.76s
12227/10943 (epoch 100.556) train_loss=203.61141968 time/batch=0.56s
12228/10943 (epoch 100.564) train_loss=115.61863708 time/batch=0.32s
12229/10943 (epoch 100.573) train_loss=291.61401367 time/batch=0.66s
12230/10943 (epoch 100.581) train_loss=300.58694458 time/batch=0.76s
12231/10943 (epoch 100.589) train_loss=238.50192261 time/batch=0.62s
12232/10943 (epoch 100.597) train_loss=227.63708496 time/batch=0.58s
12233/10943 (epoch 100.605) train_loss=265.89599609 time/batch=0.64s
12234/10943 (epoch 100.614) train_loss=184.90402222 time/batch=0.50s
12235/10943 (epoch 100.622) train_loss=296.34771729 time/batch=0.77s
12236/10943 (epoch 100.630) train_loss=183.79647827 time/batch=0.52s
12237/10943 (epoch 100.638) train_loss=188.79421997 time/batch=0.48s
12238/10943 (epoch 100.647) train_loss=255.93273926 time/batch=0.64s
12239/10943 (epoch 100.655) train_loss=284.31329346 time/batch=0.71s
12240/10943 (epoch 100.663) train_loss=168.38092041 time/batch=0.45s
12241/10943 (epoch 100.671) train_loss=299.97119141 time/batch=0.75s
12242/10943 (epoch 100.680) train_loss=199.10690308 time/batch=0.52s
12243/10943 (epoch 100.688) train_loss=246.00958252 time/batch=0.62s
12244/10943 (epoch 100.696) train_loss=296.28689575 time/batch=0.81s
12245/10943 (epoch 100.704) train_loss=329.22125244 time/batch=0.85s
12246/10943 (epoch 100.712) train_loss=232.96922302 time/batch=0.63s
12247/10943 (epoch 100.721) train_loss=276.85662842 time/batch=0.70s
12248/10943 (epoch 100.729) train_loss=217.35112000 time/batch=0.60s
12249/10943 (epoch 100.737) train_loss=223.88732910 time/batch=0.59s
12250/10943 (epoch 100.745) train_loss=331.10833740 time/batch=0.81s
12251/10943 (epoch 100.754) train_loss=143.79336548 time/batch=0.45s
12252/10943 (epoch 100.762) train_loss=336.71661377 time/batch=0.79s
12253/10943 (epoch 100.770) train_loss=190.31472778 time/batch=0.53s
12254/10943 (epoch 100.778) train_loss=299.43215942 time/batch=0.75s
12255/10943 (epoch 100.786) train_loss=204.26881409 time/batch=0.63s
12256/10943 (epoch 100.795) train_loss=238.50250244 time/batch=0.63s
12257/10943 (epoch 100.803) train_loss=272.14514160 time/batch=0.69s
setting learning rate to 0.0010021
12258/10943 (epoch 100.811) train_loss=382.43511963 time/batch=0.96s
12259/10943 (epoch 100.819) train_loss=223.30909729 time/batch=0.62s
12260/10943 (epoch 100.828) train_loss=269.75119019 time/batch=0.66s
12261/10943 (epoch 100.836) train_loss=506.78192139 time/batch=1.18s
12262/10943 (epoch 100.844) train_loss=462.52551270 time/batch=1.13s
12263/10943 (epoch 100.852) train_loss=429.74969482 time/batch=1.13s
12264/10943 (epoch 100.860) train_loss=262.12109375 time/batch=0.69s
12265/10943 (epoch 100.869) train_loss=438.70776367 time/batch=1.04s
12266/10943 (epoch 100.877) train_loss=184.15942383 time/batch=0.52s
12267/10943 (epoch 100.885) train_loss=158.82444763 time/batch=0.40s
12268/10943 (epoch 100.893) train_loss=470.49420166 time/batch=1.13s
12269/10943 (epoch 100.902) train_loss=549.16357422 time/batch=1.39s
12270/10943 (epoch 100.910) train_loss=144.17965698 time/batch=0.46s
12271/10943 (epoch 100.918) train_loss=579.11566162 time/batch=1.42s
12272/10943 (epoch 100.926) train_loss=384.24975586 time/batch=1.03s
12273/10943 (epoch 100.934) train_loss=146.77890015 time/batch=0.41s
12274/10943 (epoch 100.943) train_loss=291.02062988 time/batch=0.70s
12275/10943 (epoch 100.951) train_loss=647.27856445 time/batch=1.58s
12276/10943 (epoch 100.959) train_loss=234.98162842 time/batch=0.73s
12277/10943 (epoch 100.967) train_loss=407.88980103 time/batch=0.96s
12278/10943 (epoch 100.976) train_loss=124.91804504 time/batch=0.37s
12279/10943 (epoch 100.984) train_loss=933.27337646 time/batch=3.01s
12280/10943 (epoch 100.992) train_loss=115.22068024 time/batch=0.59s
12281/10943 (epoch 101.000) train_loss=504.25161743 time/batch=1.18s
12282/10943 (epoch 101.008) train_loss=669.80926514 time/batch=1.70s
12283/10943 (epoch 101.017) train_loss=354.75671387 time/batch=0.98s
12284/10943 (epoch 101.025) train_loss=306.61523438 time/batch=0.81s
12285/10943 (epoch 101.033) train_loss=190.10606384 time/batch=0.51s
12286/10943 (epoch 101.041) train_loss=243.74014282 time/batch=0.56s
12287/10943 (epoch 101.050) train_loss=300.67858887 time/batch=0.71s
12288/10943 (epoch 101.058) train_loss=271.72344971 time/batch=0.66s
12289/10943 (epoch 101.066) train_loss=409.33496094 time/batch=0.97s
12290/10943 (epoch 101.074) train_loss=292.62591553 time/batch=0.74s
12291/10943 (epoch 101.082) train_loss=152.43170166 time/batch=0.40s
12292/10943 (epoch 101.091) train_loss=311.87426758 time/batch=0.73s
12293/10943 (epoch 101.099) train_loss=348.00375366 time/batch=0.84s
12294/10943 (epoch 101.107) train_loss=194.85043335 time/batch=0.52s
12295/10943 (epoch 101.115) train_loss=372.92425537 time/batch=0.84s
12296/10943 (epoch 101.124) train_loss=554.82592773 time/batch=1.29s
12297/10943 (epoch 101.132) train_loss=220.48782349 time/batch=0.63s
12298/10943 (epoch 101.140) train_loss=467.41394043 time/batch=1.24s
12299/10943 (epoch 101.148) train_loss=421.67727661 time/batch=1.11s
12300/10943 (epoch 101.157) train_loss=292.37695312 time/batch=0.78s
12301/10943 (epoch 101.165) train_loss=283.14743042 time/batch=0.73s
12302/10943 (epoch 101.173) train_loss=444.70843506 time/batch=1.11s
12303/10943 (epoch 101.181) train_loss=307.67718506 time/batch=0.82s
12304/10943 (epoch 101.189) train_loss=174.11474609 time/batch=0.48s
12305/10943 (epoch 101.198) train_loss=196.61691284 time/batch=0.50s
12306/10943 (epoch 101.206) train_loss=361.75332642 time/batch=0.87s
12307/10943 (epoch 101.214) train_loss=200.69685364 time/batch=0.54s
12308/10943 (epoch 101.222) train_loss=151.82156372 time/batch=0.40s
12309/10943 (epoch 101.231) train_loss=386.17523193 time/batch=0.90s
12310/10943 (epoch 101.239) train_loss=297.02044678 time/batch=0.77s
12311/10943 (epoch 101.247) train_loss=230.10955811 time/batch=0.62s
12312/10943 (epoch 101.255) train_loss=377.76480103 time/batch=0.92s
12313/10943 (epoch 101.263) train_loss=280.55023193 time/batch=0.73s
12314/10943 (epoch 101.272) train_loss=154.79376221 time/batch=0.44s
12315/10943 (epoch 101.280) train_loss=240.01208496 time/batch=0.60s
12316/10943 (epoch 101.288) train_loss=365.96563721 time/batch=0.90s
12317/10943 (epoch 101.296) train_loss=260.86999512 time/batch=0.68s
12318/10943 (epoch 101.305) train_loss=266.91049194 time/batch=0.66s
12319/10943 (epoch 101.313) train_loss=232.06164551 time/batch=0.61s
12320/10943 (epoch 101.321) train_loss=216.27485657 time/batch=0.55s
12321/10943 (epoch 101.329) train_loss=112.53869629 time/batch=0.32s
12322/10943 (epoch 101.337) train_loss=288.79855347 time/batch=0.67s
12323/10943 (epoch 101.346) train_loss=397.71423340 time/batch=0.99s
12324/10943 (epoch 101.354) train_loss=174.02464294 time/batch=0.50s
12325/10943 (epoch 101.362) train_loss=250.61572266 time/batch=0.60s
12326/10943 (epoch 101.370) train_loss=412.98779297 time/batch=0.98s
12327/10943 (epoch 101.379) train_loss=285.28985596 time/batch=0.75s
12328/10943 (epoch 101.387) train_loss=259.43563843 time/batch=0.68s
12329/10943 (epoch 101.395) train_loss=199.33018494 time/batch=0.52s
12330/10943 (epoch 101.403) train_loss=358.27215576 time/batch=0.97s
12331/10943 (epoch 101.411) train_loss=268.84594727 time/batch=0.72s
12332/10943 (epoch 101.420) train_loss=244.70199585 time/batch=0.62s
12333/10943 (epoch 101.428) train_loss=295.60675049 time/batch=0.75s
12334/10943 (epoch 101.436) train_loss=132.68020630 time/batch=0.36s
12335/10943 (epoch 101.444) train_loss=134.13955688 time/batch=0.32s
12336/10943 (epoch 101.453) train_loss=148.03244019 time/batch=0.37s
12337/10943 (epoch 101.461) train_loss=310.60678101 time/batch=0.72s
12338/10943 (epoch 101.469) train_loss=147.08700562 time/batch=0.42s
12339/10943 (epoch 101.477) train_loss=325.90859985 time/batch=0.79s
12340/10943 (epoch 101.485) train_loss=202.33053589 time/batch=0.56s
12341/10943 (epoch 101.494) train_loss=137.01237488 time/batch=0.35s
12342/10943 (epoch 101.502) train_loss=300.87341309 time/batch=0.73s
12343/10943 (epoch 101.510) train_loss=101.14105225 time/batch=0.34s
12344/10943 (epoch 101.518) train_loss=329.19702148 time/batch=0.77s
12345/10943 (epoch 101.527) train_loss=305.88449097 time/batch=0.82s
12346/10943 (epoch 101.535) train_loss=317.68859863 time/batch=0.79s
12347/10943 (epoch 101.543) train_loss=412.00592041 time/batch=1.01s
12348/10943 (epoch 101.551) train_loss=188.20135498 time/batch=0.52s
12349/10943 (epoch 101.559) train_loss=227.51676941 time/batch=0.56s
12350/10943 (epoch 101.568) train_loss=125.47811890 time/batch=0.40s
12351/10943 (epoch 101.576) train_loss=226.34365845 time/batch=0.56s
12352/10943 (epoch 101.584) train_loss=212.84744263 time/batch=0.56s
12353/10943 (epoch 101.592) train_loss=216.68869019 time/batch=0.56s
12354/10943 (epoch 101.601) train_loss=164.82135010 time/batch=0.44s
12355/10943 (epoch 101.609) train_loss=335.21179199 time/batch=0.79s
12356/10943 (epoch 101.617) train_loss=149.18121338 time/batch=0.47s
12357/10943 (epoch 101.625) train_loss=305.82714844 time/batch=0.77s
12358/10943 (epoch 101.634) train_loss=297.83935547 time/batch=0.79s
12359/10943 (epoch 101.642) train_loss=207.37600708 time/batch=0.56s
12360/10943 (epoch 101.650) train_loss=324.78857422 time/batch=0.83s
12361/10943 (epoch 101.658) train_loss=189.62628174 time/batch=0.51s
12362/10943 (epoch 101.666) train_loss=268.34783936 time/batch=0.66s
12363/10943 (epoch 101.675) train_loss=223.25033569 time/batch=0.59s
12364/10943 (epoch 101.683) train_loss=322.33581543 time/batch=0.81s
12365/10943 (epoch 101.691) train_loss=193.81091309 time/batch=0.53s
12366/10943 (epoch 101.699) train_loss=342.23315430 time/batch=0.82s
12367/10943 (epoch 101.708) train_loss=179.22052002 time/batch=0.52s
12368/10943 (epoch 101.716) train_loss=260.63378906 time/batch=0.65s
12369/10943 (epoch 101.724) train_loss=271.38989258 time/batch=0.69s
12370/10943 (epoch 101.732) train_loss=256.37200928 time/batch=0.66s
12371/10943 (epoch 101.740) train_loss=319.34252930 time/batch=0.82s
12372/10943 (epoch 101.749) train_loss=258.74301147 time/batch=0.80s
12373/10943 (epoch 101.757) train_loss=197.56481934 time/batch=0.59s
12374/10943 (epoch 101.765) train_loss=261.93487549 time/batch=0.66s
12375/10943 (epoch 101.773) train_loss=225.35516357 time/batch=0.60s
12376/10943 (epoch 101.782) train_loss=310.42233276 time/batch=0.85s
12377/10943 (epoch 101.790) train_loss=240.16351318 time/batch=0.63s
12378/10943 (epoch 101.798) train_loss=223.94320679 time/batch=0.60s
setting learning rate to 0.0009720
  saved to metadata/gru_dropout-9_nov_folkwiki-20181207-173447_epoch57.pkl
12379/10943 (epoch 101.806) train_loss=150.77372742 time/batch=0.48s
12380/10943 (epoch 101.814) train_loss=417.74902344 time/batch=1.01s
12381/10943 (epoch 101.823) train_loss=323.60339355 time/batch=0.89s
12382/10943 (epoch 101.831) train_loss=113.97737885 time/batch=0.34s
12383/10943 (epoch 101.839) train_loss=385.57141113 time/batch=0.88s
12384/10943 (epoch 101.847) train_loss=557.39739990 time/batch=1.33s
12385/10943 (epoch 101.856) train_loss=226.40206909 time/batch=0.66s
12386/10943 (epoch 101.864) train_loss=259.59127808 time/batch=0.66s
12387/10943 (epoch 101.872) train_loss=441.11193848 time/batch=1.06s
12388/10943 (epoch 101.880) train_loss=216.48765564 time/batch=0.61s
12389/10943 (epoch 101.888) train_loss=199.44338989 time/batch=0.49s
12390/10943 (epoch 101.897) train_loss=297.76156616 time/batch=0.74s
12391/10943 (epoch 101.905) train_loss=939.48083496 time/batch=3.06s
12392/10943 (epoch 101.913) train_loss=470.00692749 time/batch=1.34s
12393/10943 (epoch 101.921) train_loss=269.91784668 time/batch=0.73s
12394/10943 (epoch 101.930) train_loss=297.82366943 time/batch=0.73s
12395/10943 (epoch 101.938) train_loss=158.11595154 time/batch=0.43s
12396/10943 (epoch 101.946) train_loss=105.47857666 time/batch=0.30s
12397/10943 (epoch 101.954) train_loss=258.80288696 time/batch=0.61s
12398/10943 (epoch 101.962) train_loss=702.98968506 time/batch=1.64s
12399/10943 (epoch 101.971) train_loss=111.98414612 time/batch=0.44s
12400/10943 (epoch 101.979) train_loss=519.37170410 time/batch=1.20s
12401/10943 (epoch 101.987) train_loss=215.93991089 time/batch=0.62s
12402/10943 (epoch 101.995) train_loss=280.79074097 time/batch=0.70s
12403/10943 (epoch 102.004) train_loss=465.05950928 time/batch=1.13s
12404/10943 (epoch 102.012) train_loss=315.49151611 time/batch=0.80s
12405/10943 (epoch 102.020) train_loss=234.40795898 time/batch=0.62s
12406/10943 (epoch 102.028) train_loss=149.26251221 time/batch=0.40s
12407/10943 (epoch 102.036) train_loss=619.81097412 time/batch=1.48s
12408/10943 (epoch 102.045) train_loss=532.06451416 time/batch=1.41s
12409/10943 (epoch 102.053) train_loss=444.15447998 time/batch=1.15s
12410/10943 (epoch 102.061) train_loss=167.73460388 time/batch=0.50s
12411/10943 (epoch 102.069) train_loss=290.81121826 time/batch=0.71s
12412/10943 (epoch 102.078) train_loss=181.58465576 time/batch=0.48s
12413/10943 (epoch 102.086) train_loss=494.35003662 time/batch=1.15s
12414/10943 (epoch 102.094) train_loss=489.14935303 time/batch=1.39s
12415/10943 (epoch 102.102) train_loss=304.04718018 time/batch=0.86s
12416/10943 (epoch 102.111) train_loss=380.29132080 time/batch=0.98s
12417/10943 (epoch 102.119) train_loss=181.54086304 time/batch=0.52s
12418/10943 (epoch 102.127) train_loss=201.54327393 time/batch=0.49s
12419/10943 (epoch 102.135) train_loss=126.44557953 time/batch=0.32s
12420/10943 (epoch 102.143) train_loss=340.54379272 time/batch=0.81s
12421/10943 (epoch 102.152) train_loss=389.04046631 time/batch=0.97s
12422/10943 (epoch 102.160) train_loss=194.05009460 time/batch=0.57s
12423/10943 (epoch 102.168) train_loss=298.95440674 time/batch=0.76s
12424/10943 (epoch 102.176) train_loss=410.16201782 time/batch=0.98s
12425/10943 (epoch 102.185) train_loss=345.36795044 time/batch=0.89s
12426/10943 (epoch 102.193) train_loss=543.90332031 time/batch=1.43s
12427/10943 (epoch 102.201) train_loss=142.41706848 time/batch=0.45s
12428/10943 (epoch 102.209) train_loss=224.13607788 time/batch=0.56s
12429/10943 (epoch 102.217) train_loss=284.01965332 time/batch=0.70s
12430/10943 (epoch 102.226) train_loss=430.51583862 time/batch=1.08s
12431/10943 (epoch 102.234) train_loss=170.37925720 time/batch=0.50s
12432/10943 (epoch 102.242) train_loss=290.74212646 time/batch=0.70s
12433/10943 (epoch 102.250) train_loss=325.99395752 time/batch=0.82s
12434/10943 (epoch 102.259) train_loss=187.16085815 time/batch=0.54s
12435/10943 (epoch 102.267) train_loss=314.88336182 time/batch=0.80s
12436/10943 (epoch 102.275) train_loss=269.38482666 time/batch=0.71s
12437/10943 (epoch 102.283) train_loss=417.22473145 time/batch=0.98s
12438/10943 (epoch 102.291) train_loss=221.42120361 time/batch=0.61s
12439/10943 (epoch 102.300) train_loss=362.60488892 time/batch=0.89s
12440/10943 (epoch 102.308) train_loss=307.90826416 time/batch=0.80s
12441/10943 (epoch 102.316) train_loss=364.34832764 time/batch=0.95s
12442/10943 (epoch 102.324) train_loss=444.99438477 time/batch=1.12s
12443/10943 (epoch 102.333) train_loss=156.50048828 time/batch=0.49s
12444/10943 (epoch 102.341) train_loss=199.06658936 time/batch=0.49s
12445/10943 (epoch 102.349) train_loss=299.26684570 time/batch=0.77s
12446/10943 (epoch 102.357) train_loss=115.75981903 time/batch=0.35s
12447/10943 (epoch 102.365) train_loss=245.01724243 time/batch=0.59s
12448/10943 (epoch 102.374) train_loss=156.19055176 time/batch=0.44s
12449/10943 (epoch 102.382) train_loss=260.10083008 time/batch=0.62s
12450/10943 (epoch 102.390) train_loss=370.24127197 time/batch=0.87s
12451/10943 (epoch 102.398) train_loss=262.78378296 time/batch=0.70s
12452/10943 (epoch 102.407) train_loss=294.92633057 time/batch=0.76s
12453/10943 (epoch 102.415) train_loss=185.33830261 time/batch=0.50s
12454/10943 (epoch 102.423) train_loss=286.55010986 time/batch=0.70s
12455/10943 (epoch 102.431) train_loss=224.14874268 time/batch=0.58s
12456/10943 (epoch 102.439) train_loss=380.67700195 time/batch=0.97s
12457/10943 (epoch 102.448) train_loss=135.89193726 time/batch=0.41s
12458/10943 (epoch 102.456) train_loss=353.48571777 time/batch=0.86s
12459/10943 (epoch 102.464) train_loss=224.53680420 time/batch=0.63s
12460/10943 (epoch 102.472) train_loss=282.62689209 time/batch=0.69s
12461/10943 (epoch 102.481) train_loss=258.11666870 time/batch=0.64s
12462/10943 (epoch 102.489) train_loss=207.19509888 time/batch=0.54s
12463/10943 (epoch 102.497) train_loss=335.64654541 time/batch=0.82s
12464/10943 (epoch 102.505) train_loss=189.03959656 time/batch=0.52s
12465/10943 (epoch 102.513) train_loss=387.87481689 time/batch=0.98s
12466/10943 (epoch 102.522) train_loss=260.25543213 time/batch=0.69s
12467/10943 (epoch 102.530) train_loss=331.55264282 time/batch=0.83s
12468/10943 (epoch 102.538) train_loss=264.91094971 time/batch=0.71s
12469/10943 (epoch 102.546) train_loss=198.13854980 time/batch=0.53s
12470/10943 (epoch 102.555) train_loss=130.58482361 time/batch=0.35s
12471/10943 (epoch 102.563) train_loss=231.61940002 time/batch=0.57s
12472/10943 (epoch 102.571) train_loss=306.75314331 time/batch=0.80s
12473/10943 (epoch 102.579) train_loss=288.59442139 time/batch=0.72s
12474/10943 (epoch 102.588) train_loss=223.24636841 time/batch=0.59s
12475/10943 (epoch 102.596) train_loss=168.95416260 time/batch=0.45s
12476/10943 (epoch 102.604) train_loss=191.90730286 time/batch=0.50s
12477/10943 (epoch 102.612) train_loss=170.13786316 time/batch=0.45s
12478/10943 (epoch 102.620) train_loss=239.98806763 time/batch=0.60s
12479/10943 (epoch 102.629) train_loss=231.47024536 time/batch=0.60s
12480/10943 (epoch 102.637) train_loss=270.15100098 time/batch=0.65s
12481/10943 (epoch 102.645) train_loss=246.34529114 time/batch=0.65s
12482/10943 (epoch 102.653) train_loss=135.93984985 time/batch=0.38s
12483/10943 (epoch 102.662) train_loss=343.39266968 time/batch=0.79s
12484/10943 (epoch 102.670) train_loss=238.89558411 time/batch=0.63s
12485/10943 (epoch 102.678) train_loss=149.39710999 time/batch=0.38s
12486/10943 (epoch 102.686) train_loss=347.87579346 time/batch=0.84s
12487/10943 (epoch 102.694) train_loss=212.96101379 time/batch=0.57s
12488/10943 (epoch 102.703) train_loss=276.24710083 time/batch=0.68s
12489/10943 (epoch 102.711) train_loss=303.16943359 time/batch=0.77s
12490/10943 (epoch 102.719) train_loss=302.28421021 time/batch=0.82s
12491/10943 (epoch 102.727) train_loss=227.28910828 time/batch=0.61s
12492/10943 (epoch 102.736) train_loss=299.90588379 time/batch=0.78s
12493/10943 (epoch 102.744) train_loss=270.28530884 time/batch=0.68s
12494/10943 (epoch 102.752) train_loss=223.45352173 time/batch=0.61s
12495/10943 (epoch 102.760) train_loss=230.53395081 time/batch=0.61s
12496/10943 (epoch 102.768) train_loss=314.21673584 time/batch=0.80s
12497/10943 (epoch 102.777) train_loss=267.16964722 time/batch=0.74s
12498/10943 (epoch 102.785) train_loss=128.23272705 time/batch=0.39s
12499/10943 (epoch 102.793) train_loss=181.51356506 time/batch=0.59s
setting learning rate to 0.0009429
12500/10943 (epoch 102.801) train_loss=106.62823486 time/batch=0.31s
12501/10943 (epoch 102.810) train_loss=393.64538574 time/batch=0.89s
12502/10943 (epoch 102.818) train_loss=344.45095825 time/batch=0.88s
12503/10943 (epoch 102.826) train_loss=224.66439819 time/batch=0.60s
12504/10943 (epoch 102.834) train_loss=460.78729248 time/batch=1.11s
12505/10943 (epoch 102.842) train_loss=98.14996338 time/batch=0.34s
12506/10943 (epoch 102.851) train_loss=152.29779053 time/batch=0.38s
12507/10943 (epoch 102.859) train_loss=949.10778809 time/batch=3.03s
12508/10943 (epoch 102.867) train_loss=451.80139160 time/batch=1.35s
12509/10943 (epoch 102.875) train_loss=161.44140625 time/batch=0.48s
12510/10943 (epoch 102.884) train_loss=180.42929077 time/batch=0.45s
12511/10943 (epoch 102.892) train_loss=306.04455566 time/batch=0.74s
12512/10943 (epoch 102.900) train_loss=544.97851562 time/batch=1.39s
12513/10943 (epoch 102.908) train_loss=361.22189331 time/batch=0.98s
12514/10943 (epoch 102.916) train_loss=559.82452393 time/batch=1.32s
12515/10943 (epoch 102.925) train_loss=293.64288330 time/batch=0.79s
12516/10943 (epoch 102.933) train_loss=425.06414795 time/batch=0.98s
12517/10943 (epoch 102.941) train_loss=226.56201172 time/batch=0.66s
12518/10943 (epoch 102.949) train_loss=378.37854004 time/batch=0.97s
12519/10943 (epoch 102.958) train_loss=301.18920898 time/batch=0.80s
12520/10943 (epoch 102.966) train_loss=495.45245361 time/batch=1.21s
12521/10943 (epoch 102.974) train_loss=474.29449463 time/batch=1.15s
12522/10943 (epoch 102.982) train_loss=231.56394958 time/batch=0.65s
12523/10943 (epoch 102.990) train_loss=614.50292969 time/batch=1.49s
12524/10943 (epoch 102.999) train_loss=467.45227051 time/batch=1.24s
12525/10943 (epoch 103.007) train_loss=301.81005859 time/batch=0.82s
12526/10943 (epoch 103.015) train_loss=314.51171875 time/batch=0.79s
12527/10943 (epoch 103.023) train_loss=195.30070496 time/batch=0.53s
12528/10943 (epoch 103.032) train_loss=679.69494629 time/batch=1.59s
12529/10943 (epoch 103.040) train_loss=193.87786865 time/batch=0.61s
12530/10943 (epoch 103.048) train_loss=486.70886230 time/batch=1.15s
12531/10943 (epoch 103.056) train_loss=283.75994873 time/batch=0.78s
12532/10943 (epoch 103.065) train_loss=138.39450073 time/batch=0.39s
12533/10943 (epoch 103.073) train_loss=135.95054626 time/batch=0.34s
12534/10943 (epoch 103.081) train_loss=347.67437744 time/batch=0.84s
12535/10943 (epoch 103.089) train_loss=260.43609619 time/batch=0.66s
12536/10943 (epoch 103.097) train_loss=456.16613770 time/batch=1.21s
12537/10943 (epoch 103.106) train_loss=233.44490051 time/batch=0.65s
12538/10943 (epoch 103.114) train_loss=184.51950073 time/batch=0.48s
12539/10943 (epoch 103.122) train_loss=420.96646118 time/batch=0.97s
12540/10943 (epoch 103.130) train_loss=197.88140869 time/batch=0.51s
12541/10943 (epoch 103.139) train_loss=221.96319580 time/batch=0.58s
12542/10943 (epoch 103.147) train_loss=405.34912109 time/batch=0.93s
12543/10943 (epoch 103.155) train_loss=122.70850372 time/batch=0.36s
12544/10943 (epoch 103.163) train_loss=454.18817139 time/batch=1.19s
12545/10943 (epoch 103.171) train_loss=110.10943604 time/batch=0.39s
12546/10943 (epoch 103.180) train_loss=157.34585571 time/batch=0.40s
12547/10943 (epoch 103.188) train_loss=262.42895508 time/batch=0.65s
12548/10943 (epoch 103.196) train_loss=268.31787109 time/batch=0.67s
12549/10943 (epoch 103.204) train_loss=447.82077026 time/batch=1.25s
12550/10943 (epoch 103.213) train_loss=136.08731079 time/batch=0.44s
12551/10943 (epoch 103.221) train_loss=199.48489380 time/batch=0.49s
12552/10943 (epoch 103.229) train_loss=264.87097168 time/batch=0.66s
12553/10943 (epoch 103.237) train_loss=262.64343262 time/batch=0.70s
12554/10943 (epoch 103.245) train_loss=195.25573730 time/batch=0.53s
12555/10943 (epoch 103.254) train_loss=217.09889221 time/batch=0.57s
12556/10943 (epoch 103.262) train_loss=301.08807373 time/batch=0.77s
12557/10943 (epoch 103.270) train_loss=353.96005249 time/batch=0.88s
12558/10943 (epoch 103.278) train_loss=151.19114685 time/batch=0.42s
12559/10943 (epoch 103.287) train_loss=306.54473877 time/batch=0.77s
12560/10943 (epoch 103.295) train_loss=428.83523560 time/batch=1.02s
12561/10943 (epoch 103.303) train_loss=269.82717896 time/batch=0.72s
12562/10943 (epoch 103.311) train_loss=254.02638245 time/batch=0.65s
12563/10943 (epoch 103.319) train_loss=122.81356049 time/batch=0.34s
12564/10943 (epoch 103.328) train_loss=325.79394531 time/batch=0.80s
12565/10943 (epoch 103.336) train_loss=132.92408752 time/batch=0.39s
12566/10943 (epoch 103.344) train_loss=330.79678345 time/batch=0.80s
12567/10943 (epoch 103.352) train_loss=167.39929199 time/batch=0.48s
12568/10943 (epoch 103.361) train_loss=353.35403442 time/batch=0.84s
12569/10943 (epoch 103.369) train_loss=534.13403320 time/batch=1.68s
12570/10943 (epoch 103.377) train_loss=284.89489746 time/batch=0.84s
12571/10943 (epoch 103.385) train_loss=237.65914917 time/batch=0.63s
12572/10943 (epoch 103.393) train_loss=244.36351013 time/batch=0.62s
12573/10943 (epoch 103.402) train_loss=148.69363403 time/batch=0.43s
12574/10943 (epoch 103.410) train_loss=385.64379883 time/batch=0.94s
12575/10943 (epoch 103.418) train_loss=289.35113525 time/batch=0.76s
12576/10943 (epoch 103.426) train_loss=153.75561523 time/batch=0.44s
12577/10943 (epoch 103.435) train_loss=326.96380615 time/batch=0.78s
12578/10943 (epoch 103.443) train_loss=237.26309204 time/batch=0.64s
12579/10943 (epoch 103.451) train_loss=357.70248413 time/batch=0.91s
12580/10943 (epoch 103.459) train_loss=371.55603027 time/batch=0.92s
12581/10943 (epoch 103.467) train_loss=241.55090332 time/batch=0.65s
12582/10943 (epoch 103.476) train_loss=226.42214966 time/batch=0.58s
12583/10943 (epoch 103.484) train_loss=273.40295410 time/batch=0.69s
12584/10943 (epoch 103.492) train_loss=301.95697021 time/batch=0.79s
12585/10943 (epoch 103.500) train_loss=233.37829590 time/batch=0.61s
12586/10943 (epoch 103.509) train_loss=220.22033691 time/batch=0.57s
12587/10943 (epoch 103.517) train_loss=156.92515564 time/batch=0.43s
12588/10943 (epoch 103.525) train_loss=295.09344482 time/batch=0.71s
12589/10943 (epoch 103.533) train_loss=366.77392578 time/batch=0.95s
12590/10943 (epoch 103.542) train_loss=284.57623291 time/batch=0.75s
12591/10943 (epoch 103.550) train_loss=331.81823730 time/batch=0.90s
12592/10943 (epoch 103.558) train_loss=171.77575684 time/batch=0.48s
12593/10943 (epoch 103.566) train_loss=214.63082886 time/batch=0.56s
12594/10943 (epoch 103.574) train_loss=260.06274414 time/batch=0.66s
12595/10943 (epoch 103.583) train_loss=210.34555054 time/batch=0.54s
12596/10943 (epoch 103.591) train_loss=203.72418213 time/batch=0.53s
12597/10943 (epoch 103.599) train_loss=171.11859131 time/batch=0.45s
12598/10943 (epoch 103.607) train_loss=246.27200317 time/batch=0.60s
12599/10943 (epoch 103.616) train_loss=151.87777710 time/batch=0.44s
12600/10943 (epoch 103.624) train_loss=216.07025146 time/batch=0.53s
12601/10943 (epoch 103.632) train_loss=207.65391541 time/batch=0.55s
12602/10943 (epoch 103.640) train_loss=237.47509766 time/batch=0.58s
12603/10943 (epoch 103.648) train_loss=142.60818481 time/batch=0.46s
12604/10943 (epoch 103.657) train_loss=292.51971436 time/batch=0.68s
12605/10943 (epoch 103.665) train_loss=298.93826294 time/batch=0.79s
12606/10943 (epoch 103.673) train_loss=334.88616943 time/batch=0.84s
12607/10943 (epoch 103.681) train_loss=304.37426758 time/batch=0.80s
12608/10943 (epoch 103.690) train_loss=187.00479126 time/batch=0.51s
12609/10943 (epoch 103.698) train_loss=284.56433105 time/batch=0.70s
12610/10943 (epoch 103.706) train_loss=252.90267944 time/batch=0.66s
12611/10943 (epoch 103.714) train_loss=262.10168457 time/batch=0.69s
12612/10943 (epoch 103.722) train_loss=199.52215576 time/batch=0.54s
12613/10943 (epoch 103.731) train_loss=288.12057495 time/batch=0.76s
12614/10943 (epoch 103.739) train_loss=312.34564209 time/batch=0.82s
12615/10943 (epoch 103.747) train_loss=196.08874512 time/batch=0.52s
12616/10943 (epoch 103.755) train_loss=217.49841309 time/batch=0.59s
12617/10943 (epoch 103.764) train_loss=283.89007568 time/batch=0.73s
12618/10943 (epoch 103.772) train_loss=330.35760498 time/batch=0.83s
12619/10943 (epoch 103.780) train_loss=270.81463623 time/batch=0.68s
12620/10943 (epoch 103.788) train_loss=302.66748047 time/batch=0.79s
setting learning rate to 0.0009146
  saved to metadata/gru_dropout-9_nov_folkwiki-20181207-173447_epoch59.pkl
12621/10943 (epoch 103.796) train_loss=497.56170654 time/batch=1.31s
12622/10943 (epoch 103.805) train_loss=174.86790466 time/batch=0.50s
12623/10943 (epoch 103.813) train_loss=930.36096191 time/batch=3.01s
12624/10943 (epoch 103.821) train_loss=145.59707642 time/batch=0.65s
12625/10943 (epoch 103.829) train_loss=303.23828125 time/batch=0.76s
12626/10943 (epoch 103.838) train_loss=422.40814209 time/batch=1.01s
12627/10943 (epoch 103.846) train_loss=336.90551758 time/batch=0.86s
12628/10943 (epoch 103.854) train_loss=494.02337646 time/batch=1.20s
12629/10943 (epoch 103.862) train_loss=388.52670288 time/batch=1.00s
12630/10943 (epoch 103.870) train_loss=95.19427490 time/batch=0.32s
12631/10943 (epoch 103.879) train_loss=121.81407166 time/batch=0.29s
12632/10943 (epoch 103.887) train_loss=471.01934814 time/batch=1.14s
12633/10943 (epoch 103.895) train_loss=218.23129272 time/batch=0.62s
12634/10943 (epoch 103.903) train_loss=542.23339844 time/batch=1.23s
12635/10943 (epoch 103.912) train_loss=475.58709717 time/batch=1.33s
12636/10943 (epoch 103.920) train_loss=387.59524536 time/batch=0.99s
12637/10943 (epoch 103.928) train_loss=226.86259460 time/batch=0.60s
12638/10943 (epoch 103.936) train_loss=430.75659180 time/batch=1.04s
12639/10943 (epoch 103.944) train_loss=561.16540527 time/batch=1.39s
12640/10943 (epoch 103.953) train_loss=369.62298584 time/batch=0.98s
12641/10943 (epoch 103.961) train_loss=111.27039337 time/batch=0.34s
12642/10943 (epoch 103.969) train_loss=594.69445801 time/batch=1.43s
12643/10943 (epoch 103.977) train_loss=327.09756470 time/batch=0.90s
12644/10943 (epoch 103.986) train_loss=171.40707397 time/batch=0.49s
12645/10943 (epoch 103.994) train_loss=160.60360718 time/batch=0.43s
12646/10943 (epoch 104.002) train_loss=158.61566162 time/batch=0.40s
12647/10943 (epoch 104.010) train_loss=439.24871826 time/batch=1.06s
12648/10943 (epoch 104.019) train_loss=298.74539185 time/batch=0.83s
12649/10943 (epoch 104.027) train_loss=355.78286743 time/batch=0.87s
12650/10943 (epoch 104.035) train_loss=128.86111450 time/batch=0.37s
12651/10943 (epoch 104.043) train_loss=302.40020752 time/batch=0.73s
12652/10943 (epoch 104.051) train_loss=304.79745483 time/batch=0.81s
12653/10943 (epoch 104.060) train_loss=148.46434021 time/batch=0.40s
12654/10943 (epoch 104.068) train_loss=702.92535400 time/batch=1.62s
12655/10943 (epoch 104.076) train_loss=286.99969482 time/batch=0.84s
12656/10943 (epoch 104.084) train_loss=172.50689697 time/batch=0.47s
12657/10943 (epoch 104.093) train_loss=192.22181702 time/batch=0.47s
12658/10943 (epoch 104.101) train_loss=297.60351562 time/batch=0.76s
12659/10943 (epoch 104.109) train_loss=232.84815979 time/batch=0.64s
12660/10943 (epoch 104.117) train_loss=176.46156311 time/batch=0.47s
12661/10943 (epoch 104.125) train_loss=421.63586426 time/batch=0.94s
12662/10943 (epoch 104.134) train_loss=130.15795898 time/batch=0.39s
12663/10943 (epoch 104.142) train_loss=575.26696777 time/batch=1.49s
12664/10943 (epoch 104.150) train_loss=115.15760803 time/batch=0.44s
12665/10943 (epoch 104.158) train_loss=235.79962158 time/batch=0.57s
12666/10943 (epoch 104.167) train_loss=212.16313171 time/batch=0.55s
12667/10943 (epoch 104.175) train_loss=354.81405640 time/batch=0.86s
12668/10943 (epoch 104.183) train_loss=332.97918701 time/batch=0.84s
12669/10943 (epoch 104.191) train_loss=344.89248657 time/batch=0.87s
12670/10943 (epoch 104.199) train_loss=268.51202393 time/batch=0.68s
12671/10943 (epoch 104.208) train_loss=355.70428467 time/batch=0.89s
12672/10943 (epoch 104.216) train_loss=383.90924072 time/batch=0.99s
12673/10943 (epoch 104.224) train_loss=410.88555908 time/batch=1.04s
12674/10943 (epoch 104.232) train_loss=426.10968018 time/batch=1.06s
12675/10943 (epoch 104.241) train_loss=162.23757935 time/batch=0.52s
12676/10943 (epoch 104.249) train_loss=215.53703308 time/batch=0.52s
12677/10943 (epoch 104.257) train_loss=308.42785645 time/batch=0.79s
12678/10943 (epoch 104.265) train_loss=262.78216553 time/batch=0.71s
12679/10943 (epoch 104.273) train_loss=387.14196777 time/batch=0.97s
12680/10943 (epoch 104.282) train_loss=152.40655518 time/batch=0.45s
12681/10943 (epoch 104.290) train_loss=461.61846924 time/batch=1.04s
12682/10943 (epoch 104.298) train_loss=201.04809570 time/batch=0.55s
12683/10943 (epoch 104.306) train_loss=269.84912109 time/batch=0.66s
12684/10943 (epoch 104.315) train_loss=235.57788086 time/batch=0.58s
12685/10943 (epoch 104.323) train_loss=435.09222412 time/batch=1.05s
12686/10943 (epoch 104.331) train_loss=181.40188599 time/batch=0.53s
12687/10943 (epoch 104.339) train_loss=141.20280457 time/batch=0.36s
12688/10943 (epoch 104.347) train_loss=354.70822144 time/batch=0.85s
12689/10943 (epoch 104.356) train_loss=281.77398682 time/batch=0.73s
12690/10943 (epoch 104.364) train_loss=237.58709717 time/batch=0.63s
12691/10943 (epoch 104.372) train_loss=293.44720459 time/batch=0.75s
12692/10943 (epoch 104.380) train_loss=325.64013672 time/batch=0.83s
12693/10943 (epoch 104.389) train_loss=385.25714111 time/batch=0.95s
12694/10943 (epoch 104.397) train_loss=321.35803223 time/batch=0.85s
12695/10943 (epoch 104.405) train_loss=290.18029785 time/batch=0.76s
12696/10943 (epoch 104.413) train_loss=313.63745117 time/batch=0.76s
12697/10943 (epoch 104.421) train_loss=325.83056641 time/batch=0.85s
12698/10943 (epoch 104.430) train_loss=289.23345947 time/batch=0.73s
12699/10943 (epoch 104.438) train_loss=155.87118530 time/batch=0.42s
12700/10943 (epoch 104.446) train_loss=224.51350403 time/batch=0.55s
12701/10943 (epoch 104.454) train_loss=222.85839844 time/batch=0.57s
12702/10943 (epoch 104.463) train_loss=262.88085938 time/batch=0.66s
12703/10943 (epoch 104.471) train_loss=251.52249146 time/batch=0.63s
12704/10943 (epoch 104.479) train_loss=297.98138428 time/batch=0.74s
12705/10943 (epoch 104.487) train_loss=236.50759888 time/batch=0.62s
12706/10943 (epoch 104.496) train_loss=346.74728394 time/batch=0.86s
12707/10943 (epoch 104.504) train_loss=308.28704834 time/batch=0.79s
12708/10943 (epoch 104.512) train_loss=150.88610840 time/batch=0.41s
12709/10943 (epoch 104.520) train_loss=235.03958130 time/batch=0.59s
12710/10943 (epoch 104.528) train_loss=225.96328735 time/batch=0.59s
12711/10943 (epoch 104.537) train_loss=125.77768707 time/batch=0.35s
12712/10943 (epoch 104.545) train_loss=201.14428711 time/batch=0.49s
12713/10943 (epoch 104.553) train_loss=279.65588379 time/batch=0.68s
12714/10943 (epoch 104.561) train_loss=261.92404175 time/batch=0.68s
12715/10943 (epoch 104.570) train_loss=279.94940186 time/batch=0.71s
12716/10943 (epoch 104.578) train_loss=139.31747437 time/batch=0.38s
12717/10943 (epoch 104.586) train_loss=260.58361816 time/batch=0.61s
12718/10943 (epoch 104.594) train_loss=238.79783630 time/batch=0.63s
12719/10943 (epoch 104.602) train_loss=195.55871582 time/batch=0.47s
12720/10943 (epoch 104.611) train_loss=196.83444214 time/batch=0.52s
12721/10943 (epoch 104.619) train_loss=197.72517395 time/batch=0.51s
12722/10943 (epoch 104.627) train_loss=182.49337769 time/batch=0.48s
12723/10943 (epoch 104.635) train_loss=330.54748535 time/batch=0.82s
12724/10943 (epoch 104.644) train_loss=222.91143799 time/batch=0.62s
12725/10943 (epoch 104.652) train_loss=196.42327881 time/batch=0.54s
12726/10943 (epoch 104.660) train_loss=256.98114014 time/batch=0.63s
12727/10943 (epoch 104.668) train_loss=291.33404541 time/batch=0.73s
12728/10943 (epoch 104.676) train_loss=263.47094727 time/batch=0.67s
12729/10943 (epoch 104.685) train_loss=285.51013184 time/batch=0.72s
12730/10943 (epoch 104.693) train_loss=280.05328369 time/batch=0.75s
12731/10943 (epoch 104.701) train_loss=225.04724121 time/batch=0.61s
12732/10943 (epoch 104.709) train_loss=290.12084961 time/batch=0.75s
12733/10943 (epoch 104.718) train_loss=205.11505127 time/batch=0.57s
12734/10943 (epoch 104.726) train_loss=192.22351074 time/batch=0.51s
12735/10943 (epoch 104.734) train_loss=282.61950684 time/batch=0.76s
12736/10943 (epoch 104.742) train_loss=207.94616699 time/batch=0.61s
12737/10943 (epoch 104.750) train_loss=288.84411621 time/batch=0.76s
12738/10943 (epoch 104.759) train_loss=263.88360596 time/batch=0.68s
12739/10943 (epoch 104.767) train_loss=267.82275391 time/batch=0.66s
12740/10943 (epoch 104.775) train_loss=233.19161987 time/batch=0.63s
12741/10943 (epoch 104.783) train_loss=174.83438110 time/batch=0.63s
setting learning rate to 0.0008871
12742/10943 (epoch 104.792) train_loss=184.83970642 time/batch=0.50s
12743/10943 (epoch 104.800) train_loss=325.23736572 time/batch=0.79s
12744/10943 (epoch 104.808) train_loss=456.92041016 time/batch=1.10s
12745/10943 (epoch 104.816) train_loss=300.69628906 time/batch=0.81s
12746/10943 (epoch 104.824) train_loss=586.95922852 time/batch=1.47s
12747/10943 (epoch 104.833) train_loss=522.60852051 time/batch=1.33s
12748/10943 (epoch 104.841) train_loss=99.03506470 time/batch=0.35s
12749/10943 (epoch 104.849) train_loss=943.12707520 time/batch=3.01s
12750/10943 (epoch 104.857) train_loss=296.04910278 time/batch=1.02s
12751/10943 (epoch 104.866) train_loss=643.09124756 time/batch=1.57s
12752/10943 (epoch 104.874) train_loss=474.98339844 time/batch=1.24s
12753/10943 (epoch 104.882) train_loss=160.59432983 time/batch=0.49s
12754/10943 (epoch 104.890) train_loss=417.18753052 time/batch=0.99s
12755/10943 (epoch 104.898) train_loss=324.52526855 time/batch=0.86s
12756/10943 (epoch 104.907) train_loss=555.55908203 time/batch=1.31s
12757/10943 (epoch 104.915) train_loss=108.31391144 time/batch=0.37s
12758/10943 (epoch 104.923) train_loss=274.52050781 time/batch=0.62s
12759/10943 (epoch 104.931) train_loss=390.19726562 time/batch=0.94s
12760/10943 (epoch 104.940) train_loss=629.14245605 time/batch=1.67s
12761/10943 (epoch 104.948) train_loss=356.60714722 time/batch=0.99s
12762/10943 (epoch 104.956) train_loss=225.36462402 time/batch=0.61s
12763/10943 (epoch 104.964) train_loss=245.30645752 time/batch=0.62s
12764/10943 (epoch 104.973) train_loss=136.37393188 time/batch=0.36s
12765/10943 (epoch 104.981) train_loss=466.28027344 time/batch=1.13s
12766/10943 (epoch 104.989) train_loss=521.06341553 time/batch=1.37s
12767/10943 (epoch 104.997) train_loss=188.15579224 time/batch=0.55s
12768/10943 (epoch 105.005) train_loss=142.46972656 time/batch=0.35s
12769/10943 (epoch 105.014) train_loss=280.92944336 time/batch=0.66s
12770/10943 (epoch 105.022) train_loss=141.08343506 time/batch=0.38s
12771/10943 (epoch 105.030) train_loss=266.58129883 time/batch=0.65s
12772/10943 (epoch 105.038) train_loss=429.98687744 time/batch=0.97s
12773/10943 (epoch 105.047) train_loss=301.51654053 time/batch=0.84s
12774/10943 (epoch 105.055) train_loss=355.96606445 time/batch=0.91s
12775/10943 (epoch 105.063) train_loss=118.84921265 time/batch=0.35s
12776/10943 (epoch 105.071) train_loss=209.85659790 time/batch=0.51s
12777/10943 (epoch 105.079) train_loss=195.37673950 time/batch=0.50s
12778/10943 (epoch 105.088) train_loss=151.44030762 time/batch=0.37s
12779/10943 (epoch 105.096) train_loss=381.03088379 time/batch=0.89s
12780/10943 (epoch 105.104) train_loss=281.78128052 time/batch=0.75s
12781/10943 (epoch 105.112) train_loss=167.92428589 time/batch=0.45s
12782/10943 (epoch 105.121) train_loss=145.60253906 time/batch=0.36s
12783/10943 (epoch 105.129) train_loss=237.34548950 time/batch=0.58s
12784/10943 (epoch 105.137) train_loss=328.79809570 time/batch=0.81s
12785/10943 (epoch 105.145) train_loss=427.40130615 time/batch=1.02s
12786/10943 (epoch 105.153) train_loss=423.85620117 time/batch=1.04s
12787/10943 (epoch 105.162) train_loss=367.31365967 time/batch=0.95s
12788/10943 (epoch 105.170) train_loss=308.39379883 time/batch=0.79s
12789/10943 (epoch 105.178) train_loss=293.64736938 time/batch=0.71s
12790/10943 (epoch 105.186) train_loss=372.94287109 time/batch=0.97s
12791/10943 (epoch 105.195) train_loss=439.56549072 time/batch=1.12s
12792/10943 (epoch 105.203) train_loss=180.92459106 time/batch=0.54s
12793/10943 (epoch 105.211) train_loss=193.49041748 time/batch=0.48s
12794/10943 (epoch 105.219) train_loss=201.18104553 time/batch=0.50s
12795/10943 (epoch 105.227) train_loss=156.77331543 time/batch=0.40s
12796/10943 (epoch 105.236) train_loss=287.46292114 time/batch=0.70s
12797/10943 (epoch 105.244) train_loss=176.04821777 time/batch=0.47s
12798/10943 (epoch 105.252) train_loss=233.93936157 time/batch=0.58s
12799/10943 (epoch 105.260) train_loss=309.80902100 time/batch=0.81s
12800/10943 (epoch 105.269) train_loss=234.34927368 time/batch=0.60s
12801/10943 (epoch 105.277) train_loss=270.07714844 time/batch=0.68s
12802/10943 (epoch 105.285) train_loss=385.57333374 time/batch=0.93s
12803/10943 (epoch 105.293) train_loss=342.42724609 time/batch=0.89s
12804/10943 (epoch 105.301) train_loss=281.30383301 time/batch=0.73s
12805/10943 (epoch 105.310) train_loss=430.30480957 time/batch=1.06s
12806/10943 (epoch 105.318) train_loss=291.08038330 time/batch=0.78s
12807/10943 (epoch 105.326) train_loss=236.17764282 time/batch=0.62s
12808/10943 (epoch 105.334) train_loss=284.78417969 time/batch=0.71s
12809/10943 (epoch 105.343) train_loss=187.50952148 time/batch=0.49s
12810/10943 (epoch 105.351) train_loss=125.94028473 time/batch=0.32s
12811/10943 (epoch 105.359) train_loss=300.47369385 time/batch=0.72s
12812/10943 (epoch 105.367) train_loss=237.90103149 time/batch=0.64s
12813/10943 (epoch 105.375) train_loss=168.74516296 time/batch=0.46s
12814/10943 (epoch 105.384) train_loss=503.83453369 time/batch=1.16s
12815/10943 (epoch 105.392) train_loss=252.68518066 time/batch=0.71s
12816/10943 (epoch 105.400) train_loss=308.32107544 time/batch=0.80s
12817/10943 (epoch 105.408) train_loss=333.91961670 time/batch=0.85s
12818/10943 (epoch 105.417) train_loss=433.51959229 time/batch=1.12s
12819/10943 (epoch 105.425) train_loss=294.43359375 time/batch=0.78s
12820/10943 (epoch 105.433) train_loss=362.40185547 time/batch=0.87s
12821/10943 (epoch 105.441) train_loss=265.57302856 time/batch=0.69s
12822/10943 (epoch 105.449) train_loss=328.81640625 time/batch=0.83s
12823/10943 (epoch 105.458) train_loss=373.77703857 time/batch=1.00s
12824/10943 (epoch 105.466) train_loss=300.75665283 time/batch=0.81s
12825/10943 (epoch 105.474) train_loss=216.06550598 time/batch=0.57s
12826/10943 (epoch 105.482) train_loss=113.65388489 time/batch=0.32s
12827/10943 (epoch 105.491) train_loss=162.34652710 time/batch=0.41s
12828/10943 (epoch 105.499) train_loss=271.85565186 time/batch=0.74s
12829/10943 (epoch 105.507) train_loss=218.63252258 time/batch=0.58s
12830/10943 (epoch 105.515) train_loss=167.53588867 time/batch=0.44s
12831/10943 (epoch 105.524) train_loss=306.52072144 time/batch=0.74s
12832/10943 (epoch 105.532) train_loss=226.28417969 time/batch=0.61s
12833/10943 (epoch 105.540) train_loss=304.85601807 time/batch=0.81s
12834/10943 (epoch 105.548) train_loss=233.44615173 time/batch=0.64s
12835/10943 (epoch 105.556) train_loss=263.09851074 time/batch=0.64s
12836/10943 (epoch 105.565) train_loss=220.50531006 time/batch=0.59s
12837/10943 (epoch 105.573) train_loss=339.94012451 time/batch=0.83s
12838/10943 (epoch 105.581) train_loss=186.61241150 time/batch=0.54s
12839/10943 (epoch 105.589) train_loss=244.56671143 time/batch=0.62s
12840/10943 (epoch 105.598) train_loss=341.24960327 time/batch=0.87s
12841/10943 (epoch 105.606) train_loss=138.90467834 time/batch=0.43s
12842/10943 (epoch 105.614) train_loss=321.89050293 time/batch=0.80s
12843/10943 (epoch 105.622) train_loss=142.58531189 time/batch=0.43s
12844/10943 (epoch 105.630) train_loss=223.72888184 time/batch=0.55s
12845/10943 (epoch 105.639) train_loss=241.88980103 time/batch=0.63s
12846/10943 (epoch 105.647) train_loss=123.89037323 time/batch=0.35s
12847/10943 (epoch 105.655) train_loss=273.35333252 time/batch=0.63s
12848/10943 (epoch 105.663) train_loss=193.75599670 time/batch=0.54s
12849/10943 (epoch 105.672) train_loss=244.88433838 time/batch=0.63s
12850/10943 (epoch 105.680) train_loss=297.67602539 time/batch=0.78s
12851/10943 (epoch 105.688) train_loss=343.51123047 time/batch=0.92s
12852/10943 (epoch 105.696) train_loss=148.01710510 time/batch=0.48s
12853/10943 (epoch 105.704) train_loss=263.00238037 time/batch=0.64s
12854/10943 (epoch 105.713) train_loss=200.98553467 time/batch=0.53s
12855/10943 (epoch 105.721) train_loss=235.11224365 time/batch=0.65s
12856/10943 (epoch 105.729) train_loss=206.32968140 time/batch=0.56s
12857/10943 (epoch 105.737) train_loss=299.43185425 time/batch=0.76s
12858/10943 (epoch 105.746) train_loss=217.92477417 time/batch=0.60s
12859/10943 (epoch 105.754) train_loss=265.09869385 time/batch=0.76s
12860/10943 (epoch 105.762) train_loss=256.47015381 time/batch=0.69s
12861/10943 (epoch 105.770) train_loss=192.87394714 time/batch=0.54s
12862/10943 (epoch 105.778) train_loss=220.16882324 time/batch=0.57s
setting learning rate to 0.0008605
  saved to metadata/gru_dropout-9_nov_folkwiki-20181207-173447_epoch61.pkl
12863/10943 (epoch 105.787) train_loss=334.82815552 time/batch=0.90s
12864/10943 (epoch 105.795) train_loss=417.33764648 time/batch=1.05s
12865/10943 (epoch 105.803) train_loss=229.52124023 time/batch=0.66s
12866/10943 (epoch 105.811) train_loss=226.42768860 time/batch=0.58s
12867/10943 (epoch 105.820) train_loss=116.84764099 time/batch=0.31s
12868/10943 (epoch 105.828) train_loss=308.00549316 time/batch=0.72s
12869/10943 (epoch 105.836) train_loss=349.15618896 time/batch=0.92s
12870/10943 (epoch 105.844) train_loss=433.34552002 time/batch=1.08s
12871/10943 (epoch 105.852) train_loss=735.00616455 time/batch=1.87s
12872/10943 (epoch 105.861) train_loss=402.65136719 time/batch=1.12s
12873/10943 (epoch 105.869) train_loss=318.48684692 time/batch=0.85s
12874/10943 (epoch 105.877) train_loss=543.85681152 time/batch=1.27s
12875/10943 (epoch 105.885) train_loss=296.69104004 time/batch=0.85s
12876/10943 (epoch 105.894) train_loss=226.55334473 time/batch=0.63s
12877/10943 (epoch 105.902) train_loss=560.03759766 time/batch=1.30s
12878/10943 (epoch 105.910) train_loss=213.22286987 time/batch=0.62s
12879/10943 (epoch 105.918) train_loss=238.15899658 time/batch=0.60s
12880/10943 (epoch 105.926) train_loss=304.35180664 time/batch=0.76s
12881/10943 (epoch 105.935) train_loss=270.97940063 time/batch=0.67s
12882/10943 (epoch 105.943) train_loss=179.02890015 time/batch=0.48s
12883/10943 (epoch 105.951) train_loss=195.30284119 time/batch=0.50s
12884/10943 (epoch 105.959) train_loss=192.64575195 time/batch=0.52s
12885/10943 (epoch 105.968) train_loss=95.43179321 time/batch=0.27s
12886/10943 (epoch 105.976) train_loss=438.70562744 time/batch=1.05s
12887/10943 (epoch 105.984) train_loss=615.79699707 time/batch=1.57s
12888/10943 (epoch 105.992) train_loss=488.17758179 time/batch=1.27s
12889/10943 (epoch 106.001) train_loss=131.05111694 time/batch=0.41s
12890/10943 (epoch 106.009) train_loss=113.44352722 time/batch=0.29s
12891/10943 (epoch 106.017) train_loss=462.73333740 time/batch=1.09s
12892/10943 (epoch 106.025) train_loss=333.56561279 time/batch=0.90s
12893/10943 (epoch 106.033) train_loss=297.34396362 time/batch=0.79s
12894/10943 (epoch 106.042) train_loss=478.60595703 time/batch=1.19s
12895/10943 (epoch 106.050) train_loss=471.13934326 time/batch=1.25s
12896/10943 (epoch 106.058) train_loss=263.35717773 time/batch=0.75s
12897/10943 (epoch 106.066) train_loss=118.80477142 time/batch=0.34s
12898/10943 (epoch 106.075) train_loss=268.02145386 time/batch=0.62s
12899/10943 (epoch 106.083) train_loss=192.99105835 time/batch=0.50s
12900/10943 (epoch 106.091) train_loss=144.63989258 time/batch=0.36s
12901/10943 (epoch 106.099) train_loss=788.87890625 time/batch=2.24s
12902/10943 (epoch 106.107) train_loss=270.89978027 time/batch=0.85s
12903/10943 (epoch 106.116) train_loss=292.59002686 time/batch=0.73s
12904/10943 (epoch 106.124) train_loss=337.20074463 time/batch=0.86s
12905/10943 (epoch 106.132) train_loss=132.30459595 time/batch=0.37s
12906/10943 (epoch 106.140) train_loss=195.67117310 time/batch=0.48s
12907/10943 (epoch 106.149) train_loss=272.77343750 time/batch=0.69s
12908/10943 (epoch 106.157) train_loss=646.54968262 time/batch=3.06s
12909/10943 (epoch 106.165) train_loss=484.01934814 time/batch=1.59s
12910/10943 (epoch 106.173) train_loss=118.73272705 time/batch=0.41s
12911/10943 (epoch 106.181) train_loss=428.39801025 time/batch=0.97s
12912/10943 (epoch 106.190) train_loss=210.31036377 time/batch=0.58s
12913/10943 (epoch 106.198) train_loss=184.31329346 time/batch=0.48s
12914/10943 (epoch 106.206) train_loss=279.10104370 time/batch=0.71s
12915/10943 (epoch 106.214) train_loss=285.17242432 time/batch=0.74s
12916/10943 (epoch 106.223) train_loss=253.24414062 time/batch=0.65s
12917/10943 (epoch 106.231) train_loss=413.25439453 time/batch=1.02s
12918/10943 (epoch 106.239) train_loss=244.09765625 time/batch=0.66s
12919/10943 (epoch 106.247) train_loss=292.26766968 time/batch=0.79s
12920/10943 (epoch 106.255) train_loss=210.52865601 time/batch=0.58s
12921/10943 (epoch 106.264) train_loss=232.61982727 time/batch=0.57s
12922/10943 (epoch 106.272) train_loss=291.22216797 time/batch=0.71s
12923/10943 (epoch 106.280) train_loss=338.15869141 time/batch=0.87s
12924/10943 (epoch 106.288) train_loss=137.87072754 time/batch=0.40s
12925/10943 (epoch 106.297) train_loss=269.20922852 time/batch=0.65s
12926/10943 (epoch 106.305) train_loss=423.00885010 time/batch=0.97s
12927/10943 (epoch 106.313) train_loss=294.80657959 time/batch=0.77s
12928/10943 (epoch 106.321) train_loss=133.88638306 time/batch=0.39s
12929/10943 (epoch 106.329) train_loss=336.51773071 time/batch=0.79s
12930/10943 (epoch 106.338) train_loss=416.54528809 time/batch=1.08s
12931/10943 (epoch 106.346) train_loss=155.23004150 time/batch=0.48s
12932/10943 (epoch 106.354) train_loss=370.63711548 time/batch=0.83s
12933/10943 (epoch 106.362) train_loss=201.94171143 time/batch=0.54s
12934/10943 (epoch 106.371) train_loss=366.85403442 time/batch=0.90s
12935/10943 (epoch 106.379) train_loss=256.75680542 time/batch=0.69s
12936/10943 (epoch 106.387) train_loss=228.11717224 time/batch=0.60s
12937/10943 (epoch 106.395) train_loss=213.17565918 time/batch=0.56s
12938/10943 (epoch 106.403) train_loss=297.54394531 time/batch=0.77s
12939/10943 (epoch 106.412) train_loss=236.17208862 time/batch=0.62s
12940/10943 (epoch 106.420) train_loss=160.34890747 time/batch=0.44s
12941/10943 (epoch 106.428) train_loss=199.90245056 time/batch=0.53s
12942/10943 (epoch 106.436) train_loss=348.50469971 time/batch=0.85s
12943/10943 (epoch 106.445) train_loss=148.04742432 time/batch=0.41s
12944/10943 (epoch 106.453) train_loss=262.41864014 time/batch=0.63s
12945/10943 (epoch 106.461) train_loss=266.53100586 time/batch=0.68s
12946/10943 (epoch 106.469) train_loss=391.17602539 time/batch=0.95s
12947/10943 (epoch 106.478) train_loss=195.83770752 time/batch=0.54s
12948/10943 (epoch 106.486) train_loss=151.33059692 time/batch=0.38s
12949/10943 (epoch 106.494) train_loss=355.21807861 time/batch=0.85s
12950/10943 (epoch 106.502) train_loss=299.85052490 time/batch=0.81s
12951/10943 (epoch 106.510) train_loss=319.72369385 time/batch=0.80s
12952/10943 (epoch 106.519) train_loss=323.74536133 time/batch=0.81s
12953/10943 (epoch 106.527) train_loss=380.80645752 time/batch=0.95s
12954/10943 (epoch 106.535) train_loss=384.66827393 time/batch=0.96s
12955/10943 (epoch 106.543) train_loss=271.86355591 time/batch=0.73s
12956/10943 (epoch 106.552) train_loss=338.43798828 time/batch=0.81s
12957/10943 (epoch 106.560) train_loss=226.78094482 time/batch=0.62s
12958/10943 (epoch 106.568) train_loss=371.38925171 time/batch=0.95s
12959/10943 (epoch 106.576) train_loss=245.31610107 time/batch=0.67s
12960/10943 (epoch 106.584) train_loss=240.89237976 time/batch=0.62s
12961/10943 (epoch 106.593) train_loss=156.56057739 time/batch=0.42s
12962/10943 (epoch 106.601) train_loss=331.83569336 time/batch=0.85s
12963/10943 (epoch 106.609) train_loss=304.37942505 time/batch=0.83s
12964/10943 (epoch 106.617) train_loss=300.02514648 time/batch=0.78s
12965/10943 (epoch 106.626) train_loss=174.18891907 time/batch=0.45s
12966/10943 (epoch 106.634) train_loss=141.72286987 time/batch=0.38s
12967/10943 (epoch 106.642) train_loss=298.39404297 time/batch=0.76s
12968/10943 (epoch 106.650) train_loss=289.98980713 time/batch=0.71s
12969/10943 (epoch 106.658) train_loss=227.15733337 time/batch=0.59s
12970/10943 (epoch 106.667) train_loss=218.61437988 time/batch=0.58s
12971/10943 (epoch 106.675) train_loss=276.97198486 time/batch=0.69s
12972/10943 (epoch 106.683) train_loss=246.50875854 time/batch=0.63s
12973/10943 (epoch 106.691) train_loss=292.30572510 time/batch=0.79s
12974/10943 (epoch 106.700) train_loss=155.71406555 time/batch=0.44s
12975/10943 (epoch 106.708) train_loss=215.06280518 time/batch=0.54s
12976/10943 (epoch 106.716) train_loss=267.77011108 time/batch=0.69s
12977/10943 (epoch 106.724) train_loss=253.91647339 time/batch=0.67s
12978/10943 (epoch 106.732) train_loss=192.33096313 time/batch=0.57s
12979/10943 (epoch 106.741) train_loss=238.48345947 time/batch=0.65s
12980/10943 (epoch 106.749) train_loss=188.12304688 time/batch=0.48s
12981/10943 (epoch 106.757) train_loss=170.00674438 time/batch=0.46s
12982/10943 (epoch 106.765) train_loss=211.72938538 time/batch=0.55s
12983/10943 (epoch 106.774) train_loss=173.06477356 time/batch=0.45s
setting learning rate to 0.0008347
12984/10943 (epoch 106.782) train_loss=943.66772461 time/batch=3.02s
12985/10943 (epoch 106.790) train_loss=98.51994324 time/batch=0.55s
12986/10943 (epoch 106.798) train_loss=304.67001343 time/batch=0.76s
12987/10943 (epoch 106.806) train_loss=417.12268066 time/batch=1.05s
12988/10943 (epoch 106.815) train_loss=386.92077637 time/batch=0.99s
12989/10943 (epoch 106.823) train_loss=215.08131409 time/batch=0.60s
12990/10943 (epoch 106.831) train_loss=322.40979004 time/batch=0.79s
12991/10943 (epoch 106.839) train_loss=464.46356201 time/batch=1.09s
12992/10943 (epoch 106.848) train_loss=443.38256836 time/batch=1.14s
12993/10943 (epoch 106.856) train_loss=174.15020752 time/batch=0.50s
12994/10943 (epoch 106.864) train_loss=554.67614746 time/batch=1.32s
12995/10943 (epoch 106.872) train_loss=349.42645264 time/batch=0.93s
12996/10943 (epoch 106.880) train_loss=694.75463867 time/batch=1.67s
12997/10943 (epoch 106.889) train_loss=465.67019653 time/batch=1.26s
12998/10943 (epoch 106.897) train_loss=550.79797363 time/batch=1.41s
12999/10943 (epoch 106.905) train_loss=117.87448120 time/batch=0.41s
Validating
    loss:	280.122264

13000/10943 (epoch 106.913) train_loss=518.03955078 time/batch=2.97s
13001/10943 (epoch 106.922) train_loss=424.80187988 time/batch=1.06s
13002/10943 (epoch 106.930) train_loss=310.42462158 time/batch=0.80s
13003/10943 (epoch 106.938) train_loss=472.61849976 time/batch=1.17s
13004/10943 (epoch 106.946) train_loss=618.96374512 time/batch=1.58s
13005/10943 (epoch 106.955) train_loss=291.84494019 time/batch=0.80s
13006/10943 (epoch 106.963) train_loss=144.70223999 time/batch=0.41s
13007/10943 (epoch 106.971) train_loss=150.98126221 time/batch=0.37s
13008/10943 (epoch 106.979) train_loss=298.81314087 time/batch=0.74s
13009/10943 (epoch 106.987) train_loss=214.18135071 time/batch=0.57s
13010/10943 (epoch 106.996) train_loss=185.25822449 time/batch=0.48s
13011/10943 (epoch 107.004) train_loss=168.31478882 time/batch=0.44s
13012/10943 (epoch 107.012) train_loss=234.43634033 time/batch=0.58s
13013/10943 (epoch 107.020) train_loss=400.85192871 time/batch=0.99s
13014/10943 (epoch 107.029) train_loss=159.07925415 time/batch=0.46s
13015/10943 (epoch 107.037) train_loss=267.63262939 time/batch=0.62s
13016/10943 (epoch 107.045) train_loss=335.17971802 time/batch=0.84s
13017/10943 (epoch 107.053) train_loss=357.91876221 time/batch=0.92s
13018/10943 (epoch 107.061) train_loss=525.79882812 time/batch=1.43s
13019/10943 (epoch 107.070) train_loss=338.58804321 time/batch=0.93s
13020/10943 (epoch 107.078) train_loss=220.61657715 time/batch=0.60s
13021/10943 (epoch 107.086) train_loss=180.24157715 time/batch=0.46s
13022/10943 (epoch 107.094) train_loss=299.48468018 time/batch=0.75s
13023/10943 (epoch 107.103) train_loss=232.13789368 time/batch=0.59s
13024/10943 (epoch 107.111) train_loss=239.72341919 time/batch=0.61s
13025/10943 (epoch 107.119) train_loss=437.07983398 time/batch=1.03s
13026/10943 (epoch 107.127) train_loss=380.91290283 time/batch=0.99s
13027/10943 (epoch 107.135) train_loss=267.46173096 time/batch=0.70s
13028/10943 (epoch 107.144) train_loss=361.39910889 time/batch=0.91s
13029/10943 (epoch 107.152) train_loss=123.74942017 time/batch=0.37s
13030/10943 (epoch 107.160) train_loss=162.78700256 time/batch=0.42s
13031/10943 (epoch 107.168) train_loss=392.19802856 time/batch=0.92s
13032/10943 (epoch 107.177) train_loss=218.86679077 time/batch=0.58s
13033/10943 (epoch 107.185) train_loss=332.79815674 time/batch=0.84s
13034/10943 (epoch 107.193) train_loss=198.23266602 time/batch=0.54s
13035/10943 (epoch 107.201) train_loss=222.43614197 time/batch=0.57s
13036/10943 (epoch 107.209) train_loss=307.05828857 time/batch=0.73s
13037/10943 (epoch 107.218) train_loss=126.40747070 time/batch=0.36s
13038/10943 (epoch 107.226) train_loss=200.95434570 time/batch=0.49s
13039/10943 (epoch 107.234) train_loss=259.55709839 time/batch=0.66s
13040/10943 (epoch 107.242) train_loss=286.15188599 time/batch=0.73s
13041/10943 (epoch 107.251) train_loss=282.60742188 time/batch=0.71s
13042/10943 (epoch 107.259) train_loss=506.44940186 time/batch=1.18s
13043/10943 (epoch 107.267) train_loss=393.19671631 time/batch=1.02s
13044/10943 (epoch 107.275) train_loss=161.33082581 time/batch=0.46s
13045/10943 (epoch 107.283) train_loss=265.69476318 time/batch=0.66s
13046/10943 (epoch 107.292) train_loss=420.94754028 time/batch=0.97s
13047/10943 (epoch 107.300) train_loss=421.67065430 time/batch=1.09s
13048/10943 (epoch 107.308) train_loss=314.93597412 time/batch=0.85s
13049/10943 (epoch 107.316) train_loss=278.56866455 time/batch=0.74s
13050/10943 (epoch 107.325) train_loss=329.33349609 time/batch=0.83s
13051/10943 (epoch 107.333) train_loss=113.88700104 time/batch=0.35s
13052/10943 (epoch 107.341) train_loss=243.36540222 time/batch=0.59s
13053/10943 (epoch 107.349) train_loss=266.06396484 time/batch=0.67s
13054/10943 (epoch 107.357) train_loss=306.18920898 time/batch=0.81s
13055/10943 (epoch 107.366) train_loss=122.60294342 time/batch=0.36s
13056/10943 (epoch 107.374) train_loss=194.69062805 time/batch=0.45s
13057/10943 (epoch 107.382) train_loss=131.51995850 time/batch=0.34s
13058/10943 (epoch 107.390) train_loss=270.04116821 time/batch=0.65s
13059/10943 (epoch 107.399) train_loss=302.91595459 time/batch=0.79s
13060/10943 (epoch 107.407) train_loss=352.64691162 time/batch=0.89s
13061/10943 (epoch 107.415) train_loss=296.91278076 time/batch=0.81s
13062/10943 (epoch 107.423) train_loss=354.63604736 time/batch=0.91s
13063/10943 (epoch 107.432) train_loss=387.22317505 time/batch=1.10s
13064/10943 (epoch 107.440) train_loss=136.04028320 time/batch=0.41s
13065/10943 (epoch 107.448) train_loss=193.55693054 time/batch=0.47s
13066/10943 (epoch 107.456) train_loss=216.29333496 time/batch=0.53s
13067/10943 (epoch 107.464) train_loss=257.69842529 time/batch=0.63s
13068/10943 (epoch 107.473) train_loss=237.80090332 time/batch=0.62s
13069/10943 (epoch 107.481) train_loss=362.25860596 time/batch=1.07s
13070/10943 (epoch 107.489) train_loss=293.62554932 time/batch=0.79s
13071/10943 (epoch 107.497) train_loss=297.88427734 time/batch=0.78s
13072/10943 (epoch 107.506) train_loss=334.26919556 time/batch=0.84s
13073/10943 (epoch 107.514) train_loss=259.61434937 time/batch=0.67s
13074/10943 (epoch 107.522) train_loss=216.12597656 time/batch=0.58s
13075/10943 (epoch 107.530) train_loss=283.25299072 time/batch=0.70s
13076/10943 (epoch 107.538) train_loss=229.66282654 time/batch=0.62s
13077/10943 (epoch 107.547) train_loss=153.32998657 time/batch=0.45s
13078/10943 (epoch 107.555) train_loss=288.24725342 time/batch=0.69s
13079/10943 (epoch 107.563) train_loss=298.28369141 time/batch=0.79s
13080/10943 (epoch 107.571) train_loss=262.14746094 time/batch=0.68s
13081/10943 (epoch 107.580) train_loss=195.83447266 time/batch=0.53s
13082/10943 (epoch 107.588) train_loss=323.89169312 time/batch=0.79s
13083/10943 (epoch 107.596) train_loss=148.10104370 time/batch=0.40s
13084/10943 (epoch 107.604) train_loss=157.07272339 time/batch=0.43s
13085/10943 (epoch 107.612) train_loss=313.81161499 time/batch=0.81s
13086/10943 (epoch 107.621) train_loss=231.70191956 time/batch=0.63s
13087/10943 (epoch 107.629) train_loss=134.28572083 time/batch=0.38s
13088/10943 (epoch 107.637) train_loss=163.96368408 time/batch=0.43s
13089/10943 (epoch 107.645) train_loss=283.99917603 time/batch=0.81s
13090/10943 (epoch 107.654) train_loss=258.36444092 time/batch=0.70s
13091/10943 (epoch 107.662) train_loss=266.41607666 time/batch=0.67s
13092/10943 (epoch 107.670) train_loss=245.50691223 time/batch=0.63s
13093/10943 (epoch 107.678) train_loss=234.47181702 time/batch=0.62s
13094/10943 (epoch 107.686) train_loss=179.67594910 time/batch=0.47s
13095/10943 (epoch 107.695) train_loss=191.08770752 time/batch=0.47s
13096/10943 (epoch 107.703) train_loss=188.07452393 time/batch=0.51s
13097/10943 (epoch 107.711) train_loss=248.21455383 time/batch=0.63s
13098/10943 (epoch 107.719) train_loss=289.16833496 time/batch=0.72s
13099/10943 (epoch 107.728) train_loss=219.58563232 time/batch=0.60s
13100/10943 (epoch 107.736) train_loss=259.87246704 time/batch=0.72s
13101/10943 (epoch 107.744) train_loss=222.84857178 time/batch=0.60s
13102/10943 (epoch 107.752) train_loss=165.08193970 time/batch=0.52s
13103/10943 (epoch 107.760) train_loss=212.23474121 time/batch=0.57s
13104/10943 (epoch 107.769) train_loss=206.66848755 time/batch=0.57s
setting learning rate to 0.0008097
  saved to metadata/gru_dropout-9_nov_folkwiki-20181207-173447_epoch63.pkl
13105/10943 (epoch 107.777) train_loss=548.26159668 time/batch=1.33s
13106/10943 (epoch 107.785) train_loss=382.86309814 time/batch=1.01s
13107/10943 (epoch 107.793) train_loss=142.06268311 time/batch=0.42s
13108/10943 (epoch 107.802) train_loss=871.87298584 time/batch=2.30s
13109/10943 (epoch 107.810) train_loss=483.78240967 time/batch=1.34s
13110/10943 (epoch 107.818) train_loss=163.04130554 time/batch=0.50s
13111/10943 (epoch 107.826) train_loss=534.72351074 time/batch=1.25s
13112/10943 (epoch 107.834) train_loss=428.36874390 time/batch=1.08s
13113/10943 (epoch 107.843) train_loss=205.38526917 time/batch=0.55s
13114/10943 (epoch 107.851) train_loss=140.62471008 time/batch=0.35s
13115/10943 (epoch 107.859) train_loss=94.18491364 time/batch=0.25s
13116/10943 (epoch 107.867) train_loss=440.31353760 time/batch=1.00s
13117/10943 (epoch 107.876) train_loss=337.94512939 time/batch=0.87s
13118/10943 (epoch 107.884) train_loss=751.92041016 time/batch=3.07s
13119/10943 (epoch 107.892) train_loss=125.98226166 time/batch=0.59s
13120/10943 (epoch 107.900) train_loss=201.90252686 time/batch=0.50s
13121/10943 (epoch 107.909) train_loss=546.31768799 time/batch=1.32s
13122/10943 (epoch 107.917) train_loss=448.04705811 time/batch=1.16s
13123/10943 (epoch 107.925) train_loss=288.39538574 time/batch=0.75s
13124/10943 (epoch 107.933) train_loss=458.74374390 time/batch=1.11s
13125/10943 (epoch 107.941) train_loss=280.87530518 time/batch=0.77s
13126/10943 (epoch 107.950) train_loss=520.59722900 time/batch=1.36s
13127/10943 (epoch 107.958) train_loss=201.20365906 time/batch=0.59s
13128/10943 (epoch 107.966) train_loss=212.27180481 time/batch=0.53s
13129/10943 (epoch 107.974) train_loss=340.05831909 time/batch=0.83s
13130/10943 (epoch 107.983) train_loss=199.32769775 time/batch=0.54s
13131/10943 (epoch 107.991) train_loss=155.64843750 time/batch=0.39s
13132/10943 (epoch 107.999) train_loss=283.22058105 time/batch=0.70s
13133/10943 (epoch 108.007) train_loss=395.15084839 time/batch=0.94s
13134/10943 (epoch 108.015) train_loss=233.74620056 time/batch=0.65s
13135/10943 (epoch 108.024) train_loss=216.91920471 time/batch=0.56s
13136/10943 (epoch 108.032) train_loss=292.75524902 time/batch=0.74s
13137/10943 (epoch 108.040) train_loss=498.12384033 time/batch=1.16s
13138/10943 (epoch 108.048) train_loss=348.83898926 time/batch=0.91s
13139/10943 (epoch 108.057) train_loss=264.04589844 time/batch=0.66s
13140/10943 (epoch 108.065) train_loss=183.18041992 time/batch=0.48s
13141/10943 (epoch 108.073) train_loss=234.55511475 time/batch=0.58s
13142/10943 (epoch 108.081) train_loss=212.01492310 time/batch=0.54s
13143/10943 (epoch 108.089) train_loss=260.25009155 time/batch=0.63s
13144/10943 (epoch 108.098) train_loss=307.25189209 time/batch=0.75s
13145/10943 (epoch 108.106) train_loss=592.38195801 time/batch=1.47s
13146/10943 (epoch 108.114) train_loss=273.02239990 time/batch=0.75s
13147/10943 (epoch 108.122) train_loss=226.16850281 time/batch=0.59s
13148/10943 (epoch 108.131) train_loss=238.54939270 time/batch=0.60s
13149/10943 (epoch 108.139) train_loss=299.00946045 time/batch=0.75s
13150/10943 (epoch 108.147) train_loss=363.82995605 time/batch=0.90s
13151/10943 (epoch 108.155) train_loss=224.43447876 time/batch=0.62s
13152/10943 (epoch 108.163) train_loss=419.28173828 time/batch=1.04s
13153/10943 (epoch 108.172) train_loss=434.34185791 time/batch=1.02s
13154/10943 (epoch 108.180) train_loss=192.36758423 time/batch=0.54s
13155/10943 (epoch 108.188) train_loss=543.88763428 time/batch=1.50s
13156/10943 (epoch 108.196) train_loss=200.38267517 time/batch=0.64s
13157/10943 (epoch 108.205) train_loss=407.69512939 time/batch=0.97s
13158/10943 (epoch 108.213) train_loss=283.96838379 time/batch=0.74s
13159/10943 (epoch 108.221) train_loss=269.78698730 time/batch=0.67s
13160/10943 (epoch 108.229) train_loss=185.41323853 time/batch=0.49s
13161/10943 (epoch 108.237) train_loss=145.40313721 time/batch=0.36s
13162/10943 (epoch 108.246) train_loss=135.39985657 time/batch=0.33s
13163/10943 (epoch 108.254) train_loss=298.46136475 time/batch=0.73s
13164/10943 (epoch 108.262) train_loss=307.62664795 time/batch=0.79s
13165/10943 (epoch 108.270) train_loss=327.79766846 time/batch=0.83s
13166/10943 (epoch 108.279) train_loss=228.31689453 time/batch=0.61s
13167/10943 (epoch 108.287) train_loss=203.97212219 time/batch=0.53s
13168/10943 (epoch 108.295) train_loss=128.44003296 time/batch=0.33s
13169/10943 (epoch 108.303) train_loss=394.73815918 time/batch=0.92s
13170/10943 (epoch 108.311) train_loss=370.90301514 time/batch=0.94s
13171/10943 (epoch 108.320) train_loss=301.66943359 time/batch=0.83s
13172/10943 (epoch 108.328) train_loss=307.08148193 time/batch=0.80s
13173/10943 (epoch 108.336) train_loss=113.91593170 time/batch=0.32s
13174/10943 (epoch 108.344) train_loss=172.18376160 time/batch=0.43s
13175/10943 (epoch 108.353) train_loss=452.41247559 time/batch=1.05s
13176/10943 (epoch 108.361) train_loss=176.13494873 time/batch=0.51s
13177/10943 (epoch 108.369) train_loss=389.62692261 time/batch=0.92s
13178/10943 (epoch 108.377) train_loss=274.58743286 time/batch=0.69s
13179/10943 (epoch 108.386) train_loss=116.54354095 time/batch=0.33s
13180/10943 (epoch 108.394) train_loss=234.57017517 time/batch=0.57s
13181/10943 (epoch 108.402) train_loss=337.86892700 time/batch=0.83s
13182/10943 (epoch 108.410) train_loss=264.12637329 time/batch=0.71s
13183/10943 (epoch 108.418) train_loss=315.55456543 time/batch=0.77s
13184/10943 (epoch 108.427) train_loss=354.68804932 time/batch=0.87s
13185/10943 (epoch 108.435) train_loss=295.10949707 time/batch=0.74s
13186/10943 (epoch 108.443) train_loss=382.11752319 time/batch=0.97s
13187/10943 (epoch 108.451) train_loss=304.41439819 time/batch=0.81s
13188/10943 (epoch 108.460) train_loss=313.34765625 time/batch=0.81s
13189/10943 (epoch 108.468) train_loss=201.87579346 time/batch=0.56s
13190/10943 (epoch 108.476) train_loss=138.36386108 time/batch=0.35s
13191/10943 (epoch 108.484) train_loss=298.62973022 time/batch=0.67s
13192/10943 (epoch 108.492) train_loss=264.82171631 time/batch=0.68s
13193/10943 (epoch 108.501) train_loss=272.05792236 time/batch=0.71s
13194/10943 (epoch 108.509) train_loss=253.17660522 time/batch=0.67s
13195/10943 (epoch 108.517) train_loss=227.14648438 time/batch=0.59s
13196/10943 (epoch 108.525) train_loss=229.20973206 time/batch=0.57s
13197/10943 (epoch 108.534) train_loss=373.91934204 time/batch=0.98s
13198/10943 (epoch 108.542) train_loss=351.66439819 time/batch=0.91s
13199/10943 (epoch 108.550) train_loss=301.31799316 time/batch=0.75s
13200/10943 (epoch 108.558) train_loss=214.58493042 time/batch=0.57s
13201/10943 (epoch 108.566) train_loss=339.18817139 time/batch=0.83s
13202/10943 (epoch 108.575) train_loss=230.13925171 time/batch=0.64s
13203/10943 (epoch 108.583) train_loss=301.91122437 time/batch=0.78s
13204/10943 (epoch 108.591) train_loss=267.09600830 time/batch=0.74s
13205/10943 (epoch 108.599) train_loss=241.66760254 time/batch=0.63s
13206/10943 (epoch 108.608) train_loss=204.84838867 time/batch=0.57s
13207/10943 (epoch 108.616) train_loss=316.30169678 time/batch=0.79s
13208/10943 (epoch 108.624) train_loss=175.50729370 time/batch=0.46s
13209/10943 (epoch 108.632) train_loss=240.65853882 time/batch=0.60s
13210/10943 (epoch 108.640) train_loss=343.30102539 time/batch=0.86s
13211/10943 (epoch 108.649) train_loss=282.57818604 time/batch=0.79s
13212/10943 (epoch 108.657) train_loss=185.45687866 time/batch=0.49s
13213/10943 (epoch 108.665) train_loss=163.92549133 time/batch=0.42s
13214/10943 (epoch 108.673) train_loss=158.56118774 time/batch=0.43s
13215/10943 (epoch 108.682) train_loss=253.03723145 time/batch=0.62s
13216/10943 (epoch 108.690) train_loss=327.42736816 time/batch=0.81s
13217/10943 (epoch 108.698) train_loss=175.76614380 time/batch=0.59s
13218/10943 (epoch 108.706) train_loss=227.20602417 time/batch=0.61s
13219/10943 (epoch 108.714) train_loss=277.32940674 time/batch=0.77s
13220/10943 (epoch 108.723) train_loss=263.33386230 time/batch=0.69s
13221/10943 (epoch 108.731) train_loss=119.18444061 time/batch=0.35s
13222/10943 (epoch 108.739) train_loss=248.38319397 time/batch=0.63s
13223/10943 (epoch 108.747) train_loss=300.90838623 time/batch=0.80s
13224/10943 (epoch 108.756) train_loss=153.47477722 time/batch=0.41s
13225/10943 (epoch 108.764) train_loss=201.09344482 time/batch=0.54s
setting learning rate to 0.0007854
13226/10943 (epoch 108.772) train_loss=294.73236084 time/batch=0.77s
13227/10943 (epoch 108.780) train_loss=358.89932251 time/batch=0.90s
13228/10943 (epoch 108.788) train_loss=701.77343750 time/batch=1.66s
13229/10943 (epoch 108.797) train_loss=334.19152832 time/batch=0.95s
13230/10943 (epoch 108.805) train_loss=511.20602417 time/batch=1.20s
13231/10943 (epoch 108.813) train_loss=648.89099121 time/batch=1.76s
13232/10943 (epoch 108.821) train_loss=381.97766113 time/batch=1.07s
13233/10943 (epoch 108.830) train_loss=201.38320923 time/batch=0.57s
13234/10943 (epoch 108.838) train_loss=202.62744141 time/batch=0.50s
13235/10943 (epoch 108.846) train_loss=96.43943787 time/batch=0.27s
13236/10943 (epoch 108.854) train_loss=282.79187012 time/batch=0.66s
13237/10943 (epoch 108.863) train_loss=348.83428955 time/batch=0.86s
13238/10943 (epoch 108.871) train_loss=551.60809326 time/batch=1.37s
13239/10943 (epoch 108.879) train_loss=261.79797363 time/batch=0.75s
13240/10943 (epoch 108.887) train_loss=551.91644287 time/batch=1.37s
13241/10943 (epoch 108.895) train_loss=173.21481323 time/batch=0.55s
13242/10943 (epoch 108.904) train_loss=293.81686401 time/batch=0.72s
13243/10943 (epoch 108.912) train_loss=151.23498535 time/batch=0.42s
13244/10943 (epoch 108.920) train_loss=132.20135498 time/batch=0.33s
13245/10943 (epoch 108.928) train_loss=325.69644165 time/batch=0.78s
13246/10943 (epoch 108.937) train_loss=337.61206055 time/batch=0.84s
13247/10943 (epoch 108.945) train_loss=491.92385864 time/batch=1.23s
13248/10943 (epoch 108.953) train_loss=225.72775269 time/batch=0.64s
13249/10943 (epoch 108.961) train_loss=910.57830811 time/batch=3.04s
13250/10943 (epoch 108.969) train_loss=220.77600098 time/batch=0.82s
13251/10943 (epoch 108.978) train_loss=109.54278564 time/batch=0.29s
13252/10943 (epoch 108.986) train_loss=173.98214722 time/batch=0.42s
13253/10943 (epoch 108.994) train_loss=414.31683350 time/batch=0.94s
13254/10943 (epoch 109.002) train_loss=192.77938843 time/batch=0.54s
13255/10943 (epoch 109.011) train_loss=440.58416748 time/batch=1.02s
13256/10943 (epoch 109.019) train_loss=269.51608276 time/batch=0.72s
13257/10943 (epoch 109.027) train_loss=524.46911621 time/batch=1.25s
13258/10943 (epoch 109.035) train_loss=373.47430420 time/batch=0.98s
13259/10943 (epoch 109.043) train_loss=309.20092773 time/batch=0.83s
13260/10943 (epoch 109.052) train_loss=149.88165283 time/batch=0.42s
13261/10943 (epoch 109.060) train_loss=162.54878235 time/batch=0.41s
13262/10943 (epoch 109.068) train_loss=237.67913818 time/batch=0.60s
13263/10943 (epoch 109.076) train_loss=452.30465698 time/batch=1.08s
13264/10943 (epoch 109.085) train_loss=301.36849976 time/batch=0.81s
13265/10943 (epoch 109.093) train_loss=141.47224426 time/batch=0.40s
13266/10943 (epoch 109.101) train_loss=154.32661438 time/batch=0.40s
13267/10943 (epoch 109.109) train_loss=305.28771973 time/batch=0.75s
13268/10943 (epoch 109.117) train_loss=247.04644775 time/batch=0.65s
13269/10943 (epoch 109.126) train_loss=289.30676270 time/batch=0.71s
13270/10943 (epoch 109.134) train_loss=270.91427612 time/batch=0.66s
13271/10943 (epoch 109.142) train_loss=256.97332764 time/batch=0.64s
13272/10943 (epoch 109.150) train_loss=485.54821777 time/batch=1.25s
13273/10943 (epoch 109.159) train_loss=196.20648193 time/batch=0.54s
13274/10943 (epoch 109.167) train_loss=323.41448975 time/batch=0.79s
13275/10943 (epoch 109.175) train_loss=230.89126587 time/batch=0.64s
13276/10943 (epoch 109.183) train_loss=456.21228027 time/batch=1.11s
13277/10943 (epoch 109.191) train_loss=263.87167358 time/batch=0.70s
13278/10943 (epoch 109.200) train_loss=403.53686523 time/batch=0.98s
13279/10943 (epoch 109.208) train_loss=153.64038086 time/batch=0.44s
13280/10943 (epoch 109.216) train_loss=430.05450439 time/batch=0.96s
13281/10943 (epoch 109.224) train_loss=413.82540894 time/batch=1.09s
13282/10943 (epoch 109.233) train_loss=438.78161621 time/batch=1.11s
13283/10943 (epoch 109.241) train_loss=143.87895203 time/batch=0.43s
13284/10943 (epoch 109.249) train_loss=291.51580811 time/batch=0.69s
13285/10943 (epoch 109.257) train_loss=264.20727539 time/batch=0.67s
13286/10943 (epoch 109.265) train_loss=122.06478882 time/batch=0.32s
13287/10943 (epoch 109.274) train_loss=177.86988831 time/batch=0.45s
13288/10943 (epoch 109.282) train_loss=493.75985718 time/batch=1.38s
13289/10943 (epoch 109.290) train_loss=271.26013184 time/batch=0.77s
13290/10943 (epoch 109.298) train_loss=218.25561523 time/batch=0.57s
13291/10943 (epoch 109.307) train_loss=234.82113647 time/batch=0.59s
13292/10943 (epoch 109.315) train_loss=311.10848999 time/batch=0.74s
13293/10943 (epoch 109.323) train_loss=119.13996887 time/batch=0.35s
13294/10943 (epoch 109.331) train_loss=235.41151428 time/batch=0.54s
13295/10943 (epoch 109.340) train_loss=288.29873657 time/batch=0.70s
13296/10943 (epoch 109.348) train_loss=136.27255249 time/batch=0.39s
13297/10943 (epoch 109.356) train_loss=179.65917969 time/batch=0.45s
13298/10943 (epoch 109.364) train_loss=273.63867188 time/batch=0.67s
13299/10943 (epoch 109.372) train_loss=196.36238098 time/batch=0.50s
13300/10943 (epoch 109.381) train_loss=303.42947388 time/batch=0.76s
13301/10943 (epoch 109.389) train_loss=328.45932007 time/batch=0.85s
13302/10943 (epoch 109.397) train_loss=209.45663452 time/batch=0.57s
13303/10943 (epoch 109.405) train_loss=221.84262085 time/batch=0.57s
13304/10943 (epoch 109.414) train_loss=328.52746582 time/batch=0.81s
13305/10943 (epoch 109.422) train_loss=196.61801147 time/batch=0.54s
13306/10943 (epoch 109.430) train_loss=285.47851562 time/batch=0.70s
13307/10943 (epoch 109.438) train_loss=194.23960876 time/batch=0.52s
13308/10943 (epoch 109.446) train_loss=361.08511353 time/batch=0.84s
13309/10943 (epoch 109.455) train_loss=176.20960999 time/batch=0.47s
13310/10943 (epoch 109.463) train_loss=204.76046753 time/batch=0.50s
13311/10943 (epoch 109.471) train_loss=296.13323975 time/batch=0.73s
13312/10943 (epoch 109.479) train_loss=160.86022949 time/batch=0.46s
13313/10943 (epoch 109.488) train_loss=365.95333862 time/batch=0.87s
13314/10943 (epoch 109.496) train_loss=398.68508911 time/batch=0.97s
13315/10943 (epoch 109.504) train_loss=224.98130798 time/batch=0.64s
13316/10943 (epoch 109.512) train_loss=375.40057373 time/batch=0.96s
13317/10943 (epoch 109.520) train_loss=300.37597656 time/batch=0.84s
13318/10943 (epoch 109.529) train_loss=380.15502930 time/batch=0.94s
13319/10943 (epoch 109.537) train_loss=121.04481506 time/batch=0.37s
13320/10943 (epoch 109.545) train_loss=376.88458252 time/batch=0.94s
13321/10943 (epoch 109.553) train_loss=260.92309570 time/batch=0.70s
13322/10943 (epoch 109.562) train_loss=187.58145142 time/batch=0.53s
13323/10943 (epoch 109.570) train_loss=127.00543213 time/batch=0.33s
13324/10943 (epoch 109.578) train_loss=282.96539307 time/batch=0.66s
13325/10943 (epoch 109.586) train_loss=281.05554199 time/batch=0.76s
13326/10943 (epoch 109.594) train_loss=257.06854248 time/batch=0.66s
13327/10943 (epoch 109.603) train_loss=278.48385620 time/batch=0.73s
13328/10943 (epoch 109.611) train_loss=182.51243591 time/batch=0.55s
13329/10943 (epoch 109.619) train_loss=310.90246582 time/batch=0.79s
13330/10943 (epoch 109.627) train_loss=244.02703857 time/batch=0.63s
13331/10943 (epoch 109.636) train_loss=295.45138550 time/batch=0.76s
13332/10943 (epoch 109.644) train_loss=313.92242432 time/batch=0.84s
13333/10943 (epoch 109.652) train_loss=224.66769409 time/batch=0.60s
13334/10943 (epoch 109.660) train_loss=238.92083740 time/batch=0.60s
13335/10943 (epoch 109.668) train_loss=210.96331787 time/batch=0.55s
13336/10943 (epoch 109.677) train_loss=261.96810913 time/batch=0.64s
13337/10943 (epoch 109.685) train_loss=394.98760986 time/batch=1.00s
13338/10943 (epoch 109.693) train_loss=236.26345825 time/batch=0.65s
13339/10943 (epoch 109.701) train_loss=182.20278931 time/batch=0.55s
13340/10943 (epoch 109.710) train_loss=299.65008545 time/batch=0.81s
13341/10943 (epoch 109.718) train_loss=359.26303101 time/batch=0.87s
13342/10943 (epoch 109.726) train_loss=173.54621887 time/batch=0.61s
13343/10943 (epoch 109.734) train_loss=262.51199341 time/batch=0.65s
13344/10943 (epoch 109.742) train_loss=258.12371826 time/batch=0.76s
13345/10943 (epoch 109.751) train_loss=273.72406006 time/batch=0.83s
13346/10943 (epoch 109.759) train_loss=228.83058167 time/batch=0.60s
setting learning rate to 0.0007618
  saved to metadata/gru_dropout-9_nov_folkwiki-20181207-173447_epoch65.pkl
13347/10943 (epoch 109.767) train_loss=462.91613770 time/batch=1.13s
13348/10943 (epoch 109.775) train_loss=465.82653809 time/batch=1.17s
13349/10943 (epoch 109.784) train_loss=170.80191040 time/batch=0.50s
13350/10943 (epoch 109.792) train_loss=522.86224365 time/batch=1.21s
13351/10943 (epoch 109.800) train_loss=418.57733154 time/batch=1.09s
13352/10943 (epoch 109.808) train_loss=301.88018799 time/batch=0.85s
13353/10943 (epoch 109.816) train_loss=564.00427246 time/batch=1.43s
13354/10943 (epoch 109.825) train_loss=235.07427979 time/batch=0.69s
13355/10943 (epoch 109.833) train_loss=366.96957397 time/batch=0.86s
13356/10943 (epoch 109.841) train_loss=727.34204102 time/batch=1.76s
13357/10943 (epoch 109.849) train_loss=392.73193359 time/batch=1.09s
13358/10943 (epoch 109.858) train_loss=345.44934082 time/batch=0.88s
13359/10943 (epoch 109.866) train_loss=433.06579590 time/batch=1.03s
13360/10943 (epoch 109.874) train_loss=120.24018860 time/batch=0.38s
13361/10943 (epoch 109.882) train_loss=96.18096924 time/batch=0.25s
13362/10943 (epoch 109.891) train_loss=203.11384583 time/batch=0.48s
13363/10943 (epoch 109.899) train_loss=112.41155243 time/batch=0.30s
13364/10943 (epoch 109.907) train_loss=413.29101562 time/batch=0.96s
13365/10943 (epoch 109.915) train_loss=574.69543457 time/batch=1.35s
13366/10943 (epoch 109.923) train_loss=277.63842773 time/batch=0.75s
13367/10943 (epoch 109.932) train_loss=147.06660461 time/batch=0.37s
13368/10943 (epoch 109.940) train_loss=344.88916016 time/batch=0.80s
13369/10943 (epoch 109.948) train_loss=332.50500488 time/batch=0.83s
13370/10943 (epoch 109.956) train_loss=371.10189819 time/batch=0.90s
13371/10943 (epoch 109.965) train_loss=473.60412598 time/batch=1.18s
13372/10943 (epoch 109.973) train_loss=133.65715027 time/batch=0.41s
13373/10943 (epoch 109.981) train_loss=266.99966431 time/batch=0.66s
13374/10943 (epoch 109.989) train_loss=394.80874634 time/batch=0.94s
13375/10943 (epoch 109.997) train_loss=215.44311523 time/batch=0.60s
13376/10943 (epoch 110.006) train_loss=509.59729004 time/batch=1.18s
13377/10943 (epoch 110.014) train_loss=652.79785156 time/batch=1.81s
13378/10943 (epoch 110.022) train_loss=391.84201050 time/batch=1.05s
13379/10943 (epoch 110.030) train_loss=313.75076294 time/batch=0.81s
13380/10943 (epoch 110.039) train_loss=297.86447144 time/batch=0.74s
13381/10943 (epoch 110.047) train_loss=234.21089172 time/batch=0.62s
13382/10943 (epoch 110.055) train_loss=205.27441406 time/batch=0.54s
13383/10943 (epoch 110.063) train_loss=298.03823853 time/batch=0.74s
13384/10943 (epoch 110.071) train_loss=396.33227539 time/batch=0.97s
13385/10943 (epoch 110.080) train_loss=291.74578857 time/batch=0.75s
13386/10943 (epoch 110.088) train_loss=161.14111328 time/batch=0.43s
13387/10943 (epoch 110.096) train_loss=242.91333008 time/batch=0.59s
13388/10943 (epoch 110.104) train_loss=119.60999298 time/batch=0.33s
13389/10943 (epoch 110.113) train_loss=881.78338623 time/batch=3.01s
13390/10943 (epoch 110.121) train_loss=336.59539795 time/batch=1.12s
13391/10943 (epoch 110.129) train_loss=200.30996704 time/batch=0.53s
13392/10943 (epoch 110.137) train_loss=437.74926758 time/batch=1.04s
13393/10943 (epoch 110.145) train_loss=531.48803711 time/batch=1.37s
13394/10943 (epoch 110.154) train_loss=156.80563354 time/batch=0.47s
13395/10943 (epoch 110.162) train_loss=159.73516846 time/batch=0.39s
13396/10943 (epoch 110.170) train_loss=225.06091309 time/batch=0.57s
13397/10943 (epoch 110.178) train_loss=227.72546387 time/batch=0.57s
13398/10943 (epoch 110.187) train_loss=301.91143799 time/batch=0.77s
13399/10943 (epoch 110.195) train_loss=329.03588867 time/batch=0.85s
13400/10943 (epoch 110.203) train_loss=275.51135254 time/batch=0.68s
13401/10943 (epoch 110.211) train_loss=289.28491211 time/batch=0.70s
13402/10943 (epoch 110.219) train_loss=427.78930664 time/batch=0.99s
13403/10943 (epoch 110.228) train_loss=265.15411377 time/batch=0.72s
13404/10943 (epoch 110.236) train_loss=147.83168030 time/batch=0.40s
13405/10943 (epoch 110.244) train_loss=289.57348633 time/batch=0.70s
13406/10943 (epoch 110.252) train_loss=239.46340942 time/batch=0.63s
13407/10943 (epoch 110.261) train_loss=198.76208496 time/batch=0.52s
13408/10943 (epoch 110.269) train_loss=300.69586182 time/batch=0.73s
13409/10943 (epoch 110.277) train_loss=313.43655396 time/batch=0.81s
13410/10943 (epoch 110.285) train_loss=326.89004517 time/batch=0.84s
13411/10943 (epoch 110.293) train_loss=118.07752228 time/batch=0.36s
13412/10943 (epoch 110.302) train_loss=350.11709595 time/batch=0.85s
13413/10943 (epoch 110.310) train_loss=439.83847046 time/batch=1.11s
13414/10943 (epoch 110.318) train_loss=350.65350342 time/batch=0.90s
13415/10943 (epoch 110.326) train_loss=294.74575806 time/batch=0.81s
13416/10943 (epoch 110.335) train_loss=311.23840332 time/batch=0.79s
13417/10943 (epoch 110.343) train_loss=325.27508545 time/batch=0.83s
13418/10943 (epoch 110.351) train_loss=263.89306641 time/batch=0.67s
13419/10943 (epoch 110.359) train_loss=176.41867065 time/batch=0.46s
13420/10943 (epoch 110.368) train_loss=247.51260376 time/batch=0.61s
13421/10943 (epoch 110.376) train_loss=306.84683228 time/batch=0.77s
13422/10943 (epoch 110.384) train_loss=242.55120850 time/batch=0.62s
13423/10943 (epoch 110.392) train_loss=445.43017578 time/batch=1.15s
13424/10943 (epoch 110.400) train_loss=314.27557373 time/batch=0.86s
13425/10943 (epoch 110.409) train_loss=390.43695068 time/batch=1.02s
13426/10943 (epoch 110.417) train_loss=192.55795288 time/batch=0.53s
13427/10943 (epoch 110.425) train_loss=155.12326050 time/batch=0.40s
13428/10943 (epoch 110.433) train_loss=242.71519470 time/batch=0.60s
13429/10943 (epoch 110.442) train_loss=332.37030029 time/batch=0.85s
13430/10943 (epoch 110.450) train_loss=286.86813354 time/batch=0.72s
13431/10943 (epoch 110.458) train_loss=185.83879089 time/batch=0.50s
13432/10943 (epoch 110.466) train_loss=360.82385254 time/batch=0.88s
13433/10943 (epoch 110.474) train_loss=280.18841553 time/batch=0.76s
13434/10943 (epoch 110.483) train_loss=212.84739685 time/batch=0.55s
13435/10943 (epoch 110.491) train_loss=188.27886963 time/batch=0.48s
13436/10943 (epoch 110.499) train_loss=292.80010986 time/batch=0.68s
13437/10943 (epoch 110.507) train_loss=350.52923584 time/batch=0.90s
13438/10943 (epoch 110.516) train_loss=219.27783203 time/batch=0.57s
13439/10943 (epoch 110.524) train_loss=256.82177734 time/batch=0.63s
13440/10943 (epoch 110.532) train_loss=270.50018311 time/batch=0.65s
13441/10943 (epoch 110.540) train_loss=221.87655640 time/batch=0.58s
13442/10943 (epoch 110.548) train_loss=262.77581787 time/batch=0.66s
13443/10943 (epoch 110.557) train_loss=280.36944580 time/batch=0.74s
13444/10943 (epoch 110.565) train_loss=260.33068848 time/batch=0.67s
13445/10943 (epoch 110.573) train_loss=166.50585938 time/batch=0.44s
13446/10943 (epoch 110.581) train_loss=260.12884521 time/batch=0.64s
13447/10943 (epoch 110.590) train_loss=245.12106323 time/batch=0.63s
13448/10943 (epoch 110.598) train_loss=318.46435547 time/batch=0.75s
13449/10943 (epoch 110.606) train_loss=150.38961792 time/batch=0.45s
13450/10943 (epoch 110.614) train_loss=229.25039673 time/batch=0.56s
13451/10943 (epoch 110.622) train_loss=231.07841492 time/batch=0.58s
13452/10943 (epoch 110.631) train_loss=274.79159546 time/batch=0.67s
13453/10943 (epoch 110.639) train_loss=207.65853882 time/batch=0.56s
13454/10943 (epoch 110.647) train_loss=141.17071533 time/batch=0.37s
13455/10943 (epoch 110.655) train_loss=282.04861450 time/batch=0.70s
13456/10943 (epoch 110.664) train_loss=217.51782227 time/batch=0.58s
13457/10943 (epoch 110.672) train_loss=263.05810547 time/batch=0.72s
13458/10943 (epoch 110.680) train_loss=137.21858215 time/batch=0.37s
13459/10943 (epoch 110.688) train_loss=129.69175720 time/batch=0.33s
13460/10943 (epoch 110.696) train_loss=219.55343628 time/batch=0.54s
13461/10943 (epoch 110.705) train_loss=171.09402466 time/batch=0.46s
13462/10943 (epoch 110.713) train_loss=206.46710205 time/batch=0.49s
13463/10943 (epoch 110.721) train_loss=171.65551758 time/batch=0.45s
13464/10943 (epoch 110.729) train_loss=221.10189819 time/batch=0.55s
13465/10943 (epoch 110.738) train_loss=191.23414612 time/batch=0.50s
13466/10943 (epoch 110.746) train_loss=275.41168213 time/batch=0.72s
13467/10943 (epoch 110.754) train_loss=201.31594849 time/batch=0.59s
setting learning rate to 0.0007390
13468/10943 (epoch 110.762) train_loss=122.05045319 time/batch=0.31s
13469/10943 (epoch 110.770) train_loss=153.47662354 time/batch=0.39s
13470/10943 (epoch 110.779) train_loss=419.90570068 time/batch=0.93s
13471/10943 (epoch 110.787) train_loss=461.15899658 time/batch=1.14s
13472/10943 (epoch 110.795) train_loss=110.87457275 time/batch=0.37s
13473/10943 (epoch 110.803) train_loss=264.63198853 time/batch=0.64s
13474/10943 (epoch 110.812) train_loss=792.58941650 time/batch=2.05s
13475/10943 (epoch 110.820) train_loss=121.80703735 time/batch=0.49s
13476/10943 (epoch 110.828) train_loss=867.05029297 time/batch=3.01s
13477/10943 (epoch 110.836) train_loss=275.22836304 time/batch=0.95s
13478/10943 (epoch 110.845) train_loss=411.05438232 time/batch=0.98s
13479/10943 (epoch 110.853) train_loss=452.69183350 time/batch=1.15s
13480/10943 (epoch 110.861) train_loss=290.32275391 time/batch=0.76s
13481/10943 (epoch 110.869) train_loss=587.21411133 time/batch=1.47s
13482/10943 (epoch 110.877) train_loss=605.80065918 time/batch=1.61s
13483/10943 (epoch 110.886) train_loss=133.79844666 time/batch=0.44s
13484/10943 (epoch 110.894) train_loss=396.75436401 time/batch=0.89s
13485/10943 (epoch 110.902) train_loss=366.02914429 time/batch=0.94s
13486/10943 (epoch 110.910) train_loss=241.97822571 time/batch=0.65s
13487/10943 (epoch 110.919) train_loss=356.46530151 time/batch=0.87s
13488/10943 (epoch 110.927) train_loss=214.11752319 time/batch=0.59s
13489/10943 (epoch 110.935) train_loss=199.72564697 time/batch=0.52s
13490/10943 (epoch 110.943) train_loss=329.93051147 time/batch=0.80s
13491/10943 (epoch 110.951) train_loss=560.69177246 time/batch=1.29s
13492/10943 (epoch 110.960) train_loss=96.14382935 time/batch=0.35s
13493/10943 (epoch 110.968) train_loss=260.09442139 time/batch=0.62s
13494/10943 (epoch 110.976) train_loss=135.75570679 time/batch=0.37s
13495/10943 (epoch 110.984) train_loss=166.28630066 time/batch=0.42s
13496/10943 (epoch 110.993) train_loss=460.87792969 time/batch=1.04s
13497/10943 (epoch 111.001) train_loss=309.48162842 time/batch=0.81s
13498/10943 (epoch 111.009) train_loss=148.18283081 time/batch=0.41s
13499/10943 (epoch 111.017) train_loss=393.66262817 time/batch=0.90s
13500/10943 (epoch 111.025) train_loss=266.32305908 time/batch=0.72s
13501/10943 (epoch 111.034) train_loss=266.79995728 time/batch=0.66s
13502/10943 (epoch 111.042) train_loss=539.30895996 time/batch=1.29s
13503/10943 (epoch 111.050) train_loss=121.19367981 time/batch=0.41s
13504/10943 (epoch 111.058) train_loss=202.96000671 time/batch=0.49s
13505/10943 (epoch 111.067) train_loss=530.51062012 time/batch=1.31s
13506/10943 (epoch 111.075) train_loss=262.88061523 time/batch=0.72s
13507/10943 (epoch 111.083) train_loss=293.76950073 time/batch=0.73s
13508/10943 (epoch 111.091) train_loss=486.98498535 time/batch=1.17s
13509/10943 (epoch 111.099) train_loss=333.23291016 time/batch=0.90s
13510/10943 (epoch 111.108) train_loss=444.94635010 time/batch=1.13s
13511/10943 (epoch 111.116) train_loss=439.74792480 time/batch=1.05s
13512/10943 (epoch 111.124) train_loss=166.84364319 time/batch=0.48s
13513/10943 (epoch 111.132) train_loss=214.57727051 time/batch=0.53s
13514/10943 (epoch 111.141) train_loss=278.51910400 time/batch=0.68s
13515/10943 (epoch 111.149) train_loss=403.26104736 time/batch=0.99s
13516/10943 (epoch 111.157) train_loss=369.63244629 time/batch=0.92s
13517/10943 (epoch 111.165) train_loss=247.47334290 time/batch=0.66s
13518/10943 (epoch 111.173) train_loss=339.83288574 time/batch=0.83s
13519/10943 (epoch 111.182) train_loss=459.37362671 time/batch=1.17s
13520/10943 (epoch 111.190) train_loss=431.98703003 time/batch=1.06s
13521/10943 (epoch 111.198) train_loss=188.19869995 time/batch=0.53s
13522/10943 (epoch 111.206) train_loss=148.29064941 time/batch=0.37s
13523/10943 (epoch 111.215) train_loss=339.71792603 time/batch=0.79s
13524/10943 (epoch 111.223) train_loss=145.42248535 time/batch=0.40s
13525/10943 (epoch 111.231) train_loss=368.81793213 time/batch=0.82s
13526/10943 (epoch 111.239) train_loss=197.28482056 time/batch=0.52s
13527/10943 (epoch 111.247) train_loss=244.25729370 time/batch=0.60s
13528/10943 (epoch 111.256) train_loss=307.75244141 time/batch=0.74s
13529/10943 (epoch 111.264) train_loss=304.27478027 time/batch=0.79s
13530/10943 (epoch 111.272) train_loss=269.32897949 time/batch=0.70s
13531/10943 (epoch 111.280) train_loss=271.45782471 time/batch=0.69s
13532/10943 (epoch 111.289) train_loss=381.21798706 time/batch=0.94s
13533/10943 (epoch 111.297) train_loss=272.86816406 time/batch=0.73s
13534/10943 (epoch 111.305) train_loss=308.18890381 time/batch=0.76s
13535/10943 (epoch 111.313) train_loss=287.89971924 time/batch=0.72s
13536/10943 (epoch 111.322) train_loss=373.27624512 time/batch=0.96s
13537/10943 (epoch 111.330) train_loss=243.23199463 time/batch=0.64s
13538/10943 (epoch 111.338) train_loss=433.35293579 time/batch=1.15s
13539/10943 (epoch 111.346) train_loss=196.33500671 time/batch=0.57s
13540/10943 (epoch 111.354) train_loss=352.11529541 time/batch=0.85s
13541/10943 (epoch 111.363) train_loss=241.90490723 time/batch=0.65s
13542/10943 (epoch 111.371) train_loss=261.77850342 time/batch=0.64s
13543/10943 (epoch 111.379) train_loss=311.06530762 time/batch=0.80s
13544/10943 (epoch 111.387) train_loss=152.96243286 time/batch=0.42s
13545/10943 (epoch 111.396) train_loss=455.99566650 time/batch=1.14s
13546/10943 (epoch 111.404) train_loss=214.74044800 time/batch=0.60s
13547/10943 (epoch 111.412) train_loss=173.46011353 time/batch=0.45s
13548/10943 (epoch 111.420) train_loss=140.15034485 time/batch=0.36s
13549/10943 (epoch 111.428) train_loss=189.18789673 time/batch=0.46s
13550/10943 (epoch 111.437) train_loss=153.68740845 time/batch=0.40s
13551/10943 (epoch 111.445) train_loss=314.97378540 time/batch=0.78s
13552/10943 (epoch 111.453) train_loss=342.67694092 time/batch=0.86s
13553/10943 (epoch 111.461) train_loss=143.88549805 time/batch=0.44s
13554/10943 (epoch 111.470) train_loss=214.52969360 time/batch=0.52s
13555/10943 (epoch 111.478) train_loss=332.98138428 time/batch=0.80s
13556/10943 (epoch 111.486) train_loss=195.20507812 time/batch=0.51s
13557/10943 (epoch 111.494) train_loss=202.79190063 time/batch=0.49s
13558/10943 (epoch 111.502) train_loss=154.80241394 time/batch=0.42s
13559/10943 (epoch 111.511) train_loss=233.76428223 time/batch=0.58s
13560/10943 (epoch 111.519) train_loss=220.82147217 time/batch=0.57s
13561/10943 (epoch 111.527) train_loss=319.03527832 time/batch=0.80s
13562/10943 (epoch 111.535) train_loss=328.78118896 time/batch=0.85s
13563/10943 (epoch 111.544) train_loss=302.49639893 time/batch=0.80s
13564/10943 (epoch 111.552) train_loss=304.41204834 time/batch=0.77s
13565/10943 (epoch 111.560) train_loss=175.19924927 time/batch=0.48s
13566/10943 (epoch 111.568) train_loss=193.56634521 time/batch=0.50s
13567/10943 (epoch 111.576) train_loss=271.04382324 time/batch=0.64s
13568/10943 (epoch 111.585) train_loss=230.05749512 time/batch=0.58s
13569/10943 (epoch 111.593) train_loss=298.62719727 time/batch=0.71s
13570/10943 (epoch 111.601) train_loss=200.43258667 time/batch=0.54s
13571/10943 (epoch 111.609) train_loss=192.86058044 time/batch=0.54s
13572/10943 (epoch 111.618) train_loss=234.96661377 time/batch=0.56s
13573/10943 (epoch 111.626) train_loss=305.95965576 time/batch=0.76s
13574/10943 (epoch 111.634) train_loss=183.14987183 time/batch=0.56s
13575/10943 (epoch 111.642) train_loss=233.63293457 time/batch=0.59s
13576/10943 (epoch 111.650) train_loss=238.58834839 time/batch=0.60s
13577/10943 (epoch 111.659) train_loss=286.42813110 time/batch=0.73s
13578/10943 (epoch 111.667) train_loss=275.03906250 time/batch=0.68s
13579/10943 (epoch 111.675) train_loss=309.02392578 time/batch=0.80s
13580/10943 (epoch 111.683) train_loss=305.82586670 time/batch=0.74s
13581/10943 (epoch 111.692) train_loss=222.87249756 time/batch=0.59s
13582/10943 (epoch 111.700) train_loss=294.11499023 time/batch=0.74s
13583/10943 (epoch 111.708) train_loss=315.17077637 time/batch=0.81s
13584/10943 (epoch 111.716) train_loss=228.05168152 time/batch=0.60s
13585/10943 (epoch 111.724) train_loss=224.62431335 time/batch=0.58s
13586/10943 (epoch 111.733) train_loss=246.12359619 time/batch=0.61s
13587/10943 (epoch 111.741) train_loss=230.49919128 time/batch=0.63s
13588/10943 (epoch 111.749) train_loss=267.45410156 time/batch=0.72s
setting learning rate to 0.0007168
  saved to metadata/gru_dropout-9_nov_folkwiki-20181207-173447_epoch67.pkl
13589/10943 (epoch 111.757) train_loss=316.05718994 time/batch=0.85s
13590/10943 (epoch 111.766) train_loss=175.23298645 time/batch=0.49s
13591/10943 (epoch 111.774) train_loss=502.06524658 time/batch=1.14s
13592/10943 (epoch 111.782) train_loss=395.81384277 time/batch=0.99s
13593/10943 (epoch 111.790) train_loss=266.07385254 time/batch=0.67s
13594/10943 (epoch 111.799) train_loss=939.23461914 time/batch=3.04s
13595/10943 (epoch 111.807) train_loss=461.00799561 time/batch=1.36s
13596/10943 (epoch 111.815) train_loss=315.35156250 time/batch=0.84s
13597/10943 (epoch 111.823) train_loss=559.65930176 time/batch=1.28s
13598/10943 (epoch 111.831) train_loss=370.67602539 time/batch=0.95s
13599/10943 (epoch 111.840) train_loss=99.46411896 time/batch=0.31s
13600/10943 (epoch 111.848) train_loss=569.67291260 time/batch=1.32s
13601/10943 (epoch 111.856) train_loss=402.02078247 time/batch=1.02s
13602/10943 (epoch 111.864) train_loss=486.13626099 time/batch=1.16s
13603/10943 (epoch 111.873) train_loss=671.24487305 time/batch=1.61s
13604/10943 (epoch 111.881) train_loss=708.96435547 time/batch=1.75s
13605/10943 (epoch 111.889) train_loss=154.99174500 time/batch=0.50s
13606/10943 (epoch 111.897) train_loss=313.83917236 time/batch=0.76s
13607/10943 (epoch 111.905) train_loss=468.36529541 time/batch=1.11s
13608/10943 (epoch 111.914) train_loss=414.36553955 time/batch=1.03s
13609/10943 (epoch 111.922) train_loss=439.03863525 time/batch=1.07s
13610/10943 (epoch 111.930) train_loss=129.18246460 time/batch=0.38s
13611/10943 (epoch 111.938) train_loss=496.09326172 time/batch=1.14s
13612/10943 (epoch 111.947) train_loss=302.97698975 time/batch=0.81s
13613/10943 (epoch 111.955) train_loss=280.21832275 time/batch=0.68s
13614/10943 (epoch 111.963) train_loss=199.21366882 time/batch=0.52s
13615/10943 (epoch 111.971) train_loss=362.65170288 time/batch=0.86s
13616/10943 (epoch 111.979) train_loss=168.49519348 time/batch=0.47s
13617/10943 (epoch 111.988) train_loss=220.90176392 time/batch=0.53s
13618/10943 (epoch 111.996) train_loss=143.27554321 time/batch=0.37s
13619/10943 (epoch 112.004) train_loss=506.88034058 time/batch=1.17s
13620/10943 (epoch 112.012) train_loss=388.63479614 time/batch=1.01s
13621/10943 (epoch 112.021) train_loss=422.66760254 time/batch=1.01s
13622/10943 (epoch 112.029) train_loss=581.77215576 time/batch=1.44s
13623/10943 (epoch 112.037) train_loss=238.48185730 time/batch=0.70s
13624/10943 (epoch 112.045) train_loss=255.63446045 time/batch=0.62s
13625/10943 (epoch 112.053) train_loss=307.87731934 time/batch=0.77s
13626/10943 (epoch 112.062) train_loss=238.55810547 time/batch=0.62s
13627/10943 (epoch 112.070) train_loss=409.77233887 time/batch=0.98s
13628/10943 (epoch 112.078) train_loss=298.04583740 time/batch=0.76s
13629/10943 (epoch 112.086) train_loss=123.71543884 time/batch=0.33s
13630/10943 (epoch 112.095) train_loss=271.13018799 time/batch=0.63s
13631/10943 (epoch 112.103) train_loss=331.77355957 time/batch=0.83s
13632/10943 (epoch 112.111) train_loss=215.48031616 time/batch=0.58s
13633/10943 (epoch 112.119) train_loss=347.60687256 time/batch=0.84s
13634/10943 (epoch 112.127) train_loss=299.43231201 time/batch=0.75s
13635/10943 (epoch 112.136) train_loss=196.52563477 time/batch=0.51s
13636/10943 (epoch 112.144) train_loss=113.04891205 time/batch=0.30s
13637/10943 (epoch 112.152) train_loss=377.15362549 time/batch=0.85s
13638/10943 (epoch 112.160) train_loss=192.56913757 time/batch=0.51s
13639/10943 (epoch 112.169) train_loss=115.55395508 time/batch=0.31s
13640/10943 (epoch 112.177) train_loss=148.89312744 time/batch=0.38s
13641/10943 (epoch 112.185) train_loss=356.09976196 time/batch=0.83s
13642/10943 (epoch 112.193) train_loss=331.65911865 time/batch=0.84s
13643/10943 (epoch 112.201) train_loss=304.04779053 time/batch=0.76s
13644/10943 (epoch 112.210) train_loss=309.86108398 time/batch=0.80s
13645/10943 (epoch 112.218) train_loss=447.47778320 time/batch=1.27s
13646/10943 (epoch 112.226) train_loss=172.41502380 time/batch=0.51s
13647/10943 (epoch 112.234) train_loss=234.25746155 time/batch=0.57s
13648/10943 (epoch 112.243) train_loss=368.99914551 time/batch=0.90s
13649/10943 (epoch 112.251) train_loss=305.12231445 time/batch=0.83s
13650/10943 (epoch 112.259) train_loss=243.70120239 time/batch=0.62s
13651/10943 (epoch 112.267) train_loss=299.49835205 time/batch=0.70s
13652/10943 (epoch 112.276) train_loss=307.16174316 time/batch=0.81s
13653/10943 (epoch 112.284) train_loss=278.27056885 time/batch=0.70s
13654/10943 (epoch 112.292) train_loss=334.77163696 time/batch=0.82s
13655/10943 (epoch 112.300) train_loss=275.96801758 time/batch=0.71s
13656/10943 (epoch 112.308) train_loss=255.95223999 time/batch=0.63s
13657/10943 (epoch 112.317) train_loss=224.11250305 time/batch=0.56s
13658/10943 (epoch 112.325) train_loss=242.88203430 time/batch=0.60s
13659/10943 (epoch 112.333) train_loss=246.13864136 time/batch=0.61s
13660/10943 (epoch 112.341) train_loss=197.71055603 time/batch=0.54s
13661/10943 (epoch 112.350) train_loss=206.30751038 time/batch=0.52s
13662/10943 (epoch 112.358) train_loss=269.15899658 time/batch=0.68s
13663/10943 (epoch 112.366) train_loss=297.07684326 time/batch=0.74s
13664/10943 (epoch 112.374) train_loss=183.50988770 time/batch=0.49s
13665/10943 (epoch 112.382) train_loss=203.44696045 time/batch=0.49s
13666/10943 (epoch 112.391) train_loss=342.18682861 time/batch=0.80s
13667/10943 (epoch 112.399) train_loss=406.01293945 time/batch=1.01s
13668/10943 (epoch 112.407) train_loss=207.20129395 time/batch=0.55s
13669/10943 (epoch 112.415) train_loss=356.69863892 time/batch=0.84s
13670/10943 (epoch 112.424) train_loss=226.25061035 time/batch=0.60s
13671/10943 (epoch 112.432) train_loss=243.71894836 time/batch=0.62s
13672/10943 (epoch 112.440) train_loss=126.65110779 time/batch=0.35s
13673/10943 (epoch 112.448) train_loss=266.70394897 time/batch=0.63s
13674/10943 (epoch 112.456) train_loss=444.49411011 time/batch=1.01s
13675/10943 (epoch 112.465) train_loss=322.66619873 time/batch=0.79s
13676/10943 (epoch 112.473) train_loss=167.68795776 time/batch=0.46s
13677/10943 (epoch 112.481) train_loss=264.23251343 time/batch=0.61s
13678/10943 (epoch 112.489) train_loss=320.87060547 time/batch=0.81s
13679/10943 (epoch 112.498) train_loss=254.54620361 time/batch=0.66s
13680/10943 (epoch 112.506) train_loss=430.76513672 time/batch=1.04s
13681/10943 (epoch 112.514) train_loss=142.64379883 time/batch=0.43s
13682/10943 (epoch 112.522) train_loss=297.55252075 time/batch=0.70s
13683/10943 (epoch 112.530) train_loss=159.01905823 time/batch=0.44s
13684/10943 (epoch 112.539) train_loss=289.17218018 time/batch=0.73s
13685/10943 (epoch 112.547) train_loss=154.01123047 time/batch=0.42s
13686/10943 (epoch 112.555) train_loss=208.61012268 time/batch=0.51s
13687/10943 (epoch 112.563) train_loss=369.63574219 time/batch=0.97s
13688/10943 (epoch 112.572) train_loss=339.62683105 time/batch=0.90s
13689/10943 (epoch 112.580) train_loss=231.17021179 time/batch=0.61s
13690/10943 (epoch 112.588) train_loss=166.57716370 time/batch=0.45s
13691/10943 (epoch 112.596) train_loss=227.68174744 time/batch=0.62s
13692/10943 (epoch 112.604) train_loss=174.85920715 time/batch=0.47s
13693/10943 (epoch 112.613) train_loss=184.30815125 time/batch=0.47s
13694/10943 (epoch 112.621) train_loss=284.18286133 time/batch=0.67s
13695/10943 (epoch 112.629) train_loss=234.47113037 time/batch=0.59s
13696/10943 (epoch 112.637) train_loss=197.04104614 time/batch=0.53s
13697/10943 (epoch 112.646) train_loss=228.05538940 time/batch=0.56s
13698/10943 (epoch 112.654) train_loss=294.22802734 time/batch=0.69s
13699/10943 (epoch 112.662) train_loss=279.13769531 time/batch=0.67s
13700/10943 (epoch 112.670) train_loss=146.74920654 time/batch=0.41s
13701/10943 (epoch 112.678) train_loss=271.70867920 time/batch=0.64s
13702/10943 (epoch 112.687) train_loss=262.83316040 time/batch=0.68s
13703/10943 (epoch 112.695) train_loss=204.07614136 time/batch=0.55s
13704/10943 (epoch 112.703) train_loss=135.48023987 time/batch=0.35s
13705/10943 (epoch 112.711) train_loss=154.56837463 time/batch=0.45s
13706/10943 (epoch 112.720) train_loss=253.13272095 time/batch=0.68s
13707/10943 (epoch 112.728) train_loss=231.93197632 time/batch=0.59s
13708/10943 (epoch 112.736) train_loss=301.35034180 time/batch=0.76s
13709/10943 (epoch 112.744) train_loss=322.17767334 time/batch=0.83s
setting learning rate to 0.0006953
13710/10943 (epoch 112.753) train_loss=892.59686279 time/batch=2.35s
13711/10943 (epoch 112.761) train_loss=351.43273926 time/batch=1.05s
13712/10943 (epoch 112.769) train_loss=520.29492188 time/batch=1.21s
13713/10943 (epoch 112.777) train_loss=130.02015686 time/batch=0.38s
13714/10943 (epoch 112.785) train_loss=134.36416626 time/batch=0.32s
13715/10943 (epoch 112.794) train_loss=612.79290771 time/batch=1.44s
13716/10943 (epoch 112.802) train_loss=316.05413818 time/batch=0.88s
13717/10943 (epoch 112.810) train_loss=528.39581299 time/batch=1.24s
13718/10943 (epoch 112.818) train_loss=200.15931702 time/batch=0.58s
13719/10943 (epoch 112.827) train_loss=190.46559143 time/batch=0.47s
13720/10943 (epoch 112.835) train_loss=366.12213135 time/batch=0.86s
13721/10943 (epoch 112.843) train_loss=311.55340576 time/batch=0.79s
13722/10943 (epoch 112.851) train_loss=294.07046509 time/batch=0.73s
13723/10943 (epoch 112.859) train_loss=355.07916260 time/batch=0.86s
13724/10943 (epoch 112.868) train_loss=366.92163086 time/batch=0.89s
13725/10943 (epoch 112.876) train_loss=288.09570312 time/batch=0.72s
13726/10943 (epoch 112.884) train_loss=307.62011719 time/batch=0.77s
13727/10943 (epoch 112.892) train_loss=277.15649414 time/batch=0.67s
13728/10943 (epoch 112.901) train_loss=318.55590820 time/batch=0.78s
13729/10943 (epoch 112.909) train_loss=142.93103027 time/batch=0.39s
13730/10943 (epoch 112.917) train_loss=570.74719238 time/batch=1.31s
13731/10943 (epoch 112.925) train_loss=485.71807861 time/batch=1.23s
13732/10943 (epoch 112.933) train_loss=434.77017212 time/batch=1.09s
13733/10943 (epoch 112.942) train_loss=162.51507568 time/batch=0.47s
13734/10943 (epoch 112.950) train_loss=507.90640259 time/batch=1.20s
13735/10943 (epoch 112.958) train_loss=319.82769775 time/batch=0.85s
13736/10943 (epoch 112.966) train_loss=338.25677490 time/batch=0.84s
13737/10943 (epoch 112.975) train_loss=257.28939819 time/batch=0.65s
13738/10943 (epoch 112.983) train_loss=220.48779297 time/batch=0.55s
13739/10943 (epoch 112.991) train_loss=110.92309570 time/batch=0.30s
13740/10943 (epoch 112.999) train_loss=289.55941772 time/batch=0.70s
13741/10943 (epoch 113.007) train_loss=575.29138184 time/batch=1.49s
13742/10943 (epoch 113.016) train_loss=293.21362305 time/batch=0.83s
13743/10943 (epoch 113.024) train_loss=407.17138672 time/batch=0.99s
13744/10943 (epoch 113.032) train_loss=313.63995361 time/batch=0.83s
13745/10943 (epoch 113.040) train_loss=142.87356567 time/batch=0.40s
13746/10943 (epoch 113.049) train_loss=216.41195679 time/batch=0.52s
13747/10943 (epoch 113.057) train_loss=456.88610840 time/batch=1.07s
13748/10943 (epoch 113.065) train_loss=790.05383301 time/batch=3.10s
13749/10943 (epoch 113.073) train_loss=204.65980530 time/batch=0.78s
13750/10943 (epoch 113.081) train_loss=269.89294434 time/batch=0.62s
13751/10943 (epoch 113.090) train_loss=453.58837891 time/batch=1.06s
13752/10943 (epoch 113.098) train_loss=162.27355957 time/batch=0.48s
13753/10943 (epoch 113.106) train_loss=97.93261719 time/batch=0.28s
13754/10943 (epoch 113.114) train_loss=231.15995789 time/batch=0.55s
13755/10943 (epoch 113.123) train_loss=118.39332581 time/batch=0.33s
13756/10943 (epoch 113.131) train_loss=234.89175415 time/batch=0.57s
13757/10943 (epoch 113.139) train_loss=482.66812134 time/batch=1.25s
13758/10943 (epoch 113.147) train_loss=308.18450928 time/batch=0.80s
13759/10943 (epoch 113.155) train_loss=161.92572021 time/batch=0.44s
13760/10943 (epoch 113.164) train_loss=145.99044800 time/batch=0.36s
13761/10943 (epoch 113.172) train_loss=119.18177032 time/batch=0.31s
13762/10943 (epoch 113.180) train_loss=244.16732788 time/batch=0.54s
13763/10943 (epoch 113.188) train_loss=441.08453369 time/batch=0.99s
13764/10943 (epoch 113.197) train_loss=530.29742432 time/batch=1.56s
13765/10943 (epoch 113.205) train_loss=200.18606567 time/batch=0.60s
13766/10943 (epoch 113.213) train_loss=219.56790161 time/batch=0.53s
13767/10943 (epoch 113.221) train_loss=340.95010376 time/batch=0.81s
13768/10943 (epoch 113.230) train_loss=317.00476074 time/batch=0.80s
13769/10943 (epoch 113.238) train_loss=381.86318970 time/batch=0.93s
13770/10943 (epoch 113.246) train_loss=369.73413086 time/batch=0.90s
13771/10943 (epoch 113.254) train_loss=424.99667358 time/batch=0.99s
13772/10943 (epoch 113.262) train_loss=213.80043030 time/batch=0.55s
13773/10943 (epoch 113.271) train_loss=156.56405640 time/batch=0.42s
13774/10943 (epoch 113.279) train_loss=246.24063110 time/batch=0.58s
13775/10943 (epoch 113.287) train_loss=447.14642334 time/batch=0.99s
13776/10943 (epoch 113.295) train_loss=246.20739746 time/batch=0.66s
13777/10943 (epoch 113.304) train_loss=297.28613281 time/batch=0.70s
13778/10943 (epoch 113.312) train_loss=318.95776367 time/batch=0.80s
13779/10943 (epoch 113.320) train_loss=229.45095825 time/batch=0.60s
13780/10943 (epoch 113.328) train_loss=433.64044189 time/batch=1.03s
13781/10943 (epoch 113.336) train_loss=395.21502686 time/batch=0.98s
13782/10943 (epoch 113.345) train_loss=195.29483032 time/batch=0.54s
13783/10943 (epoch 113.353) train_loss=228.73031616 time/batch=0.58s
13784/10943 (epoch 113.361) train_loss=135.74954224 time/batch=0.35s
13785/10943 (epoch 113.369) train_loss=299.70034790 time/batch=0.71s
13786/10943 (epoch 113.378) train_loss=186.75942993 time/batch=0.53s
13787/10943 (epoch 113.386) train_loss=271.84417725 time/batch=0.66s
13788/10943 (epoch 113.394) train_loss=280.07116699 time/batch=0.69s
13789/10943 (epoch 113.402) train_loss=274.88708496 time/batch=0.68s
13790/10943 (epoch 113.410) train_loss=293.92443848 time/batch=0.72s
13791/10943 (epoch 113.419) train_loss=366.92028809 time/batch=0.90s
13792/10943 (epoch 113.427) train_loss=148.53828430 time/batch=0.42s
13793/10943 (epoch 113.435) train_loss=307.67382812 time/batch=0.76s
13794/10943 (epoch 113.443) train_loss=284.86322021 time/batch=0.68s
13795/10943 (epoch 113.452) train_loss=179.84248352 time/batch=0.45s
13796/10943 (epoch 113.460) train_loss=300.54180908 time/batch=0.77s
13797/10943 (epoch 113.468) train_loss=219.48045349 time/batch=0.58s
13798/10943 (epoch 113.476) train_loss=381.62298584 time/batch=0.91s
13799/10943 (epoch 113.484) train_loss=230.74594116 time/batch=0.60s
13800/10943 (epoch 113.493) train_loss=299.94808960 time/batch=0.74s
13801/10943 (epoch 113.501) train_loss=337.70452881 time/batch=0.83s
13802/10943 (epoch 113.509) train_loss=271.92761230 time/batch=0.70s
13803/10943 (epoch 113.517) train_loss=401.93756104 time/batch=0.95s
13804/10943 (epoch 113.526) train_loss=265.95944214 time/batch=0.71s
13805/10943 (epoch 113.534) train_loss=189.17591858 time/batch=0.47s
13806/10943 (epoch 113.542) train_loss=217.85073853 time/batch=0.55s
13807/10943 (epoch 113.550) train_loss=260.73281860 time/batch=0.64s
13808/10943 (epoch 113.558) train_loss=237.04849243 time/batch=0.60s
13809/10943 (epoch 113.567) train_loss=197.80297852 time/batch=0.51s
13810/10943 (epoch 113.575) train_loss=267.46405029 time/batch=0.65s
13811/10943 (epoch 113.583) train_loss=359.89654541 time/batch=0.90s
13812/10943 (epoch 113.591) train_loss=275.65267944 time/batch=0.72s
13813/10943 (epoch 113.600) train_loss=234.95108032 time/batch=0.60s
13814/10943 (epoch 113.608) train_loss=163.57504272 time/batch=0.44s
13815/10943 (epoch 113.616) train_loss=255.82490540 time/batch=0.61s
13816/10943 (epoch 113.624) train_loss=292.35693359 time/batch=0.70s
13817/10943 (epoch 113.632) train_loss=226.82768250 time/batch=0.59s
13818/10943 (epoch 113.641) train_loss=179.65277100 time/batch=0.45s
13819/10943 (epoch 113.649) train_loss=161.78280640 time/batch=0.43s
13820/10943 (epoch 113.657) train_loss=245.09680176 time/batch=0.61s
13821/10943 (epoch 113.665) train_loss=391.28436279 time/batch=0.92s
13822/10943 (epoch 113.674) train_loss=169.77188110 time/batch=0.50s
13823/10943 (epoch 113.682) train_loss=320.17956543 time/batch=0.72s
13824/10943 (epoch 113.690) train_loss=173.57234192 time/batch=0.49s
13825/10943 (epoch 113.698) train_loss=245.40174866 time/batch=0.59s
13826/10943 (epoch 113.707) train_loss=337.95324707 time/batch=0.80s
13827/10943 (epoch 113.715) train_loss=290.75292969 time/batch=0.82s
13828/10943 (epoch 113.723) train_loss=207.58212280 time/batch=0.54s
13829/10943 (epoch 113.731) train_loss=233.45793152 time/batch=0.58s
13830/10943 (epoch 113.739) train_loss=350.61999512 time/batch=0.82s
setting learning rate to 0.0006744
  saved to metadata/gru_dropout-9_nov_folkwiki-20181207-173447_epoch69.pkl
13831/10943 (epoch 113.748) train_loss=312.98986816 time/batch=0.89s
13832/10943 (epoch 113.756) train_loss=757.29040527 time/batch=1.73s
13833/10943 (epoch 113.764) train_loss=181.95034790 time/batch=0.57s
13834/10943 (epoch 113.772) train_loss=162.35580444 time/batch=0.37s
13835/10943 (epoch 113.781) train_loss=372.59719849 time/batch=0.83s
13836/10943 (epoch 113.789) train_loss=282.36117554 time/batch=0.71s
13837/10943 (epoch 113.797) train_loss=408.40087891 time/batch=0.92s
13838/10943 (epoch 113.805) train_loss=350.00765991 time/batch=0.86s
13839/10943 (epoch 113.813) train_loss=291.89862061 time/batch=0.75s
13840/10943 (epoch 113.822) train_loss=542.05963135 time/batch=1.23s
13841/10943 (epoch 113.830) train_loss=109.84485626 time/batch=0.37s
13842/10943 (epoch 113.838) train_loss=144.98294067 time/batch=0.35s
13843/10943 (epoch 113.846) train_loss=204.11862183 time/batch=0.49s
13844/10943 (epoch 113.855) train_loss=596.50616455 time/batch=1.30s
13845/10943 (epoch 113.863) train_loss=956.74035645 time/batch=3.12s
13846/10943 (epoch 113.871) train_loss=595.27453613 time/batch=1.62s
13847/10943 (epoch 113.879) train_loss=405.53179932 time/batch=1.03s
13848/10943 (epoch 113.887) train_loss=218.00697327 time/batch=0.56s
13849/10943 (epoch 113.896) train_loss=235.66680908 time/batch=0.56s
13850/10943 (epoch 113.904) train_loss=478.65737915 time/batch=1.08s
13851/10943 (epoch 113.912) train_loss=222.22061157 time/batch=0.61s
13852/10943 (epoch 113.920) train_loss=304.47589111 time/batch=0.70s
13853/10943 (epoch 113.929) train_loss=449.33618164 time/batch=1.01s
13854/10943 (epoch 113.937) train_loss=452.01251221 time/batch=1.01s
13855/10943 (epoch 113.945) train_loss=206.69046021 time/batch=0.57s
13856/10943 (epoch 113.953) train_loss=257.90563965 time/batch=0.61s
13857/10943 (epoch 113.961) train_loss=481.67233276 time/batch=1.09s
13858/10943 (epoch 113.970) train_loss=529.79205322 time/batch=1.23s
13859/10943 (epoch 113.978) train_loss=495.71051025 time/batch=1.19s
13860/10943 (epoch 113.986) train_loss=645.41278076 time/batch=1.58s
13861/10943 (epoch 113.994) train_loss=494.87762451 time/batch=1.29s
13862/10943 (epoch 114.003) train_loss=166.94483948 time/batch=0.49s
13863/10943 (epoch 114.011) train_loss=454.04785156 time/batch=1.06s
13864/10943 (epoch 114.019) train_loss=459.27307129 time/batch=1.09s
13865/10943 (epoch 114.027) train_loss=536.99584961 time/batch=1.45s
13866/10943 (epoch 114.035) train_loss=107.90155029 time/batch=0.39s
13867/10943 (epoch 114.044) train_loss=192.08480835 time/batch=0.44s
13868/10943 (epoch 114.052) train_loss=314.78781128 time/batch=0.76s
13869/10943 (epoch 114.060) train_loss=145.15609741 time/batch=0.39s
13870/10943 (epoch 114.068) train_loss=319.02539062 time/batch=0.76s
13871/10943 (epoch 114.077) train_loss=180.47190857 time/batch=0.48s
13872/10943 (epoch 114.085) train_loss=319.65240479 time/batch=0.76s
13873/10943 (epoch 114.093) train_loss=152.29260254 time/batch=0.41s
13874/10943 (epoch 114.101) train_loss=247.89794922 time/batch=0.57s
13875/10943 (epoch 114.109) train_loss=353.27645874 time/batch=0.81s
13876/10943 (epoch 114.118) train_loss=180.08653259 time/batch=0.48s
13877/10943 (epoch 114.126) train_loss=401.57849121 time/batch=0.96s
13878/10943 (epoch 114.134) train_loss=169.67510986 time/batch=0.47s
13879/10943 (epoch 114.142) train_loss=314.60043335 time/batch=0.77s
13880/10943 (epoch 114.151) train_loss=352.34094238 time/batch=0.86s
13881/10943 (epoch 114.159) train_loss=342.27014160 time/batch=0.84s
13882/10943 (epoch 114.167) train_loss=365.99667358 time/batch=0.87s
13883/10943 (epoch 114.175) train_loss=277.87097168 time/batch=0.71s
13884/10943 (epoch 114.184) train_loss=430.65484619 time/batch=1.02s
13885/10943 (epoch 114.192) train_loss=274.00115967 time/batch=0.69s
13886/10943 (epoch 114.200) train_loss=212.62733459 time/batch=0.51s
13887/10943 (epoch 114.208) train_loss=300.70758057 time/batch=0.70s
13888/10943 (epoch 114.216) train_loss=142.67605591 time/batch=0.36s
13889/10943 (epoch 114.225) train_loss=228.46261597 time/batch=0.53s
13890/10943 (epoch 114.233) train_loss=369.99414062 time/batch=0.86s
13891/10943 (epoch 114.241) train_loss=237.35694885 time/batch=0.62s
13892/10943 (epoch 114.249) train_loss=430.33123779 time/batch=0.99s
13893/10943 (epoch 114.258) train_loss=193.45193481 time/batch=0.53s
13894/10943 (epoch 114.266) train_loss=225.26570129 time/batch=0.55s
13895/10943 (epoch 114.274) train_loss=200.62736511 time/batch=0.49s
13896/10943 (epoch 114.282) train_loss=249.90829468 time/batch=0.56s
13897/10943 (epoch 114.290) train_loss=317.94580078 time/batch=0.73s
13898/10943 (epoch 114.299) train_loss=149.81268311 time/batch=0.41s
13899/10943 (epoch 114.307) train_loss=281.17163086 time/batch=0.65s
13900/10943 (epoch 114.315) train_loss=157.49407959 time/batch=0.42s
13901/10943 (epoch 114.323) train_loss=325.98492432 time/batch=0.73s
13902/10943 (epoch 114.332) train_loss=247.39941406 time/batch=0.63s
13903/10943 (epoch 114.340) train_loss=336.92892456 time/batch=0.80s
13904/10943 (epoch 114.348) train_loss=280.41156006 time/batch=0.70s
13905/10943 (epoch 114.356) train_loss=333.88296509 time/batch=0.76s
13906/10943 (epoch 114.364) train_loss=196.65655518 time/batch=0.51s
13907/10943 (epoch 114.373) train_loss=322.78674316 time/batch=0.73s
13908/10943 (epoch 114.381) train_loss=242.28475952 time/batch=0.59s
13909/10943 (epoch 114.389) train_loss=286.25299072 time/batch=0.68s
13910/10943 (epoch 114.397) train_loss=243.71408081 time/batch=0.62s
13911/10943 (epoch 114.406) train_loss=239.97877502 time/batch=0.58s
13912/10943 (epoch 114.414) train_loss=322.52130127 time/batch=0.80s
13913/10943 (epoch 114.422) train_loss=160.75737000 time/batch=0.44s
13914/10943 (epoch 114.430) train_loss=316.95397949 time/batch=0.71s
13915/10943 (epoch 114.438) train_loss=449.86752319 time/batch=1.01s
13916/10943 (epoch 114.447) train_loss=208.03656006 time/batch=0.51s
13917/10943 (epoch 114.455) train_loss=130.69859314 time/batch=0.30s
13918/10943 (epoch 114.463) train_loss=216.36196899 time/batch=0.45s
13919/10943 (epoch 114.471) train_loss=298.36569214 time/batch=0.64s
13920/10943 (epoch 114.480) train_loss=280.34991455 time/batch=0.63s
13921/10943 (epoch 114.488) train_loss=393.42453003 time/batch=0.89s
13922/10943 (epoch 114.496) train_loss=231.60543823 time/batch=0.57s
13923/10943 (epoch 114.504) train_loss=261.66052246 time/batch=0.60s
13924/10943 (epoch 114.512) train_loss=127.76123047 time/batch=0.33s
13925/10943 (epoch 114.521) train_loss=138.63484192 time/batch=0.31s
13926/10943 (epoch 114.529) train_loss=178.46475220 time/batch=0.41s
13927/10943 (epoch 114.537) train_loss=123.37460327 time/batch=0.31s
13928/10943 (epoch 114.545) train_loss=235.78768921 time/batch=0.55s
13929/10943 (epoch 114.554) train_loss=235.99226379 time/batch=0.58s
13930/10943 (epoch 114.562) train_loss=220.21096802 time/batch=0.49s
13931/10943 (epoch 114.570) train_loss=355.45083618 time/batch=0.82s
13932/10943 (epoch 114.578) train_loss=414.22988892 time/batch=0.95s
13933/10943 (epoch 114.586) train_loss=253.72041321 time/batch=0.64s
13934/10943 (epoch 114.595) train_loss=388.25610352 time/batch=0.89s
13935/10943 (epoch 114.603) train_loss=196.02804565 time/batch=0.55s
13936/10943 (epoch 114.611) train_loss=310.53222656 time/batch=0.71s
13937/10943 (epoch 114.619) train_loss=388.85443115 time/batch=0.89s
13938/10943 (epoch 114.628) train_loss=283.04681396 time/batch=0.69s
13939/10943 (epoch 114.636) train_loss=244.98297119 time/batch=0.60s
13940/10943 (epoch 114.644) train_loss=244.22930908 time/batch=0.61s
13941/10943 (epoch 114.652) train_loss=371.17068481 time/batch=0.89s
13942/10943 (epoch 114.660) train_loss=305.27429199 time/batch=0.73s
13943/10943 (epoch 114.669) train_loss=330.68426514 time/batch=0.78s
13944/10943 (epoch 114.677) train_loss=306.72235107 time/batch=0.72s
13945/10943 (epoch 114.685) train_loss=304.85888672 time/batch=0.77s
13946/10943 (epoch 114.693) train_loss=349.90417480 time/batch=0.83s
13947/10943 (epoch 114.702) train_loss=280.11523438 time/batch=0.72s
13948/10943 (epoch 114.710) train_loss=274.79754639 time/batch=0.65s
13949/10943 (epoch 114.718) train_loss=309.71679688 time/batch=0.81s
13950/10943 (epoch 114.726) train_loss=273.98120117 time/batch=0.67s
13951/10943 (epoch 114.735) train_loss=264.14611816 time/batch=0.65s
setting learning rate to 0.0006542
13952/10943 (epoch 114.743) train_loss=182.56661987 time/batch=0.45s
13953/10943 (epoch 114.751) train_loss=575.86120605 time/batch=1.23s
13954/10943 (epoch 114.759) train_loss=213.44223022 time/batch=0.61s
13955/10943 (epoch 114.767) train_loss=129.59768677 time/batch=0.31s
13956/10943 (epoch 114.776) train_loss=490.94787598 time/batch=1.09s
13957/10943 (epoch 114.784) train_loss=338.23565674 time/batch=0.87s
13958/10943 (epoch 114.792) train_loss=336.91448975 time/batch=0.84s
13959/10943 (epoch 114.800) train_loss=599.08367920 time/batch=1.33s
13960/10943 (epoch 114.809) train_loss=331.84793091 time/batch=0.86s
13961/10943 (epoch 114.817) train_loss=154.56420898 time/batch=0.40s
13962/10943 (epoch 114.825) train_loss=287.60913086 time/batch=0.65s
13963/10943 (epoch 114.833) train_loss=279.08776855 time/batch=0.66s
13964/10943 (epoch 114.841) train_loss=284.17034912 time/batch=0.66s
13965/10943 (epoch 114.850) train_loss=272.20800781 time/batch=0.63s
13966/10943 (epoch 114.858) train_loss=185.02996826 time/batch=0.47s
13967/10943 (epoch 114.866) train_loss=595.40673828 time/batch=1.37s
13968/10943 (epoch 114.874) train_loss=446.46081543 time/batch=1.12s
13969/10943 (epoch 114.883) train_loss=227.78627014 time/batch=0.60s
13970/10943 (epoch 114.891) train_loss=984.01916504 time/batch=3.04s
13971/10943 (epoch 114.899) train_loss=150.61572266 time/batch=0.66s
13972/10943 (epoch 114.907) train_loss=236.09408569 time/batch=0.56s
13973/10943 (epoch 114.915) train_loss=450.37698364 time/batch=1.05s
13974/10943 (epoch 114.924) train_loss=316.63659668 time/batch=0.80s
13975/10943 (epoch 114.932) train_loss=309.95599365 time/batch=0.74s
13976/10943 (epoch 114.940) train_loss=519.78680420 time/batch=1.18s
13977/10943 (epoch 114.948) train_loss=487.30966187 time/batch=1.13s
13978/10943 (epoch 114.957) train_loss=231.40930176 time/batch=0.65s
13979/10943 (epoch 114.965) train_loss=225.00961304 time/batch=0.55s
13980/10943 (epoch 114.973) train_loss=279.63159180 time/batch=0.67s
13981/10943 (epoch 114.981) train_loss=369.37796021 time/batch=0.88s
13982/10943 (epoch 114.989) train_loss=165.98165894 time/batch=0.44s
13983/10943 (epoch 114.998) train_loss=115.74751282 time/batch=0.29s
13984/10943 (epoch 115.006) train_loss=229.28114319 time/batch=0.53s
13985/10943 (epoch 115.014) train_loss=265.94515991 time/batch=0.64s
13986/10943 (epoch 115.022) train_loss=245.23403931 time/batch=0.60s
13987/10943 (epoch 115.031) train_loss=468.40722656 time/batch=1.11s
13988/10943 (epoch 115.039) train_loss=373.41601562 time/batch=0.96s
13989/10943 (epoch 115.047) train_loss=300.65991211 time/batch=0.75s
13990/10943 (epoch 115.055) train_loss=654.16986084 time/batch=1.53s
13991/10943 (epoch 115.063) train_loss=493.37231445 time/batch=1.27s
13992/10943 (epoch 115.072) train_loss=209.29437256 time/batch=0.61s
13993/10943 (epoch 115.080) train_loss=211.17663574 time/batch=0.50s
13994/10943 (epoch 115.088) train_loss=319.17886353 time/batch=0.75s
13995/10943 (epoch 115.096) train_loss=309.89874268 time/batch=0.80s
13996/10943 (epoch 115.105) train_loss=282.99212646 time/batch=0.69s
13997/10943 (epoch 115.113) train_loss=734.69287109 time/batch=1.65s
13998/10943 (epoch 115.121) train_loss=400.27505493 time/batch=1.04s
13999/10943 (epoch 115.129) train_loss=179.53890991 time/batch=0.50s
Validating
    loss:	288.156830

14000/10943 (epoch 115.137) train_loss=413.78048706 time/batch=2.75s
14001/10943 (epoch 115.146) train_loss=452.98449707 time/batch=1.08s
14002/10943 (epoch 115.154) train_loss=376.50604248 time/batch=0.91s
14003/10943 (epoch 115.162) train_loss=323.45996094 time/batch=0.83s
14004/10943 (epoch 115.170) train_loss=100.10054779 time/batch=0.30s
14005/10943 (epoch 115.179) train_loss=354.24942017 time/batch=0.78s
14006/10943 (epoch 115.187) train_loss=247.00500488 time/batch=0.63s
14007/10943 (epoch 115.195) train_loss=129.21769714 time/batch=0.34s
14008/10943 (epoch 115.203) train_loss=420.84051514 time/batch=0.93s
14009/10943 (epoch 115.212) train_loss=376.46606445 time/batch=0.92s
14010/10943 (epoch 115.220) train_loss=140.97036743 time/batch=0.38s
14011/10943 (epoch 115.228) train_loss=324.38476562 time/batch=0.77s
14012/10943 (epoch 115.236) train_loss=166.50765991 time/batch=0.44s
14013/10943 (epoch 115.244) train_loss=304.04223633 time/batch=0.70s
14014/10943 (epoch 115.253) train_loss=399.51837158 time/batch=0.96s
14015/10943 (epoch 115.261) train_loss=133.28753662 time/batch=0.39s
14016/10943 (epoch 115.269) train_loss=248.57011414 time/batch=0.54s
14017/10943 (epoch 115.277) train_loss=354.84747314 time/batch=0.83s
14018/10943 (epoch 115.286) train_loss=514.39367676 time/batch=1.42s
14019/10943 (epoch 115.294) train_loss=242.61697388 time/batch=0.68s
14020/10943 (epoch 115.302) train_loss=406.89584351 time/batch=0.94s
14021/10943 (epoch 115.310) train_loss=457.45513916 time/batch=1.01s
14022/10943 (epoch 115.318) train_loss=320.16186523 time/batch=0.82s
14023/10943 (epoch 115.327) train_loss=233.41375732 time/batch=0.61s
14024/10943 (epoch 115.335) train_loss=318.55062866 time/batch=0.77s
14025/10943 (epoch 115.343) train_loss=157.28507996 time/batch=0.41s
14026/10943 (epoch 115.351) train_loss=216.28474426 time/batch=0.51s
14027/10943 (epoch 115.360) train_loss=341.81793213 time/batch=0.82s
14028/10943 (epoch 115.368) train_loss=156.91833496 time/batch=0.43s
14029/10943 (epoch 115.376) train_loss=327.36431885 time/batch=0.73s
14030/10943 (epoch 115.384) train_loss=299.87396240 time/batch=0.73s
14031/10943 (epoch 115.392) train_loss=203.24600220 time/batch=0.53s
14032/10943 (epoch 115.401) train_loss=256.79409790 time/batch=0.61s
14033/10943 (epoch 115.409) train_loss=170.42860413 time/batch=0.46s
14034/10943 (epoch 115.417) train_loss=156.40048218 time/batch=0.37s
14035/10943 (epoch 115.425) train_loss=478.02413940 time/batch=1.14s
14036/10943 (epoch 115.434) train_loss=339.85751343 time/batch=0.89s
14037/10943 (epoch 115.442) train_loss=274.89892578 time/batch=0.70s
14038/10943 (epoch 115.450) train_loss=206.64181519 time/batch=0.52s
14039/10943 (epoch 115.458) train_loss=354.39572144 time/batch=0.84s
14040/10943 (epoch 115.466) train_loss=407.23059082 time/batch=1.00s
14041/10943 (epoch 115.475) train_loss=288.54681396 time/batch=0.73s
14042/10943 (epoch 115.483) train_loss=195.36297607 time/batch=0.51s
14043/10943 (epoch 115.491) train_loss=286.48016357 time/batch=0.67s
14044/10943 (epoch 115.499) train_loss=117.89225769 time/batch=0.34s
14045/10943 (epoch 115.508) train_loss=249.00744629 time/batch=0.56s
14046/10943 (epoch 115.516) train_loss=145.34802246 time/batch=0.38s
14047/10943 (epoch 115.524) train_loss=201.94091797 time/batch=0.51s
14048/10943 (epoch 115.532) train_loss=313.67803955 time/batch=0.73s
14049/10943 (epoch 115.540) train_loss=190.76342773 time/batch=0.49s
14050/10943 (epoch 115.549) train_loss=375.96444702 time/batch=0.86s
14051/10943 (epoch 115.557) train_loss=315.56103516 time/batch=0.81s
14052/10943 (epoch 115.565) train_loss=146.27789307 time/batch=0.45s
14053/10943 (epoch 115.573) train_loss=188.68374634 time/batch=0.45s
14054/10943 (epoch 115.582) train_loss=340.08087158 time/batch=0.82s
14055/10943 (epoch 115.590) train_loss=293.79321289 time/batch=0.73s
14056/10943 (epoch 115.598) train_loss=192.62463379 time/batch=0.49s
14057/10943 (epoch 115.606) train_loss=219.42337036 time/batch=0.55s
14058/10943 (epoch 115.614) train_loss=304.44891357 time/batch=0.72s
14059/10943 (epoch 115.623) train_loss=199.17044067 time/batch=0.51s
14060/10943 (epoch 115.631) train_loss=296.47909546 time/batch=0.72s
14061/10943 (epoch 115.639) train_loss=274.31793213 time/batch=0.66s
14062/10943 (epoch 115.647) train_loss=273.33770752 time/batch=0.67s
14063/10943 (epoch 115.656) train_loss=192.71551514 time/batch=0.55s
14064/10943 (epoch 115.664) train_loss=249.67449951 time/batch=0.60s
14065/10943 (epoch 115.672) train_loss=205.01786804 time/batch=0.59s
14066/10943 (epoch 115.680) train_loss=367.87481689 time/batch=0.98s
14067/10943 (epoch 115.689) train_loss=241.54968262 time/batch=0.66s
14068/10943 (epoch 115.697) train_loss=279.58383179 time/batch=0.70s
14069/10943 (epoch 115.705) train_loss=230.27926636 time/batch=0.61s
14070/10943 (epoch 115.713) train_loss=249.88574219 time/batch=0.61s
14071/10943 (epoch 115.721) train_loss=293.19961548 time/batch=0.74s
14072/10943 (epoch 115.730) train_loss=253.37435913 time/batch=0.64s
setting learning rate to 0.0006346
  saved to metadata/gru_dropout-9_nov_folkwiki-20181207-173447_epoch71.pkl
14073/10943 (epoch 115.738) train_loss=97.10437012 time/batch=0.38s
14074/10943 (epoch 115.746) train_loss=527.50494385 time/batch=1.12s
14075/10943 (epoch 115.754) train_loss=399.45544434 time/batch=0.97s
14076/10943 (epoch 115.763) train_loss=567.10894775 time/batch=1.29s
14077/10943 (epoch 115.771) train_loss=710.90698242 time/batch=1.65s
14078/10943 (epoch 115.779) train_loss=371.48828125 time/batch=0.97s
14079/10943 (epoch 115.787) train_loss=250.22201538 time/batch=0.63s
14080/10943 (epoch 115.795) train_loss=627.72863770 time/batch=1.59s
14081/10943 (epoch 115.804) train_loss=458.97888184 time/batch=1.16s
14082/10943 (epoch 115.812) train_loss=949.28155518 time/batch=3.09s
14083/10943 (epoch 115.820) train_loss=429.10269165 time/batch=1.29s
14084/10943 (epoch 115.828) train_loss=354.57751465 time/batch=0.89s
14085/10943 (epoch 115.837) train_loss=221.38801575 time/batch=0.57s
14086/10943 (epoch 115.845) train_loss=315.55383301 time/batch=0.74s
14087/10943 (epoch 115.853) train_loss=123.31674194 time/batch=0.34s
14088/10943 (epoch 115.861) train_loss=367.59252930 time/batch=0.87s
14089/10943 (epoch 115.869) train_loss=140.56834412 time/batch=0.38s
14090/10943 (epoch 115.878) train_loss=224.36520386 time/batch=0.56s
14091/10943 (epoch 115.886) train_loss=170.86959839 time/batch=0.45s
14092/10943 (epoch 115.894) train_loss=232.84802246 time/batch=0.55s
14093/10943 (epoch 115.902) train_loss=446.84936523 time/batch=0.99s
14094/10943 (epoch 115.911) train_loss=276.86755371 time/batch=0.70s
14095/10943 (epoch 115.919) train_loss=286.79653931 time/batch=0.69s
14096/10943 (epoch 115.927) train_loss=199.24703979 time/batch=0.55s
14097/10943 (epoch 115.935) train_loss=319.84039307 time/batch=0.78s
14098/10943 (epoch 115.943) train_loss=481.68405151 time/batch=1.10s
14099/10943 (epoch 115.952) train_loss=467.07223511 time/batch=1.17s
14100/10943 (epoch 115.960) train_loss=314.44531250 time/batch=0.82s
14101/10943 (epoch 115.968) train_loss=354.61196899 time/batch=0.85s
14102/10943 (epoch 115.976) train_loss=198.88200378 time/batch=0.52s
14103/10943 (epoch 115.985) train_loss=141.72793579 time/batch=0.35s
14104/10943 (epoch 115.993) train_loss=300.30395508 time/batch=0.68s
14105/10943 (epoch 116.001) train_loss=506.48309326 time/batch=1.22s
14106/10943 (epoch 116.009) train_loss=265.16934204 time/batch=0.71s
14107/10943 (epoch 116.017) train_loss=454.69573975 time/batch=1.02s
14108/10943 (epoch 116.026) train_loss=152.27484131 time/batch=0.42s
14109/10943 (epoch 116.034) train_loss=411.86111450 time/batch=0.89s
14110/10943 (epoch 116.042) train_loss=158.71864319 time/batch=0.43s
14111/10943 (epoch 116.050) train_loss=449.49548340 time/batch=1.05s
14112/10943 (epoch 116.059) train_loss=249.66891479 time/batch=0.67s
14113/10943 (epoch 116.067) train_loss=191.28030396 time/batch=0.49s
14114/10943 (epoch 116.075) train_loss=468.74694824 time/batch=1.10s
14115/10943 (epoch 116.083) train_loss=222.76489258 time/batch=0.61s
14116/10943 (epoch 116.091) train_loss=471.84103394 time/batch=1.19s
14117/10943 (epoch 116.100) train_loss=216.49902344 time/batch=0.60s
14118/10943 (epoch 116.108) train_loss=396.24664307 time/batch=0.93s
14119/10943 (epoch 116.116) train_loss=119.34462738 time/batch=0.37s
14120/10943 (epoch 116.124) train_loss=173.10812378 time/batch=0.40s
14121/10943 (epoch 116.133) train_loss=368.27847290 time/batch=0.84s
14122/10943 (epoch 116.141) train_loss=314.29071045 time/batch=0.83s
14123/10943 (epoch 116.149) train_loss=400.63674927 time/batch=0.96s
14124/10943 (epoch 116.157) train_loss=151.97749329 time/batch=0.44s
14125/10943 (epoch 116.166) train_loss=610.77709961 time/batch=1.62s
14126/10943 (epoch 116.174) train_loss=529.67352295 time/batch=1.40s
14127/10943 (epoch 116.182) train_loss=250.95605469 time/batch=0.68s
14128/10943 (epoch 116.190) train_loss=411.29208374 time/batch=0.96s
14129/10943 (epoch 116.198) train_loss=292.33947754 time/batch=0.74s
14130/10943 (epoch 116.207) train_loss=186.22982788 time/batch=0.48s
14131/10943 (epoch 116.215) train_loss=247.62918091 time/batch=0.59s
14132/10943 (epoch 116.223) train_loss=224.08322144 time/batch=0.56s
14133/10943 (epoch 116.231) train_loss=337.17987061 time/batch=0.80s
14134/10943 (epoch 116.240) train_loss=170.49598694 time/batch=0.46s
14135/10943 (epoch 116.248) train_loss=350.15942383 time/batch=0.80s
14136/10943 (epoch 116.256) train_loss=295.21026611 time/batch=0.74s
14137/10943 (epoch 116.264) train_loss=242.21075439 time/batch=0.62s
14138/10943 (epoch 116.272) train_loss=295.72186279 time/batch=0.72s
14139/10943 (epoch 116.281) train_loss=231.71261597 time/batch=0.59s
14140/10943 (epoch 116.289) train_loss=434.03588867 time/batch=0.96s
14141/10943 (epoch 116.297) train_loss=178.30003357 time/batch=0.50s
14142/10943 (epoch 116.305) train_loss=450.08129883 time/batch=1.31s
14143/10943 (epoch 116.314) train_loss=308.29071045 time/batch=0.82s
14144/10943 (epoch 116.322) train_loss=207.68540955 time/batch=0.56s
14145/10943 (epoch 116.330) train_loss=260.68011475 time/batch=0.62s
14146/10943 (epoch 116.338) train_loss=246.64935303 time/batch=0.61s
14147/10943 (epoch 116.346) train_loss=178.75701904 time/batch=0.45s
14148/10943 (epoch 116.355) train_loss=320.70785522 time/batch=0.72s
14149/10943 (epoch 116.363) train_loss=157.05102539 time/batch=0.44s
14150/10943 (epoch 116.371) train_loss=275.65429688 time/batch=0.61s
14151/10943 (epoch 116.379) train_loss=198.73165894 time/batch=0.50s
14152/10943 (epoch 116.388) train_loss=163.07171631 time/batch=0.40s
14153/10943 (epoch 116.396) train_loss=297.12170410 time/batch=0.68s
14154/10943 (epoch 116.404) train_loss=282.17333984 time/batch=0.69s
14155/10943 (epoch 116.412) train_loss=185.54335022 time/batch=0.47s
14156/10943 (epoch 116.420) train_loss=173.09204102 time/batch=0.46s
14157/10943 (epoch 116.429) train_loss=353.68438721 time/batch=0.83s
14158/10943 (epoch 116.437) train_loss=311.10937500 time/batch=0.78s
14159/10943 (epoch 116.445) train_loss=317.66625977 time/batch=0.78s
14160/10943 (epoch 116.453) train_loss=145.07122803 time/batch=0.40s
14161/10943 (epoch 116.462) train_loss=264.74316406 time/batch=0.64s
14162/10943 (epoch 116.470) train_loss=258.63082886 time/batch=0.64s
14163/10943 (epoch 116.478) train_loss=338.55862427 time/batch=0.80s
14164/10943 (epoch 116.486) train_loss=234.05162048 time/batch=0.60s
14165/10943 (epoch 116.494) train_loss=233.19461060 time/batch=0.61s
14166/10943 (epoch 116.503) train_loss=273.12527466 time/batch=0.66s
14167/10943 (epoch 116.511) train_loss=245.15054321 time/batch=0.63s
14168/10943 (epoch 116.519) train_loss=118.61856079 time/batch=0.33s
14169/10943 (epoch 116.527) train_loss=379.72381592 time/batch=0.84s
14170/10943 (epoch 116.536) train_loss=134.08444214 time/batch=0.38s
14171/10943 (epoch 116.544) train_loss=134.64541626 time/batch=0.34s
14172/10943 (epoch 116.552) train_loss=308.53671265 time/batch=0.75s
14173/10943 (epoch 116.560) train_loss=316.33471680 time/batch=0.83s
14174/10943 (epoch 116.568) train_loss=300.64434814 time/batch=0.75s
14175/10943 (epoch 116.577) train_loss=213.12234497 time/batch=0.56s
14176/10943 (epoch 116.585) train_loss=225.11233521 time/batch=0.56s
14177/10943 (epoch 116.593) train_loss=305.35458374 time/batch=0.76s
14178/10943 (epoch 116.601) train_loss=198.00205994 time/batch=0.51s
14179/10943 (epoch 116.610) train_loss=325.07986450 time/batch=0.80s
14180/10943 (epoch 116.618) train_loss=310.90679932 time/batch=0.81s
14181/10943 (epoch 116.626) train_loss=133.44888306 time/batch=0.40s
14182/10943 (epoch 116.634) train_loss=203.43101501 time/batch=0.53s
14183/10943 (epoch 116.643) train_loss=345.64956665 time/batch=0.87s
14184/10943 (epoch 116.651) train_loss=269.63784790 time/batch=0.71s
14185/10943 (epoch 116.659) train_loss=311.40356445 time/batch=0.84s
14186/10943 (epoch 116.667) train_loss=298.09881592 time/batch=0.85s
14187/10943 (epoch 116.675) train_loss=281.61334229 time/batch=0.71s
14188/10943 (epoch 116.684) train_loss=213.62777710 time/batch=0.52s
14189/10943 (epoch 116.692) train_loss=223.08407593 time/batch=0.56s
14190/10943 (epoch 116.700) train_loss=288.44067383 time/batch=0.72s
14191/10943 (epoch 116.708) train_loss=268.33270264 time/batch=0.70s
14192/10943 (epoch 116.717) train_loss=232.46626282 time/batch=0.59s
14193/10943 (epoch 116.725) train_loss=267.22747803 time/batch=0.65s
setting learning rate to 0.0006155
14194/10943 (epoch 116.733) train_loss=612.79113770 time/batch=1.47s
14195/10943 (epoch 116.741) train_loss=486.64883423 time/batch=1.24s
14196/10943 (epoch 116.749) train_loss=708.11279297 time/batch=1.66s
14197/10943 (epoch 116.758) train_loss=99.66571045 time/batch=0.39s
14198/10943 (epoch 116.766) train_loss=415.30755615 time/batch=0.95s
14199/10943 (epoch 116.774) train_loss=514.63488770 time/batch=1.22s
14200/10943 (epoch 116.782) train_loss=199.19363403 time/batch=0.56s
14201/10943 (epoch 116.791) train_loss=241.34832764 time/batch=0.59s
14202/10943 (epoch 116.799) train_loss=287.51501465 time/batch=0.72s
14203/10943 (epoch 116.807) train_loss=948.33312988 time/batch=3.06s
14204/10943 (epoch 116.815) train_loss=571.43365479 time/batch=1.62s
14205/10943 (epoch 116.823) train_loss=449.04116821 time/batch=1.06s
14206/10943 (epoch 116.832) train_loss=478.48977661 time/batch=1.20s
14207/10943 (epoch 116.840) train_loss=398.11419678 time/batch=1.02s
14208/10943 (epoch 116.848) train_loss=343.05328369 time/batch=0.88s
14209/10943 (epoch 116.856) train_loss=297.51998901 time/batch=0.76s
14210/10943 (epoch 116.865) train_loss=452.68951416 time/batch=1.10s
14211/10943 (epoch 116.873) train_loss=208.72860718 time/batch=0.57s
14212/10943 (epoch 116.881) train_loss=297.76629639 time/batch=0.68s
14213/10943 (epoch 116.889) train_loss=621.82250977 time/batch=1.66s
14214/10943 (epoch 116.897) train_loss=560.31286621 time/batch=1.38s
14215/10943 (epoch 116.906) train_loss=442.24240112 time/batch=1.08s
14216/10943 (epoch 116.914) train_loss=149.99389648 time/batch=0.42s
14217/10943 (epoch 116.922) train_loss=126.39524841 time/batch=0.30s
14218/10943 (epoch 116.930) train_loss=374.21289062 time/batch=0.85s
14219/10943 (epoch 116.939) train_loss=279.59753418 time/batch=0.69s
14220/10943 (epoch 116.947) train_loss=398.25775146 time/batch=0.93s
14221/10943 (epoch 116.955) train_loss=339.96374512 time/batch=0.83s
14222/10943 (epoch 116.963) train_loss=278.61358643 time/batch=0.70s
14223/10943 (epoch 116.971) train_loss=313.74645996 time/batch=0.77s
14224/10943 (epoch 116.980) train_loss=198.81597900 time/batch=0.48s
14225/10943 (epoch 116.988) train_loss=218.05450439 time/batch=0.52s
14226/10943 (epoch 116.996) train_loss=148.72769165 time/batch=0.40s
14227/10943 (epoch 117.004) train_loss=323.58364868 time/batch=0.77s
14228/10943 (epoch 117.013) train_loss=314.53393555 time/batch=0.77s
14229/10943 (epoch 117.021) train_loss=153.12963867 time/batch=0.40s
14230/10943 (epoch 117.029) train_loss=178.30545044 time/batch=0.43s
14231/10943 (epoch 117.037) train_loss=489.26477051 time/batch=1.16s
14232/10943 (epoch 117.045) train_loss=336.97830200 time/batch=0.88s
14233/10943 (epoch 117.054) train_loss=337.38793945 time/batch=0.84s
14234/10943 (epoch 117.062) train_loss=280.50396729 time/batch=0.73s
14235/10943 (epoch 117.070) train_loss=169.73016357 time/batch=0.45s
14236/10943 (epoch 117.078) train_loss=505.95693970 time/batch=1.19s
14237/10943 (epoch 117.087) train_loss=223.70986938 time/batch=0.60s
14238/10943 (epoch 117.095) train_loss=217.26593018 time/batch=0.55s
14239/10943 (epoch 117.103) train_loss=116.64933777 time/batch=0.32s
14240/10943 (epoch 117.111) train_loss=266.06030273 time/batch=0.61s
14241/10943 (epoch 117.120) train_loss=270.89501953 time/batch=0.66s
14242/10943 (epoch 117.128) train_loss=305.96148682 time/batch=0.72s
14243/10943 (epoch 117.136) train_loss=298.77581787 time/batch=0.71s
14244/10943 (epoch 117.144) train_loss=237.74206543 time/batch=0.61s
14245/10943 (epoch 117.152) train_loss=255.24798584 time/batch=0.62s
14246/10943 (epoch 117.161) train_loss=314.62115479 time/batch=0.75s
14247/10943 (epoch 117.169) train_loss=263.58261108 time/batch=0.66s
14248/10943 (epoch 117.177) train_loss=229.24755859 time/batch=0.58s
14249/10943 (epoch 117.185) train_loss=296.58084106 time/batch=0.69s
14250/10943 (epoch 117.194) train_loss=335.33856201 time/batch=0.83s
14251/10943 (epoch 117.202) train_loss=238.20309448 time/batch=0.62s
14252/10943 (epoch 117.210) train_loss=231.67443848 time/batch=0.58s
14253/10943 (epoch 117.218) train_loss=309.43051147 time/batch=0.77s
14254/10943 (epoch 117.226) train_loss=141.71307373 time/batch=0.40s
14255/10943 (epoch 117.235) train_loss=212.00236511 time/batch=0.51s
14256/10943 (epoch 117.243) train_loss=198.55848694 time/batch=0.51s
14257/10943 (epoch 117.251) train_loss=441.51547241 time/batch=1.03s
14258/10943 (epoch 117.259) train_loss=177.96765137 time/batch=0.53s
14259/10943 (epoch 117.268) train_loss=239.22233582 time/batch=0.56s
14260/10943 (epoch 117.276) train_loss=265.30868530 time/batch=0.63s
14261/10943 (epoch 117.284) train_loss=374.18927002 time/batch=0.90s
14262/10943 (epoch 117.292) train_loss=286.76391602 time/batch=0.72s
14263/10943 (epoch 117.300) train_loss=191.63714600 time/batch=0.50s
14264/10943 (epoch 117.309) train_loss=161.66265869 time/batch=0.40s
14265/10943 (epoch 117.317) train_loss=453.95196533 time/batch=1.02s
14266/10943 (epoch 117.325) train_loss=268.70306396 time/batch=0.69s
14267/10943 (epoch 117.333) train_loss=447.42089844 time/batch=1.07s
14268/10943 (epoch 117.342) train_loss=379.66351318 time/batch=0.94s
14269/10943 (epoch 117.350) train_loss=157.02902222 time/batch=0.43s
14270/10943 (epoch 117.358) train_loss=399.55511475 time/batch=0.92s
14271/10943 (epoch 117.366) train_loss=391.52383423 time/batch=0.96s
14272/10943 (epoch 117.374) train_loss=234.39730835 time/batch=0.62s
14273/10943 (epoch 117.383) train_loss=277.76184082 time/batch=0.67s
14274/10943 (epoch 117.391) train_loss=344.05755615 time/batch=0.84s
14275/10943 (epoch 117.399) train_loss=256.22671509 time/batch=0.67s
14276/10943 (epoch 117.407) train_loss=253.78393555 time/batch=0.65s
14277/10943 (epoch 117.416) train_loss=141.04489136 time/batch=0.38s
14278/10943 (epoch 117.424) train_loss=226.96026611 time/batch=0.55s
14279/10943 (epoch 117.432) train_loss=275.95098877 time/batch=0.66s
14280/10943 (epoch 117.440) train_loss=213.47369385 time/batch=0.56s
14281/10943 (epoch 117.448) train_loss=109.76266479 time/batch=0.30s
14282/10943 (epoch 117.457) train_loss=129.14048767 time/batch=0.32s
14283/10943 (epoch 117.465) train_loss=305.86087036 time/batch=0.71s
14284/10943 (epoch 117.473) train_loss=207.87051392 time/batch=0.53s
14285/10943 (epoch 117.481) train_loss=359.71502686 time/batch=0.84s
14286/10943 (epoch 117.490) train_loss=395.62792969 time/batch=0.95s
14287/10943 (epoch 117.498) train_loss=240.51971436 time/batch=0.65s
14288/10943 (epoch 117.506) train_loss=201.35278320 time/batch=0.50s
14289/10943 (epoch 117.514) train_loss=315.27255249 time/batch=0.75s
14290/10943 (epoch 117.522) train_loss=179.78924561 time/batch=0.47s
14291/10943 (epoch 117.531) train_loss=120.92697144 time/batch=0.31s
14292/10943 (epoch 117.539) train_loss=380.86749268 time/batch=0.83s
14293/10943 (epoch 117.547) train_loss=138.18711853 time/batch=0.38s
14294/10943 (epoch 117.555) train_loss=179.32818604 time/batch=0.42s
14295/10943 (epoch 117.564) train_loss=358.91345215 time/batch=0.83s
14296/10943 (epoch 117.572) train_loss=310.89965820 time/batch=0.81s
14297/10943 (epoch 117.580) train_loss=146.92694092 time/batch=0.44s
14298/10943 (epoch 117.588) train_loss=333.84387207 time/batch=0.81s
14299/10943 (epoch 117.597) train_loss=309.21841431 time/batch=0.80s
14300/10943 (epoch 117.605) train_loss=323.83880615 time/batch=0.97s
14301/10943 (epoch 117.613) train_loss=194.39620972 time/batch=0.53s
14302/10943 (epoch 117.621) train_loss=234.38372803 time/batch=0.58s
14303/10943 (epoch 117.629) train_loss=272.90039062 time/batch=0.68s
14304/10943 (epoch 117.638) train_loss=367.51181030 time/batch=0.99s
14305/10943 (epoch 117.646) train_loss=310.15527344 time/batch=0.81s
14306/10943 (epoch 117.654) train_loss=248.39738464 time/batch=0.63s
14307/10943 (epoch 117.662) train_loss=222.81878662 time/batch=0.59s
14308/10943 (epoch 117.671) train_loss=164.53063965 time/batch=0.43s
14309/10943 (epoch 117.679) train_loss=313.94354248 time/batch=0.76s
14310/10943 (epoch 117.687) train_loss=177.98168945 time/batch=0.53s
14311/10943 (epoch 117.695) train_loss=195.00765991 time/batch=0.51s
14312/10943 (epoch 117.703) train_loss=235.63092041 time/batch=0.60s
14313/10943 (epoch 117.712) train_loss=288.95120239 time/batch=0.73s
14314/10943 (epoch 117.720) train_loss=265.94848633 time/batch=0.70s
setting learning rate to 0.0005971
  saved to metadata/gru_dropout-9_nov_folkwiki-20181207-173447_epoch73.pkl
14315/10943 (epoch 117.728) train_loss=197.48912048 time/batch=0.62s
14316/10943 (epoch 117.736) train_loss=481.82836914 time/batch=1.13s
14317/10943 (epoch 117.745) train_loss=605.80926514 time/batch=1.49s
14318/10943 (epoch 117.753) train_loss=273.67379761 time/batch=0.76s
14319/10943 (epoch 117.761) train_loss=116.77877808 time/batch=0.32s
14320/10943 (epoch 117.769) train_loss=200.41273499 time/batch=0.47s
14321/10943 (epoch 117.777) train_loss=184.62263489 time/batch=0.46s
14322/10943 (epoch 117.786) train_loss=305.69174194 time/batch=0.76s
14323/10943 (epoch 117.794) train_loss=154.53395081 time/batch=0.42s
14324/10943 (epoch 117.802) train_loss=706.85205078 time/batch=1.56s
14325/10943 (epoch 117.810) train_loss=147.18675232 time/batch=0.48s
14326/10943 (epoch 117.819) train_loss=843.55688477 time/batch=2.12s
14327/10943 (epoch 117.827) train_loss=304.44763184 time/batch=0.87s
14328/10943 (epoch 117.835) train_loss=345.88168335 time/batch=0.83s
14329/10943 (epoch 117.843) train_loss=564.81262207 time/batch=1.28s
14330/10943 (epoch 117.851) train_loss=167.19055176 time/batch=0.49s
14331/10943 (epoch 117.860) train_loss=578.64654541 time/batch=1.30s
14332/10943 (epoch 117.868) train_loss=326.64559937 time/batch=0.83s
14333/10943 (epoch 117.876) train_loss=304.38943481 time/batch=0.74s
14334/10943 (epoch 117.884) train_loss=343.69546509 time/batch=0.84s
14335/10943 (epoch 117.893) train_loss=450.93640137 time/batch=1.03s
14336/10943 (epoch 117.901) train_loss=122.32077789 time/batch=0.36s
14337/10943 (epoch 117.909) train_loss=477.87332153 time/batch=1.03s
14338/10943 (epoch 117.917) train_loss=430.72418213 time/batch=1.06s
14339/10943 (epoch 117.925) train_loss=399.90652466 time/batch=1.00s
14340/10943 (epoch 117.934) train_loss=106.71794128 time/batch=0.32s
14341/10943 (epoch 117.942) train_loss=251.82145691 time/batch=0.59s
14342/10943 (epoch 117.950) train_loss=369.75427246 time/batch=0.87s
14343/10943 (epoch 117.958) train_loss=129.16458130 time/batch=0.37s
14344/10943 (epoch 117.967) train_loss=260.43237305 time/batch=0.60s
14345/10943 (epoch 117.975) train_loss=184.18124390 time/batch=0.46s
14346/10943 (epoch 117.983) train_loss=460.91912842 time/batch=1.06s
14347/10943 (epoch 117.991) train_loss=381.13482666 time/batch=0.94s
14348/10943 (epoch 117.999) train_loss=171.99160767 time/batch=0.49s
14349/10943 (epoch 118.008) train_loss=517.41003418 time/batch=1.19s
14350/10943 (epoch 118.016) train_loss=361.59939575 time/batch=0.92s
14351/10943 (epoch 118.024) train_loss=225.86807251 time/batch=0.59s
14352/10943 (epoch 118.032) train_loss=220.10308838 time/batch=0.53s
14353/10943 (epoch 118.041) train_loss=451.16470337 time/batch=1.02s
14354/10943 (epoch 118.049) train_loss=288.58306885 time/batch=0.74s
14355/10943 (epoch 118.057) train_loss=193.78053284 time/batch=0.49s
14356/10943 (epoch 118.065) train_loss=740.68011475 time/batch=3.02s
14357/10943 (epoch 118.074) train_loss=126.91021729 time/batch=0.61s
14358/10943 (epoch 118.082) train_loss=315.01654053 time/batch=0.75s
14359/10943 (epoch 118.090) train_loss=455.91156006 time/batch=1.06s
14360/10943 (epoch 118.098) train_loss=286.38079834 time/batch=0.70s
14361/10943 (epoch 118.106) train_loss=524.99359131 time/batch=1.18s
14362/10943 (epoch 118.115) train_loss=338.11260986 time/batch=0.87s
14363/10943 (epoch 118.123) train_loss=490.87164307 time/batch=1.16s
14364/10943 (epoch 118.131) train_loss=221.17395020 time/batch=0.60s
14365/10943 (epoch 118.139) train_loss=372.38842773 time/batch=0.89s
14366/10943 (epoch 118.148) train_loss=148.33544922 time/batch=0.41s
14367/10943 (epoch 118.156) train_loss=404.21728516 time/batch=1.01s
14368/10943 (epoch 118.164) train_loss=208.28587341 time/batch=0.56s
14369/10943 (epoch 118.172) train_loss=354.16296387 time/batch=0.81s
14370/10943 (epoch 118.180) train_loss=399.62567139 time/batch=0.94s
14371/10943 (epoch 118.189) train_loss=160.49017334 time/batch=0.46s
14372/10943 (epoch 118.197) train_loss=145.07623291 time/batch=0.36s
14373/10943 (epoch 118.205) train_loss=474.60864258 time/batch=1.07s
14374/10943 (epoch 118.213) train_loss=388.90979004 time/batch=0.98s
14375/10943 (epoch 118.222) train_loss=261.69842529 time/batch=0.67s
14376/10943 (epoch 118.230) train_loss=296.14587402 time/batch=0.73s
14377/10943 (epoch 118.238) train_loss=239.67803955 time/batch=0.58s
14378/10943 (epoch 118.246) train_loss=155.78359985 time/batch=0.39s
14379/10943 (epoch 118.254) train_loss=309.60485840 time/batch=0.70s
14380/10943 (epoch 118.263) train_loss=133.37780762 time/batch=0.36s
14381/10943 (epoch 118.271) train_loss=137.11105347 time/batch=0.32s
14382/10943 (epoch 118.279) train_loss=250.76173401 time/batch=0.58s
14383/10943 (epoch 118.287) train_loss=314.17895508 time/batch=0.76s
14384/10943 (epoch 118.296) train_loss=230.80065918 time/batch=0.61s
14385/10943 (epoch 118.304) train_loss=331.15579224 time/batch=0.78s
14386/10943 (epoch 118.312) train_loss=295.09155273 time/batch=0.71s
14387/10943 (epoch 118.320) train_loss=284.77850342 time/batch=0.69s
14388/10943 (epoch 118.328) train_loss=178.50311279 time/batch=0.44s
14389/10943 (epoch 118.337) train_loss=270.79858398 time/batch=0.62s
14390/10943 (epoch 118.345) train_loss=242.89312744 time/batch=0.58s
14391/10943 (epoch 118.353) train_loss=312.96154785 time/batch=0.71s
14392/10943 (epoch 118.361) train_loss=306.76290894 time/batch=0.75s
14393/10943 (epoch 118.370) train_loss=405.86526489 time/batch=1.10s
14394/10943 (epoch 118.378) train_loss=290.24780273 time/batch=0.75s
14395/10943 (epoch 118.386) train_loss=219.55578613 time/batch=0.55s
14396/10943 (epoch 118.394) train_loss=237.50459290 time/batch=0.56s
14397/10943 (epoch 118.402) train_loss=201.93676758 time/batch=0.49s
14398/10943 (epoch 118.411) train_loss=229.45582581 time/batch=0.56s
14399/10943 (epoch 118.419) train_loss=387.27450562 time/batch=0.88s
14400/10943 (epoch 118.427) train_loss=154.29617310 time/batch=0.42s
14401/10943 (epoch 118.435) train_loss=352.08837891 time/batch=0.81s
14402/10943 (epoch 118.444) train_loss=242.52090454 time/batch=0.63s
14403/10943 (epoch 118.452) train_loss=150.82832336 time/batch=0.42s
14404/10943 (epoch 118.460) train_loss=158.89524841 time/batch=0.42s
14405/10943 (epoch 118.468) train_loss=203.81936646 time/batch=0.48s
14406/10943 (epoch 118.476) train_loss=277.88104248 time/batch=0.66s
14407/10943 (epoch 118.485) train_loss=314.82586670 time/batch=0.79s
14408/10943 (epoch 118.493) train_loss=237.63670349 time/batch=0.61s
14409/10943 (epoch 118.501) train_loss=413.63851929 time/batch=0.92s
14410/10943 (epoch 118.509) train_loss=339.03073120 time/batch=0.84s
14411/10943 (epoch 118.518) train_loss=380.05712891 time/batch=0.95s
14412/10943 (epoch 118.526) train_loss=338.68542480 time/batch=0.83s
14413/10943 (epoch 118.534) train_loss=342.01489258 time/batch=0.86s
14414/10943 (epoch 118.542) train_loss=273.02825928 time/batch=0.67s
14415/10943 (epoch 118.551) train_loss=199.59822083 time/batch=0.51s
14416/10943 (epoch 118.559) train_loss=193.59403992 time/batch=0.47s
14417/10943 (epoch 118.567) train_loss=314.96377563 time/batch=0.77s
14418/10943 (epoch 118.575) train_loss=310.55706787 time/batch=0.81s
14419/10943 (epoch 118.583) train_loss=288.35659790 time/batch=0.73s
14420/10943 (epoch 118.592) train_loss=236.38389587 time/batch=0.58s
14421/10943 (epoch 118.600) train_loss=187.61834717 time/batch=0.48s
14422/10943 (epoch 118.608) train_loss=327.35699463 time/batch=0.83s
14423/10943 (epoch 118.616) train_loss=216.92181396 time/batch=0.58s
14424/10943 (epoch 118.625) train_loss=232.16818237 time/batch=0.57s
14425/10943 (epoch 118.633) train_loss=286.11026001 time/batch=0.71s
14426/10943 (epoch 118.641) train_loss=208.48193359 time/batch=0.57s
14427/10943 (epoch 118.649) train_loss=243.74461365 time/batch=0.59s
14428/10943 (epoch 118.657) train_loss=281.75000000 time/batch=0.65s
14429/10943 (epoch 118.666) train_loss=263.17889404 time/batch=0.64s
14430/10943 (epoch 118.674) train_loss=282.83132935 time/batch=0.65s
14431/10943 (epoch 118.682) train_loss=319.69403076 time/batch=0.75s
14432/10943 (epoch 118.690) train_loss=243.89251709 time/batch=0.64s
14433/10943 (epoch 118.699) train_loss=273.39123535 time/batch=0.66s
14434/10943 (epoch 118.707) train_loss=241.59776306 time/batch=0.66s
14435/10943 (epoch 118.715) train_loss=299.23413086 time/batch=0.76s
setting learning rate to 0.0005792
14436/10943 (epoch 118.723) train_loss=246.10928345 time/batch=0.62s
14437/10943 (epoch 118.731) train_loss=706.38494873 time/batch=1.56s
14438/10943 (epoch 118.740) train_loss=452.83874512 time/batch=1.11s
14439/10943 (epoch 118.748) train_loss=434.80340576 time/batch=1.06s
14440/10943 (epoch 118.756) train_loss=317.66156006 time/batch=0.82s
14441/10943 (epoch 118.764) train_loss=480.78222656 time/batch=1.13s
14442/10943 (epoch 118.773) train_loss=584.72314453 time/batch=1.34s
14443/10943 (epoch 118.781) train_loss=583.02160645 time/batch=1.41s
14444/10943 (epoch 118.789) train_loss=300.46459961 time/batch=0.79s
14445/10943 (epoch 118.797) train_loss=458.56021118 time/batch=1.13s
14446/10943 (epoch 118.805) train_loss=521.55871582 time/batch=1.22s
14447/10943 (epoch 118.814) train_loss=233.67874146 time/batch=0.63s
14448/10943 (epoch 118.822) train_loss=564.83044434 time/batch=1.37s
14449/10943 (epoch 118.830) train_loss=415.08963013 time/batch=1.03s
14450/10943 (epoch 118.838) train_loss=503.33227539 time/batch=1.22s
14451/10943 (epoch 118.847) train_loss=308.51712036 time/batch=0.81s
14452/10943 (epoch 118.855) train_loss=954.09606934 time/batch=3.06s
14453/10943 (epoch 118.863) train_loss=560.07250977 time/batch=1.68s
14454/10943 (epoch 118.871) train_loss=237.29434204 time/batch=0.69s
14455/10943 (epoch 118.879) train_loss=184.17156982 time/batch=0.46s
14456/10943 (epoch 118.888) train_loss=567.98352051 time/batch=1.56s
14457/10943 (epoch 118.896) train_loss=129.23400879 time/batch=0.45s
14458/10943 (epoch 118.904) train_loss=251.92166138 time/batch=0.57s
14459/10943 (epoch 118.912) train_loss=509.05255127 time/batch=1.58s
14460/10943 (epoch 118.921) train_loss=180.38275146 time/batch=0.56s
14461/10943 (epoch 118.929) train_loss=167.59489441 time/batch=0.41s
14462/10943 (epoch 118.937) train_loss=522.48437500 time/batch=1.62s
14463/10943 (epoch 118.945) train_loss=115.33981323 time/batch=0.42s
14464/10943 (epoch 118.953) train_loss=406.57299805 time/batch=0.91s
14465/10943 (epoch 118.962) train_loss=314.07452393 time/batch=0.82s
14466/10943 (epoch 118.970) train_loss=382.00762939 time/batch=0.88s
14467/10943 (epoch 118.978) train_loss=204.43096924 time/batch=0.53s
14468/10943 (epoch 118.986) train_loss=326.89428711 time/batch=0.77s
14469/10943 (epoch 118.995) train_loss=159.63308716 time/batch=0.41s
14470/10943 (epoch 119.003) train_loss=319.67266846 time/batch=0.72s
14471/10943 (epoch 119.011) train_loss=380.56890869 time/batch=0.92s
14472/10943 (epoch 119.019) train_loss=305.24151611 time/batch=0.79s
14473/10943 (epoch 119.027) train_loss=124.25389099 time/batch=0.33s
14474/10943 (epoch 119.036) train_loss=395.17306519 time/batch=0.88s
14475/10943 (epoch 119.044) train_loss=279.15686035 time/batch=0.71s
14476/10943 (epoch 119.052) train_loss=132.17425537 time/batch=0.36s
14477/10943 (epoch 119.060) train_loss=223.51293945 time/batch=0.51s
14478/10943 (epoch 119.069) train_loss=136.64424133 time/batch=0.35s
14479/10943 (epoch 119.077) train_loss=308.45727539 time/batch=0.69s
14480/10943 (epoch 119.085) train_loss=343.91656494 time/batch=0.83s
14481/10943 (epoch 119.093) train_loss=298.69714355 time/batch=0.75s
14482/10943 (epoch 119.102) train_loss=143.02249146 time/batch=0.38s
14483/10943 (epoch 119.110) train_loss=439.08505249 time/batch=0.93s
14484/10943 (epoch 119.118) train_loss=270.82232666 time/batch=0.67s
14485/10943 (epoch 119.126) train_loss=437.89782715 time/batch=0.99s
14486/10943 (epoch 119.134) train_loss=338.64318848 time/batch=0.85s
14487/10943 (epoch 119.143) train_loss=199.83094788 time/batch=0.55s
14488/10943 (epoch 119.151) train_loss=211.56031799 time/batch=0.49s
14489/10943 (epoch 119.159) train_loss=161.72370911 time/batch=0.40s
14490/10943 (epoch 119.167) train_loss=308.02239990 time/batch=0.76s
14491/10943 (epoch 119.176) train_loss=283.36572266 time/batch=0.67s
14492/10943 (epoch 119.184) train_loss=151.55152893 time/batch=0.38s
14493/10943 (epoch 119.192) train_loss=274.68194580 time/batch=0.65s
14494/10943 (epoch 119.200) train_loss=147.69146729 time/batch=0.41s
14495/10943 (epoch 119.208) train_loss=312.86065674 time/batch=0.77s
14496/10943 (epoch 119.217) train_loss=342.68530273 time/batch=0.85s
14497/10943 (epoch 119.225) train_loss=179.31753540 time/batch=0.46s
14498/10943 (epoch 119.233) train_loss=192.61831665 time/batch=0.46s
14499/10943 (epoch 119.241) train_loss=244.01541138 time/batch=0.58s
14500/10943 (epoch 119.250) train_loss=376.67358398 time/batch=0.89s
14501/10943 (epoch 119.258) train_loss=379.33026123 time/batch=0.91s
14502/10943 (epoch 119.266) train_loss=274.83227539 time/batch=0.70s
14503/10943 (epoch 119.274) train_loss=358.79089355 time/batch=0.85s
14504/10943 (epoch 119.282) train_loss=221.71427917 time/batch=0.58s
14505/10943 (epoch 119.291) train_loss=179.51661682 time/batch=0.45s
14506/10943 (epoch 119.299) train_loss=225.66207886 time/batch=0.52s
14507/10943 (epoch 119.307) train_loss=442.30587769 time/batch=1.02s
14508/10943 (epoch 119.315) train_loss=241.43461609 time/batch=0.66s
14509/10943 (epoch 119.324) train_loss=140.53396606 time/batch=0.37s
14510/10943 (epoch 119.332) train_loss=384.22018433 time/batch=0.89s
14511/10943 (epoch 119.340) train_loss=267.54772949 time/batch=0.68s
14512/10943 (epoch 119.348) train_loss=281.61291504 time/batch=0.66s
14513/10943 (epoch 119.356) train_loss=118.19180298 time/batch=0.33s
14514/10943 (epoch 119.365) train_loss=177.61973572 time/batch=0.43s
14515/10943 (epoch 119.373) train_loss=337.89202881 time/batch=0.74s
14516/10943 (epoch 119.381) train_loss=192.08120728 time/batch=0.49s
14517/10943 (epoch 119.389) train_loss=296.35342407 time/batch=0.71s
14518/10943 (epoch 119.398) train_loss=407.19195557 time/batch=0.99s
14519/10943 (epoch 119.406) train_loss=196.83322144 time/batch=0.53s
14520/10943 (epoch 119.414) train_loss=293.62792969 time/batch=0.75s
14521/10943 (epoch 119.422) train_loss=218.72671509 time/batch=0.56s
14522/10943 (epoch 119.430) train_loss=219.23013306 time/batch=0.55s
14523/10943 (epoch 119.439) train_loss=350.09716797 time/batch=0.81s
14524/10943 (epoch 119.447) train_loss=257.48599243 time/batch=0.65s
14525/10943 (epoch 119.455) train_loss=234.57344055 time/batch=0.58s
14526/10943 (epoch 119.463) train_loss=239.73892212 time/batch=0.61s
14527/10943 (epoch 119.472) train_loss=301.48562622 time/batch=0.69s
14528/10943 (epoch 119.480) train_loss=163.74313354 time/batch=0.43s
14529/10943 (epoch 119.488) train_loss=186.23803711 time/batch=0.45s
14530/10943 (epoch 119.496) train_loss=274.78253174 time/batch=0.65s
14531/10943 (epoch 119.504) train_loss=353.87393188 time/batch=0.84s
14532/10943 (epoch 119.513) train_loss=308.60372925 time/batch=0.72s
14533/10943 (epoch 119.521) train_loss=369.93988037 time/batch=0.97s
14534/10943 (epoch 119.529) train_loss=362.82534790 time/batch=0.87s
14535/10943 (epoch 119.537) train_loss=212.84539795 time/batch=0.54s
14536/10943 (epoch 119.546) train_loss=244.19183350 time/batch=0.60s
14537/10943 (epoch 119.554) train_loss=354.59167480 time/batch=0.85s
14538/10943 (epoch 119.562) train_loss=287.20776367 time/batch=0.69s
14539/10943 (epoch 119.570) train_loss=243.90411377 time/batch=0.60s
14540/10943 (epoch 119.579) train_loss=319.41436768 time/batch=0.78s
14541/10943 (epoch 119.587) train_loss=252.13046265 time/batch=0.65s
14542/10943 (epoch 119.595) train_loss=290.04537964 time/batch=0.68s
14543/10943 (epoch 119.603) train_loss=236.94487000 time/batch=0.59s
14544/10943 (epoch 119.611) train_loss=298.09307861 time/batch=0.71s
14545/10943 (epoch 119.620) train_loss=348.03948975 time/batch=0.86s
14546/10943 (epoch 119.628) train_loss=330.65136719 time/batch=0.83s
14547/10943 (epoch 119.636) train_loss=278.43551636 time/batch=0.70s
14548/10943 (epoch 119.644) train_loss=108.66038513 time/batch=0.33s
14549/10943 (epoch 119.653) train_loss=265.52703857 time/batch=0.61s
14550/10943 (epoch 119.661) train_loss=266.82653809 time/batch=0.63s
14551/10943 (epoch 119.669) train_loss=304.19659424 time/batch=0.77s
14552/10943 (epoch 119.677) train_loss=244.59301758 time/batch=0.64s
14553/10943 (epoch 119.685) train_loss=209.63757324 time/batch=0.56s
14554/10943 (epoch 119.694) train_loss=145.81237793 time/batch=0.37s
14555/10943 (epoch 119.702) train_loss=257.68130493 time/batch=0.68s
14556/10943 (epoch 119.710) train_loss=220.76898193 time/batch=0.71s
setting learning rate to 0.0005618
  saved to metadata/gru_dropout-9_nov_folkwiki-20181207-173447_epoch75.pkl
14557/10943 (epoch 119.718) train_loss=784.77563477 time/batch=1.90s
14558/10943 (epoch 119.727) train_loss=106.64102936 time/batch=0.42s
14559/10943 (epoch 119.735) train_loss=495.53747559 time/batch=1.08s
14560/10943 (epoch 119.743) train_loss=520.81433105 time/batch=1.20s
14561/10943 (epoch 119.751) train_loss=303.85052490 time/batch=0.77s
14562/10943 (epoch 119.759) train_loss=785.28057861 time/batch=2.00s
14563/10943 (epoch 119.768) train_loss=283.31188965 time/batch=0.79s
14564/10943 (epoch 119.776) train_loss=153.40014648 time/batch=0.40s
14565/10943 (epoch 119.784) train_loss=200.28201294 time/batch=0.46s
14566/10943 (epoch 119.792) train_loss=187.70016479 time/batch=0.43s
14567/10943 (epoch 119.801) train_loss=612.56152344 time/batch=1.25s
14568/10943 (epoch 119.809) train_loss=415.61987305 time/batch=1.01s
14569/10943 (epoch 119.817) train_loss=600.78668213 time/batch=1.33s
14570/10943 (epoch 119.825) train_loss=431.52941895 time/batch=1.00s
14571/10943 (epoch 119.833) train_loss=395.33599854 time/batch=0.92s
14572/10943 (epoch 119.842) train_loss=459.76385498 time/batch=1.03s
14573/10943 (epoch 119.850) train_loss=241.72851562 time/batch=0.62s
14574/10943 (epoch 119.858) train_loss=604.72497559 time/batch=1.37s
14575/10943 (epoch 119.866) train_loss=380.22756958 time/batch=0.93s
14576/10943 (epoch 119.875) train_loss=567.70593262 time/batch=1.21s
14577/10943 (epoch 119.883) train_loss=492.62908936 time/batch=1.19s
14578/10943 (epoch 119.891) train_loss=322.21322632 time/batch=0.76s
14579/10943 (epoch 119.899) train_loss=616.10076904 time/batch=1.47s
14580/10943 (epoch 119.907) train_loss=510.24060059 time/batch=1.27s
14581/10943 (epoch 119.916) train_loss=299.13375854 time/batch=0.72s
14582/10943 (epoch 119.924) train_loss=208.33190918 time/batch=0.50s
14583/10943 (epoch 119.932) train_loss=231.83131409 time/batch=0.54s
14584/10943 (epoch 119.940) train_loss=479.63598633 time/batch=1.03s
14585/10943 (epoch 119.949) train_loss=394.34124756 time/batch=0.92s
14586/10943 (epoch 119.957) train_loss=141.87158203 time/batch=0.38s
14587/10943 (epoch 119.965) train_loss=437.96340942 time/batch=0.95s
14588/10943 (epoch 119.973) train_loss=796.81994629 time/batch=3.06s
14589/10943 (epoch 119.981) train_loss=230.22576904 time/batch=0.78s
14590/10943 (epoch 119.990) train_loss=199.72814941 time/batch=0.46s
14591/10943 (epoch 119.998) train_loss=361.13412476 time/batch=0.79s
14592/10943 (epoch 120.006) train_loss=289.81185913 time/batch=0.69s
14593/10943 (epoch 120.014) train_loss=174.43634033 time/batch=0.42s
14594/10943 (epoch 120.023) train_loss=317.68444824 time/batch=0.67s
14595/10943 (epoch 120.031) train_loss=151.07943726 time/batch=0.37s
14596/10943 (epoch 120.039) train_loss=436.61273193 time/batch=0.93s
14597/10943 (epoch 120.047) train_loss=117.52891541 time/batch=0.35s
14598/10943 (epoch 120.056) train_loss=344.77871704 time/batch=0.73s
14599/10943 (epoch 120.064) train_loss=334.62054443 time/batch=0.75s
14600/10943 (epoch 120.072) train_loss=392.14132690 time/batch=0.87s
14601/10943 (epoch 120.080) train_loss=213.65017700 time/batch=0.50s
14602/10943 (epoch 120.088) train_loss=163.36404419 time/batch=0.37s
14603/10943 (epoch 120.097) train_loss=266.69476318 time/batch=0.59s
14604/10943 (epoch 120.105) train_loss=271.49264526 time/batch=0.62s
14605/10943 (epoch 120.113) train_loss=389.29635620 time/batch=0.83s
14606/10943 (epoch 120.121) train_loss=496.70794678 time/batch=1.08s
14607/10943 (epoch 120.130) train_loss=342.37652588 time/batch=0.85s
14608/10943 (epoch 120.138) train_loss=240.09799194 time/batch=0.58s
14609/10943 (epoch 120.146) train_loss=475.51092529 time/batch=0.98s
14610/10943 (epoch 120.154) train_loss=345.09277344 time/batch=0.80s
14611/10943 (epoch 120.162) train_loss=360.31365967 time/batch=0.84s
14612/10943 (epoch 120.171) train_loss=209.19439697 time/batch=0.51s
14613/10943 (epoch 120.179) train_loss=341.87164307 time/batch=0.73s
14614/10943 (epoch 120.187) train_loss=125.85588074 time/batch=0.34s
14615/10943 (epoch 120.195) train_loss=180.73625183 time/batch=0.42s
14616/10943 (epoch 120.204) train_loss=279.86300659 time/batch=0.62s
14617/10943 (epoch 120.212) train_loss=253.55682373 time/batch=0.57s
14618/10943 (epoch 120.220) train_loss=275.34979248 time/batch=0.63s
14619/10943 (epoch 120.228) train_loss=246.89419556 time/batch=0.59s
14620/10943 (epoch 120.236) train_loss=292.67462158 time/batch=0.64s
14621/10943 (epoch 120.245) train_loss=363.86975098 time/batch=0.82s
14622/10943 (epoch 120.253) train_loss=347.16290283 time/batch=0.79s
14623/10943 (epoch 120.261) train_loss=411.59729004 time/batch=0.93s
14624/10943 (epoch 120.269) train_loss=329.87896729 time/batch=0.75s
14625/10943 (epoch 120.278) train_loss=302.79089355 time/batch=0.70s
14626/10943 (epoch 120.286) train_loss=257.69622803 time/batch=0.60s
14627/10943 (epoch 120.294) train_loss=235.49880981 time/batch=0.53s
14628/10943 (epoch 120.302) train_loss=229.89080811 time/batch=0.52s
14629/10943 (epoch 120.310) train_loss=207.95748901 time/batch=0.50s
14630/10943 (epoch 120.319) train_loss=149.48002625 time/batch=0.35s
14631/10943 (epoch 120.327) train_loss=127.27436829 time/batch=0.31s
14632/10943 (epoch 120.335) train_loss=341.72698975 time/batch=0.74s
14633/10943 (epoch 120.343) train_loss=321.63186646 time/batch=0.77s
14634/10943 (epoch 120.352) train_loss=392.41180420 time/batch=0.92s
14635/10943 (epoch 120.360) train_loss=305.39691162 time/batch=0.72s
14636/10943 (epoch 120.368) train_loss=466.61990356 time/batch=1.02s
14637/10943 (epoch 120.376) train_loss=255.20079041 time/batch=0.66s
14638/10943 (epoch 120.384) train_loss=252.16403198 time/batch=0.60s
14639/10943 (epoch 120.393) train_loss=429.38439941 time/batch=0.93s
14640/10943 (epoch 120.401) train_loss=245.01481628 time/batch=0.62s
14641/10943 (epoch 120.409) train_loss=398.95166016 time/batch=0.86s
14642/10943 (epoch 120.417) train_loss=171.88819885 time/batch=0.47s
14643/10943 (epoch 120.426) train_loss=277.99511719 time/batch=0.66s
14644/10943 (epoch 120.434) train_loss=257.41894531 time/batch=0.61s
14645/10943 (epoch 120.442) train_loss=227.62643433 time/batch=0.57s
14646/10943 (epoch 120.450) train_loss=243.35183716 time/batch=0.60s
14647/10943 (epoch 120.458) train_loss=321.05740356 time/batch=0.77s
14648/10943 (epoch 120.467) train_loss=282.31027222 time/batch=0.67s
14649/10943 (epoch 120.475) train_loss=327.80194092 time/batch=0.80s
14650/10943 (epoch 120.483) train_loss=286.09722900 time/batch=0.68s
14651/10943 (epoch 120.491) train_loss=133.42681885 time/batch=0.36s
14652/10943 (epoch 120.500) train_loss=322.46429443 time/batch=0.75s
14653/10943 (epoch 120.508) train_loss=369.77490234 time/batch=0.91s
14654/10943 (epoch 120.516) train_loss=190.48095703 time/batch=0.48s
14655/10943 (epoch 120.524) train_loss=134.83251953 time/batch=0.33s
14656/10943 (epoch 120.533) train_loss=333.90972900 time/batch=0.77s
14657/10943 (epoch 120.541) train_loss=166.45391846 time/batch=0.44s
14658/10943 (epoch 120.549) train_loss=185.70166016 time/batch=0.44s
14659/10943 (epoch 120.557) train_loss=350.31103516 time/batch=0.78s
14660/10943 (epoch 120.565) train_loss=383.46343994 time/batch=0.97s
14661/10943 (epoch 120.574) train_loss=281.85144043 time/batch=0.71s
14662/10943 (epoch 120.582) train_loss=283.08416748 time/batch=0.67s
14663/10943 (epoch 120.590) train_loss=189.65571594 time/batch=0.52s
14664/10943 (epoch 120.598) train_loss=311.27337646 time/batch=0.79s
14665/10943 (epoch 120.607) train_loss=304.94274902 time/batch=0.74s
14666/10943 (epoch 120.615) train_loss=235.13336182 time/batch=0.59s
14667/10943 (epoch 120.623) train_loss=150.85624695 time/batch=0.37s
14668/10943 (epoch 120.631) train_loss=242.16412354 time/batch=0.58s
14669/10943 (epoch 120.639) train_loss=300.43447876 time/batch=0.71s
14670/10943 (epoch 120.648) train_loss=204.84635925 time/batch=0.53s
14671/10943 (epoch 120.656) train_loss=156.03427124 time/batch=0.38s
14672/10943 (epoch 120.664) train_loss=259.84774780 time/batch=0.59s
14673/10943 (epoch 120.672) train_loss=349.62652588 time/batch=0.83s
14674/10943 (epoch 120.681) train_loss=211.97187805 time/batch=0.56s
14675/10943 (epoch 120.689) train_loss=285.82104492 time/batch=0.69s
14676/10943 (epoch 120.697) train_loss=178.38879395 time/batch=0.53s
14677/10943 (epoch 120.705) train_loss=248.97525024 time/batch=0.70s
setting learning rate to 0.0005449
14678/10943 (epoch 120.713) train_loss=801.35424805 time/batch=1.85s
14679/10943 (epoch 120.722) train_loss=792.22021484 time/batch=2.12s
14680/10943 (epoch 120.730) train_loss=614.66387939 time/batch=1.50s
14681/10943 (epoch 120.738) train_loss=792.92724609 time/batch=2.41s
14682/10943 (epoch 120.746) train_loss=125.69746399 time/batch=0.51s
14683/10943 (epoch 120.755) train_loss=230.67749023 time/batch=0.52s
14684/10943 (epoch 120.763) train_loss=502.45849609 time/batch=1.12s
14685/10943 (epoch 120.771) train_loss=149.22627258 time/batch=0.43s
14686/10943 (epoch 120.779) train_loss=129.91503906 time/batch=0.30s
14687/10943 (epoch 120.787) train_loss=456.31304932 time/batch=1.00s
14688/10943 (epoch 120.796) train_loss=100.72148895 time/batch=0.32s
14689/10943 (epoch 120.804) train_loss=435.06726074 time/batch=0.93s
14690/10943 (epoch 120.812) train_loss=185.61734009 time/batch=0.50s
14691/10943 (epoch 120.820) train_loss=230.21789551 time/batch=0.54s
14692/10943 (epoch 120.829) train_loss=288.81982422 time/batch=0.65s
14693/10943 (epoch 120.837) train_loss=143.82458496 time/batch=0.36s
14694/10943 (epoch 120.845) train_loss=464.55059814 time/batch=0.95s
14695/10943 (epoch 120.853) train_loss=587.32080078 time/batch=1.29s
14696/10943 (epoch 120.861) train_loss=306.81851196 time/batch=0.77s
14697/10943 (epoch 120.870) train_loss=472.54412842 time/batch=1.05s
14698/10943 (epoch 120.878) train_loss=240.47084045 time/batch=0.63s
14699/10943 (epoch 120.886) train_loss=157.62852478 time/batch=0.38s
14700/10943 (epoch 120.894) train_loss=167.55706787 time/batch=0.41s
14701/10943 (epoch 120.903) train_loss=236.74607849 time/batch=0.56s
14702/10943 (epoch 120.911) train_loss=464.92797852 time/batch=1.05s
14703/10943 (epoch 120.919) train_loss=394.80953979 time/batch=0.95s
14704/10943 (epoch 120.927) train_loss=231.58168030 time/batch=0.60s
14705/10943 (epoch 120.935) train_loss=169.68359375 time/batch=0.40s
14706/10943 (epoch 120.944) train_loss=384.05993652 time/batch=0.84s
14707/10943 (epoch 120.952) train_loss=427.90063477 time/batch=0.96s
14708/10943 (epoch 120.960) train_loss=119.44577789 time/batch=0.37s
14709/10943 (epoch 120.968) train_loss=379.19635010 time/batch=0.85s
14710/10943 (epoch 120.977) train_loss=311.64190674 time/batch=0.75s
14711/10943 (epoch 120.985) train_loss=265.71313477 time/batch=0.64s
14712/10943 (epoch 120.993) train_loss=228.68269348 time/batch=0.55s
14713/10943 (epoch 121.001) train_loss=128.85661316 time/batch=0.33s
14714/10943 (epoch 121.010) train_loss=517.00817871 time/batch=1.13s
14715/10943 (epoch 121.018) train_loss=238.33935547 time/batch=0.63s
14716/10943 (epoch 121.026) train_loss=661.46484375 time/batch=3.04s
14717/10943 (epoch 121.034) train_loss=188.51406860 time/batch=0.70s
14718/10943 (epoch 121.042) train_loss=502.02737427 time/batch=1.14s
14719/10943 (epoch 121.051) train_loss=476.73776245 time/batch=1.23s
14720/10943 (epoch 121.059) train_loss=175.63421631 time/batch=0.51s
14721/10943 (epoch 121.067) train_loss=534.84844971 time/batch=1.23s
14722/10943 (epoch 121.075) train_loss=321.27416992 time/batch=0.85s
14723/10943 (epoch 121.084) train_loss=446.35046387 time/batch=1.01s
14724/10943 (epoch 121.092) train_loss=294.17312622 time/batch=0.76s
14725/10943 (epoch 121.100) train_loss=157.65008545 time/batch=0.41s
14726/10943 (epoch 121.108) train_loss=252.85850525 time/batch=0.57s
14727/10943 (epoch 121.116) train_loss=350.94451904 time/batch=0.78s
14728/10943 (epoch 121.125) train_loss=269.24304199 time/batch=0.66s
14729/10943 (epoch 121.133) train_loss=179.12728882 time/batch=0.46s
14730/10943 (epoch 121.141) train_loss=284.86633301 time/batch=0.66s
14731/10943 (epoch 121.149) train_loss=323.17059326 time/batch=0.76s
14732/10943 (epoch 121.158) train_loss=245.91567993 time/batch=0.62s
14733/10943 (epoch 121.166) train_loss=303.30346680 time/batch=0.70s
14734/10943 (epoch 121.174) train_loss=420.36831665 time/batch=1.01s
14735/10943 (epoch 121.182) train_loss=370.60229492 time/batch=0.90s
14736/10943 (epoch 121.190) train_loss=311.09530640 time/batch=0.74s
14737/10943 (epoch 121.199) train_loss=232.78422546 time/batch=0.57s
14738/10943 (epoch 121.207) train_loss=195.96286011 time/batch=0.47s
14739/10943 (epoch 121.215) train_loss=277.10797119 time/batch=0.65s
14740/10943 (epoch 121.223) train_loss=323.36849976 time/batch=0.79s
14741/10943 (epoch 121.232) train_loss=411.81994629 time/batch=0.94s
14742/10943 (epoch 121.240) train_loss=206.90419006 time/batch=0.57s
14743/10943 (epoch 121.248) train_loss=206.19247437 time/batch=0.51s
14744/10943 (epoch 121.256) train_loss=512.28015137 time/batch=1.17s
14745/10943 (epoch 121.264) train_loss=299.41430664 time/batch=0.78s
14746/10943 (epoch 121.273) train_loss=396.04699707 time/batch=0.95s
14747/10943 (epoch 121.281) train_loss=160.21084595 time/batch=0.46s
14748/10943 (epoch 121.289) train_loss=285.22439575 time/batch=0.66s
14749/10943 (epoch 121.297) train_loss=277.50711060 time/batch=0.65s
14750/10943 (epoch 121.306) train_loss=217.73982239 time/batch=0.54s
14751/10943 (epoch 121.314) train_loss=199.69410706 time/batch=0.46s
14752/10943 (epoch 121.322) train_loss=131.37332153 time/batch=0.33s
14753/10943 (epoch 121.330) train_loss=212.45440674 time/batch=0.51s
14754/10943 (epoch 121.338) train_loss=170.48423767 time/batch=0.46s
14755/10943 (epoch 121.347) train_loss=210.03369141 time/batch=0.49s
14756/10943 (epoch 121.355) train_loss=277.13662720 time/batch=0.65s
14757/10943 (epoch 121.363) train_loss=311.33334351 time/batch=0.77s
14758/10943 (epoch 121.371) train_loss=199.36044312 time/batch=0.52s
14759/10943 (epoch 121.380) train_loss=322.30584717 time/batch=0.73s
14760/10943 (epoch 121.388) train_loss=252.00424194 time/batch=0.63s
14761/10943 (epoch 121.396) train_loss=360.42730713 time/batch=0.83s
14762/10943 (epoch 121.404) train_loss=353.29467773 time/batch=0.85s
14763/10943 (epoch 121.412) train_loss=290.39236450 time/batch=0.68s
14764/10943 (epoch 121.421) train_loss=310.58459473 time/batch=0.73s
14765/10943 (epoch 121.429) train_loss=321.75637817 time/batch=0.79s
14766/10943 (epoch 121.437) train_loss=152.46150208 time/batch=0.39s
14767/10943 (epoch 121.445) train_loss=318.19677734 time/batch=0.77s
14768/10943 (epoch 121.454) train_loss=348.70190430 time/batch=0.83s
14769/10943 (epoch 121.462) train_loss=330.46688843 time/batch=0.82s
14770/10943 (epoch 121.470) train_loss=265.02221680 time/batch=0.66s
14771/10943 (epoch 121.478) train_loss=238.81021118 time/batch=0.58s
14772/10943 (epoch 121.487) train_loss=213.72656250 time/batch=0.58s
14773/10943 (epoch 121.495) train_loss=308.86676025 time/batch=0.73s
14774/10943 (epoch 121.503) train_loss=381.19433594 time/batch=0.96s
14775/10943 (epoch 121.511) train_loss=200.49044800 time/batch=0.54s
14776/10943 (epoch 121.519) train_loss=139.42601013 time/batch=0.37s
14777/10943 (epoch 121.528) train_loss=153.82023621 time/batch=0.44s
14778/10943 (epoch 121.536) train_loss=279.84286499 time/batch=0.65s
14779/10943 (epoch 121.544) train_loss=376.10989380 time/batch=0.87s
14780/10943 (epoch 121.552) train_loss=335.03497314 time/batch=0.85s
14781/10943 (epoch 121.561) train_loss=326.68988037 time/batch=0.80s
14782/10943 (epoch 121.569) train_loss=365.85299683 time/batch=0.86s
14783/10943 (epoch 121.577) train_loss=222.28970337 time/batch=0.62s
14784/10943 (epoch 121.585) train_loss=283.70971680 time/batch=0.68s
14785/10943 (epoch 121.593) train_loss=332.39721680 time/batch=0.81s
14786/10943 (epoch 121.602) train_loss=312.70904541 time/batch=0.78s
14787/10943 (epoch 121.610) train_loss=401.34353638 time/batch=0.97s
14788/10943 (epoch 121.618) train_loss=256.69244385 time/batch=0.67s
14789/10943 (epoch 121.626) train_loss=183.95472717 time/batch=0.50s
14790/10943 (epoch 121.635) train_loss=247.23901367 time/batch=0.58s
14791/10943 (epoch 121.643) train_loss=246.75781250 time/batch=0.61s
14792/10943 (epoch 121.651) train_loss=282.17620850 time/batch=0.67s
14793/10943 (epoch 121.659) train_loss=309.04598999 time/batch=0.77s
14794/10943 (epoch 121.667) train_loss=240.81799316 time/batch=0.62s
14795/10943 (epoch 121.676) train_loss=225.23405457 time/batch=0.58s
14796/10943 (epoch 121.684) train_loss=293.25640869 time/batch=0.76s
14797/10943 (epoch 121.692) train_loss=250.58721924 time/batch=0.68s
14798/10943 (epoch 121.700) train_loss=338.02197266 time/batch=0.95s
setting learning rate to 0.0005286
  saved to metadata/gru_dropout-9_nov_folkwiki-20181207-173447_epoch77.pkl
14799/10943 (epoch 121.709) train_loss=468.16665649 time/batch=1.17s
14800/10943 (epoch 121.717) train_loss=671.00164795 time/batch=1.56s
14801/10943 (epoch 121.725) train_loss=277.13055420 time/batch=0.77s
14802/10943 (epoch 121.733) train_loss=340.62426758 time/batch=0.84s
14803/10943 (epoch 121.741) train_loss=495.83694458 time/batch=1.17s
14804/10943 (epoch 121.750) train_loss=318.62713623 time/batch=0.80s
14805/10943 (epoch 121.758) train_loss=447.12728882 time/batch=1.04s
14806/10943 (epoch 121.766) train_loss=579.33276367 time/batch=1.29s
14807/10943 (epoch 121.774) train_loss=343.41204834 time/batch=0.88s
14808/10943 (epoch 121.783) train_loss=202.58889771 time/batch=0.52s
14809/10943 (epoch 121.791) train_loss=569.93969727 time/batch=1.26s
14810/10943 (epoch 121.799) train_loss=357.70803833 time/batch=0.92s
14811/10943 (epoch 121.807) train_loss=390.06884766 time/batch=0.89s
14812/10943 (epoch 121.815) train_loss=298.91213989 time/batch=0.72s
14813/10943 (epoch 121.824) train_loss=474.31069946 time/batch=1.08s
14814/10943 (epoch 121.832) train_loss=281.62640381 time/batch=0.73s
14815/10943 (epoch 121.840) train_loss=354.01263428 time/batch=0.86s
14816/10943 (epoch 121.848) train_loss=157.04505920 time/batch=0.41s
14817/10943 (epoch 121.857) train_loss=189.31889343 time/batch=0.45s
14818/10943 (epoch 121.865) train_loss=989.77313232 time/batch=3.03s
14819/10943 (epoch 121.873) train_loss=412.63623047 time/batch=1.19s
14820/10943 (epoch 121.881) train_loss=240.04911804 time/batch=0.63s
14821/10943 (epoch 121.889) train_loss=154.00450134 time/batch=0.37s
14822/10943 (epoch 121.898) train_loss=586.68457031 time/batch=1.33s
14823/10943 (epoch 121.906) train_loss=364.35083008 time/batch=0.92s
14824/10943 (epoch 121.914) train_loss=405.00460815 time/batch=0.96s
14825/10943 (epoch 121.922) train_loss=110.54927063 time/batch=0.33s
14826/10943 (epoch 121.931) train_loss=277.29095459 time/batch=0.66s
14827/10943 (epoch 121.939) train_loss=305.14447021 time/batch=0.70s
14828/10943 (epoch 121.947) train_loss=619.63592529 time/batch=1.57s
14829/10943 (epoch 121.955) train_loss=374.62249756 time/batch=1.01s
14830/10943 (epoch 121.964) train_loss=106.23882294 time/batch=0.34s
14831/10943 (epoch 121.972) train_loss=310.01934814 time/batch=0.68s
14832/10943 (epoch 121.980) train_loss=287.76031494 time/batch=0.67s
14833/10943 (epoch 121.988) train_loss=634.52264404 time/batch=1.63s
14834/10943 (epoch 121.996) train_loss=416.72662354 time/batch=1.05s
14835/10943 (epoch 122.005) train_loss=180.59439087 time/batch=0.48s
14836/10943 (epoch 122.013) train_loss=563.94152832 time/batch=1.62s
14837/10943 (epoch 122.021) train_loss=239.02885437 time/batch=0.70s
14838/10943 (epoch 122.029) train_loss=181.06451416 time/batch=0.45s
14839/10943 (epoch 122.038) train_loss=247.72363281 time/batch=0.58s
14840/10943 (epoch 122.046) train_loss=487.79632568 time/batch=1.10s
14841/10943 (epoch 122.054) train_loss=404.61285400 time/batch=1.01s
14842/10943 (epoch 122.062) train_loss=313.89648438 time/batch=0.79s
14843/10943 (epoch 122.070) train_loss=200.91125488 time/batch=0.52s
14844/10943 (epoch 122.079) train_loss=267.02453613 time/batch=0.63s
14845/10943 (epoch 122.087) train_loss=368.96829224 time/batch=0.87s
14846/10943 (epoch 122.095) train_loss=127.44299316 time/batch=0.35s
14847/10943 (epoch 122.103) train_loss=296.68603516 time/batch=0.67s
14848/10943 (epoch 122.112) train_loss=441.13323975 time/batch=1.04s
14849/10943 (epoch 122.120) train_loss=321.70550537 time/batch=0.80s
14850/10943 (epoch 122.128) train_loss=122.62178040 time/batch=0.35s
14851/10943 (epoch 122.136) train_loss=161.23611450 time/batch=0.39s
14852/10943 (epoch 122.144) train_loss=436.83374023 time/batch=0.94s
14853/10943 (epoch 122.153) train_loss=484.22967529 time/batch=1.19s
14854/10943 (epoch 122.161) train_loss=326.41513062 time/batch=0.85s
14855/10943 (epoch 122.169) train_loss=295.08581543 time/batch=0.73s
14856/10943 (epoch 122.177) train_loss=352.63519287 time/batch=0.83s
14857/10943 (epoch 122.186) train_loss=297.84692383 time/batch=0.75s
14858/10943 (epoch 122.194) train_loss=275.39111328 time/batch=0.68s
14859/10943 (epoch 122.202) train_loss=179.55514526 time/batch=0.47s
14860/10943 (epoch 122.210) train_loss=346.00375366 time/batch=0.83s
14861/10943 (epoch 122.218) train_loss=319.35046387 time/batch=0.82s
14862/10943 (epoch 122.227) train_loss=228.96398926 time/batch=0.59s
14863/10943 (epoch 122.235) train_loss=277.96807861 time/batch=0.63s
14864/10943 (epoch 122.243) train_loss=247.92538452 time/batch=0.58s
14865/10943 (epoch 122.251) train_loss=314.09979248 time/batch=0.77s
14866/10943 (epoch 122.260) train_loss=228.85302734 time/batch=0.58s
14867/10943 (epoch 122.268) train_loss=217.49949646 time/batch=0.53s
14868/10943 (epoch 122.276) train_loss=327.43167114 time/batch=0.79s
14869/10943 (epoch 122.284) train_loss=265.29211426 time/batch=0.64s
14870/10943 (epoch 122.292) train_loss=408.95849609 time/batch=0.97s
14871/10943 (epoch 122.301) train_loss=352.28411865 time/batch=0.92s
14872/10943 (epoch 122.309) train_loss=314.30426025 time/batch=0.81s
14873/10943 (epoch 122.317) train_loss=193.33793640 time/batch=0.49s
14874/10943 (epoch 122.325) train_loss=167.93243408 time/batch=0.40s
14875/10943 (epoch 122.334) train_loss=240.21090698 time/batch=0.60s
14876/10943 (epoch 122.342) train_loss=272.01766968 time/batch=0.67s
14877/10943 (epoch 122.350) train_loss=187.79476929 time/batch=0.49s
14878/10943 (epoch 122.358) train_loss=308.70791626 time/batch=0.73s
14879/10943 (epoch 122.366) train_loss=146.77711487 time/batch=0.39s
14880/10943 (epoch 122.375) train_loss=289.23675537 time/batch=0.69s
14881/10943 (epoch 122.383) train_loss=132.24462891 time/batch=0.36s
14882/10943 (epoch 122.391) train_loss=420.56268311 time/batch=0.95s
14883/10943 (epoch 122.399) train_loss=159.79122925 time/batch=0.44s
14884/10943 (epoch 122.408) train_loss=251.83004761 time/batch=0.59s
14885/10943 (epoch 122.416) train_loss=288.38964844 time/batch=0.72s
14886/10943 (epoch 122.424) train_loss=254.03804016 time/batch=0.64s
14887/10943 (epoch 122.432) train_loss=233.17587280 time/batch=0.59s
14888/10943 (epoch 122.441) train_loss=177.29856873 time/batch=0.47s
14889/10943 (epoch 122.449) train_loss=359.79003906 time/batch=0.86s
14890/10943 (epoch 122.457) train_loss=319.61126709 time/batch=0.82s
14891/10943 (epoch 122.465) train_loss=272.11401367 time/batch=0.67s
14892/10943 (epoch 122.473) train_loss=444.55270386 time/batch=1.00s
14893/10943 (epoch 122.482) train_loss=320.36859131 time/batch=0.81s
14894/10943 (epoch 122.490) train_loss=139.92471313 time/batch=0.37s
14895/10943 (epoch 122.498) train_loss=251.30499268 time/batch=0.59s
14896/10943 (epoch 122.506) train_loss=203.16888428 time/batch=0.52s
14897/10943 (epoch 122.515) train_loss=317.95657349 time/batch=0.76s
14898/10943 (epoch 122.523) train_loss=118.44056702 time/batch=0.35s
14899/10943 (epoch 122.531) train_loss=152.15322876 time/batch=0.37s
14900/10943 (epoch 122.539) train_loss=171.92794800 time/batch=0.46s
14901/10943 (epoch 122.547) train_loss=268.73114014 time/batch=0.63s
14902/10943 (epoch 122.556) train_loss=267.13092041 time/batch=0.65s
14903/10943 (epoch 122.564) train_loss=243.49278259 time/batch=0.60s
14904/10943 (epoch 122.572) train_loss=250.35829163 time/batch=0.68s
14905/10943 (epoch 122.580) train_loss=271.96484375 time/batch=0.73s
14906/10943 (epoch 122.589) train_loss=299.69549561 time/batch=0.79s
14907/10943 (epoch 122.597) train_loss=141.57244873 time/batch=0.38s
14908/10943 (epoch 122.605) train_loss=377.91845703 time/batch=0.96s
14909/10943 (epoch 122.613) train_loss=205.98164368 time/batch=0.58s
14910/10943 (epoch 122.621) train_loss=229.91038513 time/batch=0.57s
14911/10943 (epoch 122.630) train_loss=184.62773132 time/batch=0.49s
14912/10943 (epoch 122.638) train_loss=220.82818604 time/batch=0.53s
14913/10943 (epoch 122.646) train_loss=283.64880371 time/batch=0.77s
14914/10943 (epoch 122.654) train_loss=210.96319580 time/batch=0.52s
14915/10943 (epoch 122.663) train_loss=204.72863770 time/batch=0.50s
14916/10943 (epoch 122.671) train_loss=317.55917358 time/batch=0.98s
14917/10943 (epoch 122.679) train_loss=229.51803589 time/batch=0.61s
14918/10943 (epoch 122.687) train_loss=220.71009827 time/batch=0.55s
14919/10943 (epoch 122.695) train_loss=206.23251343 time/batch=0.51s
setting learning rate to 0.0005127
14920/10943 (epoch 122.704) train_loss=100.22833252 time/batch=0.28s
14921/10943 (epoch 122.712) train_loss=322.70715332 time/batch=0.76s
14922/10943 (epoch 122.720) train_loss=673.73876953 time/batch=1.56s
14923/10943 (epoch 122.728) train_loss=335.98532104 time/batch=0.90s
14924/10943 (epoch 122.737) train_loss=225.45046997 time/batch=0.58s
14925/10943 (epoch 122.745) train_loss=207.16717529 time/batch=0.51s
14926/10943 (epoch 122.753) train_loss=288.70935059 time/batch=0.64s
14927/10943 (epoch 122.761) train_loss=592.35980225 time/batch=1.36s
14928/10943 (epoch 122.769) train_loss=976.62554932 time/batch=3.12s
14929/10943 (epoch 122.778) train_loss=301.22723389 time/batch=0.98s
14930/10943 (epoch 122.786) train_loss=223.11608887 time/batch=0.56s
14931/10943 (epoch 122.794) train_loss=687.95739746 time/batch=1.58s
14932/10943 (epoch 122.802) train_loss=534.78521729 time/batch=1.30s
14933/10943 (epoch 122.811) train_loss=382.76116943 time/batch=0.95s
14934/10943 (epoch 122.819) train_loss=423.93341064 time/batch=1.01s
14935/10943 (epoch 122.827) train_loss=490.72265625 time/batch=1.17s
14936/10943 (epoch 122.835) train_loss=323.28778076 time/batch=0.82s
14937/10943 (epoch 122.843) train_loss=266.24331665 time/batch=0.66s
14938/10943 (epoch 122.852) train_loss=466.66729736 time/batch=1.10s
14939/10943 (epoch 122.860) train_loss=239.38519287 time/batch=0.63s
14940/10943 (epoch 122.868) train_loss=557.06567383 time/batch=1.23s
14941/10943 (epoch 122.876) train_loss=157.63949585 time/batch=0.46s
14942/10943 (epoch 122.885) train_loss=258.81893921 time/batch=0.60s
14943/10943 (epoch 122.893) train_loss=249.13697815 time/batch=0.61s
14944/10943 (epoch 122.901) train_loss=345.64660645 time/batch=0.80s
14945/10943 (epoch 122.909) train_loss=368.98016357 time/batch=0.86s
14946/10943 (epoch 122.918) train_loss=184.13081360 time/batch=0.49s
14947/10943 (epoch 122.926) train_loss=355.33666992 time/batch=0.81s
14948/10943 (epoch 122.934) train_loss=125.23123169 time/batch=0.37s
14949/10943 (epoch 122.942) train_loss=409.31365967 time/batch=0.89s
14950/10943 (epoch 122.950) train_loss=243.25463867 time/batch=0.64s
14951/10943 (epoch 122.959) train_loss=575.05017090 time/batch=1.27s
14952/10943 (epoch 122.967) train_loss=385.60437012 time/batch=0.97s
14953/10943 (epoch 122.975) train_loss=130.09408569 time/batch=0.36s
14954/10943 (epoch 122.983) train_loss=324.28604126 time/batch=0.73s
14955/10943 (epoch 122.992) train_loss=153.13114929 time/batch=0.42s
14956/10943 (epoch 123.000) train_loss=205.47474670 time/batch=0.50s
14957/10943 (epoch 123.008) train_loss=251.14997864 time/batch=0.60s
14958/10943 (epoch 123.016) train_loss=283.38568115 time/batch=0.65s
14959/10943 (epoch 123.024) train_loss=624.64526367 time/batch=1.65s
14960/10943 (epoch 123.033) train_loss=122.99253845 time/batch=0.45s
14961/10943 (epoch 123.041) train_loss=452.41934204 time/batch=0.98s
14962/10943 (epoch 123.049) train_loss=173.68710327 time/batch=0.47s
14963/10943 (epoch 123.057) train_loss=141.51512146 time/batch=0.33s
14964/10943 (epoch 123.066) train_loss=325.78210449 time/batch=0.76s
14965/10943 (epoch 123.074) train_loss=406.89065552 time/batch=0.97s
14966/10943 (epoch 123.082) train_loss=323.04922485 time/batch=0.83s
14967/10943 (epoch 123.090) train_loss=151.60974121 time/batch=0.41s
14968/10943 (epoch 123.098) train_loss=238.90328979 time/batch=0.55s
14969/10943 (epoch 123.107) train_loss=312.76977539 time/batch=0.71s
14970/10943 (epoch 123.115) train_loss=196.72880554 time/batch=0.48s
14971/10943 (epoch 123.123) train_loss=401.79547119 time/batch=0.90s
14972/10943 (epoch 123.131) train_loss=202.76144409 time/batch=0.54s
14973/10943 (epoch 123.140) train_loss=353.14471436 time/batch=0.82s
14974/10943 (epoch 123.148) train_loss=122.41090393 time/batch=0.36s
14975/10943 (epoch 123.156) train_loss=406.97238159 time/batch=0.88s
14976/10943 (epoch 123.164) train_loss=156.99542236 time/batch=0.43s
14977/10943 (epoch 123.172) train_loss=312.87130737 time/batch=0.67s
14978/10943 (epoch 123.181) train_loss=447.25756836 time/batch=0.99s
14979/10943 (epoch 123.189) train_loss=221.79333496 time/batch=0.56s
14980/10943 (epoch 123.197) train_loss=493.39324951 time/batch=1.06s
14981/10943 (epoch 123.205) train_loss=471.59973145 time/batch=1.10s
14982/10943 (epoch 123.214) train_loss=218.87988281 time/batch=0.55s
14983/10943 (epoch 123.222) train_loss=478.64257812 time/batch=0.97s
14984/10943 (epoch 123.230) train_loss=282.05300903 time/batch=0.71s
14985/10943 (epoch 123.238) train_loss=312.98916626 time/batch=0.72s
14986/10943 (epoch 123.246) train_loss=180.87194824 time/batch=0.46s
14987/10943 (epoch 123.255) train_loss=308.55197144 time/batch=0.67s
14988/10943 (epoch 123.263) train_loss=287.05834961 time/batch=0.70s
14989/10943 (epoch 123.271) train_loss=238.86576843 time/batch=0.60s
14990/10943 (epoch 123.279) train_loss=326.87402344 time/batch=0.77s
14991/10943 (epoch 123.288) train_loss=170.03443909 time/batch=0.45s
14992/10943 (epoch 123.296) train_loss=318.36325073 time/batch=0.69s
14993/10943 (epoch 123.304) train_loss=245.76702881 time/batch=0.58s
14994/10943 (epoch 123.312) train_loss=266.36309814 time/batch=0.61s
14995/10943 (epoch 123.320) train_loss=327.12292480 time/batch=0.74s
14996/10943 (epoch 123.329) train_loss=509.64624023 time/batch=1.15s
14997/10943 (epoch 123.337) train_loss=203.67712402 time/batch=0.54s
14998/10943 (epoch 123.345) train_loss=327.67858887 time/batch=0.79s
14999/10943 (epoch 123.353) train_loss=411.90435791 time/batch=0.96s
Validating
    loss:	293.809550

15000/10943 (epoch 123.362) train_loss=215.15455627 time/batch=2.33s
15001/10943 (epoch 123.370) train_loss=473.13867188 time/batch=1.13s
15002/10943 (epoch 123.378) train_loss=169.21539307 time/batch=0.49s
15003/10943 (epoch 123.386) train_loss=335.42483521 time/batch=0.73s
15004/10943 (epoch 123.395) train_loss=290.19781494 time/batch=0.69s
15005/10943 (epoch 123.403) train_loss=283.49920654 time/batch=0.67s
15006/10943 (epoch 123.411) train_loss=372.28405762 time/batch=0.86s
15007/10943 (epoch 123.419) train_loss=197.45687866 time/batch=0.51s
15008/10943 (epoch 123.427) train_loss=256.16690063 time/batch=0.59s
15009/10943 (epoch 123.436) train_loss=293.32012939 time/batch=0.66s
15010/10943 (epoch 123.444) train_loss=247.54365540 time/batch=0.61s
15011/10943 (epoch 123.452) train_loss=354.02569580 time/batch=0.81s
15012/10943 (epoch 123.460) train_loss=363.50515747 time/batch=0.87s
15013/10943 (epoch 123.469) train_loss=386.66793823 time/batch=0.89s
15014/10943 (epoch 123.477) train_loss=232.91369629 time/batch=0.58s
15015/10943 (epoch 123.485) train_loss=244.83657837 time/batch=0.57s
15016/10943 (epoch 123.493) train_loss=309.73327637 time/batch=0.72s
15017/10943 (epoch 123.501) train_loss=320.59057617 time/batch=0.77s
15018/10943 (epoch 123.510) train_loss=413.25500488 time/batch=0.97s
15019/10943 (epoch 123.518) train_loss=265.23809814 time/batch=0.67s
15020/10943 (epoch 123.526) train_loss=279.62683105 time/batch=0.63s
15021/10943 (epoch 123.534) train_loss=324.69326782 time/batch=0.77s
15022/10943 (epoch 123.543) train_loss=406.59127808 time/batch=1.01s
15023/10943 (epoch 123.551) train_loss=172.04595947 time/batch=0.49s
15024/10943 (epoch 123.559) train_loss=128.09248352 time/batch=0.32s
15025/10943 (epoch 123.567) train_loss=317.82745361 time/batch=0.74s
15026/10943 (epoch 123.575) train_loss=288.72491455 time/batch=0.68s
15027/10943 (epoch 123.584) train_loss=210.49179077 time/batch=0.50s
15028/10943 (epoch 123.592) train_loss=252.16098022 time/batch=0.56s
15029/10943 (epoch 123.600) train_loss=150.65676880 time/batch=0.37s
15030/10943 (epoch 123.608) train_loss=184.81072998 time/batch=0.43s
15031/10943 (epoch 123.617) train_loss=238.56483459 time/batch=0.56s
15032/10943 (epoch 123.625) train_loss=190.01208496 time/batch=0.49s
15033/10943 (epoch 123.633) train_loss=259.27545166 time/batch=0.64s
15034/10943 (epoch 123.641) train_loss=355.41162109 time/batch=0.82s
15035/10943 (epoch 123.649) train_loss=303.25018311 time/batch=0.75s
15036/10943 (epoch 123.658) train_loss=305.79345703 time/batch=0.79s
15037/10943 (epoch 123.666) train_loss=145.19027710 time/batch=0.38s
15038/10943 (epoch 123.674) train_loss=232.63323975 time/batch=0.56s
15039/10943 (epoch 123.682) train_loss=231.45120239 time/batch=0.57s
15040/10943 (epoch 123.691) train_loss=260.91534424 time/batch=0.67s
setting learning rate to 0.0004973
  saved to metadata/gru_dropout-9_nov_folkwiki-20181207-173447_epoch79.pkl
15041/10943 (epoch 123.699) train_loss=602.56152344 time/batch=1.32s
15042/10943 (epoch 123.707) train_loss=490.21011353 time/batch=1.17s
15043/10943 (epoch 123.715) train_loss=381.11468506 time/batch=0.91s
15044/10943 (epoch 123.723) train_loss=221.30053711 time/batch=0.54s
15045/10943 (epoch 123.732) train_loss=217.08007812 time/batch=0.50s
15046/10943 (epoch 123.740) train_loss=326.87017822 time/batch=0.75s
15047/10943 (epoch 123.748) train_loss=115.36342621 time/batch=0.32s
15048/10943 (epoch 123.756) train_loss=699.36303711 time/batch=1.50s
15049/10943 (epoch 123.765) train_loss=312.46411133 time/batch=0.82s
15050/10943 (epoch 123.773) train_loss=465.46203613 time/batch=1.02s
15051/10943 (epoch 123.781) train_loss=495.92218018 time/batch=1.17s
15052/10943 (epoch 123.789) train_loss=577.73846436 time/batch=1.32s
15053/10943 (epoch 123.797) train_loss=286.01547241 time/batch=0.72s
15054/10943 (epoch 123.806) train_loss=180.22470093 time/batch=0.45s
15055/10943 (epoch 123.814) train_loss=1015.74072266 time/batch=3.04s
15056/10943 (epoch 123.822) train_loss=411.72503662 time/batch=1.16s
15057/10943 (epoch 123.830) train_loss=695.83935547 time/batch=1.60s
15058/10943 (epoch 123.839) train_loss=484.62500000 time/batch=1.15s
15059/10943 (epoch 123.847) train_loss=509.91390991 time/batch=1.12s
15060/10943 (epoch 123.855) train_loss=564.28228760 time/batch=1.22s
15061/10943 (epoch 123.863) train_loss=225.14239502 time/batch=0.58s
15062/10943 (epoch 123.871) train_loss=299.71435547 time/batch=0.67s
15063/10943 (epoch 123.880) train_loss=358.48114014 time/batch=0.83s
15064/10943 (epoch 123.888) train_loss=468.77569580 time/batch=0.99s
15065/10943 (epoch 123.896) train_loss=162.26818848 time/batch=0.45s
15066/10943 (epoch 123.904) train_loss=143.12158203 time/batch=0.32s
15067/10943 (epoch 123.913) train_loss=325.64157104 time/batch=0.70s
15068/10943 (epoch 123.921) train_loss=486.18750000 time/batch=1.13s
15069/10943 (epoch 123.929) train_loss=440.41168213 time/batch=0.99s
15070/10943 (epoch 123.937) train_loss=161.55505371 time/batch=0.43s
15071/10943 (epoch 123.946) train_loss=429.46575928 time/batch=0.89s
15072/10943 (epoch 123.954) train_loss=233.01820374 time/batch=0.57s
15073/10943 (epoch 123.962) train_loss=296.36740112 time/batch=0.65s
15074/10943 (epoch 123.970) train_loss=339.01806641 time/batch=0.80s
15075/10943 (epoch 123.978) train_loss=302.44360352 time/batch=0.67s
15076/10943 (epoch 123.987) train_loss=704.28558350 time/batch=1.65s
15077/10943 (epoch 123.995) train_loss=346.91094971 time/batch=0.92s
15078/10943 (epoch 124.003) train_loss=421.22247314 time/batch=0.94s
15079/10943 (epoch 124.011) train_loss=407.38964844 time/batch=0.93s
15080/10943 (epoch 124.020) train_loss=561.80499268 time/batch=1.30s
15081/10943 (epoch 124.028) train_loss=347.48059082 time/batch=0.85s
15082/10943 (epoch 124.036) train_loss=446.33450317 time/batch=0.97s
15083/10943 (epoch 124.044) train_loss=226.99508667 time/batch=0.53s
15084/10943 (epoch 124.052) train_loss=465.62286377 time/batch=0.96s
15085/10943 (epoch 124.061) train_loss=526.88195801 time/batch=1.32s
15086/10943 (epoch 124.069) train_loss=423.78668213 time/batch=0.92s
15087/10943 (epoch 124.077) train_loss=426.55670166 time/batch=0.92s
15088/10943 (epoch 124.085) train_loss=188.25064087 time/batch=0.44s
15089/10943 (epoch 124.094) train_loss=319.36608887 time/batch=0.63s
15090/10943 (epoch 124.102) train_loss=287.87390137 time/batch=0.61s
15091/10943 (epoch 124.110) train_loss=437.49670410 time/batch=0.86s
15092/10943 (epoch 124.118) train_loss=592.40979004 time/batch=1.35s
15093/10943 (epoch 124.126) train_loss=394.20513916 time/batch=0.90s
15094/10943 (epoch 124.135) train_loss=298.02395630 time/batch=0.66s
15095/10943 (epoch 124.143) train_loss=218.01977539 time/batch=0.47s
15096/10943 (epoch 124.151) train_loss=358.95367432 time/batch=0.73s
15097/10943 (epoch 124.159) train_loss=247.64007568 time/batch=0.56s
15098/10943 (epoch 124.168) train_loss=338.69409180 time/batch=0.73s
15099/10943 (epoch 124.176) train_loss=292.00463867 time/batch=0.64s
15100/10943 (epoch 124.184) train_loss=112.82395935 time/batch=0.31s
15101/10943 (epoch 124.192) train_loss=155.26930237 time/batch=0.34s
15102/10943 (epoch 124.200) train_loss=238.05438232 time/batch=0.50s
15103/10943 (epoch 124.209) train_loss=135.20764160 time/batch=0.32s
15104/10943 (epoch 124.217) train_loss=196.55047607 time/batch=0.41s
15105/10943 (epoch 124.225) train_loss=256.44494629 time/batch=0.56s
15106/10943 (epoch 124.233) train_loss=404.31628418 time/batch=0.88s
15107/10943 (epoch 124.242) train_loss=272.52044678 time/batch=0.63s
15108/10943 (epoch 124.250) train_loss=302.99655151 time/batch=0.66s
15109/10943 (epoch 124.258) train_loss=249.27702332 time/batch=0.57s
15110/10943 (epoch 124.266) train_loss=201.12551880 time/batch=0.45s
15111/10943 (epoch 124.274) train_loss=220.07032776 time/batch=0.48s
15112/10943 (epoch 124.283) train_loss=282.96881104 time/batch=0.60s
15113/10943 (epoch 124.291) train_loss=174.40077209 time/batch=0.42s
15114/10943 (epoch 124.299) train_loss=282.03979492 time/batch=0.60s
15115/10943 (epoch 124.307) train_loss=366.17169189 time/batch=0.76s
15116/10943 (epoch 124.316) train_loss=180.84512329 time/batch=0.44s
15117/10943 (epoch 124.324) train_loss=363.99627686 time/batch=0.75s
15118/10943 (epoch 124.332) train_loss=346.03445435 time/batch=0.73s
15119/10943 (epoch 124.340) train_loss=133.78021240 time/batch=0.33s
15120/10943 (epoch 124.348) train_loss=379.19476318 time/batch=0.78s
15121/10943 (epoch 124.357) train_loss=389.79937744 time/batch=0.83s
15122/10943 (epoch 124.365) train_loss=302.31457520 time/batch=0.65s
15123/10943 (epoch 124.373) train_loss=321.31954956 time/batch=0.67s
15124/10943 (epoch 124.381) train_loss=244.18576050 time/batch=0.55s
15125/10943 (epoch 124.390) train_loss=302.86645508 time/batch=0.68s
15126/10943 (epoch 124.398) train_loss=258.54248047 time/batch=0.57s
15127/10943 (epoch 124.406) train_loss=264.13693237 time/batch=0.56s
15128/10943 (epoch 124.414) train_loss=365.95849609 time/batch=0.77s
15129/10943 (epoch 124.423) train_loss=373.32556152 time/batch=0.81s
15130/10943 (epoch 124.431) train_loss=285.24615479 time/batch=0.60s
15131/10943 (epoch 124.439) train_loss=223.97335815 time/batch=0.48s
15132/10943 (epoch 124.447) train_loss=378.20117188 time/batch=0.77s
15133/10943 (epoch 124.455) train_loss=283.72180176 time/batch=0.64s
15134/10943 (epoch 124.464) train_loss=274.63549805 time/batch=0.59s
15135/10943 (epoch 124.472) train_loss=429.82153320 time/batch=0.81s
15136/10943 (epoch 124.480) train_loss=174.85276794 time/batch=0.40s
15137/10943 (epoch 124.488) train_loss=345.01132202 time/batch=0.68s
15138/10943 (epoch 124.497) train_loss=345.12646484 time/batch=0.74s
15139/10943 (epoch 124.505) train_loss=332.79818726 time/batch=0.70s
15140/10943 (epoch 124.513) train_loss=355.88952637 time/batch=0.75s
15141/10943 (epoch 124.521) train_loss=410.25531006 time/batch=0.91s
15142/10943 (epoch 124.529) train_loss=327.08172607 time/batch=0.69s
15143/10943 (epoch 124.538) train_loss=516.70336914 time/batch=1.00s
15144/10943 (epoch 124.546) train_loss=290.27185059 time/batch=0.64s
15145/10943 (epoch 124.554) train_loss=363.69912720 time/batch=0.74s
15146/10943 (epoch 124.562) train_loss=276.75579834 time/batch=0.60s
15147/10943 (epoch 124.571) train_loss=271.08163452 time/batch=0.58s
15148/10943 (epoch 124.579) train_loss=202.96498108 time/batch=0.46s
15149/10943 (epoch 124.587) train_loss=294.76144409 time/batch=0.61s
15150/10943 (epoch 124.595) train_loss=219.39141846 time/batch=0.47s
15151/10943 (epoch 124.603) train_loss=215.92703247 time/batch=0.46s
15152/10943 (epoch 124.612) train_loss=413.51461792 time/batch=0.92s
15153/10943 (epoch 124.620) train_loss=164.41708374 time/batch=0.42s
15154/10943 (epoch 124.628) train_loss=194.64921570 time/batch=0.45s
15155/10943 (epoch 124.636) train_loss=144.25180054 time/batch=0.33s
15156/10943 (epoch 124.645) train_loss=249.45916748 time/batch=0.55s
15157/10943 (epoch 124.653) train_loss=144.44560242 time/batch=0.37s
15158/10943 (epoch 124.661) train_loss=324.19207764 time/batch=0.67s
15159/10943 (epoch 124.669) train_loss=358.85705566 time/batch=0.72s
15160/10943 (epoch 124.677) train_loss=263.52062988 time/batch=0.60s
15161/10943 (epoch 124.686) train_loss=261.35473633 time/batch=0.69s
setting learning rate to 0.0004824
15162/10943 (epoch 124.694) train_loss=361.43710327 time/batch=0.70s
15163/10943 (epoch 124.702) train_loss=287.93411255 time/batch=0.61s
15164/10943 (epoch 124.710) train_loss=707.97137451 time/batch=1.39s
15165/10943 (epoch 124.719) train_loss=591.14862061 time/batch=1.22s
15166/10943 (epoch 124.727) train_loss=530.48431396 time/batch=1.06s
15167/10943 (epoch 124.735) train_loss=1051.90356445 time/batch=2.38s
15168/10943 (epoch 124.743) train_loss=146.05316162 time/batch=0.53s
15169/10943 (epoch 124.751) train_loss=290.58041382 time/batch=0.57s
15170/10943 (epoch 124.760) train_loss=855.95678711 time/batch=1.60s
15171/10943 (epoch 124.768) train_loss=616.94885254 time/batch=1.31s
15172/10943 (epoch 124.776) train_loss=720.58935547 time/batch=1.52s
15173/10943 (epoch 124.784) train_loss=194.40290833 time/batch=0.52s
15174/10943 (epoch 124.793) train_loss=541.05603027 time/batch=1.03s
15175/10943 (epoch 124.801) train_loss=165.65765381 time/batch=0.41s
15176/10943 (epoch 124.809) train_loss=356.90829468 time/batch=0.71s
15177/10943 (epoch 124.817) train_loss=166.66267395 time/batch=0.39s
15178/10943 (epoch 124.825) train_loss=425.21084595 time/batch=0.80s
15179/10943 (epoch 124.834) train_loss=333.14202881 time/batch=0.71s
15180/10943 (epoch 124.842) train_loss=408.19204712 time/batch=0.85s
15181/10943 (epoch 124.850) train_loss=383.48797607 time/batch=0.82s
15182/10943 (epoch 124.858) train_loss=552.65545654 time/batch=1.11s
15183/10943 (epoch 124.867) train_loss=133.69342041 time/batch=0.36s
15184/10943 (epoch 124.875) train_loss=212.94131470 time/batch=0.41s
15185/10943 (epoch 124.883) train_loss=353.03747559 time/batch=0.70s
15186/10943 (epoch 124.891) train_loss=127.20850372 time/batch=0.33s
15187/10943 (epoch 124.900) train_loss=286.64666748 time/batch=0.58s
15188/10943 (epoch 124.908) train_loss=212.14297485 time/batch=0.46s
15189/10943 (epoch 124.916) train_loss=553.85504150 time/batch=1.03s
15190/10943 (epoch 124.924) train_loss=590.40203857 time/batch=1.20s
15191/10943 (epoch 124.932) train_loss=498.39233398 time/batch=1.03s
15192/10943 (epoch 124.941) train_loss=360.91046143 time/batch=0.78s
15193/10943 (epoch 124.949) train_loss=378.01428223 time/batch=0.78s
15194/10943 (epoch 124.957) train_loss=822.65301514 time/batch=3.07s
15195/10943 (epoch 124.965) train_loss=383.22583008 time/batch=1.04s
15196/10943 (epoch 124.974) train_loss=383.78698730 time/batch=0.80s
15197/10943 (epoch 124.982) train_loss=157.22692871 time/batch=0.35s
15198/10943 (epoch 124.990) train_loss=528.32885742 time/batch=0.97s
15199/10943 (epoch 124.998) train_loss=123.63409424 time/batch=0.38s
15200/10943 (epoch 125.006) train_loss=380.46844482 time/batch=0.71s
15201/10943 (epoch 125.015) train_loss=357.40563965 time/batch=0.76s
15202/10943 (epoch 125.023) train_loss=568.97747803 time/batch=1.22s
15203/10943 (epoch 125.031) train_loss=672.21899414 time/batch=1.32s
15204/10943 (epoch 125.039) train_loss=256.87390137 time/batch=0.62s
15205/10943 (epoch 125.048) train_loss=310.89672852 time/batch=0.62s
15206/10943 (epoch 125.056) train_loss=197.27917480 time/batch=0.44s
15207/10943 (epoch 125.064) train_loss=350.61386108 time/batch=0.68s
15208/10943 (epoch 125.072) train_loss=458.03100586 time/batch=0.93s
15209/10943 (epoch 125.080) train_loss=291.79437256 time/batch=0.64s
15210/10943 (epoch 125.089) train_loss=468.73345947 time/batch=0.95s
15211/10943 (epoch 125.097) train_loss=375.99359131 time/batch=0.81s
15212/10943 (epoch 125.105) train_loss=424.49151611 time/batch=0.86s
15213/10943 (epoch 125.113) train_loss=176.18420410 time/batch=0.43s
15214/10943 (epoch 125.122) train_loss=320.14334106 time/batch=0.64s
15215/10943 (epoch 125.130) train_loss=579.32122803 time/batch=1.26s
15216/10943 (epoch 125.138) train_loss=417.36602783 time/batch=0.92s
15217/10943 (epoch 125.146) train_loss=191.28807068 time/batch=0.45s
15218/10943 (epoch 125.154) train_loss=287.48046875 time/batch=0.55s
15219/10943 (epoch 125.163) train_loss=477.47015381 time/batch=0.92s
15220/10943 (epoch 125.171) train_loss=145.82574463 time/batch=0.38s
15221/10943 (epoch 125.179) train_loss=432.35629272 time/batch=0.82s
15222/10943 (epoch 125.187) train_loss=433.20901489 time/batch=0.89s
15223/10943 (epoch 125.196) train_loss=172.41545105 time/batch=0.40s
15224/10943 (epoch 125.204) train_loss=496.80407715 time/batch=0.99s
15225/10943 (epoch 125.212) train_loss=280.64245605 time/batch=0.65s
15226/10943 (epoch 125.220) train_loss=323.60369873 time/batch=0.65s
15227/10943 (epoch 125.228) train_loss=375.61413574 time/batch=0.78s
15228/10943 (epoch 125.237) train_loss=255.03176880 time/batch=0.56s
15229/10943 (epoch 125.245) train_loss=236.96218872 time/batch=0.53s
15230/10943 (epoch 125.253) train_loss=467.78613281 time/batch=0.92s
15231/10943 (epoch 125.261) train_loss=328.35562134 time/batch=0.70s
15232/10943 (epoch 125.270) train_loss=277.92620850 time/batch=0.58s
15233/10943 (epoch 125.278) train_loss=289.41876221 time/batch=0.59s
15234/10943 (epoch 125.286) train_loss=361.20217896 time/batch=0.76s
15235/10943 (epoch 125.294) train_loss=156.80355835 time/batch=0.38s
15236/10943 (epoch 125.302) train_loss=271.35226440 time/batch=0.55s
15237/10943 (epoch 125.311) train_loss=329.22760010 time/batch=0.68s
15238/10943 (epoch 125.319) train_loss=224.99850464 time/batch=0.49s
15239/10943 (epoch 125.327) train_loss=401.56323242 time/batch=0.80s
15240/10943 (epoch 125.335) train_loss=352.39178467 time/batch=0.74s
15241/10943 (epoch 125.344) train_loss=399.81811523 time/batch=0.82s
15242/10943 (epoch 125.352) train_loss=276.76797485 time/batch=0.61s
15243/10943 (epoch 125.360) train_loss=365.63909912 time/batch=0.77s
15244/10943 (epoch 125.368) train_loss=307.78204346 time/batch=0.66s
15245/10943 (epoch 125.377) train_loss=333.90451050 time/batch=0.67s
15246/10943 (epoch 125.385) train_loss=445.62820435 time/batch=0.88s
15247/10943 (epoch 125.393) train_loss=182.44519043 time/batch=0.44s
15248/10943 (epoch 125.401) train_loss=408.87994385 time/batch=0.79s
15249/10943 (epoch 125.409) train_loss=228.39489746 time/batch=0.52s
15250/10943 (epoch 125.418) train_loss=179.47448730 time/batch=0.37s
15251/10943 (epoch 125.426) train_loss=262.89202881 time/batch=0.52s
15252/10943 (epoch 125.434) train_loss=440.85580444 time/batch=0.89s
15253/10943 (epoch 125.442) train_loss=422.67669678 time/batch=0.88s
15254/10943 (epoch 125.451) train_loss=476.30123901 time/batch=0.97s
15255/10943 (epoch 125.459) train_loss=270.47088623 time/batch=0.59s
15256/10943 (epoch 125.467) train_loss=228.85623169 time/batch=0.46s
15257/10943 (epoch 125.475) train_loss=182.07733154 time/batch=0.43s
15258/10943 (epoch 125.483) train_loss=224.46151733 time/batch=0.44s
15259/10943 (epoch 125.492) train_loss=268.65844727 time/batch=0.54s
15260/10943 (epoch 125.500) train_loss=427.47906494 time/batch=0.88s
15261/10943 (epoch 125.508) train_loss=369.52505493 time/batch=0.80s
15262/10943 (epoch 125.516) train_loss=240.31636047 time/batch=0.52s
15263/10943 (epoch 125.525) train_loss=491.61425781 time/batch=0.94s
15264/10943 (epoch 125.533) train_loss=336.38735962 time/batch=0.69s
15265/10943 (epoch 125.541) train_loss=241.38055420 time/batch=0.51s
15266/10943 (epoch 125.549) train_loss=298.75195312 time/batch=0.60s
15267/10943 (epoch 125.557) train_loss=216.31266785 time/batch=0.48s
15268/10943 (epoch 125.566) train_loss=257.52420044 time/batch=0.54s
15269/10943 (epoch 125.574) train_loss=381.56069946 time/batch=0.78s
15270/10943 (epoch 125.582) train_loss=315.36102295 time/batch=0.66s
15271/10943 (epoch 125.590) train_loss=392.50088501 time/batch=0.80s
15272/10943 (epoch 125.599) train_loss=356.65298462 time/batch=0.80s
15273/10943 (epoch 125.607) train_loss=244.11058044 time/batch=0.54s
15274/10943 (epoch 125.615) train_loss=275.61407471 time/batch=0.57s
15275/10943 (epoch 125.623) train_loss=264.42211914 time/batch=0.58s
15276/10943 (epoch 125.631) train_loss=330.87353516 time/batch=0.69s
15277/10943 (epoch 125.640) train_loss=310.25543213 time/batch=0.64s
15278/10943 (epoch 125.648) train_loss=259.18554688 time/batch=0.59s
15279/10943 (epoch 125.656) train_loss=231.96356201 time/batch=0.49s
15280/10943 (epoch 125.664) train_loss=251.46258545 time/batch=0.60s
15281/10943 (epoch 125.673) train_loss=221.07038879 time/batch=0.62s
15282/10943 (epoch 125.681) train_loss=322.81488037 time/batch=0.70s
setting learning rate to 0.0004679
  saved to metadata/gru_dropout-9_nov_folkwiki-20181207-173447_epoch81.pkl
15283/10943 (epoch 125.689) train_loss=396.02392578 time/batch=0.90s
15284/10943 (epoch 125.697) train_loss=697.58752441 time/batch=1.33s
15285/10943 (epoch 125.705) train_loss=1135.35351562 time/batch=3.12s
15286/10943 (epoch 125.714) train_loss=628.58734131 time/batch=1.45s
15287/10943 (epoch 125.722) train_loss=798.92108154 time/batch=1.62s
15288/10943 (epoch 125.730) train_loss=626.38549805 time/batch=1.30s
15289/10943 (epoch 125.738) train_loss=449.70556641 time/batch=0.95s
15290/10943 (epoch 125.747) train_loss=375.68908691 time/batch=0.77s
15291/10943 (epoch 125.755) train_loss=547.99780273 time/batch=1.12s
15292/10943 (epoch 125.763) train_loss=520.57757568 time/batch=1.02s
15293/10943 (epoch 125.771) train_loss=268.81906128 time/batch=0.60s
15294/10943 (epoch 125.779) train_loss=164.39126587 time/batch=0.36s
15295/10943 (epoch 125.788) train_loss=255.49615479 time/batch=0.51s
15296/10943 (epoch 125.796) train_loss=202.98913574 time/batch=0.43s
15297/10943 (epoch 125.804) train_loss=847.97247314 time/batch=1.63s
15298/10943 (epoch 125.812) train_loss=370.58856201 time/batch=0.85s
15299/10943 (epoch 125.821) train_loss=286.30694580 time/batch=0.60s
15300/10943 (epoch 125.829) train_loss=552.74914551 time/batch=1.11s
15301/10943 (epoch 125.837) train_loss=509.82220459 time/batch=1.05s
15302/10943 (epoch 125.845) train_loss=384.88922119 time/batch=0.79s
15303/10943 (epoch 125.854) train_loss=663.99121094 time/batch=1.25s
15304/10943 (epoch 125.862) train_loss=363.70562744 time/batch=0.78s
15305/10943 (epoch 125.870) train_loss=225.03642273 time/batch=0.49s
15306/10943 (epoch 125.878) train_loss=697.51672363 time/batch=1.38s
15307/10943 (epoch 125.886) train_loss=343.66732788 time/batch=0.80s
15308/10943 (epoch 125.895) train_loss=145.21316528 time/batch=0.35s
15309/10943 (epoch 125.903) train_loss=197.08422852 time/batch=0.40s
15310/10943 (epoch 125.911) train_loss=446.23022461 time/batch=0.85s
15311/10943 (epoch 125.919) train_loss=226.55303955 time/batch=0.51s
15312/10943 (epoch 125.928) train_loss=324.15734863 time/batch=0.62s
15313/10943 (epoch 125.936) train_loss=461.04510498 time/batch=0.92s
15314/10943 (epoch 125.944) train_loss=447.81353760 time/batch=0.91s
15315/10943 (epoch 125.952) train_loss=359.00952148 time/batch=0.76s
15316/10943 (epoch 125.960) train_loss=492.84231567 time/batch=0.94s
15317/10943 (epoch 125.969) train_loss=551.41870117 time/batch=1.07s
15318/10943 (epoch 125.977) train_loss=218.19926453 time/batch=0.51s
15319/10943 (epoch 125.985) train_loss=178.28063965 time/batch=0.37s
15320/10943 (epoch 125.993) train_loss=292.73330688 time/batch=0.58s
15321/10943 (epoch 126.002) train_loss=325.64062500 time/batch=0.65s
15322/10943 (epoch 126.010) train_loss=266.99322510 time/batch=0.55s
15323/10943 (epoch 126.018) train_loss=193.17680359 time/batch=0.43s
15324/10943 (epoch 126.026) train_loss=308.08758545 time/batch=0.60s
15325/10943 (epoch 126.034) train_loss=537.79858398 time/batch=0.99s
15326/10943 (epoch 126.043) train_loss=479.00408936 time/batch=0.99s
15327/10943 (epoch 126.051) train_loss=383.28173828 time/batch=0.79s
15328/10943 (epoch 126.059) train_loss=285.64764404 time/batch=0.60s
15329/10943 (epoch 126.067) train_loss=300.29568481 time/batch=0.61s
15330/10943 (epoch 126.076) train_loss=595.12744141 time/batch=1.13s
15331/10943 (epoch 126.084) train_loss=285.08026123 time/batch=0.65s
15332/10943 (epoch 126.092) train_loss=146.64202881 time/batch=0.32s
15333/10943 (epoch 126.100) train_loss=157.88269043 time/batch=0.33s
15334/10943 (epoch 126.108) train_loss=494.92446899 time/batch=0.94s
15335/10943 (epoch 126.117) train_loss=333.65988159 time/batch=0.71s
15336/10943 (epoch 126.125) train_loss=250.72023010 time/batch=0.53s
15337/10943 (epoch 126.133) train_loss=296.75842285 time/batch=0.59s
15338/10943 (epoch 126.141) train_loss=164.50845337 time/batch=0.37s
15339/10943 (epoch 126.150) train_loss=227.24617004 time/batch=0.46s
15340/10943 (epoch 126.158) train_loss=176.07315063 time/batch=0.38s
15341/10943 (epoch 126.166) train_loss=391.55105591 time/batch=0.77s
15342/10943 (epoch 126.174) train_loss=285.93829346 time/batch=0.62s
15343/10943 (epoch 126.182) train_loss=565.48968506 time/batch=1.12s
15344/10943 (epoch 126.191) train_loss=431.74002075 time/batch=0.90s
15345/10943 (epoch 126.199) train_loss=628.13922119 time/batch=1.42s
15346/10943 (epoch 126.207) train_loss=418.02865601 time/batch=0.91s
15347/10943 (epoch 126.215) train_loss=211.50050354 time/batch=0.46s
15348/10943 (epoch 126.224) train_loss=383.74957275 time/batch=0.76s
15349/10943 (epoch 126.232) train_loss=126.84680939 time/batch=0.33s
15350/10943 (epoch 126.240) train_loss=266.60110474 time/batch=0.52s
15351/10943 (epoch 126.248) train_loss=375.98712158 time/batch=0.76s
15352/10943 (epoch 126.256) train_loss=482.54193115 time/batch=0.93s
15353/10943 (epoch 126.265) train_loss=355.73406982 time/batch=0.78s
15354/10943 (epoch 126.273) train_loss=353.37567139 time/batch=0.73s
15355/10943 (epoch 126.281) train_loss=348.31454468 time/batch=0.70s
15356/10943 (epoch 126.289) train_loss=434.17248535 time/batch=0.87s
15357/10943 (epoch 126.298) train_loss=505.25186157 time/batch=1.05s
15358/10943 (epoch 126.306) train_loss=272.65570068 time/batch=0.62s
15359/10943 (epoch 126.314) train_loss=146.91461182 time/batch=0.36s
15360/10943 (epoch 126.322) train_loss=237.65716553 time/batch=0.50s
15361/10943 (epoch 126.331) train_loss=453.94198608 time/batch=1.00s
15362/10943 (epoch 126.339) train_loss=257.40374756 time/batch=0.60s
15363/10943 (epoch 126.347) train_loss=363.17828369 time/batch=0.74s
15364/10943 (epoch 126.355) train_loss=115.30435181 time/batch=0.32s
15365/10943 (epoch 126.363) train_loss=442.40875244 time/batch=0.84s
15366/10943 (epoch 126.372) train_loss=420.34002686 time/batch=0.86s
15367/10943 (epoch 126.380) train_loss=274.20166016 time/batch=0.60s
15368/10943 (epoch 126.388) train_loss=303.00939941 time/batch=0.62s
15369/10943 (epoch 126.396) train_loss=380.46813965 time/batch=0.77s
15370/10943 (epoch 126.405) train_loss=193.05673218 time/batch=0.48s
15371/10943 (epoch 126.413) train_loss=254.28985596 time/batch=0.56s
15372/10943 (epoch 126.421) train_loss=407.65512085 time/batch=0.83s
15373/10943 (epoch 126.429) train_loss=329.35217285 time/batch=0.71s
15374/10943 (epoch 126.437) train_loss=155.13945007 time/batch=0.38s
15375/10943 (epoch 126.446) train_loss=231.42164612 time/batch=0.47s
15376/10943 (epoch 126.454) train_loss=402.59048462 time/batch=0.79s
15377/10943 (epoch 126.462) train_loss=412.77798462 time/batch=0.87s
15378/10943 (epoch 126.470) train_loss=384.79727173 time/batch=0.80s
15379/10943 (epoch 126.479) train_loss=248.11154175 time/batch=0.52s
15380/10943 (epoch 126.487) train_loss=292.94036865 time/batch=0.59s
15381/10943 (epoch 126.495) train_loss=329.16714478 time/batch=0.68s
15382/10943 (epoch 126.503) train_loss=182.27740479 time/batch=0.41s
15383/10943 (epoch 126.511) train_loss=275.02264404 time/batch=0.56s
15384/10943 (epoch 126.520) train_loss=409.95080566 time/batch=0.86s
15385/10943 (epoch 126.528) train_loss=387.62957764 time/batch=0.82s
15386/10943 (epoch 126.536) train_loss=347.35726929 time/batch=0.72s
15387/10943 (epoch 126.544) train_loss=366.36297607 time/batch=0.77s
15388/10943 (epoch 126.553) train_loss=332.47222900 time/batch=0.66s
15389/10943 (epoch 126.561) train_loss=333.43804932 time/batch=0.67s
15390/10943 (epoch 126.569) train_loss=210.11447144 time/batch=0.46s
15391/10943 (epoch 126.577) train_loss=304.16064453 time/batch=0.61s
15392/10943 (epoch 126.585) train_loss=318.97686768 time/batch=0.63s
15393/10943 (epoch 126.594) train_loss=236.35134888 time/batch=0.52s
15394/10943 (epoch 126.602) train_loss=168.09487915 time/batch=0.37s
15395/10943 (epoch 126.610) train_loss=198.09617615 time/batch=0.44s
15396/10943 (epoch 126.618) train_loss=379.24935913 time/batch=0.77s
15397/10943 (epoch 126.627) train_loss=383.37509155 time/batch=0.82s
15398/10943 (epoch 126.635) train_loss=234.34700012 time/batch=0.52s
15399/10943 (epoch 126.643) train_loss=228.93679810 time/batch=0.57s
15400/10943 (epoch 126.651) train_loss=339.60290527 time/batch=0.67s
15401/10943 (epoch 126.659) train_loss=334.14263916 time/batch=0.68s
15402/10943 (epoch 126.668) train_loss=288.09710693 time/batch=0.62s
15403/10943 (epoch 126.676) train_loss=312.78036499 time/batch=0.65s
setting learning rate to 0.0004539
15404/10943 (epoch 126.684) train_loss=442.87042236 time/batch=0.89s
15405/10943 (epoch 126.692) train_loss=693.52746582 time/batch=1.39s
15406/10943 (epoch 126.701) train_loss=707.62829590 time/batch=1.45s
15407/10943 (epoch 126.709) train_loss=456.87753296 time/batch=0.96s
15408/10943 (epoch 126.717) train_loss=329.66949463 time/batch=0.71s
15409/10943 (epoch 126.725) train_loss=258.30224609 time/batch=0.56s
15410/10943 (epoch 126.733) train_loss=327.56457520 time/batch=0.64s
15411/10943 (epoch 126.742) train_loss=380.80627441 time/batch=0.81s
15412/10943 (epoch 126.750) train_loss=217.50878906 time/batch=0.49s
15413/10943 (epoch 126.758) train_loss=160.36773682 time/batch=0.34s
15414/10943 (epoch 126.766) train_loss=848.77764893 time/batch=1.60s
15415/10943 (epoch 126.775) train_loss=1070.92163086 time/batch=2.44s
15416/10943 (epoch 126.783) train_loss=305.34594727 time/batch=0.81s
15417/10943 (epoch 126.791) train_loss=544.37109375 time/batch=1.04s
15418/10943 (epoch 126.799) train_loss=452.14776611 time/batch=0.92s
15419/10943 (epoch 126.808) train_loss=845.09277344 time/batch=3.06s
15420/10943 (epoch 126.816) train_loss=539.42578125 time/batch=1.25s
15421/10943 (epoch 126.824) train_loss=200.00875854 time/batch=0.47s
15422/10943 (epoch 126.832) train_loss=572.81256104 time/batch=1.04s
15423/10943 (epoch 126.840) train_loss=502.06970215 time/batch=0.98s
15424/10943 (epoch 126.849) train_loss=430.34225464 time/batch=0.91s
15425/10943 (epoch 126.857) train_loss=327.20272827 time/batch=0.70s
15426/10943 (epoch 126.865) train_loss=411.23944092 time/batch=0.83s
15427/10943 (epoch 126.873) train_loss=475.24215698 time/batch=0.97s
15428/10943 (epoch 126.882) train_loss=546.73315430 time/batch=1.13s
15429/10943 (epoch 126.890) train_loss=394.11175537 time/batch=0.83s
15430/10943 (epoch 126.898) train_loss=525.72357178 time/batch=1.03s
15431/10943 (epoch 126.906) train_loss=602.55639648 time/batch=1.20s
15432/10943 (epoch 126.914) train_loss=389.64227295 time/batch=0.84s
15433/10943 (epoch 126.923) train_loss=287.80511475 time/batch=0.63s
15434/10943 (epoch 126.931) train_loss=142.42361450 time/batch=0.33s
15435/10943 (epoch 126.939) train_loss=163.14282227 time/batch=0.34s
15436/10943 (epoch 126.947) train_loss=694.59484863 time/batch=1.36s
15437/10943 (epoch 126.956) train_loss=417.50054932 time/batch=0.91s
15438/10943 (epoch 126.964) train_loss=634.69274902 time/batch=1.22s
15439/10943 (epoch 126.972) train_loss=349.77966309 time/batch=0.79s
15440/10943 (epoch 126.980) train_loss=256.35131836 time/batch=0.55s
15441/10943 (epoch 126.988) train_loss=601.81158447 time/batch=1.19s
15442/10943 (epoch 126.997) train_loss=579.75134277 time/batch=1.47s
15443/10943 (epoch 127.005) train_loss=243.15933228 time/batch=0.61s
15444/10943 (epoch 127.013) train_loss=250.27552795 time/batch=0.51s
15445/10943 (epoch 127.021) train_loss=332.87829590 time/batch=0.66s
15446/10943 (epoch 127.030) train_loss=545.44909668 time/batch=1.10s
15447/10943 (epoch 127.038) train_loss=185.73150635 time/batch=0.44s
15448/10943 (epoch 127.046) train_loss=147.49752808 time/batch=0.30s
15449/10943 (epoch 127.054) train_loss=388.21093750 time/batch=0.72s
15450/10943 (epoch 127.062) train_loss=327.10742188 time/batch=0.66s
15451/10943 (epoch 127.071) train_loss=357.96414185 time/batch=0.70s
15452/10943 (epoch 127.079) train_loss=484.63916016 time/batch=0.93s
15453/10943 (epoch 127.087) train_loss=436.03735352 time/batch=0.87s
15454/10943 (epoch 127.095) train_loss=372.06188965 time/batch=0.74s
15455/10943 (epoch 127.104) train_loss=318.42114258 time/batch=0.65s
15456/10943 (epoch 127.112) train_loss=350.97290039 time/batch=0.70s
15457/10943 (epoch 127.120) train_loss=220.23548889 time/batch=0.49s
15458/10943 (epoch 127.128) train_loss=111.60700989 time/batch=0.26s
15459/10943 (epoch 127.136) train_loss=327.99108887 time/batch=0.61s
15460/10943 (epoch 127.145) train_loss=168.94497681 time/batch=0.38s
15461/10943 (epoch 127.153) train_loss=221.09436035 time/batch=0.45s
15462/10943 (epoch 127.161) train_loss=174.23561096 time/batch=0.36s
15463/10943 (epoch 127.169) train_loss=379.37173462 time/batch=0.76s
15464/10943 (epoch 127.178) train_loss=129.41096497 time/batch=0.32s
15465/10943 (epoch 127.186) train_loss=525.39990234 time/batch=0.97s
15466/10943 (epoch 127.194) train_loss=422.82031250 time/batch=0.87s
15467/10943 (epoch 127.202) train_loss=367.15783691 time/batch=0.76s
15468/10943 (epoch 127.210) train_loss=329.83139038 time/batch=0.70s
15469/10943 (epoch 127.219) train_loss=225.78526306 time/batch=0.50s
15470/10943 (epoch 127.227) train_loss=239.28956604 time/batch=0.49s
15471/10943 (epoch 127.235) train_loss=199.21000671 time/batch=0.41s
15472/10943 (epoch 127.243) train_loss=179.42419434 time/batch=0.37s
15473/10943 (epoch 127.252) train_loss=237.85050964 time/batch=0.50s
15474/10943 (epoch 127.260) train_loss=325.05963135 time/batch=0.64s
15475/10943 (epoch 127.268) train_loss=500.81433105 time/batch=1.03s
15476/10943 (epoch 127.276) train_loss=295.68402100 time/batch=0.66s
15477/10943 (epoch 127.285) train_loss=216.03486633 time/batch=0.48s
15478/10943 (epoch 127.293) train_loss=458.24639893 time/batch=0.90s
15479/10943 (epoch 127.301) train_loss=378.30358887 time/batch=0.80s
15480/10943 (epoch 127.309) train_loss=207.45898438 time/batch=0.46s
15481/10943 (epoch 127.317) train_loss=267.47305298 time/batch=0.53s
15482/10943 (epoch 127.326) train_loss=410.39923096 time/batch=0.84s
15483/10943 (epoch 127.334) train_loss=199.48159790 time/batch=0.44s
15484/10943 (epoch 127.342) train_loss=278.19149780 time/batch=0.57s
15485/10943 (epoch 127.350) train_loss=354.14086914 time/batch=0.69s
15486/10943 (epoch 127.359) train_loss=328.48519897 time/batch=0.68s
15487/10943 (epoch 127.367) train_loss=310.51281738 time/batch=0.63s
15488/10943 (epoch 127.375) train_loss=219.54342651 time/batch=0.50s
15489/10943 (epoch 127.383) train_loss=206.45256042 time/batch=0.47s
15490/10943 (epoch 127.391) train_loss=144.88009644 time/batch=0.32s
15491/10943 (epoch 127.400) train_loss=414.58465576 time/batch=0.81s
15492/10943 (epoch 127.408) train_loss=251.80261230 time/batch=0.57s
15493/10943 (epoch 127.416) train_loss=243.88369751 time/batch=0.51s
15494/10943 (epoch 127.424) train_loss=219.02789307 time/batch=0.48s
15495/10943 (epoch 127.433) train_loss=270.46575928 time/batch=0.55s
15496/10943 (epoch 127.441) train_loss=402.12252808 time/batch=0.80s
15497/10943 (epoch 127.449) train_loss=256.37628174 time/batch=0.58s
15498/10943 (epoch 127.457) train_loss=466.63800049 time/batch=0.94s
15499/10943 (epoch 127.465) train_loss=307.86303711 time/batch=0.67s
15500/10943 (epoch 127.474) train_loss=194.98937988 time/batch=0.49s
15501/10943 (epoch 127.482) train_loss=294.71472168 time/batch=0.60s
15502/10943 (epoch 127.490) train_loss=276.68334961 time/batch=0.58s
15503/10943 (epoch 127.498) train_loss=392.23794556 time/batch=0.80s
15504/10943 (epoch 127.507) train_loss=383.96435547 time/batch=0.77s
15505/10943 (epoch 127.515) train_loss=346.58319092 time/batch=0.72s
15506/10943 (epoch 127.523) train_loss=351.15426636 time/batch=0.75s
15507/10943 (epoch 127.531) train_loss=338.34869385 time/batch=0.73s
15508/10943 (epoch 127.539) train_loss=271.62219238 time/batch=0.60s
15509/10943 (epoch 127.548) train_loss=274.40655518 time/batch=0.58s
15510/10943 (epoch 127.556) train_loss=451.73913574 time/batch=0.95s
15511/10943 (epoch 127.564) train_loss=448.00906372 time/batch=1.01s
15512/10943 (epoch 127.572) train_loss=155.10498047 time/batch=0.41s
15513/10943 (epoch 127.581) train_loss=373.61401367 time/batch=0.74s
15514/10943 (epoch 127.589) train_loss=354.25942993 time/batch=0.77s
15515/10943 (epoch 127.597) train_loss=268.98477173 time/batch=0.58s
15516/10943 (epoch 127.605) train_loss=285.32287598 time/batch=0.59s
15517/10943 (epoch 127.613) train_loss=201.53421021 time/batch=0.49s
15518/10943 (epoch 127.622) train_loss=345.80667114 time/batch=0.70s
15519/10943 (epoch 127.630) train_loss=288.50244141 time/batch=0.62s
15520/10943 (epoch 127.638) train_loss=272.47991943 time/batch=0.61s
15521/10943 (epoch 127.646) train_loss=372.50653076 time/batch=0.78s
15522/10943 (epoch 127.655) train_loss=311.88473511 time/batch=0.66s
15523/10943 (epoch 127.663) train_loss=281.51678467 time/batch=0.75s
15524/10943 (epoch 127.671) train_loss=323.70321655 time/batch=0.80s
setting learning rate to 0.0004403
  saved to metadata/gru_dropout-9_nov_folkwiki-20181207-173447_epoch83.pkl
15525/10943 (epoch 127.679) train_loss=190.67628479 time/batch=0.51s
15526/10943 (epoch 127.687) train_loss=600.95330811 time/batch=1.12s
15527/10943 (epoch 127.696) train_loss=329.37158203 time/batch=0.74s
15528/10943 (epoch 127.704) train_loss=152.52203369 time/batch=0.35s
15529/10943 (epoch 127.712) train_loss=278.08026123 time/batch=0.56s
15530/10943 (epoch 127.720) train_loss=693.55743408 time/batch=1.31s
15531/10943 (epoch 127.729) train_loss=731.98535156 time/batch=1.49s
15532/10943 (epoch 127.737) train_loss=495.16375732 time/batch=1.07s
15533/10943 (epoch 127.745) train_loss=1124.24340820 time/batch=3.09s
15534/10943 (epoch 127.753) train_loss=342.32611084 time/batch=0.93s
15535/10943 (epoch 127.762) train_loss=731.65087891 time/batch=1.49s
15536/10943 (epoch 127.770) train_loss=342.87091064 time/batch=0.75s
15537/10943 (epoch 127.778) train_loss=348.74542236 time/batch=0.68s
15538/10943 (epoch 127.786) train_loss=527.27209473 time/batch=1.00s
15539/10943 (epoch 127.794) train_loss=596.48950195 time/batch=1.21s
15540/10943 (epoch 127.803) train_loss=290.82192993 time/batch=0.68s
15541/10943 (epoch 127.811) train_loss=677.65325928 time/batch=1.31s
15542/10943 (epoch 127.819) train_loss=352.70989990 time/batch=0.79s
15543/10943 (epoch 127.827) train_loss=452.74850464 time/batch=0.90s
15544/10943 (epoch 127.836) train_loss=545.52441406 time/batch=1.12s
15545/10943 (epoch 127.844) train_loss=554.61584473 time/batch=1.15s
15546/10943 (epoch 127.852) train_loss=373.67044067 time/batch=0.77s
15547/10943 (epoch 127.860) train_loss=244.60769653 time/batch=0.51s
15548/10943 (epoch 127.868) train_loss=528.96899414 time/batch=0.98s
15549/10943 (epoch 127.877) train_loss=392.91473389 time/batch=0.83s
15550/10943 (epoch 127.885) train_loss=494.40325928 time/batch=0.95s
15551/10943 (epoch 127.893) train_loss=140.38005066 time/batch=0.35s
15552/10943 (epoch 127.901) train_loss=114.76885986 time/batch=0.25s
15553/10943 (epoch 127.910) train_loss=410.81146240 time/batch=0.76s
15554/10943 (epoch 127.918) train_loss=330.98092651 time/batch=0.70s
15555/10943 (epoch 127.926) train_loss=228.14538574 time/batch=0.50s
15556/10943 (epoch 127.934) train_loss=357.55767822 time/batch=0.71s
15557/10943 (epoch 127.942) train_loss=442.62420654 time/batch=0.91s
15558/10943 (epoch 127.951) train_loss=406.86260986 time/batch=0.85s
15559/10943 (epoch 127.959) train_loss=137.64611816 time/batch=0.35s
15560/10943 (epoch 127.967) train_loss=865.54467773 time/batch=1.60s
15561/10943 (epoch 127.975) train_loss=388.22424316 time/batch=0.88s
15562/10943 (epoch 127.984) train_loss=616.78784180 time/batch=1.19s
15563/10943 (epoch 127.992) train_loss=296.53024292 time/batch=0.67s
15564/10943 (epoch 128.000) train_loss=281.70544434 time/batch=0.57s
15565/10943 (epoch 128.008) train_loss=457.90435791 time/batch=0.85s
15566/10943 (epoch 128.016) train_loss=531.41271973 time/batch=1.06s
15567/10943 (epoch 128.025) train_loss=186.66889954 time/batch=0.44s
15568/10943 (epoch 128.033) train_loss=339.64556885 time/batch=0.63s
15569/10943 (epoch 128.041) train_loss=626.98889160 time/batch=1.50s
15570/10943 (epoch 128.049) train_loss=146.75062561 time/batch=0.44s
15571/10943 (epoch 128.058) train_loss=357.76675415 time/batch=0.70s
15572/10943 (epoch 128.066) train_loss=207.61679077 time/batch=0.46s
15573/10943 (epoch 128.074) train_loss=483.18176270 time/batch=0.90s
15574/10943 (epoch 128.082) train_loss=166.61581421 time/batch=0.39s
15575/10943 (epoch 128.090) train_loss=223.18133545 time/batch=0.45s
15576/10943 (epoch 128.099) train_loss=478.06167603 time/batch=0.94s
15577/10943 (epoch 128.107) train_loss=466.77209473 time/batch=0.96s
15578/10943 (epoch 128.115) train_loss=416.81832886 time/batch=0.85s
15579/10943 (epoch 128.123) train_loss=391.97521973 time/batch=0.78s
15580/10943 (epoch 128.132) train_loss=391.67706299 time/batch=0.81s
15581/10943 (epoch 128.140) train_loss=214.10067749 time/batch=0.46s
15582/10943 (epoch 128.148) train_loss=338.99627686 time/batch=0.63s
15583/10943 (epoch 128.156) train_loss=205.92677307 time/batch=0.45s
15584/10943 (epoch 128.164) train_loss=247.59713745 time/batch=0.49s
15585/10943 (epoch 128.173) train_loss=296.53271484 time/batch=0.61s
15586/10943 (epoch 128.181) train_loss=172.06082153 time/batch=0.37s
15587/10943 (epoch 128.189) train_loss=246.31172180 time/batch=0.49s
15588/10943 (epoch 128.197) train_loss=215.32104492 time/batch=0.45s
15589/10943 (epoch 128.206) train_loss=444.55572510 time/batch=0.82s
15590/10943 (epoch 128.214) train_loss=566.30212402 time/batch=1.54s
15591/10943 (epoch 128.222) train_loss=169.36367798 time/batch=0.47s
15592/10943 (epoch 128.230) train_loss=153.34841919 time/batch=0.31s
15593/10943 (epoch 128.238) train_loss=362.69769287 time/batch=0.69s
15594/10943 (epoch 128.247) train_loss=362.23663330 time/batch=0.70s
15595/10943 (epoch 128.255) train_loss=195.88150024 time/batch=0.42s
15596/10943 (epoch 128.263) train_loss=349.02743530 time/batch=0.68s
15597/10943 (epoch 128.271) train_loss=282.73004150 time/batch=0.59s
15598/10943 (epoch 128.280) train_loss=228.01263428 time/batch=0.46s
15599/10943 (epoch 128.288) train_loss=275.40588379 time/batch=0.54s
15600/10943 (epoch 128.296) train_loss=167.59494019 time/batch=0.36s
15601/10943 (epoch 128.304) train_loss=389.09533691 time/batch=0.74s
15602/10943 (epoch 128.313) train_loss=429.05017090 time/batch=0.84s
15603/10943 (epoch 128.321) train_loss=434.86834717 time/batch=0.88s
15604/10943 (epoch 128.329) train_loss=327.61175537 time/batch=0.71s
15605/10943 (epoch 128.337) train_loss=383.40618896 time/batch=0.76s
15606/10943 (epoch 128.345) train_loss=474.47674561 time/batch=0.95s
15607/10943 (epoch 128.354) train_loss=388.40280151 time/batch=0.82s
15608/10943 (epoch 128.362) train_loss=267.37640381 time/batch=0.58s
15609/10943 (epoch 128.370) train_loss=380.78192139 time/batch=0.74s
15610/10943 (epoch 128.378) train_loss=422.35375977 time/batch=0.86s
15611/10943 (epoch 128.387) train_loss=266.20541382 time/batch=0.57s
15612/10943 (epoch 128.395) train_loss=281.57177734 time/batch=0.58s
15613/10943 (epoch 128.403) train_loss=292.84741211 time/batch=0.58s
15614/10943 (epoch 128.411) train_loss=427.72320557 time/batch=0.82s
15615/10943 (epoch 128.419) train_loss=456.84127808 time/batch=0.98s
15616/10943 (epoch 128.428) train_loss=268.76300049 time/batch=0.59s
15617/10943 (epoch 128.436) train_loss=381.50903320 time/batch=0.78s
15618/10943 (epoch 128.444) train_loss=281.38397217 time/batch=0.62s
15619/10943 (epoch 128.452) train_loss=181.52548218 time/batch=0.39s
15620/10943 (epoch 128.461) train_loss=269.25302124 time/batch=0.54s
15621/10943 (epoch 128.469) train_loss=531.29260254 time/batch=1.02s
15622/10943 (epoch 128.477) train_loss=186.88967896 time/batch=0.45s
15623/10943 (epoch 128.485) train_loss=307.68951416 time/batch=0.60s
15624/10943 (epoch 128.493) train_loss=291.72705078 time/batch=0.60s
15625/10943 (epoch 128.502) train_loss=325.62271118 time/batch=0.63s
15626/10943 (epoch 128.510) train_loss=292.12548828 time/batch=0.60s
15627/10943 (epoch 128.518) train_loss=405.10333252 time/batch=0.83s
15628/10943 (epoch 128.526) train_loss=301.76721191 time/batch=0.63s
15629/10943 (epoch 128.535) train_loss=357.83706665 time/batch=0.70s
15630/10943 (epoch 128.543) train_loss=479.14312744 time/batch=0.97s
15631/10943 (epoch 128.551) train_loss=396.32891846 time/batch=0.87s
15632/10943 (epoch 128.559) train_loss=239.67886353 time/batch=0.55s
15633/10943 (epoch 128.567) train_loss=192.31962585 time/batch=0.43s
15634/10943 (epoch 128.576) train_loss=227.87989807 time/batch=0.47s
15635/10943 (epoch 128.584) train_loss=303.10861206 time/batch=0.61s
15636/10943 (epoch 128.592) train_loss=248.76858521 time/batch=0.52s
15637/10943 (epoch 128.600) train_loss=389.89697266 time/batch=0.76s
15638/10943 (epoch 128.609) train_loss=370.24160767 time/batch=0.78s
15639/10943 (epoch 128.617) train_loss=322.72155762 time/batch=0.66s
15640/10943 (epoch 128.625) train_loss=343.33056641 time/batch=0.77s
15641/10943 (epoch 128.633) train_loss=238.10314941 time/batch=0.51s
15642/10943 (epoch 128.641) train_loss=310.61822510 time/batch=0.63s
15643/10943 (epoch 128.650) train_loss=240.96903992 time/batch=0.53s
15644/10943 (epoch 128.658) train_loss=263.08834839 time/batch=0.59s
15645/10943 (epoch 128.666) train_loss=316.79779053 time/batch=0.68s
setting learning rate to 0.0004271
15646/10943 (epoch 128.674) train_loss=1086.03247070 time/batch=2.34s
15647/10943 (epoch 128.683) train_loss=562.31921387 time/batch=1.25s
15648/10943 (epoch 128.691) train_loss=429.68615723 time/batch=0.88s
15649/10943 (epoch 128.699) train_loss=401.24227905 time/batch=0.82s
15650/10943 (epoch 128.707) train_loss=342.53668213 time/batch=0.66s
15651/10943 (epoch 128.715) train_loss=680.93078613 time/batch=1.25s
15652/10943 (epoch 128.724) train_loss=781.85974121 time/batch=1.59s
15653/10943 (epoch 128.732) train_loss=611.76007080 time/batch=1.27s
15654/10943 (epoch 128.740) train_loss=385.14895630 time/batch=0.80s
15655/10943 (epoch 128.748) train_loss=446.76095581 time/batch=0.89s
15656/10943 (epoch 128.757) train_loss=390.86206055 time/batch=0.82s
15657/10943 (epoch 128.765) train_loss=796.60900879 time/batch=1.60s
15658/10943 (epoch 128.773) train_loss=293.60375977 time/batch=0.71s
15659/10943 (epoch 128.781) train_loss=280.97473145 time/batch=0.60s
15660/10943 (epoch 128.790) train_loss=123.52973938 time/batch=0.29s
15661/10943 (epoch 128.798) train_loss=563.31286621 time/batch=1.03s
15662/10943 (epoch 128.806) train_loss=623.80419922 time/batch=1.25s
15663/10943 (epoch 128.814) train_loss=548.63458252 time/batch=1.12s
15664/10943 (epoch 128.822) train_loss=362.76980591 time/batch=0.74s
15665/10943 (epoch 128.831) train_loss=811.46508789 time/batch=3.06s
15666/10943 (epoch 128.839) train_loss=331.80392456 time/batch=0.94s
15667/10943 (epoch 128.847) train_loss=168.39526367 time/batch=0.37s
15668/10943 (epoch 128.855) train_loss=514.26159668 time/batch=0.98s
15669/10943 (epoch 128.864) train_loss=165.63128662 time/batch=0.41s
15670/10943 (epoch 128.872) train_loss=409.88940430 time/batch=0.78s
15671/10943 (epoch 128.880) train_loss=426.33004761 time/batch=0.87s
15672/10943 (epoch 128.888) train_loss=164.26663208 time/batch=0.39s
15673/10943 (epoch 128.896) train_loss=324.73635864 time/batch=0.61s
15674/10943 (epoch 128.905) train_loss=295.02270508 time/batch=0.60s
15675/10943 (epoch 128.913) train_loss=148.47787476 time/batch=0.32s
15676/10943 (epoch 128.921) train_loss=492.57971191 time/batch=0.92s
15677/10943 (epoch 128.929) train_loss=126.90631104 time/batch=0.34s
15678/10943 (epoch 128.938) train_loss=379.47076416 time/batch=0.71s
15679/10943 (epoch 128.946) train_loss=247.70193481 time/batch=0.54s
15680/10943 (epoch 128.954) train_loss=215.76464844 time/batch=0.45s
15681/10943 (epoch 128.962) train_loss=496.90261841 time/batch=0.91s
15682/10943 (epoch 128.970) train_loss=522.68768311 time/batch=1.03s
15683/10943 (epoch 128.979) train_loss=705.22314453 time/batch=1.34s
15684/10943 (epoch 128.987) train_loss=544.12506104 time/batch=1.05s
15685/10943 (epoch 128.995) train_loss=491.81365967 time/batch=0.97s
15686/10943 (epoch 129.003) train_loss=185.07098389 time/batch=0.45s
15687/10943 (epoch 129.012) train_loss=426.61651611 time/batch=0.80s
15688/10943 (epoch 129.020) train_loss=454.80386353 time/batch=0.89s
15689/10943 (epoch 129.028) train_loss=232.32722473 time/batch=0.51s
15690/10943 (epoch 129.036) train_loss=285.68707275 time/batch=0.57s
15691/10943 (epoch 129.044) train_loss=178.83184814 time/batch=0.39s
15692/10943 (epoch 129.053) train_loss=541.15118408 time/batch=1.02s
15693/10943 (epoch 129.061) train_loss=282.68957520 time/batch=0.64s
15694/10943 (epoch 129.069) train_loss=569.16033936 time/batch=1.12s
15695/10943 (epoch 129.077) train_loss=198.84426880 time/batch=0.49s
15696/10943 (epoch 129.086) train_loss=624.38800049 time/batch=1.30s
15697/10943 (epoch 129.094) train_loss=474.41400146 time/batch=0.99s
15698/10943 (epoch 129.102) train_loss=278.38256836 time/batch=0.60s
15699/10943 (epoch 129.110) train_loss=270.58328247 time/batch=0.55s
15700/10943 (epoch 129.118) train_loss=451.38940430 time/batch=0.89s
15701/10943 (epoch 129.127) train_loss=297.68139648 time/batch=0.65s
15702/10943 (epoch 129.135) train_loss=192.31597900 time/batch=0.41s
15703/10943 (epoch 129.143) train_loss=233.49806213 time/batch=0.46s
15704/10943 (epoch 129.151) train_loss=453.25933838 time/batch=0.89s
15705/10943 (epoch 129.160) train_loss=168.43963623 time/batch=0.41s
15706/10943 (epoch 129.168) train_loss=548.02618408 time/batch=1.07s
15707/10943 (epoch 129.176) train_loss=386.30279541 time/batch=0.83s
15708/10943 (epoch 129.184) train_loss=201.53335571 time/batch=0.45s
15709/10943 (epoch 129.192) train_loss=210.49076843 time/batch=0.44s
15710/10943 (epoch 129.201) train_loss=264.95343018 time/batch=0.51s
15711/10943 (epoch 129.209) train_loss=243.41490173 time/batch=0.49s
15712/10943 (epoch 129.217) train_loss=384.38226318 time/batch=0.74s
15713/10943 (epoch 129.225) train_loss=244.41354370 time/batch=0.55s
15714/10943 (epoch 129.234) train_loss=142.27130127 time/batch=0.32s
15715/10943 (epoch 129.242) train_loss=288.61639404 time/batch=0.54s
15716/10943 (epoch 129.250) train_loss=148.18627930 time/batch=0.33s
15717/10943 (epoch 129.258) train_loss=231.30374146 time/batch=0.45s
15718/10943 (epoch 129.267) train_loss=337.74865723 time/batch=0.66s
15719/10943 (epoch 129.275) train_loss=238.27107239 time/batch=0.50s
15720/10943 (epoch 129.283) train_loss=384.12738037 time/batch=0.75s
15721/10943 (epoch 129.291) train_loss=302.44812012 time/batch=0.63s
15722/10943 (epoch 129.299) train_loss=238.96008301 time/batch=0.49s
15723/10943 (epoch 129.308) train_loss=153.69503784 time/batch=0.36s
15724/10943 (epoch 129.316) train_loss=335.41058350 time/batch=0.62s
15725/10943 (epoch 129.324) train_loss=307.40637207 time/batch=0.64s
15726/10943 (epoch 129.332) train_loss=356.59375000 time/batch=0.70s
15727/10943 (epoch 129.341) train_loss=289.66784668 time/batch=0.61s
15728/10943 (epoch 129.349) train_loss=312.25427246 time/batch=0.62s
15729/10943 (epoch 129.357) train_loss=265.72509766 time/batch=0.56s
15730/10943 (epoch 129.365) train_loss=337.09039307 time/batch=0.67s
15731/10943 (epoch 129.373) train_loss=264.91833496 time/batch=0.56s
15732/10943 (epoch 129.382) train_loss=331.37023926 time/batch=0.65s
15733/10943 (epoch 129.390) train_loss=288.99270630 time/batch=0.62s
15734/10943 (epoch 129.398) train_loss=360.68624878 time/batch=0.69s
15735/10943 (epoch 129.406) train_loss=246.04757690 time/batch=0.52s
15736/10943 (epoch 129.415) train_loss=406.90612793 time/batch=0.80s
15737/10943 (epoch 129.423) train_loss=209.83985901 time/batch=0.47s
15738/10943 (epoch 129.431) train_loss=348.26135254 time/batch=0.70s
15739/10943 (epoch 129.439) train_loss=315.26068115 time/batch=0.65s
15740/10943 (epoch 129.447) train_loss=298.74594116 time/batch=0.63s
15741/10943 (epoch 129.456) train_loss=214.38272095 time/batch=0.45s
15742/10943 (epoch 129.464) train_loss=439.27203369 time/batch=0.85s
15743/10943 (epoch 129.472) train_loss=334.17300415 time/batch=0.71s
15744/10943 (epoch 129.480) train_loss=429.64550781 time/batch=0.91s
15745/10943 (epoch 129.489) train_loss=272.31961060 time/batch=0.63s
15746/10943 (epoch 129.497) train_loss=232.86593628 time/batch=0.51s
15747/10943 (epoch 129.505) train_loss=295.06756592 time/batch=0.59s
15748/10943 (epoch 129.513) train_loss=352.52130127 time/batch=0.75s
15749/10943 (epoch 129.521) train_loss=271.37408447 time/batch=0.66s
15750/10943 (epoch 129.530) train_loss=356.38571167 time/batch=0.73s
15751/10943 (epoch 129.538) train_loss=372.23944092 time/batch=0.79s
15752/10943 (epoch 129.546) train_loss=364.10095215 time/batch=0.74s
15753/10943 (epoch 129.554) train_loss=325.69952393 time/batch=0.70s
15754/10943 (epoch 129.563) train_loss=219.78945923 time/batch=0.54s
15755/10943 (epoch 129.571) train_loss=321.40975952 time/batch=0.67s
15756/10943 (epoch 129.579) train_loss=415.79238892 time/batch=0.85s
15757/10943 (epoch 129.587) train_loss=181.73077393 time/batch=0.44s
15758/10943 (epoch 129.595) train_loss=340.34356689 time/batch=0.68s
15759/10943 (epoch 129.604) train_loss=391.50396729 time/batch=0.81s
15760/10943 (epoch 129.612) train_loss=381.85769653 time/batch=0.81s
15761/10943 (epoch 129.620) train_loss=380.82147217 time/batch=0.78s
15762/10943 (epoch 129.628) train_loss=475.97085571 time/batch=0.96s
15763/10943 (epoch 129.637) train_loss=376.23889160 time/batch=0.83s
15764/10943 (epoch 129.645) train_loss=429.02255249 time/batch=1.00s
15765/10943 (epoch 129.653) train_loss=210.00283813 time/batch=0.58s
15766/10943 (epoch 129.661) train_loss=351.43804932 time/batch=0.77s
setting learning rate to 0.0004143
  saved to metadata/gru_dropout-9_nov_folkwiki-20181207-173447_epoch85.pkl
15767/10943 (epoch 129.669) train_loss=212.76382446 time/batch=0.54s
15768/10943 (epoch 129.678) train_loss=369.54199219 time/batch=0.72s
15769/10943 (epoch 129.686) train_loss=474.45123291 time/batch=0.94s
15770/10943 (epoch 129.694) train_loss=615.88494873 time/batch=1.25s
15771/10943 (epoch 129.702) train_loss=703.69342041 time/batch=1.43s
15772/10943 (epoch 129.711) train_loss=598.39013672 time/batch=1.23s
15773/10943 (epoch 129.719) train_loss=889.00921631 time/batch=1.82s
15774/10943 (epoch 129.727) train_loss=552.50439453 time/batch=1.17s
15775/10943 (epoch 129.735) train_loss=383.52484131 time/batch=0.81s
15776/10943 (epoch 129.744) train_loss=322.35522461 time/batch=0.65s
15777/10943 (epoch 129.752) train_loss=282.63790894 time/batch=0.58s
15778/10943 (epoch 129.760) train_loss=284.50271606 time/batch=0.58s
15779/10943 (epoch 129.768) train_loss=530.26605225 time/batch=0.99s
15780/10943 (epoch 129.776) train_loss=799.60729980 time/batch=1.58s
15781/10943 (epoch 129.785) train_loss=310.30456543 time/batch=0.71s
15782/10943 (epoch 129.793) train_loss=428.95477295 time/batch=0.84s
15783/10943 (epoch 129.801) train_loss=1106.45068359 time/batch=3.07s
15784/10943 (epoch 129.809) train_loss=303.64971924 time/batch=0.87s
15785/10943 (epoch 129.818) train_loss=345.39407349 time/batch=0.65s
15786/10943 (epoch 129.826) train_loss=285.82861328 time/batch=0.58s
15787/10943 (epoch 129.834) train_loss=321.01525879 time/batch=0.63s
15788/10943 (epoch 129.842) train_loss=183.00430298 time/batch=0.41s
15789/10943 (epoch 129.850) train_loss=701.16705322 time/batch=1.28s
15790/10943 (epoch 129.859) train_loss=340.33493042 time/batch=0.74s
15791/10943 (epoch 129.867) train_loss=449.07879639 time/batch=0.86s
15792/10943 (epoch 129.875) train_loss=496.33685303 time/batch=0.96s
15793/10943 (epoch 129.883) train_loss=230.17231750 time/batch=0.53s
15794/10943 (epoch 129.892) train_loss=415.39447021 time/batch=0.80s
15795/10943 (epoch 129.900) train_loss=267.15124512 time/batch=0.57s
15796/10943 (epoch 129.908) train_loss=251.48742676 time/batch=0.50s
15797/10943 (epoch 129.916) train_loss=357.53228760 time/batch=0.71s
15798/10943 (epoch 129.924) train_loss=280.93298340 time/batch=0.58s
15799/10943 (epoch 129.933) train_loss=195.53958130 time/batch=0.40s
15800/10943 (epoch 129.941) train_loss=267.25183105 time/batch=0.54s
15801/10943 (epoch 129.949) train_loss=412.97009277 time/batch=0.79s
15802/10943 (epoch 129.957) train_loss=449.24688721 time/batch=0.93s
15803/10943 (epoch 129.966) train_loss=542.01739502 time/batch=1.00s
15804/10943 (epoch 129.974) train_loss=392.72045898 time/batch=0.84s
15805/10943 (epoch 129.982) train_loss=416.51885986 time/batch=0.86s
15806/10943 (epoch 129.990) train_loss=282.61975098 time/batch=0.61s
15807/10943 (epoch 129.998) train_loss=696.95800781 time/batch=1.40s
15808/10943 (epoch 130.007) train_loss=579.99096680 time/batch=1.15s
15809/10943 (epoch 130.015) train_loss=393.40014648 time/batch=0.83s
15810/10943 (epoch 130.023) train_loss=245.53846741 time/batch=0.54s
15811/10943 (epoch 130.031) train_loss=184.81077576 time/batch=0.40s
15812/10943 (epoch 130.040) train_loss=342.08874512 time/batch=0.69s
15813/10943 (epoch 130.048) train_loss=378.85284424 time/batch=0.79s
15814/10943 (epoch 130.056) train_loss=520.80322266 time/batch=1.02s
15815/10943 (epoch 130.064) train_loss=175.54808044 time/batch=0.43s
15816/10943 (epoch 130.072) train_loss=548.30004883 time/batch=1.05s
15817/10943 (epoch 130.081) train_loss=334.96231079 time/batch=0.71s
15818/10943 (epoch 130.089) train_loss=430.44140625 time/batch=0.84s
15819/10943 (epoch 130.097) train_loss=238.84790039 time/batch=0.54s
15820/10943 (epoch 130.105) train_loss=438.99359131 time/batch=0.85s
15821/10943 (epoch 130.114) train_loss=405.10409546 time/batch=0.85s
15822/10943 (epoch 130.122) train_loss=584.16455078 time/batch=1.19s
15823/10943 (epoch 130.130) train_loss=399.03057861 time/batch=0.83s
15824/10943 (epoch 130.138) train_loss=307.33847046 time/batch=0.65s
15825/10943 (epoch 130.146) train_loss=239.41967773 time/batch=0.50s
15826/10943 (epoch 130.155) train_loss=435.01538086 time/batch=0.83s
15827/10943 (epoch 130.163) train_loss=571.44146729 time/batch=1.19s
15828/10943 (epoch 130.171) train_loss=458.98123169 time/batch=0.95s
15829/10943 (epoch 130.179) train_loss=234.20986938 time/batch=0.50s
15830/10943 (epoch 130.188) train_loss=123.02394104 time/batch=0.28s
15831/10943 (epoch 130.196) train_loss=203.27505493 time/batch=0.41s
15832/10943 (epoch 130.204) train_loss=446.95840454 time/batch=0.85s
15833/10943 (epoch 130.212) train_loss=145.47377014 time/batch=0.36s
15834/10943 (epoch 130.221) train_loss=356.49307251 time/batch=0.67s
15835/10943 (epoch 130.229) train_loss=396.25225830 time/batch=0.81s
15836/10943 (epoch 130.237) train_loss=261.56549072 time/batch=0.59s
15837/10943 (epoch 130.245) train_loss=124.79238892 time/batch=0.30s
15838/10943 (epoch 130.253) train_loss=331.66870117 time/batch=0.61s
15839/10943 (epoch 130.262) train_loss=288.25161743 time/batch=0.58s
15840/10943 (epoch 130.270) train_loss=479.79028320 time/batch=0.94s
15841/10943 (epoch 130.278) train_loss=381.60647583 time/batch=0.79s
15842/10943 (epoch 130.286) train_loss=438.48016357 time/batch=0.89s
15843/10943 (epoch 130.295) train_loss=450.81652832 time/batch=0.96s
15844/10943 (epoch 130.303) train_loss=515.83459473 time/batch=1.05s
15845/10943 (epoch 130.311) train_loss=581.61889648 time/batch=1.25s
15846/10943 (epoch 130.319) train_loss=337.01727295 time/batch=0.74s
15847/10943 (epoch 130.327) train_loss=465.27368164 time/batch=0.97s
15848/10943 (epoch 130.336) train_loss=267.26751709 time/batch=0.60s
15849/10943 (epoch 130.344) train_loss=165.84925842 time/batch=0.36s
15850/10943 (epoch 130.352) train_loss=259.60729980 time/batch=0.51s
15851/10943 (epoch 130.360) train_loss=313.62231445 time/batch=0.64s
15852/10943 (epoch 130.369) train_loss=333.47381592 time/batch=0.68s
15853/10943 (epoch 130.377) train_loss=289.04037476 time/batch=0.61s
15854/10943 (epoch 130.385) train_loss=368.70916748 time/batch=0.75s
15855/10943 (epoch 130.393) train_loss=303.65020752 time/batch=0.69s
15856/10943 (epoch 130.401) train_loss=328.53680420 time/batch=0.70s
15857/10943 (epoch 130.410) train_loss=176.70542908 time/batch=0.40s
15858/10943 (epoch 130.418) train_loss=377.07995605 time/batch=0.76s
15859/10943 (epoch 130.426) train_loss=377.53781128 time/batch=0.79s
15860/10943 (epoch 130.434) train_loss=231.67822266 time/batch=0.55s
15861/10943 (epoch 130.443) train_loss=205.32943726 time/batch=0.45s
15862/10943 (epoch 130.451) train_loss=177.58746338 time/batch=0.37s
15863/10943 (epoch 130.459) train_loss=150.50369263 time/batch=0.32s
15864/10943 (epoch 130.467) train_loss=369.74377441 time/batch=0.67s
15865/10943 (epoch 130.475) train_loss=346.61468506 time/batch=0.73s
15866/10943 (epoch 130.484) train_loss=197.54953003 time/batch=0.44s
15867/10943 (epoch 130.492) train_loss=238.77343750 time/batch=0.49s
15868/10943 (epoch 130.500) train_loss=163.87698364 time/batch=0.37s
15869/10943 (epoch 130.508) train_loss=286.24990845 time/batch=0.58s
15870/10943 (epoch 130.517) train_loss=148.52639771 time/batch=0.35s
15871/10943 (epoch 130.525) train_loss=281.34213257 time/batch=0.58s
15872/10943 (epoch 130.533) train_loss=290.56634521 time/batch=0.61s
15873/10943 (epoch 130.541) train_loss=138.29286194 time/batch=0.32s
15874/10943 (epoch 130.549) train_loss=318.78283691 time/batch=0.64s
15875/10943 (epoch 130.558) train_loss=332.27954102 time/batch=0.69s
15876/10943 (epoch 130.566) train_loss=358.24658203 time/batch=0.77s
15877/10943 (epoch 130.574) train_loss=273.26666260 time/batch=0.62s
15878/10943 (epoch 130.582) train_loss=213.02468872 time/batch=0.47s
15879/10943 (epoch 130.591) train_loss=227.57173157 time/batch=0.47s
15880/10943 (epoch 130.599) train_loss=185.61546326 time/batch=0.42s
15881/10943 (epoch 130.607) train_loss=168.15270996 time/batch=0.44s
15882/10943 (epoch 130.615) train_loss=264.84912109 time/batch=0.59s
15883/10943 (epoch 130.623) train_loss=262.80816650 time/batch=0.69s
15884/10943 (epoch 130.632) train_loss=352.39059448 time/batch=0.74s
15885/10943 (epoch 130.640) train_loss=350.29525757 time/batch=0.70s
15886/10943 (epoch 130.648) train_loss=360.27377319 time/batch=0.72s
15887/10943 (epoch 130.656) train_loss=388.33947754 time/batch=0.80s
setting learning rate to 0.0004018
15888/10943 (epoch 130.665) train_loss=887.36663818 time/batch=1.73s
15889/10943 (epoch 130.673) train_loss=818.33990479 time/batch=1.86s
15890/10943 (epoch 130.681) train_loss=299.55975342 time/batch=0.72s
15891/10943 (epoch 130.689) train_loss=154.20269775 time/batch=0.35s
15892/10943 (epoch 130.698) train_loss=137.03717041 time/batch=0.29s
15893/10943 (epoch 130.706) train_loss=490.43145752 time/batch=0.94s
15894/10943 (epoch 130.714) train_loss=279.30191040 time/batch=0.64s
15895/10943 (epoch 130.722) train_loss=539.24230957 time/batch=1.09s
15896/10943 (epoch 130.730) train_loss=221.89097595 time/batch=0.54s
15897/10943 (epoch 130.739) train_loss=291.02337646 time/batch=0.58s
15898/10943 (epoch 130.747) train_loss=564.06225586 time/batch=1.10s
15899/10943 (epoch 130.755) train_loss=183.37324524 time/batch=0.45s
15900/10943 (epoch 130.763) train_loss=444.70794678 time/batch=0.85s
15901/10943 (epoch 130.772) train_loss=330.70993042 time/batch=0.73s
15902/10943 (epoch 130.780) train_loss=206.79576111 time/batch=0.44s
15903/10943 (epoch 130.788) train_loss=515.74353027 time/batch=1.00s
15904/10943 (epoch 130.796) train_loss=441.15368652 time/batch=0.94s
15905/10943 (epoch 130.804) train_loss=674.58618164 time/batch=1.30s
15906/10943 (epoch 130.813) train_loss=558.76934814 time/batch=1.18s
15907/10943 (epoch 130.821) train_loss=181.73263550 time/batch=0.45s
15908/10943 (epoch 130.829) train_loss=322.43249512 time/batch=0.64s
15909/10943 (epoch 130.837) train_loss=601.95935059 time/batch=1.21s
15910/10943 (epoch 130.846) train_loss=244.14704895 time/batch=0.61s
15911/10943 (epoch 130.854) train_loss=413.16674805 time/batch=0.83s
15912/10943 (epoch 130.862) train_loss=574.91479492 time/batch=1.17s
15913/10943 (epoch 130.870) train_loss=258.75634766 time/batch=0.60s
15914/10943 (epoch 130.878) train_loss=1071.85961914 time/batch=3.02s
15915/10943 (epoch 130.887) train_loss=419.21939087 time/batch=1.08s
15916/10943 (epoch 130.895) train_loss=509.78991699 time/batch=0.98s
15917/10943 (epoch 130.903) train_loss=435.07824707 time/batch=0.89s
15918/10943 (epoch 130.911) train_loss=164.47244263 time/batch=0.40s
15919/10943 (epoch 130.920) train_loss=493.14727783 time/batch=0.90s
15920/10943 (epoch 130.928) train_loss=446.61303711 time/batch=0.90s
15921/10943 (epoch 130.936) train_loss=283.68078613 time/batch=0.61s
15922/10943 (epoch 130.944) train_loss=444.39324951 time/batch=0.87s
15923/10943 (epoch 130.952) train_loss=263.63122559 time/batch=0.58s
15924/10943 (epoch 130.961) train_loss=690.45166016 time/batch=1.39s
15925/10943 (epoch 130.969) train_loss=229.88168335 time/batch=0.57s
15926/10943 (epoch 130.977) train_loss=168.74258423 time/batch=0.35s
15927/10943 (epoch 130.985) train_loss=426.87805176 time/batch=0.84s
15928/10943 (epoch 130.994) train_loss=699.27905273 time/batch=1.34s
15929/10943 (epoch 131.002) train_loss=299.52136230 time/batch=0.68s
15930/10943 (epoch 131.010) train_loss=356.66625977 time/batch=0.69s
15931/10943 (epoch 131.018) train_loss=361.92086792 time/batch=0.71s
15932/10943 (epoch 131.026) train_loss=243.50119019 time/batch=0.51s
15933/10943 (epoch 131.035) train_loss=162.50173950 time/batch=0.34s
15934/10943 (epoch 131.043) train_loss=382.67846680 time/batch=0.74s
15935/10943 (epoch 131.051) train_loss=383.72521973 time/batch=0.81s
15936/10943 (epoch 131.059) train_loss=337.67608643 time/batch=0.73s
15937/10943 (epoch 131.068) train_loss=321.59762573 time/batch=0.66s
15938/10943 (epoch 131.076) train_loss=471.36441040 time/batch=0.97s
15939/10943 (epoch 131.084) train_loss=644.46606445 time/batch=1.36s
15940/10943 (epoch 131.092) train_loss=267.05548096 time/batch=0.62s
15941/10943 (epoch 131.100) train_loss=296.22836304 time/batch=0.59s
15942/10943 (epoch 131.109) train_loss=420.02325439 time/batch=0.88s
15943/10943 (epoch 131.117) train_loss=212.95344543 time/batch=0.49s
15944/10943 (epoch 131.125) train_loss=361.62588501 time/batch=0.70s
15945/10943 (epoch 131.133) train_loss=271.24865723 time/batch=0.58s
15946/10943 (epoch 131.142) train_loss=479.83367920 time/batch=0.91s
15947/10943 (epoch 131.150) train_loss=378.04483032 time/batch=0.81s
15948/10943 (epoch 131.158) train_loss=229.87544250 time/batch=0.49s
15949/10943 (epoch 131.166) train_loss=175.37239075 time/batch=0.38s
15950/10943 (epoch 131.175) train_loss=233.83874512 time/batch=0.47s
15951/10943 (epoch 131.183) train_loss=284.02041626 time/batch=0.55s
15952/10943 (epoch 131.191) train_loss=116.02817535 time/batch=0.28s
15953/10943 (epoch 131.199) train_loss=126.35644531 time/batch=0.29s
15954/10943 (epoch 131.207) train_loss=526.66577148 time/batch=1.00s
15955/10943 (epoch 131.216) train_loss=552.80493164 time/batch=1.16s
15956/10943 (epoch 131.224) train_loss=397.77532959 time/batch=0.84s
15957/10943 (epoch 131.232) train_loss=297.21026611 time/batch=0.64s
15958/10943 (epoch 131.240) train_loss=321.16082764 time/batch=0.64s
15959/10943 (epoch 131.249) train_loss=366.88882446 time/batch=0.75s
15960/10943 (epoch 131.257) train_loss=505.58261108 time/batch=1.00s
15961/10943 (epoch 131.265) train_loss=387.20037842 time/batch=0.85s
15962/10943 (epoch 131.273) train_loss=345.86395264 time/batch=0.72s
15963/10943 (epoch 131.281) train_loss=327.59533691 time/batch=0.66s
15964/10943 (epoch 131.290) train_loss=313.59869385 time/batch=0.63s
15965/10943 (epoch 131.298) train_loss=231.49147034 time/batch=0.48s
15966/10943 (epoch 131.306) train_loss=191.11431885 time/batch=0.39s
15967/10943 (epoch 131.314) train_loss=441.36407471 time/batch=0.88s
15968/10943 (epoch 131.323) train_loss=241.38867188 time/batch=0.54s
15969/10943 (epoch 131.331) train_loss=201.30468750 time/batch=0.42s
15970/10943 (epoch 131.339) train_loss=201.33135986 time/batch=0.42s
15971/10943 (epoch 131.347) train_loss=373.02233887 time/batch=0.72s
15972/10943 (epoch 131.355) train_loss=417.02697754 time/batch=0.84s
15973/10943 (epoch 131.364) train_loss=180.57635498 time/batch=0.44s
15974/10943 (epoch 131.372) train_loss=243.40968323 time/batch=0.50s
15975/10943 (epoch 131.380) train_loss=142.67765808 time/batch=0.32s
15976/10943 (epoch 131.388) train_loss=355.88131714 time/batch=0.69s
15977/10943 (epoch 131.397) train_loss=243.73513794 time/batch=0.52s
15978/10943 (epoch 131.405) train_loss=325.35388184 time/batch=0.63s
15979/10943 (epoch 131.413) train_loss=284.90072632 time/batch=0.63s
15980/10943 (epoch 131.421) train_loss=152.24064636 time/batch=0.34s
15981/10943 (epoch 131.429) train_loss=221.59840393 time/batch=0.47s
15982/10943 (epoch 131.438) train_loss=265.05175781 time/batch=0.54s
15983/10943 (epoch 131.446) train_loss=269.76940918 time/batch=0.56s
15984/10943 (epoch 131.454) train_loss=535.29052734 time/batch=1.03s
15985/10943 (epoch 131.462) train_loss=172.12615967 time/batch=0.47s
15986/10943 (epoch 131.471) train_loss=275.51983643 time/batch=0.56s
15987/10943 (epoch 131.479) train_loss=352.06665039 time/batch=0.72s
15988/10943 (epoch 131.487) train_loss=310.29983521 time/batch=0.65s
15989/10943 (epoch 131.495) train_loss=192.48986816 time/batch=0.45s
15990/10943 (epoch 131.503) train_loss=407.83966064 time/batch=0.79s
15991/10943 (epoch 131.512) train_loss=368.36901855 time/batch=0.76s
15992/10943 (epoch 131.520) train_loss=475.42315674 time/batch=1.00s
15993/10943 (epoch 131.528) train_loss=285.09124756 time/batch=0.62s
15994/10943 (epoch 131.536) train_loss=337.85467529 time/batch=0.65s
15995/10943 (epoch 131.545) train_loss=349.10284424 time/batch=0.72s
15996/10943 (epoch 131.553) train_loss=381.88772583 time/batch=0.77s
15997/10943 (epoch 131.561) train_loss=326.50439453 time/batch=0.69s
15998/10943 (epoch 131.569) train_loss=276.63769531 time/batch=0.61s
15999/10943 (epoch 131.577) train_loss=375.61047363 time/batch=0.77s
Validating
    loss:	332.049222

16000/10943 (epoch 131.586) train_loss=261.70614624 time/batch=2.49s
16001/10943 (epoch 131.594) train_loss=308.93902588 time/batch=0.65s
16002/10943 (epoch 131.602) train_loss=323.15966797 time/batch=0.68s
16003/10943 (epoch 131.610) train_loss=382.40979004 time/batch=0.79s
16004/10943 (epoch 131.619) train_loss=420.92974854 time/batch=0.83s
16005/10943 (epoch 131.627) train_loss=375.45959473 time/batch=0.80s
16006/10943 (epoch 131.635) train_loss=329.89181519 time/batch=0.68s
16007/10943 (epoch 131.643) train_loss=345.58184814 time/batch=0.72s
16008/10943 (epoch 131.652) train_loss=398.63107300 time/batch=0.81s
setting learning rate to 0.0003898
  saved to metadata/gru_dropout-9_nov_folkwiki-20181207-173447_epoch87.pkl
16009/10943 (epoch 131.660) train_loss=360.37484741 time/batch=0.82s
16010/10943 (epoch 131.668) train_loss=299.85839844 time/batch=0.64s
16011/10943 (epoch 131.676) train_loss=442.37628174 time/batch=0.90s
16012/10943 (epoch 131.684) train_loss=751.10662842 time/batch=1.51s
16013/10943 (epoch 131.693) train_loss=388.55380249 time/batch=0.89s
16014/10943 (epoch 131.701) train_loss=654.76947021 time/batch=1.25s
16015/10943 (epoch 131.709) train_loss=545.90386963 time/batch=1.04s
16016/10943 (epoch 131.717) train_loss=119.86547852 time/batch=0.33s
16017/10943 (epoch 131.726) train_loss=127.65011597 time/batch=0.28s
16018/10943 (epoch 131.734) train_loss=550.89819336 time/batch=1.00s
16019/10943 (epoch 131.742) train_loss=359.09179688 time/batch=0.74s
16020/10943 (epoch 131.750) train_loss=222.47195435 time/batch=0.47s
16021/10943 (epoch 131.758) train_loss=1026.34777832 time/batch=2.13s
16022/10943 (epoch 131.767) train_loss=367.50073242 time/batch=0.86s
16023/10943 (epoch 131.775) train_loss=242.96861267 time/batch=0.50s
16024/10943 (epoch 131.783) train_loss=650.13256836 time/batch=1.18s
16025/10943 (epoch 131.791) train_loss=725.64062500 time/batch=1.39s
16026/10943 (epoch 131.800) train_loss=343.13992310 time/batch=0.74s
16027/10943 (epoch 131.808) train_loss=294.02972412 time/batch=0.61s
16028/10943 (epoch 131.816) train_loss=368.64938354 time/batch=0.69s
16029/10943 (epoch 131.824) train_loss=381.64550781 time/batch=0.77s
16030/10943 (epoch 131.832) train_loss=480.94631958 time/batch=1.00s
16031/10943 (epoch 131.841) train_loss=788.73028564 time/batch=1.61s
16032/10943 (epoch 131.849) train_loss=302.97747803 time/batch=0.74s
16033/10943 (epoch 131.857) train_loss=222.07185364 time/batch=0.46s
16034/10943 (epoch 131.865) train_loss=172.09832764 time/batch=0.34s
16035/10943 (epoch 131.874) train_loss=588.70806885 time/batch=1.11s
16036/10943 (epoch 131.882) train_loss=149.45268250 time/batch=0.39s
16037/10943 (epoch 131.890) train_loss=170.70294189 time/batch=0.35s
16038/10943 (epoch 131.898) train_loss=644.25366211 time/batch=1.22s
16039/10943 (epoch 131.906) train_loss=558.48168945 time/batch=1.17s
16040/10943 (epoch 131.915) train_loss=490.02374268 time/batch=0.98s
16041/10943 (epoch 131.923) train_loss=484.27966309 time/batch=0.98s
16042/10943 (epoch 131.931) train_loss=536.07849121 time/batch=1.07s
16043/10943 (epoch 131.939) train_loss=429.80578613 time/batch=0.86s
16044/10943 (epoch 131.948) train_loss=225.69680786 time/batch=0.50s
16045/10943 (epoch 131.956) train_loss=384.99673462 time/batch=0.75s
16046/10943 (epoch 131.964) train_loss=595.93627930 time/batch=1.28s
16047/10943 (epoch 131.972) train_loss=287.67636108 time/batch=0.64s
16048/10943 (epoch 131.980) train_loss=323.97692871 time/batch=0.63s
16049/10943 (epoch 131.989) train_loss=387.40924072 time/batch=0.77s
16050/10943 (epoch 131.997) train_loss=392.23535156 time/batch=0.79s
16051/10943 (epoch 132.005) train_loss=334.30874634 time/batch=0.73s
16052/10943 (epoch 132.013) train_loss=532.05847168 time/batch=1.00s
16053/10943 (epoch 132.022) train_loss=337.40032959 time/batch=0.71s
16054/10943 (epoch 132.030) train_loss=214.49441528 time/batch=0.48s
16055/10943 (epoch 132.038) train_loss=527.75427246 time/batch=1.02s
16056/10943 (epoch 132.046) train_loss=933.70031738 time/batch=3.09s
16057/10943 (epoch 132.054) train_loss=468.43197632 time/batch=1.15s
16058/10943 (epoch 132.063) train_loss=464.23107910 time/batch=0.93s
16059/10943 (epoch 132.071) train_loss=389.65454102 time/batch=0.82s
16060/10943 (epoch 132.079) train_loss=364.02679443 time/batch=0.73s
16061/10943 (epoch 132.087) train_loss=420.71575928 time/batch=0.82s
16062/10943 (epoch 132.096) train_loss=335.22085571 time/batch=0.69s
16063/10943 (epoch 132.104) train_loss=228.18014526 time/batch=0.50s
16064/10943 (epoch 132.112) train_loss=239.01263428 time/batch=0.48s
16065/10943 (epoch 132.120) train_loss=143.03240967 time/batch=0.32s
16066/10943 (epoch 132.129) train_loss=359.37585449 time/batch=0.69s
16067/10943 (epoch 132.137) train_loss=153.49218750 time/batch=0.35s
16068/10943 (epoch 132.145) train_loss=254.14793396 time/batch=0.50s
16069/10943 (epoch 132.153) train_loss=382.95117188 time/batch=0.73s
16070/10943 (epoch 132.161) train_loss=158.89300537 time/batch=0.36s
16071/10943 (epoch 132.170) train_loss=181.43145752 time/batch=0.37s
16072/10943 (epoch 132.178) train_loss=153.04730225 time/batch=0.32s
16073/10943 (epoch 132.186) train_loss=554.51208496 time/batch=1.02s
16074/10943 (epoch 132.194) train_loss=287.76342773 time/batch=0.63s
16075/10943 (epoch 132.203) train_loss=418.88839722 time/batch=0.80s
16076/10943 (epoch 132.211) train_loss=457.88763428 time/batch=0.93s
16077/10943 (epoch 132.219) train_loss=297.54315186 time/batch=0.64s
16078/10943 (epoch 132.227) train_loss=386.88354492 time/batch=0.73s
16079/10943 (epoch 132.235) train_loss=568.16516113 time/batch=1.08s
16080/10943 (epoch 132.244) train_loss=493.47821045 time/batch=0.97s
16081/10943 (epoch 132.252) train_loss=218.33421326 time/batch=0.48s
16082/10943 (epoch 132.260) train_loss=179.05255127 time/batch=0.36s
16083/10943 (epoch 132.268) train_loss=248.32125854 time/batch=0.50s
16084/10943 (epoch 132.277) train_loss=187.95686340 time/batch=0.39s
16085/10943 (epoch 132.285) train_loss=355.18884277 time/batch=0.68s
16086/10943 (epoch 132.293) train_loss=493.12512207 time/batch=1.08s
16087/10943 (epoch 132.301) train_loss=344.75991821 time/batch=0.71s
16088/10943 (epoch 132.309) train_loss=197.00396729 time/batch=0.42s
16089/10943 (epoch 132.318) train_loss=195.24229431 time/batch=0.40s
16090/10943 (epoch 132.326) train_loss=456.23056030 time/batch=1.05s
16091/10943 (epoch 132.334) train_loss=233.63934326 time/batch=0.55s
16092/10943 (epoch 132.342) train_loss=285.33374023 time/batch=0.56s
16093/10943 (epoch 132.351) train_loss=427.81341553 time/batch=0.82s
16094/10943 (epoch 132.359) train_loss=238.02917480 time/batch=0.53s
16095/10943 (epoch 132.367) train_loss=276.42886353 time/batch=0.54s
16096/10943 (epoch 132.375) train_loss=234.03204346 time/batch=0.49s
16097/10943 (epoch 132.383) train_loss=174.61022949 time/batch=0.37s
16098/10943 (epoch 132.392) train_loss=276.07846069 time/batch=0.54s
16099/10943 (epoch 132.400) train_loss=249.95422363 time/batch=0.53s
16100/10943 (epoch 132.408) train_loss=377.80902100 time/batch=0.71s
16101/10943 (epoch 132.416) train_loss=395.10101318 time/batch=0.80s
16102/10943 (epoch 132.425) train_loss=348.53094482 time/batch=0.75s
16103/10943 (epoch 132.433) train_loss=446.67034912 time/batch=0.87s
16104/10943 (epoch 132.441) train_loss=409.54608154 time/batch=0.82s
16105/10943 (epoch 132.449) train_loss=436.12457275 time/batch=0.87s
16106/10943 (epoch 132.457) train_loss=428.36566162 time/batch=0.87s
16107/10943 (epoch 132.466) train_loss=291.58868408 time/batch=0.61s
16108/10943 (epoch 132.474) train_loss=292.86032104 time/batch=0.58s
16109/10943 (epoch 132.482) train_loss=321.33364868 time/batch=0.62s
16110/10943 (epoch 132.490) train_loss=299.49615479 time/batch=0.61s
16111/10943 (epoch 132.499) train_loss=324.83734131 time/batch=0.63s
16112/10943 (epoch 132.507) train_loss=268.98162842 time/batch=0.56s
16113/10943 (epoch 132.515) train_loss=320.20205688 time/batch=0.63s
16114/10943 (epoch 132.523) train_loss=339.55737305 time/batch=0.66s
16115/10943 (epoch 132.531) train_loss=339.34121704 time/batch=0.67s
16116/10943 (epoch 132.540) train_loss=265.63989258 time/batch=0.54s
16117/10943 (epoch 132.548) train_loss=264.42251587 time/batch=0.54s
16118/10943 (epoch 132.556) train_loss=253.50708008 time/batch=0.52s
16119/10943 (epoch 132.564) train_loss=409.25866699 time/batch=0.79s
16120/10943 (epoch 132.573) train_loss=324.95339966 time/batch=0.68s
16121/10943 (epoch 132.581) train_loss=431.81671143 time/batch=0.84s
16122/10943 (epoch 132.589) train_loss=200.53398132 time/batch=0.55s
16123/10943 (epoch 132.597) train_loss=343.35058594 time/batch=0.66s
16124/10943 (epoch 132.605) train_loss=361.95684814 time/batch=0.76s
16125/10943 (epoch 132.614) train_loss=215.52799988 time/batch=0.54s
16126/10943 (epoch 132.622) train_loss=279.21127319 time/batch=0.58s
16127/10943 (epoch 132.630) train_loss=294.83520508 time/batch=0.60s
16128/10943 (epoch 132.638) train_loss=386.67037964 time/batch=0.78s
16129/10943 (epoch 132.647) train_loss=295.03741455 time/batch=0.69s
setting learning rate to 0.0003781
16130/10943 (epoch 132.655) train_loss=175.29060364 time/batch=0.38s
16131/10943 (epoch 132.663) train_loss=215.49481201 time/batch=0.43s
16132/10943 (epoch 132.671) train_loss=293.93225098 time/batch=0.59s
16133/10943 (epoch 132.680) train_loss=298.38412476 time/batch=0.61s
16134/10943 (epoch 132.688) train_loss=697.03552246 time/batch=1.25s
16135/10943 (epoch 132.696) train_loss=438.68215942 time/batch=0.92s
16136/10943 (epoch 132.704) train_loss=211.02763367 time/batch=0.47s
16137/10943 (epoch 132.712) train_loss=725.56311035 time/batch=1.41s
16138/10943 (epoch 132.721) train_loss=571.44616699 time/batch=1.19s
16139/10943 (epoch 132.729) train_loss=636.72467041 time/batch=1.22s
16140/10943 (epoch 132.737) train_loss=118.59344482 time/batch=0.35s
16141/10943 (epoch 132.745) train_loss=267.85604858 time/batch=0.52s
16142/10943 (epoch 132.754) train_loss=503.71487427 time/batch=0.98s
16143/10943 (epoch 132.762) train_loss=487.05679321 time/batch=0.98s
16144/10943 (epoch 132.770) train_loss=390.35107422 time/batch=0.80s
16145/10943 (epoch 132.778) train_loss=246.73184204 time/batch=0.54s
16146/10943 (epoch 132.786) train_loss=394.19183350 time/batch=0.75s
16147/10943 (epoch 132.795) train_loss=803.30627441 time/batch=1.59s
16148/10943 (epoch 132.803) train_loss=396.39044189 time/batch=0.91s
16149/10943 (epoch 132.811) train_loss=897.44201660 time/batch=1.77s
16150/10943 (epoch 132.819) train_loss=708.31610107 time/batch=1.46s
16151/10943 (epoch 132.828) train_loss=458.84762573 time/batch=1.00s
16152/10943 (epoch 132.836) train_loss=375.05456543 time/batch=0.76s
16153/10943 (epoch 132.844) train_loss=392.24176025 time/batch=0.80s
16154/10943 (epoch 132.852) train_loss=409.61529541 time/batch=0.83s
16155/10943 (epoch 132.860) train_loss=130.73260498 time/batch=0.33s
16156/10943 (epoch 132.869) train_loss=546.44268799 time/batch=0.95s
16157/10943 (epoch 132.877) train_loss=314.33245850 time/batch=0.67s
16158/10943 (epoch 132.885) train_loss=421.76867676 time/batch=0.82s
16159/10943 (epoch 132.893) train_loss=568.41876221 time/batch=1.14s
16160/10943 (epoch 132.902) train_loss=215.76196289 time/batch=0.51s
16161/10943 (epoch 132.910) train_loss=182.39340210 time/batch=0.38s
16162/10943 (epoch 132.918) train_loss=617.74200439 time/batch=1.15s
16163/10943 (epoch 132.926) train_loss=147.89605713 time/batch=0.39s
16164/10943 (epoch 132.934) train_loss=262.17898560 time/batch=0.51s
16165/10943 (epoch 132.943) train_loss=1022.14801025 time/batch=2.32s
16166/10943 (epoch 132.951) train_loss=377.65237427 time/batch=0.92s
16167/10943 (epoch 132.959) train_loss=257.45690918 time/batch=0.52s
16168/10943 (epoch 132.967) train_loss=545.80877686 time/batch=0.98s
16169/10943 (epoch 132.976) train_loss=196.35351562 time/batch=0.46s
16170/10943 (epoch 132.984) train_loss=339.90557861 time/batch=0.66s
16171/10943 (epoch 132.992) train_loss=144.81921387 time/batch=0.34s
16172/10943 (epoch 133.000) train_loss=359.87884521 time/batch=0.67s
16173/10943 (epoch 133.008) train_loss=398.26269531 time/batch=0.79s
16174/10943 (epoch 133.017) train_loss=452.25424194 time/batch=0.89s
16175/10943 (epoch 133.025) train_loss=430.90927124 time/batch=0.87s
16176/10943 (epoch 133.033) train_loss=272.40124512 time/batch=0.57s
16177/10943 (epoch 133.041) train_loss=436.32949829 time/batch=0.84s
16178/10943 (epoch 133.050) train_loss=693.38507080 time/batch=3.08s
16179/10943 (epoch 133.058) train_loss=535.32470703 time/batch=1.27s
16180/10943 (epoch 133.066) train_loss=164.12869263 time/batch=0.39s
16181/10943 (epoch 133.074) train_loss=488.22338867 time/batch=0.92s
16182/10943 (epoch 133.082) train_loss=570.65454102 time/batch=1.10s
16183/10943 (epoch 133.091) train_loss=343.65319824 time/batch=0.71s
16184/10943 (epoch 133.099) train_loss=581.28729248 time/batch=1.12s
16185/10943 (epoch 133.107) train_loss=486.33813477 time/batch=0.97s
16186/10943 (epoch 133.115) train_loss=170.66079712 time/batch=0.40s
16187/10943 (epoch 133.124) train_loss=312.31799316 time/batch=0.58s
16188/10943 (epoch 133.132) train_loss=175.72830200 time/batch=0.39s
16189/10943 (epoch 133.140) train_loss=481.87014771 time/batch=0.89s
16190/10943 (epoch 133.148) train_loss=380.55877686 time/batch=0.74s
16191/10943 (epoch 133.157) train_loss=382.33673096 time/batch=0.75s
16192/10943 (epoch 133.165) train_loss=228.81152344 time/batch=0.49s
16193/10943 (epoch 133.173) train_loss=452.59619141 time/batch=0.84s
16194/10943 (epoch 133.181) train_loss=195.41806030 time/batch=0.45s
16195/10943 (epoch 133.189) train_loss=252.28413391 time/batch=0.53s
16196/10943 (epoch 133.198) train_loss=215.65048218 time/batch=0.45s
16197/10943 (epoch 133.206) train_loss=247.72695923 time/batch=0.49s
16198/10943 (epoch 133.214) train_loss=494.55206299 time/batch=0.94s
16199/10943 (epoch 133.222) train_loss=304.35034180 time/batch=0.65s
16200/10943 (epoch 133.231) train_loss=383.63146973 time/batch=0.75s
16201/10943 (epoch 133.239) train_loss=428.44787598 time/batch=0.85s
16202/10943 (epoch 133.247) train_loss=346.33816528 time/batch=0.70s
16203/10943 (epoch 133.255) train_loss=250.12210083 time/batch=0.53s
16204/10943 (epoch 133.263) train_loss=228.06402588 time/batch=0.45s
16205/10943 (epoch 133.272) train_loss=331.19720459 time/batch=0.65s
16206/10943 (epoch 133.280) train_loss=215.72427368 time/batch=0.48s
16207/10943 (epoch 133.288) train_loss=237.71566772 time/batch=0.47s
16208/10943 (epoch 133.296) train_loss=193.67279053 time/batch=0.41s
16209/10943 (epoch 133.305) train_loss=556.32836914 time/batch=1.15s
16210/10943 (epoch 133.313) train_loss=285.29455566 time/batch=0.63s
16211/10943 (epoch 133.321) train_loss=286.61120605 time/batch=0.58s
16212/10943 (epoch 133.329) train_loss=454.38745117 time/batch=0.88s
16213/10943 (epoch 133.337) train_loss=275.34680176 time/batch=0.59s
16214/10943 (epoch 133.346) train_loss=388.62249756 time/batch=0.75s
16215/10943 (epoch 133.354) train_loss=388.70007324 time/batch=0.76s
16216/10943 (epoch 133.362) train_loss=242.97186279 time/batch=0.55s
16217/10943 (epoch 133.370) train_loss=323.49539185 time/batch=0.62s
16218/10943 (epoch 133.379) train_loss=262.01885986 time/batch=0.56s
16219/10943 (epoch 133.387) train_loss=349.79980469 time/batch=0.69s
16220/10943 (epoch 133.395) train_loss=381.95965576 time/batch=0.79s
16221/10943 (epoch 133.403) train_loss=167.03289795 time/batch=0.40s
16222/10943 (epoch 133.411) train_loss=304.08486938 time/batch=0.60s
16223/10943 (epoch 133.420) train_loss=369.11895752 time/batch=0.72s
16224/10943 (epoch 133.428) train_loss=279.91625977 time/batch=0.60s
16225/10943 (epoch 133.436) train_loss=433.89202881 time/batch=0.85s
16226/10943 (epoch 133.444) train_loss=266.53521729 time/batch=0.60s
16227/10943 (epoch 133.453) train_loss=145.40322876 time/batch=0.33s
16228/10943 (epoch 133.461) train_loss=321.30938721 time/batch=0.60s
16229/10943 (epoch 133.469) train_loss=350.33581543 time/batch=0.69s
16230/10943 (epoch 133.477) train_loss=469.77017212 time/batch=1.02s
16231/10943 (epoch 133.485) train_loss=167.22901917 time/batch=0.43s
16232/10943 (epoch 133.494) train_loss=332.55810547 time/batch=0.65s
16233/10943 (epoch 133.502) train_loss=376.26425171 time/batch=0.79s
16234/10943 (epoch 133.510) train_loss=228.88519287 time/batch=0.51s
16235/10943 (epoch 133.518) train_loss=189.89843750 time/batch=0.47s
16236/10943 (epoch 133.527) train_loss=339.32720947 time/batch=0.67s
16237/10943 (epoch 133.535) train_loss=400.27374268 time/batch=0.80s
16238/10943 (epoch 133.543) train_loss=307.95339966 time/batch=0.66s
16239/10943 (epoch 133.551) train_loss=325.66806030 time/batch=0.65s
16240/10943 (epoch 133.559) train_loss=352.90136719 time/batch=0.73s
16241/10943 (epoch 133.568) train_loss=286.83239746 time/batch=0.59s
16242/10943 (epoch 133.576) train_loss=400.91082764 time/batch=0.79s
16243/10943 (epoch 133.584) train_loss=341.08532715 time/batch=0.68s
16244/10943 (epoch 133.592) train_loss=400.95953369 time/batch=0.81s
16245/10943 (epoch 133.601) train_loss=289.47601318 time/batch=0.62s
16246/10943 (epoch 133.609) train_loss=271.46575928 time/batch=0.57s
16247/10943 (epoch 133.617) train_loss=293.14831543 time/batch=0.59s
16248/10943 (epoch 133.625) train_loss=338.20236206 time/batch=0.65s
16249/10943 (epoch 133.634) train_loss=333.53482056 time/batch=0.70s
16250/10943 (epoch 133.642) train_loss=286.30139160 time/batch=0.61s
setting learning rate to 0.0003668
  saved to metadata/gru_dropout-9_nov_folkwiki-20181207-173447_epoch89.pkl
