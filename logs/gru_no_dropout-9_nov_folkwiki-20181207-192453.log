vocabulary size: 226
n tunes: 4083
n train tunes: 3891.0
n validation tunes: 192.0
min, max length 55 822
Building the model
  number of parameters: 10384102
  layer output shapes:               #params:   output shape:
    InputLayer                       0          (32, None)
    EmbeddingLayer                   51076      (32, None, 226)
    InputLayer                       0          (32, None)
    GRULayer                         2465600    (32, None, 800)
    GRULayer                         3843200    (32, None, 800)
    GRULayer                         3843200    (32, None, 800)
    ReshapeLayer                     0          (None, 800)
    DenseLayer                       181026     (None, 226)
Train model
Load metadata for resuming
setting learning rate to 0.0030000
7781/10943 (epoch 63.992) train_loss=411.05834961 time/batch=1.17s
7782/10943 (epoch 64.000) train_loss=331.30651855 time/batch=0.84s
7783/10943 (epoch 64.008) train_loss=734.71228027 time/batch=1.66s
7784/10943 (epoch 64.016) train_loss=570.73956299 time/batch=1.47s
7785/10943 (epoch 64.025) train_loss=146.20668030 time/batch=0.48s
7786/10943 (epoch 64.033) train_loss=210.46090698 time/batch=0.54s
7787/10943 (epoch 64.041) train_loss=302.44851685 time/batch=0.82s
7788/10943 (epoch 64.049) train_loss=88.62497711 time/batch=0.31s
7789/10943 (epoch 64.058) train_loss=330.83993530 time/batch=0.87s
7790/10943 (epoch 64.066) train_loss=662.67553711 time/batch=1.92s
7791/10943 (epoch 64.074) train_loss=797.41833496 time/batch=3.15s
7792/10943 (epoch 64.082) train_loss=266.34643555 time/batch=0.95s
7793/10943 (epoch 64.090) train_loss=249.23947144 time/batch=0.65s
7794/10943 (epoch 64.099) train_loss=193.86978149 time/batch=0.55s
7795/10943 (epoch 64.107) train_loss=278.75201416 time/batch=0.74s
7796/10943 (epoch 64.115) train_loss=375.74853516 time/batch=0.99s
7797/10943 (epoch 64.123) train_loss=327.90539551 time/batch=0.86s
7798/10943 (epoch 64.132) train_loss=156.89570618 time/batch=0.41s
7799/10943 (epoch 64.140) train_loss=128.04237366 time/batch=0.29s
7800/10943 (epoch 64.148) train_loss=165.60736084 time/batch=0.44s
7801/10943 (epoch 64.156) train_loss=270.17065430 time/batch=0.73s
7802/10943 (epoch 64.164) train_loss=355.16400146 time/batch=0.94s
7803/10943 (epoch 64.173) train_loss=144.63163757 time/batch=0.46s
7804/10943 (epoch 64.181) train_loss=389.50408936 time/batch=0.93s
7805/10943 (epoch 64.189) train_loss=188.77320862 time/batch=0.58s
7806/10943 (epoch 64.197) train_loss=165.04776001 time/batch=0.47s
7807/10943 (epoch 64.206) train_loss=342.95089722 time/batch=0.92s
7808/10943 (epoch 64.214) train_loss=326.04925537 time/batch=0.92s
7809/10943 (epoch 64.222) train_loss=516.42749023 time/batch=1.31s
7810/10943 (epoch 64.230) train_loss=413.36212158 time/batch=1.17s
7811/10943 (epoch 64.238) train_loss=147.24557495 time/batch=0.48s
7812/10943 (epoch 64.247) train_loss=266.84710693 time/batch=0.71s
7813/10943 (epoch 64.255) train_loss=402.01684570 time/batch=1.03s
7814/10943 (epoch 64.263) train_loss=218.18865967 time/batch=0.64s
7815/10943 (epoch 64.271) train_loss=100.05490875 time/batch=0.30s
7816/10943 (epoch 64.280) train_loss=479.28137207 time/batch=1.19s
7817/10943 (epoch 64.288) train_loss=309.82342529 time/batch=0.90s
7818/10943 (epoch 64.296) train_loss=421.69711304 time/batch=1.18s
7819/10943 (epoch 64.304) train_loss=269.02053833 time/batch=0.85s
7820/10943 (epoch 64.313) train_loss=232.97236633 time/batch=0.66s
7821/10943 (epoch 64.321) train_loss=449.65972900 time/batch=1.28s
7822/10943 (epoch 64.329) train_loss=362.67169189 time/batch=1.05s
7823/10943 (epoch 64.337) train_loss=184.75875854 time/batch=0.58s
7824/10943 (epoch 64.345) train_loss=226.59295654 time/batch=0.66s
7825/10943 (epoch 64.354) train_loss=344.55169678 time/batch=0.92s
7826/10943 (epoch 64.362) train_loss=454.55847168 time/batch=1.20s
7827/10943 (epoch 64.370) train_loss=135.34762573 time/batch=0.45s
7828/10943 (epoch 64.378) train_loss=268.89880371 time/batch=0.74s
7829/10943 (epoch 64.387) train_loss=349.41778564 time/batch=0.96s
7830/10943 (epoch 64.395) train_loss=397.15997314 time/batch=1.12s
7831/10943 (epoch 64.403) train_loss=131.01701355 time/batch=0.43s
7832/10943 (epoch 64.411) train_loss=290.84933472 time/batch=0.78s
7833/10943 (epoch 64.419) train_loss=141.20333862 time/batch=0.42s
7834/10943 (epoch 64.428) train_loss=251.62808228 time/batch=0.68s
7835/10943 (epoch 64.436) train_loss=156.22445679 time/batch=0.46s
7836/10943 (epoch 64.444) train_loss=292.24041748 time/batch=0.79s
7837/10943 (epoch 64.452) train_loss=337.64666748 time/batch=0.97s
7838/10943 (epoch 64.461) train_loss=277.47296143 time/batch=0.83s
7839/10943 (epoch 64.469) train_loss=208.53637695 time/batch=0.60s
7840/10943 (epoch 64.477) train_loss=189.11007690 time/batch=0.55s
7841/10943 (epoch 64.485) train_loss=108.85272980 time/batch=0.31s
7842/10943 (epoch 64.493) train_loss=204.52272034 time/batch=0.54s
7843/10943 (epoch 64.502) train_loss=126.17579651 time/batch=0.37s
7844/10943 (epoch 64.510) train_loss=136.48094177 time/batch=0.40s
7845/10943 (epoch 64.518) train_loss=209.34313965 time/batch=0.59s
7846/10943 (epoch 64.526) train_loss=410.27273560 time/batch=1.10s
7847/10943 (epoch 64.535) train_loss=177.00428772 time/batch=0.58s
7848/10943 (epoch 64.543) train_loss=288.50762939 time/batch=0.80s
7849/10943 (epoch 64.551) train_loss=167.42735291 time/batch=0.52s
7850/10943 (epoch 64.559) train_loss=243.91812134 time/batch=0.67s
7851/10943 (epoch 64.567) train_loss=265.67077637 time/batch=0.79s
7852/10943 (epoch 64.576) train_loss=274.89233398 time/batch=0.79s
7853/10943 (epoch 64.584) train_loss=300.30053711 time/batch=0.85s
7854/10943 (epoch 64.592) train_loss=213.00036621 time/batch=0.63s
7855/10943 (epoch 64.600) train_loss=103.10078430 time/batch=0.33s
7856/10943 (epoch 64.609) train_loss=232.20129395 time/batch=0.60s
7857/10943 (epoch 64.617) train_loss=297.40527344 time/batch=0.82s
7858/10943 (epoch 64.625) train_loss=324.76132202 time/batch=1.01s
7859/10943 (epoch 64.633) train_loss=174.55767822 time/batch=0.53s
7860/10943 (epoch 64.641) train_loss=265.70895386 time/batch=0.74s
7861/10943 (epoch 64.650) train_loss=291.87603760 time/batch=0.86s
7862/10943 (epoch 64.658) train_loss=253.55682373 time/batch=0.74s
7863/10943 (epoch 64.666) train_loss=422.03039551 time/batch=1.41s
7864/10943 (epoch 64.674) train_loss=185.76367188 time/batch=0.60s
7865/10943 (epoch 64.683) train_loss=215.22885132 time/batch=0.62s
7866/10943 (epoch 64.691) train_loss=304.25338745 time/batch=0.85s
7867/10943 (epoch 64.699) train_loss=146.64514160 time/batch=0.48s
7868/10943 (epoch 64.707) train_loss=234.93310547 time/batch=0.63s
7869/10943 (epoch 64.715) train_loss=217.90722656 time/batch=0.61s
7870/10943 (epoch 64.724) train_loss=199.28170776 time/batch=0.59s
7871/10943 (epoch 64.732) train_loss=197.47427368 time/batch=0.58s
7872/10943 (epoch 64.740) train_loss=225.98120117 time/batch=0.64s
7873/10943 (epoch 64.748) train_loss=134.76216125 time/batch=0.46s
7874/10943 (epoch 64.757) train_loss=152.09875488 time/batch=0.44s
7875/10943 (epoch 64.765) train_loss=122.66892242 time/batch=0.45s
7876/10943 (epoch 64.773) train_loss=202.88665771 time/batch=0.59s
7877/10943 (epoch 64.781) train_loss=252.09721375 time/batch=0.70s
7878/10943 (epoch 64.790) train_loss=173.67160034 time/batch=0.54s
7879/10943 (epoch 64.798) train_loss=171.59606934 time/batch=0.49s
7880/10943 (epoch 64.806) train_loss=178.51840210 time/batch=0.49s
7881/10943 (epoch 64.814) train_loss=261.26174927 time/batch=0.71s
7882/10943 (epoch 64.822) train_loss=109.78261566 time/batch=0.36s
7883/10943 (epoch 64.831) train_loss=301.83410645 time/batch=0.82s
7884/10943 (epoch 64.839) train_loss=201.35058594 time/batch=0.62s
7885/10943 (epoch 64.847) train_loss=146.94772339 time/batch=0.51s
7886/10943 (epoch 64.855) train_loss=201.19989014 time/batch=0.59s
7887/10943 (epoch 64.864) train_loss=187.28567505 time/batch=0.53s
7888/10943 (epoch 64.872) train_loss=237.27636719 time/batch=0.65s
7889/10943 (epoch 64.880) train_loss=149.92054749 time/batch=0.56s
7890/10943 (epoch 64.888) train_loss=265.42767334 time/batch=0.71s
7891/10943 (epoch 64.896) train_loss=220.09579468 time/batch=0.67s
7892/10943 (epoch 64.905) train_loss=231.83882141 time/batch=0.67s
7893/10943 (epoch 64.913) train_loss=328.72772217 time/batch=0.99s
7894/10943 (epoch 64.921) train_loss=206.00473022 time/batch=0.64s
7895/10943 (epoch 64.929) train_loss=272.20043945 time/batch=0.84s
7896/10943 (epoch 64.938) train_loss=212.14126587 time/batch=0.69s
7897/10943 (epoch 64.946) train_loss=261.60122681 time/batch=0.71s
7898/10943 (epoch 64.954) train_loss=259.14868164 time/batch=0.86s
7899/10943 (epoch 64.962) train_loss=220.20611572 time/batch=0.70s
7900/10943 (epoch 64.970) train_loss=254.30596924 time/batch=0.70s
7901/10943 (epoch 64.979) train_loss=235.88507080 time/batch=0.73s
7902/10943 (epoch 64.987) train_loss=136.87408447 time/batch=0.43s
7903/10943 (epoch 64.995) train_loss=225.90277100 time/batch=0.63s
7904/10943 (epoch 65.003) train_loss=356.00939941 time/batch=1.01s
7905/10943 (epoch 65.012) train_loss=435.72741699 time/batch=1.25s
7906/10943 (epoch 65.020) train_loss=840.18530273 time/batch=3.11s
7907/10943 (epoch 65.028) train_loss=544.57360840 time/batch=1.60s
7908/10943 (epoch 65.036) train_loss=277.60751343 time/batch=0.88s
7909/10943 (epoch 65.044) train_loss=376.93756104 time/batch=1.02s
7910/10943 (epoch 65.053) train_loss=255.95137024 time/batch=0.81s
7911/10943 (epoch 65.061) train_loss=274.44311523 time/batch=0.83s
7912/10943 (epoch 65.069) train_loss=167.90423584 time/batch=0.54s
7913/10943 (epoch 65.077) train_loss=616.90826416 time/batch=1.63s
7914/10943 (epoch 65.086) train_loss=238.25729370 time/batch=0.82s
7915/10943 (epoch 65.094) train_loss=385.60095215 time/batch=1.10s
7916/10943 (epoch 65.102) train_loss=83.38346863 time/batch=0.34s
7917/10943 (epoch 65.110) train_loss=290.74279785 time/batch=0.78s
7918/10943 (epoch 65.118) train_loss=537.41021729 time/batch=1.54s
7919/10943 (epoch 65.127) train_loss=198.32223511 time/batch=0.69s
7920/10943 (epoch 65.135) train_loss=258.45861816 time/batch=0.75s
7921/10943 (epoch 65.143) train_loss=467.72720337 time/batch=1.37s
7922/10943 (epoch 65.151) train_loss=128.00714111 time/batch=0.45s
7923/10943 (epoch 65.160) train_loss=152.56175232 time/batch=0.44s
7924/10943 (epoch 65.168) train_loss=196.15972900 time/batch=0.60s
7925/10943 (epoch 65.176) train_loss=375.50335693 time/batch=1.05s
7926/10943 (epoch 65.184) train_loss=151.82865906 time/batch=0.49s
7927/10943 (epoch 65.192) train_loss=229.71282959 time/batch=0.67s
7928/10943 (epoch 65.201) train_loss=109.39297485 time/batch=0.34s
7929/10943 (epoch 65.209) train_loss=331.82766724 time/batch=0.91s
7930/10943 (epoch 65.217) train_loss=284.33218384 time/batch=0.87s
7931/10943 (epoch 65.225) train_loss=408.19293213 time/batch=1.16s
7932/10943 (epoch 65.234) train_loss=270.11309814 time/batch=0.82s
7933/10943 (epoch 65.242) train_loss=196.92604065 time/batch=0.61s
7934/10943 (epoch 65.250) train_loss=160.25250244 time/batch=0.48s
7935/10943 (epoch 65.258) train_loss=227.75073242 time/batch=0.62s
7936/10943 (epoch 65.267) train_loss=175.32461548 time/batch=0.52s
7937/10943 (epoch 65.275) train_loss=250.11401367 time/batch=0.70s
7938/10943 (epoch 65.283) train_loss=307.34732056 time/batch=0.90s
7939/10943 (epoch 65.291) train_loss=107.64501953 time/batch=0.35s
7940/10943 (epoch 65.299) train_loss=281.94338989 time/batch=0.80s
7941/10943 (epoch 65.308) train_loss=435.40930176 time/batch=1.20s
7942/10943 (epoch 65.316) train_loss=375.02716064 time/batch=1.02s
7943/10943 (epoch 65.324) train_loss=107.07620239 time/batch=0.38s
7944/10943 (epoch 65.332) train_loss=267.93981934 time/batch=0.74s
7945/10943 (epoch 65.341) train_loss=303.17169189 time/batch=0.91s
7946/10943 (epoch 65.349) train_loss=120.74339294 time/batch=0.40s
7947/10943 (epoch 65.357) train_loss=256.80453491 time/batch=0.77s
7948/10943 (epoch 65.365) train_loss=149.97747803 time/batch=0.49s
7949/10943 (epoch 65.373) train_loss=307.31323242 time/batch=0.88s
7950/10943 (epoch 65.382) train_loss=293.10491943 time/batch=0.89s
7951/10943 (epoch 65.390) train_loss=112.35862732 time/batch=0.39s
7952/10943 (epoch 65.398) train_loss=391.99462891 time/batch=1.04s
7953/10943 (epoch 65.406) train_loss=241.28106689 time/batch=0.73s
7954/10943 (epoch 65.415) train_loss=128.84692383 time/batch=0.41s
7955/10943 (epoch 65.423) train_loss=251.74998474 time/batch=0.66s
7956/10943 (epoch 65.431) train_loss=220.66729736 time/batch=0.68s
7957/10943 (epoch 65.439) train_loss=96.05838013 time/batch=0.31s
7958/10943 (epoch 65.447) train_loss=381.23095703 time/batch=1.03s
7959/10943 (epoch 65.456) train_loss=369.75012207 time/batch=1.15s
7960/10943 (epoch 65.464) train_loss=123.86528778 time/batch=0.44s
7961/10943 (epoch 65.472) train_loss=311.24887085 time/batch=0.88s
7962/10943 (epoch 65.480) train_loss=266.45083618 time/batch=0.78s
7963/10943 (epoch 65.489) train_loss=196.75463867 time/batch=0.61s
7964/10943 (epoch 65.497) train_loss=139.58435059 time/batch=0.45s
7965/10943 (epoch 65.505) train_loss=476.91668701 time/batch=1.38s
7966/10943 (epoch 65.513) train_loss=188.11727905 time/batch=0.65s
7967/10943 (epoch 65.521) train_loss=398.32980347 time/batch=1.21s
7968/10943 (epoch 65.530) train_loss=195.72341919 time/batch=0.65s
7969/10943 (epoch 65.538) train_loss=222.37808228 time/batch=0.66s
7970/10943 (epoch 65.546) train_loss=117.44824982 time/batch=0.38s
7971/10943 (epoch 65.554) train_loss=179.96421814 time/batch=0.53s
7972/10943 (epoch 65.563) train_loss=209.03225708 time/batch=0.63s
7973/10943 (epoch 65.571) train_loss=136.66941833 time/batch=0.41s
7974/10943 (epoch 65.579) train_loss=163.79574585 time/batch=0.47s
7975/10943 (epoch 65.587) train_loss=239.65570068 time/batch=0.72s
7976/10943 (epoch 65.595) train_loss=228.91845703 time/batch=0.70s
7977/10943 (epoch 65.604) train_loss=194.93395996 time/batch=0.60s
7978/10943 (epoch 65.612) train_loss=182.13465881 time/batch=0.55s
7979/10943 (epoch 65.620) train_loss=245.10867310 time/batch=0.68s
7980/10943 (epoch 65.628) train_loss=295.91360474 time/batch=0.85s
7981/10943 (epoch 65.637) train_loss=168.34812927 time/batch=0.56s
7982/10943 (epoch 65.645) train_loss=243.02418518 time/batch=0.69s
7983/10943 (epoch 65.653) train_loss=171.77934265 time/batch=0.54s
7984/10943 (epoch 65.661) train_loss=172.74649048 time/batch=0.50s
7985/10943 (epoch 65.669) train_loss=247.24638367 time/batch=0.71s
7986/10943 (epoch 65.678) train_loss=203.58457947 time/batch=0.62s
7987/10943 (epoch 65.686) train_loss=329.30950928 time/batch=0.92s
7988/10943 (epoch 65.694) train_loss=157.69879150 time/batch=0.52s
7989/10943 (epoch 65.702) train_loss=203.42395020 time/batch=0.60s
7990/10943 (epoch 65.711) train_loss=216.68447876 time/batch=0.62s
7991/10943 (epoch 65.719) train_loss=164.43176270 time/batch=0.49s
7992/10943 (epoch 65.727) train_loss=332.03045654 time/batch=0.94s
7993/10943 (epoch 65.735) train_loss=256.00750732 time/batch=0.82s
7994/10943 (epoch 65.744) train_loss=255.15176392 time/batch=0.80s
7995/10943 (epoch 65.752) train_loss=145.57946777 time/batch=0.47s
7996/10943 (epoch 65.760) train_loss=212.99462891 time/batch=0.62s
7997/10943 (epoch 65.768) train_loss=156.02703857 time/batch=0.49s
7998/10943 (epoch 65.776) train_loss=116.97046661 time/batch=0.37s
7999/10943 (epoch 65.785) train_loss=225.16806030 time/batch=0.64s
Validating
    loss:	263.239428

8000/10943 (epoch 65.793) train_loss=198.33203125 time/batch=2.45s
8001/10943 (epoch 65.801) train_loss=339.23645020 time/batch=0.97s
8002/10943 (epoch 65.809) train_loss=137.56100464 time/batch=0.43s
8003/10943 (epoch 65.818) train_loss=197.87243652 time/batch=0.55s
8004/10943 (epoch 65.826) train_loss=184.63223267 time/batch=0.52s
8005/10943 (epoch 65.834) train_loss=150.55335999 time/batch=0.53s
8006/10943 (epoch 65.842) train_loss=223.46682739 time/batch=0.66s
8007/10943 (epoch 65.850) train_loss=167.00543213 time/batch=0.56s
8008/10943 (epoch 65.859) train_loss=227.13415527 time/batch=0.63s
8009/10943 (epoch 65.867) train_loss=234.51062012 time/batch=0.67s
8010/10943 (epoch 65.875) train_loss=246.61393738 time/batch=0.74s
8011/10943 (epoch 65.883) train_loss=167.65919495 time/batch=0.60s
8012/10943 (epoch 65.892) train_loss=205.99966431 time/batch=0.61s
8013/10943 (epoch 65.900) train_loss=332.10491943 time/batch=0.94s
8014/10943 (epoch 65.908) train_loss=264.74047852 time/batch=0.83s
8015/10943 (epoch 65.916) train_loss=264.94940186 time/batch=0.77s
8016/10943 (epoch 65.924) train_loss=291.71377563 time/batch=0.85s
8017/10943 (epoch 65.933) train_loss=233.54589844 time/batch=0.75s
8018/10943 (epoch 65.941) train_loss=279.60888672 time/batch=0.81s
8019/10943 (epoch 65.949) train_loss=189.61099243 time/batch=0.62s
8020/10943 (epoch 65.957) train_loss=315.38247681 time/batch=0.92s
8021/10943 (epoch 65.966) train_loss=281.03814697 time/batch=0.84s
8022/10943 (epoch 65.974) train_loss=247.36978149 time/batch=0.83s
setting learning rate to 0.0029100
  saved to metadata/gru_no_dropout-9_nov_folkwiki-20181207-192453_epoch21.pkl
8023/10943 (epoch 65.982) train_loss=244.81776428 time/batch=0.86s
8024/10943 (epoch 65.990) train_loss=246.12307739 time/batch=0.81s
8025/10943 (epoch 65.998) train_loss=629.59301758 time/batch=1.76s
8026/10943 (epoch 66.007) train_loss=148.01995850 time/batch=0.59s
8027/10943 (epoch 66.015) train_loss=164.47444153 time/batch=0.51s
8028/10943 (epoch 66.023) train_loss=181.51419067 time/batch=0.55s
8029/10943 (epoch 66.031) train_loss=349.06161499 time/batch=0.96s
8030/10943 (epoch 66.040) train_loss=192.53341675 time/batch=0.63s
8031/10943 (epoch 66.048) train_loss=389.73699951 time/batch=1.11s
8032/10943 (epoch 66.056) train_loss=155.78906250 time/batch=0.55s
8033/10943 (epoch 66.064) train_loss=763.86206055 time/batch=3.03s
8034/10943 (epoch 66.072) train_loss=386.20843506 time/batch=1.28s
8035/10943 (epoch 66.081) train_loss=360.62609863 time/batch=1.05s
8036/10943 (epoch 66.089) train_loss=207.38821411 time/batch=0.67s
8037/10943 (epoch 66.097) train_loss=469.56558228 time/batch=1.34s
8038/10943 (epoch 66.105) train_loss=366.09143066 time/batch=1.14s
8039/10943 (epoch 66.114) train_loss=490.69909668 time/batch=1.51s
8040/10943 (epoch 66.122) train_loss=159.57257080 time/batch=0.59s
8041/10943 (epoch 66.130) train_loss=134.14395142 time/batch=0.39s
8042/10943 (epoch 66.138) train_loss=454.48275757 time/batch=1.24s
8043/10943 (epoch 66.146) train_loss=256.01461792 time/batch=0.82s
8044/10943 (epoch 66.155) train_loss=413.94836426 time/batch=1.17s
8045/10943 (epoch 66.163) train_loss=276.52911377 time/batch=0.89s
8046/10943 (epoch 66.171) train_loss=145.08447266 time/batch=0.46s
8047/10943 (epoch 66.179) train_loss=305.54223633 time/batch=0.86s
8048/10943 (epoch 66.188) train_loss=195.62165833 time/batch=0.63s
8049/10943 (epoch 66.196) train_loss=245.43061829 time/batch=0.75s
8050/10943 (epoch 66.204) train_loss=129.29049683 time/batch=0.43s
8051/10943 (epoch 66.212) train_loss=508.11532593 time/batch=1.44s
8052/10943 (epoch 66.221) train_loss=180.20004272 time/batch=0.66s
8053/10943 (epoch 66.229) train_loss=259.02038574 time/batch=0.75s
8054/10943 (epoch 66.237) train_loss=395.92285156 time/batch=1.14s
8055/10943 (epoch 66.245) train_loss=370.17526245 time/batch=1.10s
8056/10943 (epoch 66.253) train_loss=325.08963013 time/batch=0.98s
8057/10943 (epoch 66.262) train_loss=326.24645996 time/batch=0.93s
8058/10943 (epoch 66.270) train_loss=216.81710815 time/batch=0.64s
8059/10943 (epoch 66.278) train_loss=234.22218323 time/batch=0.70s
8060/10943 (epoch 66.286) train_loss=124.03668213 time/batch=0.39s
8061/10943 (epoch 66.295) train_loss=119.11721802 time/batch=0.34s
8062/10943 (epoch 66.303) train_loss=416.59063721 time/batch=1.11s
8063/10943 (epoch 66.311) train_loss=189.74920654 time/batch=0.64s
8064/10943 (epoch 66.319) train_loss=118.74442291 time/batch=0.36s
8065/10943 (epoch 66.327) train_loss=221.18307495 time/batch=0.62s
8066/10943 (epoch 66.336) train_loss=96.69606018 time/batch=0.32s
8067/10943 (epoch 66.344) train_loss=95.82676697 time/batch=0.28s
8068/10943 (epoch 66.352) train_loss=189.94197083 time/batch=0.54s
8069/10943 (epoch 66.360) train_loss=239.87701416 time/batch=0.68s
8070/10943 (epoch 66.369) train_loss=218.02616882 time/batch=0.65s
8071/10943 (epoch 66.377) train_loss=233.51782227 time/batch=0.71s
8072/10943 (epoch 66.385) train_loss=108.28150940 time/batch=0.35s
8073/10943 (epoch 66.393) train_loss=86.80344391 time/batch=0.26s
8074/10943 (epoch 66.401) train_loss=173.22595215 time/batch=0.48s
8075/10943 (epoch 66.410) train_loss=368.70465088 time/batch=1.00s
8076/10943 (epoch 66.418) train_loss=94.54203796 time/batch=0.36s
8077/10943 (epoch 66.426) train_loss=228.25482178 time/batch=0.61s
8078/10943 (epoch 66.434) train_loss=363.43600464 time/batch=1.04s
8079/10943 (epoch 66.443) train_loss=223.77764893 time/batch=0.70s
8080/10943 (epoch 66.451) train_loss=248.80914307 time/batch=0.73s
8081/10943 (epoch 66.459) train_loss=162.84793091 time/batch=0.50s
8082/10943 (epoch 66.467) train_loss=340.10980225 time/batch=0.93s
8083/10943 (epoch 66.475) train_loss=244.21754456 time/batch=0.77s
8084/10943 (epoch 66.484) train_loss=167.41989136 time/batch=0.52s
8085/10943 (epoch 66.492) train_loss=114.19060516 time/batch=0.33s
8086/10943 (epoch 66.500) train_loss=200.23492432 time/batch=0.57s
8087/10943 (epoch 66.508) train_loss=218.43370056 time/batch=0.64s
8088/10943 (epoch 66.517) train_loss=282.87429810 time/batch=0.80s
8089/10943 (epoch 66.525) train_loss=169.76959229 time/batch=0.56s
8090/10943 (epoch 66.533) train_loss=132.32005310 time/batch=0.41s
8091/10943 (epoch 66.541) train_loss=175.15475464 time/batch=0.47s
8092/10943 (epoch 66.549) train_loss=253.76690674 time/batch=0.73s
8093/10943 (epoch 66.558) train_loss=303.18029785 time/batch=0.88s
8094/10943 (epoch 66.566) train_loss=129.27410889 time/batch=0.44s
8095/10943 (epoch 66.574) train_loss=104.02352905 time/batch=0.30s
8096/10943 (epoch 66.582) train_loss=187.35935974 time/batch=0.52s
8097/10943 (epoch 66.591) train_loss=293.65515137 time/batch=0.84s
8098/10943 (epoch 66.599) train_loss=129.07833862 time/batch=0.44s
8099/10943 (epoch 66.607) train_loss=326.16043091 time/batch=0.88s
8100/10943 (epoch 66.615) train_loss=163.01808167 time/batch=0.52s
8101/10943 (epoch 66.623) train_loss=224.08195496 time/batch=0.64s
8102/10943 (epoch 66.632) train_loss=161.50866699 time/batch=0.47s
8103/10943 (epoch 66.640) train_loss=181.86505127 time/batch=0.53s
8104/10943 (epoch 66.648) train_loss=273.85800171 time/batch=0.79s
8105/10943 (epoch 66.656) train_loss=194.42005920 time/batch=0.60s
8106/10943 (epoch 66.665) train_loss=148.69206238 time/batch=0.44s
8107/10943 (epoch 66.673) train_loss=167.74586487 time/batch=0.48s
8108/10943 (epoch 66.681) train_loss=262.03381348 time/batch=0.77s
8109/10943 (epoch 66.689) train_loss=286.73852539 time/batch=0.84s
8110/10943 (epoch 66.698) train_loss=363.82525635 time/batch=1.07s
8111/10943 (epoch 66.706) train_loss=276.49584961 time/batch=0.79s
8112/10943 (epoch 66.714) train_loss=119.65727234 time/batch=0.37s
8113/10943 (epoch 66.722) train_loss=243.17314148 time/batch=0.66s
8114/10943 (epoch 66.730) train_loss=143.99978638 time/batch=0.47s
8115/10943 (epoch 66.739) train_loss=178.60781860 time/batch=0.50s
8116/10943 (epoch 66.747) train_loss=252.15505981 time/batch=0.76s
8117/10943 (epoch 66.755) train_loss=150.31459045 time/batch=0.48s
8118/10943 (epoch 66.763) train_loss=133.10935974 time/batch=0.52s
8119/10943 (epoch 66.772) train_loss=234.91003418 time/batch=0.67s
8120/10943 (epoch 66.780) train_loss=211.29852295 time/batch=0.63s
8121/10943 (epoch 66.788) train_loss=194.59683228 time/batch=0.55s
8122/10943 (epoch 66.796) train_loss=282.34811401 time/batch=0.81s
8123/10943 (epoch 66.804) train_loss=218.96847534 time/batch=0.65s
8124/10943 (epoch 66.813) train_loss=310.21563721 time/batch=0.90s
8125/10943 (epoch 66.821) train_loss=198.79129028 time/batch=0.63s
8126/10943 (epoch 66.829) train_loss=250.09591675 time/batch=0.67s
8127/10943 (epoch 66.837) train_loss=302.62500000 time/batch=0.85s
8128/10943 (epoch 66.846) train_loss=283.46813965 time/batch=0.82s
8129/10943 (epoch 66.854) train_loss=199.81983948 time/batch=0.61s
8130/10943 (epoch 66.862) train_loss=179.13388062 time/batch=0.57s
8131/10943 (epoch 66.870) train_loss=265.11291504 time/batch=0.77s
8132/10943 (epoch 66.878) train_loss=203.60847473 time/batch=0.60s
8133/10943 (epoch 66.887) train_loss=193.03338623 time/batch=0.60s
8134/10943 (epoch 66.895) train_loss=209.31268311 time/batch=0.62s
8135/10943 (epoch 66.903) train_loss=273.32006836 time/batch=0.80s
8136/10943 (epoch 66.911) train_loss=289.20056152 time/batch=0.84s
8137/10943 (epoch 66.920) train_loss=222.66545105 time/batch=0.71s
8138/10943 (epoch 66.928) train_loss=195.85270691 time/batch=0.64s
8139/10943 (epoch 66.936) train_loss=296.31091309 time/batch=0.85s
8140/10943 (epoch 66.944) train_loss=246.60374451 time/batch=0.75s
8141/10943 (epoch 66.952) train_loss=230.85295105 time/batch=0.67s
8142/10943 (epoch 66.961) train_loss=247.29425049 time/batch=0.74s
8143/10943 (epoch 66.969) train_loss=224.48323059 time/batch=0.70s
setting learning rate to 0.0028227
8144/10943 (epoch 66.977) train_loss=308.59075928 time/batch=0.92s
8145/10943 (epoch 66.985) train_loss=562.14642334 time/batch=1.57s
8146/10943 (epoch 66.994) train_loss=187.05880737 time/batch=0.65s
8147/10943 (epoch 67.002) train_loss=302.14550781 time/batch=0.86s
8148/10943 (epoch 67.010) train_loss=450.91101074 time/batch=1.31s
8149/10943 (epoch 67.018) train_loss=242.53594971 time/batch=0.85s
8150/10943 (epoch 67.026) train_loss=313.62438965 time/batch=0.94s
8151/10943 (epoch 67.035) train_loss=369.51312256 time/batch=1.09s
8152/10943 (epoch 67.043) train_loss=466.73345947 time/batch=1.41s
8153/10943 (epoch 67.051) train_loss=414.20516968 time/batch=1.20s
8154/10943 (epoch 67.059) train_loss=525.60668945 time/batch=1.63s
8155/10943 (epoch 67.068) train_loss=381.55096436 time/batch=1.13s
8156/10943 (epoch 67.076) train_loss=324.53948975 time/batch=0.94s
8157/10943 (epoch 67.084) train_loss=755.77294922 time/batch=2.96s
8158/10943 (epoch 67.092) train_loss=468.77346802 time/batch=1.86s
8159/10943 (epoch 67.100) train_loss=162.14660645 time/batch=0.63s
8160/10943 (epoch 67.109) train_loss=271.27014160 time/batch=0.77s
8161/10943 (epoch 67.117) train_loss=335.30725098 time/batch=1.01s
8162/10943 (epoch 67.125) train_loss=111.88554382 time/batch=0.37s
8163/10943 (epoch 67.133) train_loss=160.62786865 time/batch=0.46s
8164/10943 (epoch 67.142) train_loss=123.84565735 time/batch=0.37s
8165/10943 (epoch 67.150) train_loss=346.20745850 time/batch=0.90s
8166/10943 (epoch 67.158) train_loss=236.45118713 time/batch=0.74s
8167/10943 (epoch 67.166) train_loss=227.56961060 time/batch=0.71s
8168/10943 (epoch 67.175) train_loss=166.62745667 time/batch=0.53s
8169/10943 (epoch 67.183) train_loss=391.63085938 time/batch=1.12s
8170/10943 (epoch 67.191) train_loss=218.03527832 time/batch=0.68s
8171/10943 (epoch 67.199) train_loss=130.19567871 time/batch=0.41s
8172/10943 (epoch 67.207) train_loss=240.03555298 time/batch=0.72s
8173/10943 (epoch 67.216) train_loss=97.69589233 time/batch=0.32s
8174/10943 (epoch 67.224) train_loss=161.87429810 time/batch=0.48s
8175/10943 (epoch 67.232) train_loss=121.91957092 time/batch=0.36s
8176/10943 (epoch 67.240) train_loss=404.51528931 time/batch=1.14s
8177/10943 (epoch 67.249) train_loss=358.82095337 time/batch=1.09s
8178/10943 (epoch 67.257) train_loss=84.96017456 time/batch=0.32s
8179/10943 (epoch 67.265) train_loss=369.22253418 time/batch=0.96s
8180/10943 (epoch 67.273) train_loss=297.30871582 time/batch=0.87s
8181/10943 (epoch 67.281) train_loss=293.25790405 time/batch=0.88s
8182/10943 (epoch 67.290) train_loss=367.43811035 time/batch=1.11s
8183/10943 (epoch 67.298) train_loss=133.77108765 time/batch=0.47s
8184/10943 (epoch 67.306) train_loss=173.81768799 time/batch=0.50s
8185/10943 (epoch 67.314) train_loss=117.22085571 time/batch=0.36s
8186/10943 (epoch 67.323) train_loss=147.94812012 time/batch=0.44s
8187/10943 (epoch 67.331) train_loss=175.07356262 time/batch=0.53s
8188/10943 (epoch 67.339) train_loss=170.70945740 time/batch=0.54s
8189/10943 (epoch 67.347) train_loss=140.85717773 time/batch=0.41s
8190/10943 (epoch 67.355) train_loss=367.25115967 time/batch=1.01s
8191/10943 (epoch 67.364) train_loss=272.47326660 time/batch=0.85s
8192/10943 (epoch 67.372) train_loss=248.18099976 time/batch=0.75s
8193/10943 (epoch 67.380) train_loss=214.26144409 time/batch=0.68s
8194/10943 (epoch 67.388) train_loss=119.55685425 time/batch=0.39s
8195/10943 (epoch 67.397) train_loss=188.72247314 time/batch=0.53s
8196/10943 (epoch 67.405) train_loss=316.52627563 time/batch=0.93s
8197/10943 (epoch 67.413) train_loss=141.42918396 time/batch=0.47s
8198/10943 (epoch 67.421) train_loss=250.40306091 time/batch=0.71s
8199/10943 (epoch 67.429) train_loss=185.53517151 time/batch=0.58s
8200/10943 (epoch 67.438) train_loss=109.65287781 time/batch=0.34s
8201/10943 (epoch 67.446) train_loss=328.09878540 time/batch=0.93s
8202/10943 (epoch 67.454) train_loss=166.56420898 time/batch=0.56s
8203/10943 (epoch 67.462) train_loss=289.18536377 time/batch=0.83s
8204/10943 (epoch 67.471) train_loss=280.76492310 time/batch=0.84s
8205/10943 (epoch 67.479) train_loss=97.88044739 time/batch=0.34s
8206/10943 (epoch 67.487) train_loss=163.00213623 time/batch=0.50s
8207/10943 (epoch 67.495) train_loss=217.19940186 time/batch=0.65s
8208/10943 (epoch 67.503) train_loss=256.44165039 time/batch=0.78s
8209/10943 (epoch 67.512) train_loss=120.35631561 time/batch=0.37s
8210/10943 (epoch 67.520) train_loss=231.67236328 time/batch=0.64s
8211/10943 (epoch 67.528) train_loss=102.05226135 time/batch=0.35s
8212/10943 (epoch 67.536) train_loss=269.17132568 time/batch=0.74s
8213/10943 (epoch 67.545) train_loss=217.56628418 time/batch=0.66s
8214/10943 (epoch 67.553) train_loss=269.54867554 time/batch=0.79s
8215/10943 (epoch 67.561) train_loss=156.78730774 time/batch=0.50s
8216/10943 (epoch 67.569) train_loss=212.15771484 time/batch=0.62s
8217/10943 (epoch 67.577) train_loss=213.27301025 time/batch=0.65s
8218/10943 (epoch 67.586) train_loss=244.85127258 time/batch=0.74s
8219/10943 (epoch 67.594) train_loss=248.60406494 time/batch=0.76s
8220/10943 (epoch 67.602) train_loss=267.09375000 time/batch=0.83s
8221/10943 (epoch 67.610) train_loss=295.10003662 time/batch=0.91s
8222/10943 (epoch 67.619) train_loss=289.46270752 time/batch=0.88s
8223/10943 (epoch 67.627) train_loss=214.92175293 time/batch=0.68s
8224/10943 (epoch 67.635) train_loss=216.79013062 time/batch=0.63s
8225/10943 (epoch 67.643) train_loss=251.64836121 time/batch=0.77s
8226/10943 (epoch 67.652) train_loss=244.85873413 time/batch=0.75s
8227/10943 (epoch 67.660) train_loss=278.37573242 time/batch=0.84s
8228/10943 (epoch 67.668) train_loss=231.71612549 time/batch=0.74s
8229/10943 (epoch 67.676) train_loss=183.65316772 time/batch=0.58s
8230/10943 (epoch 67.684) train_loss=180.64091492 time/batch=0.54s
8231/10943 (epoch 67.693) train_loss=161.80615234 time/batch=0.46s
8232/10943 (epoch 67.701) train_loss=95.97287750 time/batch=0.30s
8233/10943 (epoch 67.709) train_loss=229.35652161 time/batch=0.63s
8234/10943 (epoch 67.717) train_loss=178.25267029 time/batch=0.56s
8235/10943 (epoch 67.726) train_loss=224.89970398 time/batch=0.66s
8236/10943 (epoch 67.734) train_loss=243.89669800 time/batch=0.76s
8237/10943 (epoch 67.742) train_loss=189.13255310 time/batch=0.58s
8238/10943 (epoch 67.750) train_loss=185.15574646 time/batch=0.56s
8239/10943 (epoch 67.758) train_loss=191.38325500 time/batch=0.59s
8240/10943 (epoch 67.767) train_loss=237.62733459 time/batch=0.67s
8241/10943 (epoch 67.775) train_loss=258.72671509 time/batch=0.80s
8242/10943 (epoch 67.783) train_loss=160.00447083 time/batch=0.50s
8243/10943 (epoch 67.791) train_loss=158.62901306 time/batch=0.55s
8244/10943 (epoch 67.800) train_loss=197.83291626 time/batch=0.61s
8245/10943 (epoch 67.808) train_loss=129.74725342 time/batch=0.43s
8246/10943 (epoch 67.816) train_loss=234.78157043 time/batch=0.68s
8247/10943 (epoch 67.824) train_loss=252.27159119 time/batch=0.80s
8248/10943 (epoch 67.832) train_loss=211.00064087 time/batch=0.65s
8249/10943 (epoch 67.841) train_loss=142.58105469 time/batch=0.44s
8250/10943 (epoch 67.849) train_loss=141.60505676 time/batch=0.44s
8251/10943 (epoch 67.857) train_loss=190.21292114 time/batch=0.56s
8252/10943 (epoch 67.865) train_loss=107.41195679 time/batch=0.38s
8253/10943 (epoch 67.874) train_loss=126.31307220 time/batch=0.41s
8254/10943 (epoch 67.882) train_loss=261.07849121 time/batch=0.76s
8255/10943 (epoch 67.890) train_loss=243.10447693 time/batch=0.73s
8256/10943 (epoch 67.898) train_loss=204.77563477 time/batch=0.62s
8257/10943 (epoch 67.906) train_loss=188.49353027 time/batch=0.61s
8258/10943 (epoch 67.915) train_loss=195.50636292 time/batch=0.59s
8259/10943 (epoch 67.923) train_loss=208.23954773 time/batch=0.65s
8260/10943 (epoch 67.931) train_loss=186.20791626 time/batch=0.59s
8261/10943 (epoch 67.939) train_loss=157.79629517 time/batch=0.56s
8262/10943 (epoch 67.948) train_loss=193.18446350 time/batch=0.60s
8263/10943 (epoch 67.956) train_loss=227.29084778 time/batch=0.69s
8264/10943 (epoch 67.964) train_loss=205.57409668 time/batch=0.63s
setting learning rate to 0.0027380
  saved to metadata/gru_no_dropout-9_nov_folkwiki-20181207-192453_epoch23.pkl
8265/10943 (epoch 67.972) train_loss=324.53131104 time/batch=1.00s
8266/10943 (epoch 67.980) train_loss=464.67770386 time/batch=1.26s
8267/10943 (epoch 67.989) train_loss=180.85818481 time/batch=0.62s
8268/10943 (epoch 67.997) train_loss=86.67784119 time/batch=0.27s
8269/10943 (epoch 68.005) train_loss=626.72607422 time/batch=1.74s
8270/10943 (epoch 68.013) train_loss=251.13270569 time/batch=0.88s
8271/10943 (epoch 68.022) train_loss=200.59970093 time/batch=0.62s
8272/10943 (epoch 68.030) train_loss=177.15820312 time/batch=0.59s
8273/10943 (epoch 68.038) train_loss=231.17199707 time/batch=0.77s
8274/10943 (epoch 68.046) train_loss=425.14801025 time/batch=1.24s
8275/10943 (epoch 68.054) train_loss=328.91790771 time/batch=1.03s
8276/10943 (epoch 68.063) train_loss=130.85032654 time/batch=0.45s
8277/10943 (epoch 68.071) train_loss=165.89819336 time/batch=0.51s
8278/10943 (epoch 68.079) train_loss=170.18655396 time/batch=0.51s
8279/10943 (epoch 68.087) train_loss=701.18499756 time/batch=2.93s
8280/10943 (epoch 68.096) train_loss=413.68927002 time/batch=1.42s
8281/10943 (epoch 68.104) train_loss=389.90582275 time/batch=1.18s
8282/10943 (epoch 68.112) train_loss=497.67892456 time/batch=1.52s
8283/10943 (epoch 68.120) train_loss=377.39703369 time/batch=1.11s
8284/10943 (epoch 68.129) train_loss=187.38717651 time/batch=0.62s
8285/10943 (epoch 68.137) train_loss=112.49386597 time/batch=0.34s
8286/10943 (epoch 68.145) train_loss=403.74734497 time/batch=1.23s
8287/10943 (epoch 68.153) train_loss=310.30535889 time/batch=0.97s
8288/10943 (epoch 68.161) train_loss=318.01550293 time/batch=0.94s
8289/10943 (epoch 68.170) train_loss=198.87191772 time/batch=0.66s
8290/10943 (epoch 68.178) train_loss=99.16778564 time/batch=0.31s
8291/10943 (epoch 68.186) train_loss=238.35711670 time/batch=0.69s
8292/10943 (epoch 68.194) train_loss=349.08599854 time/batch=0.98s
8293/10943 (epoch 68.203) train_loss=308.08746338 time/batch=0.95s
8294/10943 (epoch 68.211) train_loss=377.14447021 time/batch=1.29s
8295/10943 (epoch 68.219) train_loss=352.01513672 time/batch=1.04s
8296/10943 (epoch 68.227) train_loss=267.82873535 time/batch=0.84s
8297/10943 (epoch 68.235) train_loss=101.89746857 time/batch=0.35s
8298/10943 (epoch 68.244) train_loss=228.85568237 time/batch=0.69s
8299/10943 (epoch 68.252) train_loss=223.34710693 time/batch=0.73s
8300/10943 (epoch 68.260) train_loss=349.47595215 time/batch=1.04s
8301/10943 (epoch 68.268) train_loss=268.74560547 time/batch=0.87s
8302/10943 (epoch 68.277) train_loss=172.68638611 time/batch=0.58s
8303/10943 (epoch 68.285) train_loss=127.56082153 time/batch=0.41s
8304/10943 (epoch 68.293) train_loss=344.94857788 time/batch=1.01s
8305/10943 (epoch 68.301) train_loss=94.26339722 time/batch=0.37s
8306/10943 (epoch 68.309) train_loss=303.61029053 time/batch=0.88s
8307/10943 (epoch 68.318) train_loss=167.84716797 time/batch=0.56s
8308/10943 (epoch 68.326) train_loss=254.25759888 time/batch=0.61s
8309/10943 (epoch 68.334) train_loss=121.98562622 time/batch=0.39s
8310/10943 (epoch 68.342) train_loss=280.50158691 time/batch=0.84s
8311/10943 (epoch 68.351) train_loss=121.88237000 time/batch=0.40s
8312/10943 (epoch 68.359) train_loss=155.02851868 time/batch=0.46s
8313/10943 (epoch 68.367) train_loss=79.69439697 time/batch=0.27s
8314/10943 (epoch 68.375) train_loss=142.69123840 time/batch=0.42s
8315/10943 (epoch 68.383) train_loss=203.93312073 time/batch=0.63s
8316/10943 (epoch 68.392) train_loss=423.50219727 time/batch=1.34s
8317/10943 (epoch 68.400) train_loss=348.78753662 time/batch=1.12s
8318/10943 (epoch 68.408) train_loss=211.73818970 time/batch=0.71s
8319/10943 (epoch 68.416) train_loss=264.41448975 time/batch=0.80s
8320/10943 (epoch 68.425) train_loss=107.26297760 time/batch=0.35s
8321/10943 (epoch 68.433) train_loss=234.15890503 time/batch=0.72s
8322/10943 (epoch 68.441) train_loss=140.22784424 time/batch=0.46s
8323/10943 (epoch 68.449) train_loss=212.36430359 time/batch=0.65s
8324/10943 (epoch 68.457) train_loss=227.56155396 time/batch=0.69s
8325/10943 (epoch 68.466) train_loss=278.67962646 time/batch=0.85s
8326/10943 (epoch 68.474) train_loss=245.28970337 time/batch=0.79s
8327/10943 (epoch 68.482) train_loss=281.59326172 time/batch=0.88s
8328/10943 (epoch 68.490) train_loss=210.79795837 time/batch=0.70s
8329/10943 (epoch 68.499) train_loss=243.75488281 time/batch=0.77s
8330/10943 (epoch 68.507) train_loss=229.75250244 time/batch=0.70s
8331/10943 (epoch 68.515) train_loss=149.08163452 time/batch=0.49s
8332/10943 (epoch 68.523) train_loss=125.62799835 time/batch=0.36s
8333/10943 (epoch 68.531) train_loss=153.73301697 time/batch=0.49s
8334/10943 (epoch 68.540) train_loss=136.62216187 time/batch=0.44s
8335/10943 (epoch 68.548) train_loss=319.08270264 time/batch=1.31s
8336/10943 (epoch 68.556) train_loss=258.44488525 time/batch=0.86s
8337/10943 (epoch 68.564) train_loss=280.29809570 time/batch=0.86s
8338/10943 (epoch 68.573) train_loss=210.14123535 time/batch=0.65s
8339/10943 (epoch 68.581) train_loss=247.63497925 time/batch=0.73s
8340/10943 (epoch 68.589) train_loss=207.05741882 time/batch=0.65s
8341/10943 (epoch 68.597) train_loss=133.37287903 time/batch=0.43s
8342/10943 (epoch 68.605) train_loss=118.51344299 time/batch=0.37s
8343/10943 (epoch 68.614) train_loss=103.47401428 time/batch=0.31s
8344/10943 (epoch 68.622) train_loss=185.61709595 time/batch=0.53s
8345/10943 (epoch 68.630) train_loss=228.95654297 time/batch=0.66s
8346/10943 (epoch 68.638) train_loss=261.64578247 time/batch=0.81s
8347/10943 (epoch 68.647) train_loss=225.59530640 time/batch=0.72s
8348/10943 (epoch 68.655) train_loss=147.38903809 time/batch=0.47s
8349/10943 (epoch 68.663) train_loss=109.80570984 time/batch=0.34s
8350/10943 (epoch 68.671) train_loss=130.41567993 time/batch=0.41s
8351/10943 (epoch 68.680) train_loss=198.31631470 time/batch=0.64s
8352/10943 (epoch 68.688) train_loss=158.75170898 time/batch=0.51s
8353/10943 (epoch 68.696) train_loss=124.91865540 time/batch=0.43s
8354/10943 (epoch 68.704) train_loss=243.28620911 time/batch=0.75s
8355/10943 (epoch 68.712) train_loss=191.48574829 time/batch=0.63s
8356/10943 (epoch 68.721) train_loss=295.76159668 time/batch=0.85s
8357/10943 (epoch 68.729) train_loss=248.92233276 time/batch=0.77s
8358/10943 (epoch 68.737) train_loss=184.24734497 time/batch=0.58s
8359/10943 (epoch 68.745) train_loss=183.72854614 time/batch=0.58s
8360/10943 (epoch 68.754) train_loss=181.76695251 time/batch=0.57s
8361/10943 (epoch 68.762) train_loss=136.19631958 time/batch=0.46s
8362/10943 (epoch 68.770) train_loss=178.66752625 time/batch=0.53s
8363/10943 (epoch 68.778) train_loss=177.65182495 time/batch=0.55s
8364/10943 (epoch 68.786) train_loss=239.60589600 time/batch=0.69s
8365/10943 (epoch 68.795) train_loss=302.57794189 time/batch=1.35s
8366/10943 (epoch 68.803) train_loss=171.28070068 time/batch=0.58s
8367/10943 (epoch 68.811) train_loss=154.00067139 time/batch=0.47s
8368/10943 (epoch 68.819) train_loss=188.51547241 time/batch=0.58s
8369/10943 (epoch 68.828) train_loss=146.86746216 time/batch=0.49s
8370/10943 (epoch 68.836) train_loss=188.33148193 time/batch=0.58s
8371/10943 (epoch 68.844) train_loss=239.86053467 time/batch=0.75s
8372/10943 (epoch 68.852) train_loss=164.48980713 time/batch=0.54s
8373/10943 (epoch 68.860) train_loss=170.76922607 time/batch=0.55s
8374/10943 (epoch 68.869) train_loss=205.18603516 time/batch=0.62s
8375/10943 (epoch 68.877) train_loss=231.38537598 time/batch=0.70s
8376/10943 (epoch 68.885) train_loss=209.20141602 time/batch=0.64s
8377/10943 (epoch 68.893) train_loss=218.89714050 time/batch=0.64s
8378/10943 (epoch 68.902) train_loss=219.34970093 time/batch=0.68s
8379/10943 (epoch 68.910) train_loss=225.72286987 time/batch=0.69s
8380/10943 (epoch 68.918) train_loss=181.30505371 time/batch=0.60s
8381/10943 (epoch 68.926) train_loss=178.28219604 time/batch=0.59s
8382/10943 (epoch 68.934) train_loss=268.88818359 time/batch=0.80s
8383/10943 (epoch 68.943) train_loss=204.93949890 time/batch=0.71s
8384/10943 (epoch 68.951) train_loss=260.87258911 time/batch=0.80s
8385/10943 (epoch 68.959) train_loss=230.80371094 time/batch=0.77s
setting learning rate to 0.0026559
8386/10943 (epoch 68.967) train_loss=350.31909180 time/batch=1.05s
8387/10943 (epoch 68.976) train_loss=372.03414917 time/batch=1.07s
8388/10943 (epoch 68.984) train_loss=159.37194824 time/batch=0.54s
8389/10943 (epoch 68.992) train_loss=418.03656006 time/batch=1.17s
8390/10943 (epoch 69.000) train_loss=455.71881104 time/batch=1.48s
8391/10943 (epoch 69.008) train_loss=258.71240234 time/batch=0.91s
8392/10943 (epoch 69.017) train_loss=284.19030762 time/batch=0.86s
8393/10943 (epoch 69.025) train_loss=153.62586975 time/batch=0.54s
8394/10943 (epoch 69.033) train_loss=331.34509277 time/batch=0.94s
8395/10943 (epoch 69.041) train_loss=371.26687622 time/batch=1.14s
8396/10943 (epoch 69.050) train_loss=265.94506836 time/batch=0.86s
8397/10943 (epoch 69.058) train_loss=115.39400482 time/batch=0.39s
8398/10943 (epoch 69.066) train_loss=553.41040039 time/batch=1.55s
8399/10943 (epoch 69.074) train_loss=128.53736877 time/batch=0.53s
8400/10943 (epoch 69.082) train_loss=140.26725769 time/batch=0.43s
8401/10943 (epoch 69.091) train_loss=441.79827881 time/batch=1.22s
8402/10943 (epoch 69.099) train_loss=143.50527954 time/batch=0.54s
8403/10943 (epoch 69.107) train_loss=680.53845215 time/batch=2.25s
8404/10943 (epoch 69.115) train_loss=209.26136780 time/batch=0.82s
8405/10943 (epoch 69.124) train_loss=261.34222412 time/batch=0.81s
8406/10943 (epoch 69.132) train_loss=319.63946533 time/batch=0.99s
8407/10943 (epoch 69.140) train_loss=202.84213257 time/batch=0.69s
8408/10943 (epoch 69.148) train_loss=80.00860596 time/batch=0.29s
8409/10943 (epoch 69.157) train_loss=177.48211670 time/batch=0.57s
8410/10943 (epoch 69.165) train_loss=112.67143250 time/batch=0.37s
8411/10943 (epoch 69.173) train_loss=291.68511963 time/batch=0.89s
8412/10943 (epoch 69.181) train_loss=323.09732056 time/batch=1.06s
8413/10943 (epoch 69.189) train_loss=101.53596497 time/batch=0.40s
8414/10943 (epoch 69.198) train_loss=169.78155518 time/batch=0.58s
8415/10943 (epoch 69.206) train_loss=258.27600098 time/batch=0.87s
8416/10943 (epoch 69.214) train_loss=225.00955200 time/batch=0.81s
8417/10943 (epoch 69.222) train_loss=406.72579956 time/batch=1.33s
8418/10943 (epoch 69.231) train_loss=211.83300781 time/batch=0.77s
8419/10943 (epoch 69.239) train_loss=220.04319763 time/batch=0.73s
8420/10943 (epoch 69.247) train_loss=281.49636841 time/batch=0.90s
8421/10943 (epoch 69.255) train_loss=143.60749817 time/batch=0.51s
8422/10943 (epoch 69.263) train_loss=409.00518799 time/batch=1.33s
8423/10943 (epoch 69.272) train_loss=115.94367981 time/batch=0.47s
8424/10943 (epoch 69.280) train_loss=419.12445068 time/batch=1.44s
8425/10943 (epoch 69.288) train_loss=352.04324341 time/batch=1.11s
8426/10943 (epoch 69.296) train_loss=334.58233643 time/batch=1.07s
8427/10943 (epoch 69.305) train_loss=301.33435059 time/batch=1.00s
8428/10943 (epoch 69.313) train_loss=162.77748108 time/batch=0.55s
8429/10943 (epoch 69.321) train_loss=272.53530884 time/batch=0.87s
8430/10943 (epoch 69.329) train_loss=308.17395020 time/batch=0.98s
8431/10943 (epoch 69.337) train_loss=243.25085449 time/batch=0.80s
8432/10943 (epoch 69.346) train_loss=272.05310059 time/batch=0.91s
8433/10943 (epoch 69.354) train_loss=192.17430115 time/batch=0.67s
8434/10943 (epoch 69.362) train_loss=381.66741943 time/batch=1.48s
8435/10943 (epoch 69.370) train_loss=113.20075989 time/batch=0.45s
8436/10943 (epoch 69.379) train_loss=317.85235596 time/batch=1.01s
8437/10943 (epoch 69.387) train_loss=117.82147217 time/batch=0.45s
8438/10943 (epoch 69.395) train_loss=132.04360962 time/batch=0.43s
8439/10943 (epoch 69.403) train_loss=195.26324463 time/batch=0.62s
8440/10943 (epoch 69.411) train_loss=422.93991089 time/batch=3.05s
8441/10943 (epoch 69.420) train_loss=184.59410095 time/batch=0.88s
8442/10943 (epoch 69.428) train_loss=220.45103455 time/batch=0.72s
8443/10943 (epoch 69.436) train_loss=254.28088379 time/batch=0.82s
8444/10943 (epoch 69.444) train_loss=228.88893127 time/batch=0.82s
8445/10943 (epoch 69.453) train_loss=142.42651367 time/batch=0.52s
8446/10943 (epoch 69.461) train_loss=138.97451782 time/batch=0.47s
8447/10943 (epoch 69.469) train_loss=175.16429138 time/batch=0.57s
8448/10943 (epoch 69.477) train_loss=94.13589478 time/batch=0.33s
8449/10943 (epoch 69.485) train_loss=168.37628174 time/batch=0.52s
8450/10943 (epoch 69.494) train_loss=203.54852295 time/batch=0.66s
8451/10943 (epoch 69.502) train_loss=158.56071472 time/batch=0.54s
8452/10943 (epoch 69.510) train_loss=123.43421173 time/batch=0.38s
8453/10943 (epoch 69.518) train_loss=165.39474487 time/batch=0.54s
8454/10943 (epoch 69.527) train_loss=163.05749512 time/batch=0.54s
8455/10943 (epoch 69.535) train_loss=99.69148254 time/batch=0.32s
8456/10943 (epoch 69.543) train_loss=175.79222107 time/batch=0.54s
8457/10943 (epoch 69.551) train_loss=138.83694458 time/batch=0.47s
8458/10943 (epoch 69.559) train_loss=260.02618408 time/batch=0.83s
8459/10943 (epoch 69.568) train_loss=128.32025146 time/batch=0.47s
8460/10943 (epoch 69.576) train_loss=242.60017395 time/batch=0.74s
8461/10943 (epoch 69.584) train_loss=137.30545044 time/batch=0.46s
8462/10943 (epoch 69.592) train_loss=81.49540710 time/batch=0.28s
8463/10943 (epoch 69.601) train_loss=237.22088623 time/batch=0.74s
8464/10943 (epoch 69.609) train_loss=132.83561707 time/batch=0.45s
8465/10943 (epoch 69.617) train_loss=236.76081848 time/batch=0.76s
8466/10943 (epoch 69.625) train_loss=212.29278564 time/batch=0.72s
8467/10943 (epoch 69.634) train_loss=179.60156250 time/batch=0.59s
8468/10943 (epoch 69.642) train_loss=307.79824829 time/batch=1.03s
8469/10943 (epoch 69.650) train_loss=208.25369263 time/batch=0.73s
8470/10943 (epoch 69.658) train_loss=289.80718994 time/batch=0.93s
8471/10943 (epoch 69.666) train_loss=148.97352600 time/batch=0.53s
8472/10943 (epoch 69.675) train_loss=115.41256714 time/batch=0.38s
8473/10943 (epoch 69.683) train_loss=249.65823364 time/batch=0.81s
8474/10943 (epoch 69.691) train_loss=204.92114258 time/batch=0.66s
8475/10943 (epoch 69.699) train_loss=105.17816162 time/batch=0.43s
8476/10943 (epoch 69.708) train_loss=174.29179382 time/batch=0.52s
8477/10943 (epoch 69.716) train_loss=229.37496948 time/batch=0.75s
8478/10943 (epoch 69.724) train_loss=207.01654053 time/batch=0.71s
8479/10943 (epoch 69.732) train_loss=255.02548218 time/batch=0.89s
8480/10943 (epoch 69.740) train_loss=221.61083984 time/batch=0.77s
8481/10943 (epoch 69.749) train_loss=177.40371704 time/batch=0.61s
8482/10943 (epoch 69.757) train_loss=170.39828491 time/batch=0.57s
8483/10943 (epoch 69.765) train_loss=151.48728943 time/batch=0.52s
8484/10943 (epoch 69.773) train_loss=118.77702332 time/batch=0.49s
8485/10943 (epoch 69.782) train_loss=154.98358154 time/batch=0.49s
8486/10943 (epoch 69.790) train_loss=191.45663452 time/batch=0.60s
8487/10943 (epoch 69.798) train_loss=251.18536377 time/batch=0.81s
8488/10943 (epoch 69.806) train_loss=186.46987915 time/batch=0.63s
8489/10943 (epoch 69.814) train_loss=236.52651978 time/batch=0.77s
8490/10943 (epoch 69.823) train_loss=244.51786804 time/batch=0.82s
8491/10943 (epoch 69.831) train_loss=179.03262329 time/batch=0.64s
8492/10943 (epoch 69.839) train_loss=213.66052246 time/batch=0.65s
8493/10943 (epoch 69.847) train_loss=216.96212769 time/batch=0.72s
8494/10943 (epoch 69.856) train_loss=202.21215820 time/batch=0.65s
8495/10943 (epoch 69.864) train_loss=176.98828125 time/batch=0.59s
8496/10943 (epoch 69.872) train_loss=207.67529297 time/batch=0.66s
8497/10943 (epoch 69.880) train_loss=229.31344604 time/batch=0.74s
8498/10943 (epoch 69.888) train_loss=175.21643066 time/batch=0.64s
8499/10943 (epoch 69.897) train_loss=181.73208618 time/batch=0.66s
8500/10943 (epoch 69.905) train_loss=196.39105225 time/batch=0.66s
8501/10943 (epoch 69.913) train_loss=224.66358948 time/batch=0.80s
8502/10943 (epoch 69.921) train_loss=203.43615723 time/batch=0.69s
8503/10943 (epoch 69.930) train_loss=233.02719116 time/batch=0.74s
8504/10943 (epoch 69.938) train_loss=240.11297607 time/batch=0.80s
8505/10943 (epoch 69.946) train_loss=229.98008728 time/batch=0.73s
8506/10943 (epoch 69.954) train_loss=232.11424255 time/batch=0.81s
setting learning rate to 0.0025762
  saved to metadata/gru_no_dropout-9_nov_folkwiki-20181207-192453_epoch25.pkl
8507/10943 (epoch 69.962) train_loss=368.08380127 time/batch=1.20s
8508/10943 (epoch 69.971) train_loss=311.17175293 time/batch=0.98s
8509/10943 (epoch 69.979) train_loss=344.29476929 time/batch=1.12s
8510/10943 (epoch 69.987) train_loss=673.56109619 time/batch=2.32s
8511/10943 (epoch 69.995) train_loss=541.61291504 time/batch=1.71s
8512/10943 (epoch 70.004) train_loss=615.43981934 time/batch=3.13s
8513/10943 (epoch 70.012) train_loss=201.80822754 time/batch=0.93s
8514/10943 (epoch 70.020) train_loss=125.43300629 time/batch=0.42s
8515/10943 (epoch 70.028) train_loss=178.18835449 time/batch=0.58s
8516/10943 (epoch 70.036) train_loss=422.84924316 time/batch=1.27s
8517/10943 (epoch 70.045) train_loss=194.75009155 time/batch=0.74s
8518/10943 (epoch 70.053) train_loss=414.52813721 time/batch=1.34s
8519/10943 (epoch 70.061) train_loss=140.55690002 time/batch=0.56s
8520/10943 (epoch 70.069) train_loss=157.96826172 time/batch=0.54s
8521/10943 (epoch 70.078) train_loss=144.69877625 time/batch=0.49s
8522/10943 (epoch 70.086) train_loss=84.87797546 time/batch=0.30s
8523/10943 (epoch 70.094) train_loss=72.76028442 time/batch=0.25s
8524/10943 (epoch 70.102) train_loss=316.47045898 time/batch=0.96s
8525/10943 (epoch 70.111) train_loss=364.70718384 time/batch=1.12s
8526/10943 (epoch 70.119) train_loss=98.85330200 time/batch=0.41s
8527/10943 (epoch 70.127) train_loss=213.49642944 time/batch=0.67s
8528/10943 (epoch 70.135) train_loss=269.43112183 time/batch=0.88s
8529/10943 (epoch 70.143) train_loss=220.82017517 time/batch=0.78s
8530/10943 (epoch 70.152) train_loss=158.23080444 time/batch=0.52s
8531/10943 (epoch 70.160) train_loss=132.20657349 time/batch=0.43s
8532/10943 (epoch 70.168) train_loss=126.24702454 time/batch=0.43s
8533/10943 (epoch 70.176) train_loss=145.78610229 time/batch=0.50s
8534/10943 (epoch 70.185) train_loss=194.63516235 time/batch=0.67s
8535/10943 (epoch 70.193) train_loss=146.71023560 time/batch=0.48s
8536/10943 (epoch 70.201) train_loss=113.80205536 time/batch=0.39s
8537/10943 (epoch 70.209) train_loss=266.07412720 time/batch=0.87s
8538/10943 (epoch 70.217) train_loss=170.15597534 time/batch=0.60s
8539/10943 (epoch 70.226) train_loss=227.93588257 time/batch=0.77s
8540/10943 (epoch 70.234) train_loss=430.18603516 time/batch=1.41s
8541/10943 (epoch 70.242) train_loss=357.56945801 time/batch=1.10s
8542/10943 (epoch 70.250) train_loss=397.71395874 time/batch=1.23s
8543/10943 (epoch 70.259) train_loss=100.91512299 time/batch=0.40s
8544/10943 (epoch 70.267) train_loss=336.72738647 time/batch=1.06s
8545/10943 (epoch 70.275) train_loss=218.03781128 time/batch=0.76s
8546/10943 (epoch 70.283) train_loss=119.75981140 time/batch=0.41s
8547/10943 (epoch 70.291) train_loss=159.94003296 time/batch=0.51s
8548/10943 (epoch 70.300) train_loss=116.68820190 time/batch=0.40s
8549/10943 (epoch 70.308) train_loss=207.67442322 time/batch=0.68s
8550/10943 (epoch 70.316) train_loss=352.31060791 time/batch=1.17s
8551/10943 (epoch 70.324) train_loss=198.75692749 time/batch=0.74s
8552/10943 (epoch 70.333) train_loss=94.44409180 time/batch=0.33s
8553/10943 (epoch 70.341) train_loss=307.24005127 time/batch=0.94s
8554/10943 (epoch 70.349) train_loss=237.47912598 time/batch=0.80s
8555/10943 (epoch 70.357) train_loss=196.83279419 time/batch=0.64s
8556/10943 (epoch 70.365) train_loss=120.55361938 time/batch=0.43s
8557/10943 (epoch 70.374) train_loss=199.32861328 time/batch=0.67s
8558/10943 (epoch 70.382) train_loss=267.57330322 time/batch=0.94s
8559/10943 (epoch 70.390) train_loss=272.64199829 time/batch=0.92s
8560/10943 (epoch 70.398) train_loss=225.20222473 time/batch=0.77s
8561/10943 (epoch 70.407) train_loss=145.55664062 time/batch=0.50s
8562/10943 (epoch 70.415) train_loss=359.13543701 time/batch=1.17s
8563/10943 (epoch 70.423) train_loss=280.12539673 time/batch=1.00s
8564/10943 (epoch 70.431) train_loss=167.27912903 time/batch=0.60s
8565/10943 (epoch 70.439) train_loss=213.57833862 time/batch=0.71s
8566/10943 (epoch 70.448) train_loss=245.54760742 time/batch=0.83s
8567/10943 (epoch 70.456) train_loss=214.26312256 time/batch=0.75s
8568/10943 (epoch 70.464) train_loss=336.62615967 time/batch=1.21s
8569/10943 (epoch 70.472) train_loss=128.62583923 time/batch=0.52s
8570/10943 (epoch 70.481) train_loss=216.36477661 time/batch=0.69s
8571/10943 (epoch 70.489) train_loss=215.34275818 time/batch=0.74s
8572/10943 (epoch 70.497) train_loss=172.44876099 time/batch=0.64s
8573/10943 (epoch 70.505) train_loss=129.87280273 time/batch=0.47s
8574/10943 (epoch 70.513) train_loss=98.04342651 time/batch=0.32s
8575/10943 (epoch 70.522) train_loss=172.67446899 time/batch=0.55s
8576/10943 (epoch 70.530) train_loss=178.06382751 time/batch=0.62s
8577/10943 (epoch 70.538) train_loss=149.38047791 time/batch=0.53s
8578/10943 (epoch 70.546) train_loss=227.85220337 time/batch=0.79s
8579/10943 (epoch 70.555) train_loss=200.57078552 time/batch=0.68s
8580/10943 (epoch 70.563) train_loss=341.08001709 time/batch=1.00s
8581/10943 (epoch 70.571) train_loss=134.77865601 time/batch=0.51s
8582/10943 (epoch 70.579) train_loss=252.13636780 time/batch=0.80s
8583/10943 (epoch 70.588) train_loss=272.10882568 time/batch=0.95s
8584/10943 (epoch 70.596) train_loss=225.61245728 time/batch=0.79s
8585/10943 (epoch 70.604) train_loss=155.57135010 time/batch=0.55s
8586/10943 (epoch 70.612) train_loss=280.26895142 time/batch=0.92s
8587/10943 (epoch 70.620) train_loss=101.02490234 time/batch=0.39s
8588/10943 (epoch 70.629) train_loss=202.01480103 time/batch=0.65s
8589/10943 (epoch 70.637) train_loss=168.83340454 time/batch=0.58s
8590/10943 (epoch 70.645) train_loss=286.10253906 time/batch=0.92s
8591/10943 (epoch 70.653) train_loss=145.88899231 time/batch=0.54s
8592/10943 (epoch 70.662) train_loss=300.30767822 time/batch=0.92s
8593/10943 (epoch 70.670) train_loss=263.62512207 time/batch=0.98s
8594/10943 (epoch 70.678) train_loss=154.88323975 time/batch=0.56s
8595/10943 (epoch 70.686) train_loss=317.53292847 time/batch=1.37s
8596/10943 (epoch 70.694) train_loss=174.24316406 time/batch=0.68s
8597/10943 (epoch 70.703) train_loss=250.34246826 time/batch=0.95s
8598/10943 (epoch 70.711) train_loss=179.58624268 time/batch=0.64s
8599/10943 (epoch 70.719) train_loss=223.85234070 time/batch=0.78s
8600/10943 (epoch 70.727) train_loss=199.72201538 time/batch=0.69s
8601/10943 (epoch 70.736) train_loss=201.38841248 time/batch=0.65s
8602/10943 (epoch 70.744) train_loss=227.28897095 time/batch=0.75s
8603/10943 (epoch 70.752) train_loss=233.55319214 time/batch=0.81s
8604/10943 (epoch 70.760) train_loss=182.92607117 time/batch=0.66s
8605/10943 (epoch 70.768) train_loss=170.94088745 time/batch=0.59s
8606/10943 (epoch 70.777) train_loss=112.76702881 time/batch=0.39s
8607/10943 (epoch 70.785) train_loss=164.08065796 time/batch=0.54s
8608/10943 (epoch 70.793) train_loss=245.65377808 time/batch=0.81s
8609/10943 (epoch 70.801) train_loss=115.94137573 time/batch=0.40s
8610/10943 (epoch 70.810) train_loss=249.79733276 time/batch=0.80s
8611/10943 (epoch 70.818) train_loss=225.06115723 time/batch=0.81s
8612/10943 (epoch 70.826) train_loss=199.26892090 time/batch=0.68s
8613/10943 (epoch 70.834) train_loss=202.94543457 time/batch=0.66s
8614/10943 (epoch 70.842) train_loss=226.48188782 time/batch=0.77s
8615/10943 (epoch 70.851) train_loss=229.74348450 time/batch=0.79s
8616/10943 (epoch 70.859) train_loss=266.17044067 time/batch=1.41s
8617/10943 (epoch 70.867) train_loss=160.94885254 time/batch=0.64s
8618/10943 (epoch 70.875) train_loss=111.73136139 time/batch=0.35s
8619/10943 (epoch 70.884) train_loss=205.58691406 time/batch=0.72s
8620/10943 (epoch 70.892) train_loss=181.51199341 time/batch=0.65s
8621/10943 (epoch 70.900) train_loss=179.37545776 time/batch=0.59s
8622/10943 (epoch 70.908) train_loss=115.28330994 time/batch=0.43s
8623/10943 (epoch 70.916) train_loss=179.40136719 time/batch=0.56s
8624/10943 (epoch 70.925) train_loss=186.50393677 time/batch=0.63s
8625/10943 (epoch 70.933) train_loss=173.79534912 time/batch=0.59s
8626/10943 (epoch 70.941) train_loss=255.08993530 time/batch=0.81s
8627/10943 (epoch 70.949) train_loss=236.97352600 time/batch=0.82s
setting learning rate to 0.0024989
8628/10943 (epoch 70.958) train_loss=400.45837402 time/batch=1.25s
8629/10943 (epoch 70.966) train_loss=256.10952759 time/batch=0.89s
8630/10943 (epoch 70.974) train_loss=120.85476685 time/batch=0.42s
8631/10943 (epoch 70.982) train_loss=167.82675171 time/batch=0.59s
8632/10943 (epoch 70.990) train_loss=278.28356934 time/batch=0.86s
8633/10943 (epoch 70.999) train_loss=432.30194092 time/batch=1.45s
8634/10943 (epoch 71.007) train_loss=449.78869629 time/batch=1.38s
8635/10943 (epoch 71.015) train_loss=147.83720398 time/batch=0.59s
8636/10943 (epoch 71.023) train_loss=94.40737152 time/batch=0.31s
8637/10943 (epoch 71.032) train_loss=176.11903381 time/batch=0.59s
8638/10943 (epoch 71.040) train_loss=464.48394775 time/batch=1.52s
8639/10943 (epoch 71.048) train_loss=120.59454346 time/batch=0.53s
8640/10943 (epoch 71.056) train_loss=259.09896851 time/batch=0.84s
8641/10943 (epoch 71.065) train_loss=107.30857086 time/batch=0.39s
8642/10943 (epoch 71.073) train_loss=127.52711487 time/batch=0.41s
8643/10943 (epoch 71.081) train_loss=123.98234558 time/batch=0.42s
8644/10943 (epoch 71.089) train_loss=100.01353455 time/batch=0.32s
8645/10943 (epoch 71.097) train_loss=176.28518677 time/batch=0.60s
8646/10943 (epoch 71.106) train_loss=398.55941772 time/batch=1.32s
8647/10943 (epoch 71.114) train_loss=713.52124023 time/batch=3.12s
8648/10943 (epoch 71.122) train_loss=256.22854614 time/batch=1.10s
8649/10943 (epoch 71.130) train_loss=356.55187988 time/batch=1.09s
8650/10943 (epoch 71.139) train_loss=315.40002441 time/batch=1.04s
8651/10943 (epoch 71.147) train_loss=108.50270081 time/batch=0.41s
8652/10943 (epoch 71.155) train_loss=144.95382690 time/batch=0.45s
8653/10943 (epoch 71.163) train_loss=261.49456787 time/batch=0.88s
8654/10943 (epoch 71.171) train_loss=132.87670898 time/batch=0.49s
8655/10943 (epoch 71.180) train_loss=73.11857605 time/batch=0.26s
8656/10943 (epoch 71.188) train_loss=166.05694580 time/batch=0.56s
8657/10943 (epoch 71.196) train_loss=210.47399902 time/batch=0.77s
8658/10943 (epoch 71.204) train_loss=195.68074036 time/batch=0.68s
8659/10943 (epoch 71.213) train_loss=103.64295959 time/batch=0.38s
8660/10943 (epoch 71.221) train_loss=219.99145508 time/batch=0.71s
8661/10943 (epoch 71.229) train_loss=524.18371582 time/batch=1.68s
8662/10943 (epoch 71.237) train_loss=170.81820679 time/batch=0.75s
8663/10943 (epoch 71.245) train_loss=196.80102539 time/batch=0.68s
8664/10943 (epoch 71.254) train_loss=354.74517822 time/batch=1.13s
8665/10943 (epoch 71.262) train_loss=233.66754150 time/batch=0.82s
8666/10943 (epoch 71.270) train_loss=217.39593506 time/batch=0.73s
8667/10943 (epoch 71.278) train_loss=148.92947388 time/batch=0.52s
8668/10943 (epoch 71.287) train_loss=331.38439941 time/batch=1.03s
8669/10943 (epoch 71.295) train_loss=217.14566040 time/batch=0.77s
8670/10943 (epoch 71.303) train_loss=184.47970581 time/batch=0.64s
8671/10943 (epoch 71.311) train_loss=158.36520386 time/batch=0.56s
8672/10943 (epoch 71.319) train_loss=322.87371826 time/batch=0.95s
8673/10943 (epoch 71.328) train_loss=207.45976257 time/batch=0.72s
8674/10943 (epoch 71.336) train_loss=185.35449219 time/batch=0.65s
8675/10943 (epoch 71.344) train_loss=143.34985352 time/batch=0.51s
8676/10943 (epoch 71.352) train_loss=254.20431519 time/batch=0.85s
8677/10943 (epoch 71.361) train_loss=194.37760925 time/batch=0.69s
8678/10943 (epoch 71.369) train_loss=289.50607300 time/batch=0.95s
8679/10943 (epoch 71.377) train_loss=174.94616699 time/batch=0.65s
8680/10943 (epoch 71.385) train_loss=219.03320312 time/batch=0.69s
8681/10943 (epoch 71.393) train_loss=213.75839233 time/batch=0.78s
8682/10943 (epoch 71.402) train_loss=299.21969604 time/batch=0.97s
8683/10943 (epoch 71.410) train_loss=154.32693481 time/batch=0.59s
8684/10943 (epoch 71.418) train_loss=208.78408813 time/batch=0.69s
8685/10943 (epoch 71.426) train_loss=190.14024353 time/batch=0.70s
8686/10943 (epoch 71.435) train_loss=317.68762207 time/batch=1.03s
8687/10943 (epoch 71.443) train_loss=230.94978333 time/batch=0.82s
8688/10943 (epoch 71.451) train_loss=204.71775818 time/batch=0.73s
8689/10943 (epoch 71.459) train_loss=144.90155029 time/batch=0.50s
8690/10943 (epoch 71.467) train_loss=154.70631409 time/batch=0.49s
8691/10943 (epoch 71.476) train_loss=160.37826538 time/batch=0.56s
8692/10943 (epoch 71.484) train_loss=329.77075195 time/batch=1.00s
8693/10943 (epoch 71.492) train_loss=151.05294800 time/batch=0.57s
8694/10943 (epoch 71.500) train_loss=101.50146484 time/batch=0.36s
8695/10943 (epoch 71.509) train_loss=288.19488525 time/batch=0.94s
8696/10943 (epoch 71.517) train_loss=376.50088501 time/batch=1.20s
8697/10943 (epoch 71.525) train_loss=165.71005249 time/batch=0.62s
8698/10943 (epoch 71.533) train_loss=353.77325439 time/batch=1.17s
8699/10943 (epoch 71.542) train_loss=269.39898682 time/batch=0.94s
8700/10943 (epoch 71.550) train_loss=204.10531616 time/batch=0.68s
8701/10943 (epoch 71.558) train_loss=227.70352173 time/batch=0.77s
8702/10943 (epoch 71.566) train_loss=153.50323486 time/batch=0.56s
8703/10943 (epoch 71.574) train_loss=102.02482605 time/batch=0.37s
8704/10943 (epoch 71.583) train_loss=191.06782532 time/batch=0.63s
8705/10943 (epoch 71.591) train_loss=166.81520081 time/batch=0.55s
8706/10943 (epoch 71.599) train_loss=250.53518677 time/batch=0.81s
8707/10943 (epoch 71.607) train_loss=245.66143799 time/batch=0.88s
8708/10943 (epoch 71.616) train_loss=277.21319580 time/batch=1.03s
8709/10943 (epoch 71.624) train_loss=175.12527466 time/batch=0.62s
8710/10943 (epoch 71.632) train_loss=130.20077515 time/batch=0.41s
8711/10943 (epoch 71.640) train_loss=175.62667847 time/batch=0.59s
8712/10943 (epoch 71.648) train_loss=301.06402588 time/batch=1.00s
8713/10943 (epoch 71.657) train_loss=215.65527344 time/batch=0.78s
8714/10943 (epoch 71.665) train_loss=116.10295105 time/batch=0.42s
8715/10943 (epoch 71.673) train_loss=112.34471130 time/batch=0.39s
8716/10943 (epoch 71.681) train_loss=138.01747131 time/batch=0.48s
8717/10943 (epoch 71.690) train_loss=226.19271851 time/batch=0.76s
8718/10943 (epoch 71.698) train_loss=126.60620117 time/batch=0.47s
8719/10943 (epoch 71.706) train_loss=347.35760498 time/batch=1.15s
8720/10943 (epoch 71.714) train_loss=165.65499878 time/batch=0.64s
8721/10943 (epoch 71.722) train_loss=247.60209656 time/batch=0.87s
8722/10943 (epoch 71.731) train_loss=248.74322510 time/batch=0.91s
8723/10943 (epoch 71.739) train_loss=290.32940674 time/batch=1.05s
8724/10943 (epoch 71.747) train_loss=198.34967041 time/batch=0.71s
8725/10943 (epoch 71.755) train_loss=86.86236572 time/batch=0.31s
8726/10943 (epoch 71.764) train_loss=89.13770294 time/batch=0.30s
8727/10943 (epoch 71.772) train_loss=209.73266602 time/batch=0.65s
8728/10943 (epoch 71.780) train_loss=222.84332275 time/batch=0.74s
8729/10943 (epoch 71.788) train_loss=239.76066589 time/batch=0.84s
8730/10943 (epoch 71.796) train_loss=189.47308350 time/batch=0.66s
8731/10943 (epoch 71.805) train_loss=216.69290161 time/batch=0.78s
8732/10943 (epoch 71.813) train_loss=303.32135010 time/batch=1.10s
8733/10943 (epoch 71.821) train_loss=154.31236267 time/batch=0.61s
8734/10943 (epoch 71.829) train_loss=234.92883301 time/batch=0.79s
8735/10943 (epoch 71.838) train_loss=236.07797241 time/batch=0.81s
8736/10943 (epoch 71.846) train_loss=221.60992432 time/batch=0.74s
8737/10943 (epoch 71.854) train_loss=110.55973816 time/batch=0.47s
8738/10943 (epoch 71.862) train_loss=226.74407959 time/batch=0.77s
8739/10943 (epoch 71.870) train_loss=199.15202332 time/batch=0.76s
8740/10943 (epoch 71.879) train_loss=194.85708618 time/batch=0.69s
8741/10943 (epoch 71.887) train_loss=151.69168091 time/batch=0.59s
8742/10943 (epoch 71.895) train_loss=243.36627197 time/batch=0.82s
8743/10943 (epoch 71.903) train_loss=175.52777100 time/batch=0.62s
8744/10943 (epoch 71.912) train_loss=126.22213745 time/batch=0.47s
8745/10943 (epoch 71.920) train_loss=179.72912598 time/batch=0.77s
8746/10943 (epoch 71.928) train_loss=168.19407654 time/batch=0.61s
8747/10943 (epoch 71.936) train_loss=167.01522827 time/batch=0.58s
8748/10943 (epoch 71.944) train_loss=193.76889038 time/batch=0.79s
setting learning rate to 0.0024239
  saved to metadata/gru_no_dropout-9_nov_folkwiki-20181207-192453_epoch27.pkl
8749/10943 (epoch 71.953) train_loss=117.84593964 time/batch=0.48s
8750/10943 (epoch 71.961) train_loss=389.41320801 time/batch=1.21s
8751/10943 (epoch 71.969) train_loss=282.05575562 time/batch=1.02s
8752/10943 (epoch 71.977) train_loss=250.78257751 time/batch=0.89s
8753/10943 (epoch 71.986) train_loss=81.94379425 time/batch=0.32s
8754/10943 (epoch 71.994) train_loss=698.80871582 time/batch=3.01s
8755/10943 (epoch 72.002) train_loss=388.81079102 time/batch=1.41s
8756/10943 (epoch 72.010) train_loss=223.36665344 time/batch=0.78s
8757/10943 (epoch 72.019) train_loss=157.17977905 time/batch=0.58s
8758/10943 (epoch 72.027) train_loss=363.52471924 time/batch=1.17s
8759/10943 (epoch 72.035) train_loss=214.57214355 time/batch=0.83s
8760/10943 (epoch 72.043) train_loss=423.74340820 time/batch=1.48s
8761/10943 (epoch 72.051) train_loss=216.79611206 time/batch=0.89s
8762/10943 (epoch 72.060) train_loss=515.35736084 time/batch=1.67s
8763/10943 (epoch 72.068) train_loss=242.52407837 time/batch=0.96s
8764/10943 (epoch 72.076) train_loss=435.74822998 time/batch=1.54s
8765/10943 (epoch 72.084) train_loss=143.06634521 time/batch=0.61s
8766/10943 (epoch 72.093) train_loss=215.16384888 time/batch=0.78s
8767/10943 (epoch 72.101) train_loss=212.30149841 time/batch=0.73s
8768/10943 (epoch 72.109) train_loss=225.81564331 time/batch=0.84s
8769/10943 (epoch 72.117) train_loss=75.65834045 time/batch=0.33s
8770/10943 (epoch 72.125) train_loss=185.48930359 time/batch=0.65s
8771/10943 (epoch 72.134) train_loss=286.20581055 time/batch=0.99s
8772/10943 (epoch 72.142) train_loss=215.99746704 time/batch=0.80s
8773/10943 (epoch 72.150) train_loss=94.46122742 time/batch=0.34s
8774/10943 (epoch 72.158) train_loss=237.96823120 time/batch=0.78s
8775/10943 (epoch 72.167) train_loss=189.01452637 time/batch=0.65s
8776/10943 (epoch 72.175) train_loss=331.74511719 time/batch=1.13s
8777/10943 (epoch 72.183) train_loss=200.08666992 time/batch=0.78s
8778/10943 (epoch 72.191) train_loss=389.79290771 time/batch=1.27s
8779/10943 (epoch 72.199) train_loss=297.40356445 time/batch=1.10s
8780/10943 (epoch 72.208) train_loss=104.66595459 time/batch=0.43s
8781/10943 (epoch 72.216) train_loss=320.71765137 time/batch=0.97s
8782/10943 (epoch 72.224) train_loss=183.74395752 time/batch=0.67s
8783/10943 (epoch 72.232) train_loss=400.38229370 time/batch=1.30s
8784/10943 (epoch 72.241) train_loss=288.16912842 time/batch=1.00s
8785/10943 (epoch 72.249) train_loss=158.95007324 time/batch=0.54s
8786/10943 (epoch 72.257) train_loss=351.92178345 time/batch=1.05s
8787/10943 (epoch 72.265) train_loss=338.01077271 time/batch=1.37s
8788/10943 (epoch 72.273) train_loss=98.07146454 time/batch=0.43s
8789/10943 (epoch 72.282) train_loss=320.60995483 time/batch=1.05s
8790/10943 (epoch 72.290) train_loss=290.57345581 time/batch=0.99s
8791/10943 (epoch 72.298) train_loss=288.81964111 time/batch=0.96s
8792/10943 (epoch 72.306) train_loss=152.52072144 time/batch=0.58s
8793/10943 (epoch 72.315) train_loss=212.13267517 time/batch=0.75s
8794/10943 (epoch 72.323) train_loss=157.34536743 time/batch=0.57s
8795/10943 (epoch 72.331) train_loss=86.14900208 time/batch=0.32s
8796/10943 (epoch 72.339) train_loss=309.09008789 time/batch=0.98s
8797/10943 (epoch 72.347) train_loss=194.93930054 time/batch=0.70s
8798/10943 (epoch 72.356) train_loss=144.52677917 time/batch=0.53s
8799/10943 (epoch 72.364) train_loss=269.31951904 time/batch=0.94s
8800/10943 (epoch 72.372) train_loss=204.75357056 time/batch=0.77s
8801/10943 (epoch 72.380) train_loss=287.82592773 time/batch=0.98s
8802/10943 (epoch 72.389) train_loss=145.77825928 time/batch=0.57s
8803/10943 (epoch 72.397) train_loss=133.80822754 time/batch=0.46s
8804/10943 (epoch 72.405) train_loss=117.75857544 time/batch=0.41s
8805/10943 (epoch 72.413) train_loss=227.18890381 time/batch=0.74s
8806/10943 (epoch 72.421) train_loss=121.07254028 time/batch=0.46s
8807/10943 (epoch 72.430) train_loss=262.72875977 time/batch=0.86s
8808/10943 (epoch 72.438) train_loss=188.14607239 time/batch=0.69s
8809/10943 (epoch 72.446) train_loss=124.92645264 time/batch=0.45s
8810/10943 (epoch 72.454) train_loss=126.46371460 time/batch=0.44s
8811/10943 (epoch 72.463) train_loss=107.80970764 time/batch=0.35s
8812/10943 (epoch 72.471) train_loss=200.75323486 time/batch=0.71s
8813/10943 (epoch 72.479) train_loss=98.80654144 time/batch=0.36s
8814/10943 (epoch 72.487) train_loss=142.14572144 time/batch=0.48s
8815/10943 (epoch 72.496) train_loss=255.69497681 time/batch=0.88s
8816/10943 (epoch 72.504) train_loss=240.88336182 time/batch=0.87s
8817/10943 (epoch 72.512) train_loss=178.59284973 time/batch=0.65s
8818/10943 (epoch 72.520) train_loss=188.77171326 time/batch=0.64s
8819/10943 (epoch 72.528) train_loss=198.52905273 time/batch=0.66s
8820/10943 (epoch 72.537) train_loss=124.25548553 time/batch=0.45s
8821/10943 (epoch 72.545) train_loss=193.93159485 time/batch=0.65s
8822/10943 (epoch 72.553) train_loss=161.45985413 time/batch=0.58s
8823/10943 (epoch 72.561) train_loss=249.22494507 time/batch=0.85s
8824/10943 (epoch 72.570) train_loss=113.08325195 time/batch=0.41s
8825/10943 (epoch 72.578) train_loss=302.38180542 time/batch=1.05s
8826/10943 (epoch 72.586) train_loss=165.80166626 time/batch=0.65s
8827/10943 (epoch 72.594) train_loss=273.09411621 time/batch=0.86s
8828/10943 (epoch 72.602) train_loss=168.04281616 time/batch=0.63s
8829/10943 (epoch 72.611) train_loss=139.80813599 time/batch=0.51s
8830/10943 (epoch 72.619) train_loss=114.79386139 time/batch=0.39s
8831/10943 (epoch 72.627) train_loss=254.32495117 time/batch=0.87s
8832/10943 (epoch 72.635) train_loss=216.81213379 time/batch=0.73s
8833/10943 (epoch 72.644) train_loss=166.72305298 time/batch=0.59s
8834/10943 (epoch 72.652) train_loss=215.12170410 time/batch=0.72s
8835/10943 (epoch 72.660) train_loss=216.21755981 time/batch=0.79s
8836/10943 (epoch 72.668) train_loss=217.98580933 time/batch=0.80s
8837/10943 (epoch 72.676) train_loss=189.76792908 time/batch=0.67s
8838/10943 (epoch 72.685) train_loss=159.70642090 time/batch=0.57s
8839/10943 (epoch 72.693) train_loss=107.19723511 time/batch=0.37s
8840/10943 (epoch 72.701) train_loss=193.32928467 time/batch=0.64s
8841/10943 (epoch 72.709) train_loss=196.95162964 time/batch=0.70s
8842/10943 (epoch 72.718) train_loss=221.57412720 time/batch=0.80s
8843/10943 (epoch 72.726) train_loss=218.72094727 time/batch=0.77s
8844/10943 (epoch 72.734) train_loss=218.41931152 time/batch=0.81s
8845/10943 (epoch 72.742) train_loss=178.99017334 time/batch=0.67s
8846/10943 (epoch 72.750) train_loss=117.49893188 time/batch=0.45s
8847/10943 (epoch 72.759) train_loss=121.71569824 time/batch=0.43s
8848/10943 (epoch 72.767) train_loss=98.74822235 time/batch=0.36s
8849/10943 (epoch 72.775) train_loss=139.95523071 time/batch=0.46s
8850/10943 (epoch 72.783) train_loss=168.75946045 time/batch=0.58s
8851/10943 (epoch 72.792) train_loss=211.16587830 time/batch=0.72s
8852/10943 (epoch 72.800) train_loss=216.18096924 time/batch=0.79s
8853/10943 (epoch 72.808) train_loss=150.25325012 time/batch=0.54s
8854/10943 (epoch 72.816) train_loss=232.93109131 time/batch=0.79s
8855/10943 (epoch 72.824) train_loss=166.13525391 time/batch=0.61s
8856/10943 (epoch 72.833) train_loss=176.09683228 time/batch=0.60s
8857/10943 (epoch 72.841) train_loss=135.64566040 time/batch=0.47s
8858/10943 (epoch 72.849) train_loss=172.28186035 time/batch=0.57s
8859/10943 (epoch 72.857) train_loss=166.81402588 time/batch=0.56s
8860/10943 (epoch 72.866) train_loss=151.24575806 time/batch=0.54s
8861/10943 (epoch 72.874) train_loss=132.01943970 time/batch=0.51s
8862/10943 (epoch 72.882) train_loss=167.16958618 time/batch=0.63s
8863/10943 (epoch 72.890) train_loss=253.56045532 time/batch=0.83s
8864/10943 (epoch 72.898) train_loss=241.74761963 time/batch=0.84s
8865/10943 (epoch 72.907) train_loss=202.57546997 time/batch=0.71s
8866/10943 (epoch 72.915) train_loss=178.66516113 time/batch=0.61s
8867/10943 (epoch 72.923) train_loss=172.08815002 time/batch=0.60s
8868/10943 (epoch 72.931) train_loss=188.45143127 time/batch=0.69s
8869/10943 (epoch 72.940) train_loss=178.79302979 time/batch=0.70s
setting learning rate to 0.0023512
8870/10943 (epoch 72.948) train_loss=234.08541870 time/batch=0.83s
8871/10943 (epoch 72.956) train_loss=106.89524841 time/batch=0.41s
8872/10943 (epoch 72.964) train_loss=207.44573975 time/batch=0.74s
8873/10943 (epoch 72.973) train_loss=134.32116699 time/batch=0.49s
8874/10943 (epoch 72.981) train_loss=321.54571533 time/batch=1.05s
8875/10943 (epoch 72.989) train_loss=233.27032471 time/batch=0.86s
8876/10943 (epoch 72.997) train_loss=409.30212402 time/batch=1.31s
8877/10943 (epoch 73.005) train_loss=622.50317383 time/batch=2.24s
8878/10943 (epoch 73.014) train_loss=386.52752686 time/batch=1.31s
8879/10943 (epoch 73.022) train_loss=367.42022705 time/batch=1.25s
8880/10943 (epoch 73.030) train_loss=404.86138916 time/batch=1.42s
8881/10943 (epoch 73.038) train_loss=526.33386230 time/batch=2.26s
8882/10943 (epoch 73.047) train_loss=165.43954468 time/batch=0.78s
8883/10943 (epoch 73.055) train_loss=315.65447998 time/batch=1.04s
8884/10943 (epoch 73.063) train_loss=331.12670898 time/batch=1.20s
8885/10943 (epoch 73.071) train_loss=289.20465088 time/batch=1.05s
8886/10943 (epoch 73.079) train_loss=213.35562134 time/batch=0.84s
8887/10943 (epoch 73.088) train_loss=529.01397705 time/batch=3.07s
8888/10943 (epoch 73.096) train_loss=128.10946655 time/batch=0.73s
8889/10943 (epoch 73.104) train_loss=83.90542603 time/batch=0.27s
8890/10943 (epoch 73.112) train_loss=140.94883728 time/batch=0.49s
8891/10943 (epoch 73.121) train_loss=216.45619202 time/batch=0.77s
8892/10943 (epoch 73.129) train_loss=239.41342163 time/batch=0.87s
8893/10943 (epoch 73.137) train_loss=182.47753906 time/batch=0.69s
8894/10943 (epoch 73.145) train_loss=86.24870300 time/batch=0.33s
8895/10943 (epoch 73.153) train_loss=375.92724609 time/batch=1.19s
8896/10943 (epoch 73.162) train_loss=141.91864014 time/batch=0.56s
8897/10943 (epoch 73.170) train_loss=83.50219727 time/batch=0.30s
8898/10943 (epoch 73.178) train_loss=236.29739380 time/batch=0.80s
8899/10943 (epoch 73.186) train_loss=206.51495361 time/batch=0.74s
8900/10943 (epoch 73.195) train_loss=281.90039062 time/batch=0.93s
8901/10943 (epoch 73.203) train_loss=188.12124634 time/batch=0.72s
8902/10943 (epoch 73.211) train_loss=117.37223816 time/batch=0.43s
8903/10943 (epoch 73.219) train_loss=197.65936279 time/batch=0.63s
8904/10943 (epoch 73.227) train_loss=156.03584290 time/batch=0.60s
8905/10943 (epoch 73.236) train_loss=200.76626587 time/batch=0.77s
8906/10943 (epoch 73.244) train_loss=217.88723755 time/batch=0.80s
8907/10943 (epoch 73.252) train_loss=313.01281738 time/batch=1.08s
8908/10943 (epoch 73.260) train_loss=243.46774292 time/batch=0.89s
8909/10943 (epoch 73.269) train_loss=197.82174683 time/batch=0.77s
8910/10943 (epoch 73.277) train_loss=248.83917236 time/batch=0.91s
8911/10943 (epoch 73.285) train_loss=95.48214722 time/batch=0.37s
8912/10943 (epoch 73.293) train_loss=113.40155029 time/batch=0.40s
8913/10943 (epoch 73.301) train_loss=122.83031464 time/batch=0.43s
8914/10943 (epoch 73.310) train_loss=167.68739319 time/batch=0.60s
8915/10943 (epoch 73.318) train_loss=294.13671875 time/batch=0.96s
8916/10943 (epoch 73.326) train_loss=241.26232910 time/batch=0.86s
8917/10943 (epoch 73.334) train_loss=137.19638062 time/batch=0.52s
8918/10943 (epoch 73.343) train_loss=239.53717041 time/batch=0.85s
8919/10943 (epoch 73.351) train_loss=304.11627197 time/batch=1.02s
8920/10943 (epoch 73.359) train_loss=170.15682983 time/batch=0.65s
8921/10943 (epoch 73.367) train_loss=179.95613098 time/batch=0.67s
8922/10943 (epoch 73.375) train_loss=113.43663788 time/batch=0.39s
8923/10943 (epoch 73.384) train_loss=253.15982056 time/batch=0.89s
8924/10943 (epoch 73.392) train_loss=215.77174377 time/batch=0.80s
8925/10943 (epoch 73.400) train_loss=391.13714600 time/batch=1.41s
8926/10943 (epoch 73.408) train_loss=219.24203491 time/batch=0.82s
8927/10943 (epoch 73.417) train_loss=97.33773804 time/batch=0.36s
8928/10943 (epoch 73.425) train_loss=254.69760132 time/batch=0.83s
8929/10943 (epoch 73.433) train_loss=86.96340942 time/batch=0.35s
8930/10943 (epoch 73.441) train_loss=137.58129883 time/batch=0.46s
8931/10943 (epoch 73.449) train_loss=187.17460632 time/batch=0.62s
8932/10943 (epoch 73.458) train_loss=167.10369873 time/batch=0.61s
8933/10943 (epoch 73.466) train_loss=258.93090820 time/batch=0.87s
8934/10943 (epoch 73.474) train_loss=108.61759949 time/batch=0.40s
8935/10943 (epoch 73.482) train_loss=141.47857666 time/batch=0.51s
8936/10943 (epoch 73.491) train_loss=279.73309326 time/batch=0.94s
8937/10943 (epoch 73.499) train_loss=188.24891663 time/batch=0.68s
8938/10943 (epoch 73.507) train_loss=124.32289124 time/batch=0.47s
8939/10943 (epoch 73.515) train_loss=152.85691833 time/batch=0.49s
8940/10943 (epoch 73.524) train_loss=190.37684631 time/batch=0.67s
8941/10943 (epoch 73.532) train_loss=92.00444794 time/batch=0.35s
8942/10943 (epoch 73.540) train_loss=231.89524841 time/batch=0.77s
8943/10943 (epoch 73.548) train_loss=165.58097839 time/batch=0.62s
8944/10943 (epoch 73.556) train_loss=139.83691406 time/batch=0.51s
8945/10943 (epoch 73.565) train_loss=226.07069397 time/batch=0.79s
8946/10943 (epoch 73.573) train_loss=172.16149902 time/batch=0.62s
8947/10943 (epoch 73.581) train_loss=201.01040649 time/batch=0.73s
8948/10943 (epoch 73.589) train_loss=123.41514587 time/batch=0.46s
8949/10943 (epoch 73.598) train_loss=321.15795898 time/batch=1.13s
8950/10943 (epoch 73.606) train_loss=212.97360229 time/batch=0.80s
8951/10943 (epoch 73.614) train_loss=248.30590820 time/batch=0.90s
8952/10943 (epoch 73.622) train_loss=290.94830322 time/batch=1.00s
8953/10943 (epoch 73.630) train_loss=192.83924866 time/batch=0.71s
8954/10943 (epoch 73.639) train_loss=321.42816162 time/batch=1.08s
8955/10943 (epoch 73.647) train_loss=165.34487915 time/batch=0.63s
8956/10943 (epoch 73.655) train_loss=141.89710999 time/batch=0.51s
8957/10943 (epoch 73.663) train_loss=218.23065186 time/batch=0.88s
8958/10943 (epoch 73.672) train_loss=169.78546143 time/batch=0.62s
8959/10943 (epoch 73.680) train_loss=279.14294434 time/batch=0.93s
8960/10943 (epoch 73.688) train_loss=227.35023499 time/batch=0.79s
8961/10943 (epoch 73.696) train_loss=297.97167969 time/batch=1.02s
8962/10943 (epoch 73.704) train_loss=221.35176086 time/batch=0.83s
8963/10943 (epoch 73.713) train_loss=218.56469727 time/batch=0.82s
8964/10943 (epoch 73.721) train_loss=114.55822754 time/batch=0.45s
8965/10943 (epoch 73.729) train_loss=111.28649139 time/batch=0.35s
8966/10943 (epoch 73.737) train_loss=156.53410339 time/batch=0.55s
8967/10943 (epoch 73.746) train_loss=200.51278687 time/batch=0.69s
8968/10943 (epoch 73.754) train_loss=165.90518188 time/batch=0.63s
8969/10943 (epoch 73.762) train_loss=189.88940430 time/batch=0.70s
8970/10943 (epoch 73.770) train_loss=179.42187500 time/batch=0.66s
8971/10943 (epoch 73.778) train_loss=210.38153076 time/batch=0.78s
8972/10943 (epoch 73.787) train_loss=165.66246033 time/batch=0.60s
8973/10943 (epoch 73.795) train_loss=125.99156952 time/batch=0.48s
8974/10943 (epoch 73.803) train_loss=209.74850464 time/batch=0.70s
8975/10943 (epoch 73.811) train_loss=96.78874207 time/batch=0.40s
8976/10943 (epoch 73.820) train_loss=154.50070190 time/batch=0.51s
8977/10943 (epoch 73.828) train_loss=152.93914795 time/batch=0.55s
8978/10943 (epoch 73.836) train_loss=173.87033081 time/batch=0.61s
8979/10943 (epoch 73.844) train_loss=165.46212769 time/batch=0.59s
8980/10943 (epoch 73.852) train_loss=165.39335632 time/batch=0.58s
8981/10943 (epoch 73.861) train_loss=108.95427704 time/batch=0.42s
8982/10943 (epoch 73.869) train_loss=143.57638550 time/batch=0.51s
8983/10943 (epoch 73.877) train_loss=156.78157043 time/batch=0.54s
8984/10943 (epoch 73.885) train_loss=135.28561401 time/batch=0.55s
8985/10943 (epoch 73.894) train_loss=193.54742432 time/batch=0.67s
8986/10943 (epoch 73.902) train_loss=215.59307861 time/batch=0.70s
8987/10943 (epoch 73.910) train_loss=189.91860962 time/batch=0.71s
8988/10943 (epoch 73.918) train_loss=211.35220337 time/batch=0.71s
8989/10943 (epoch 73.926) train_loss=175.04948425 time/batch=0.65s
8990/10943 (epoch 73.935) train_loss=155.02830505 time/batch=0.60s
setting learning rate to 0.0022807
  saved to metadata/gru_no_dropout-9_nov_folkwiki-20181207-192453_epoch29.pkl
8991/10943 (epoch 73.943) train_loss=302.60357666 time/batch=1.06s
8992/10943 (epoch 73.951) train_loss=356.80200195 time/batch=1.22s
8993/10943 (epoch 73.959) train_loss=142.34994507 time/batch=0.56s
8994/10943 (epoch 73.968) train_loss=165.46717834 time/batch=0.67s
8995/10943 (epoch 73.976) train_loss=123.90950775 time/batch=0.45s
8996/10943 (epoch 73.984) train_loss=370.22448730 time/batch=1.20s
8997/10943 (epoch 73.992) train_loss=186.52413940 time/batch=0.73s
8998/10943 (epoch 74.001) train_loss=268.73681641 time/batch=0.93s
8999/10943 (epoch 74.009) train_loss=85.54365540 time/batch=0.37s
Validating
    loss:	265.112447

9000/10943 (epoch 74.017) train_loss=167.29867554 time/batch=2.45s
9001/10943 (epoch 74.025) train_loss=335.11639404 time/batch=1.12s
9002/10943 (epoch 74.033) train_loss=516.60302734 time/batch=1.71s
9003/10943 (epoch 74.042) train_loss=206.14642334 time/batch=0.84s
9004/10943 (epoch 74.050) train_loss=247.29870605 time/batch=0.91s
9005/10943 (epoch 74.058) train_loss=102.14379883 time/batch=0.40s
9006/10943 (epoch 74.066) train_loss=273.57714844 time/batch=0.91s
9007/10943 (epoch 74.075) train_loss=91.57412720 time/batch=0.38s
9008/10943 (epoch 74.083) train_loss=93.02780914 time/batch=0.34s
9009/10943 (epoch 74.091) train_loss=99.64605713 time/batch=0.34s
9010/10943 (epoch 74.099) train_loss=278.42938232 time/batch=0.96s
9011/10943 (epoch 74.107) train_loss=310.99426270 time/batch=1.09s
9012/10943 (epoch 74.116) train_loss=251.57626343 time/batch=0.96s
9013/10943 (epoch 74.124) train_loss=226.92684937 time/batch=0.87s
9014/10943 (epoch 74.132) train_loss=245.30838013 time/batch=0.86s
9015/10943 (epoch 74.140) train_loss=569.81188965 time/batch=2.08s
9016/10943 (epoch 74.149) train_loss=118.88097382 time/batch=0.57s
9017/10943 (epoch 74.157) train_loss=72.36802673 time/batch=0.26s
9018/10943 (epoch 74.165) train_loss=214.29524231 time/batch=0.73s
9019/10943 (epoch 74.173) train_loss=382.65380859 time/batch=1.41s
9020/10943 (epoch 74.181) train_loss=147.49099731 time/batch=0.64s
9021/10943 (epoch 74.190) train_loss=149.49101257 time/batch=0.57s
9022/10943 (epoch 74.198) train_loss=95.07522583 time/batch=0.33s
9023/10943 (epoch 74.206) train_loss=553.51489258 time/batch=3.03s
9024/10943 (epoch 74.214) train_loss=353.25146484 time/batch=1.47s
9025/10943 (epoch 74.223) train_loss=280.59194946 time/batch=0.99s
9026/10943 (epoch 74.231) train_loss=252.52050781 time/batch=0.89s
9027/10943 (epoch 74.239) train_loss=185.48275757 time/batch=0.71s
9028/10943 (epoch 74.247) train_loss=178.24169922 time/batch=0.65s
9029/10943 (epoch 74.255) train_loss=159.85118103 time/batch=0.61s
9030/10943 (epoch 74.264) train_loss=236.60317993 time/batch=0.85s
9031/10943 (epoch 74.272) train_loss=292.10241699 time/batch=1.02s
9032/10943 (epoch 74.280) train_loss=85.31812286 time/batch=0.35s
9033/10943 (epoch 74.288) train_loss=408.15408325 time/batch=1.37s
9034/10943 (epoch 74.297) train_loss=319.57098389 time/batch=1.18s
9035/10943 (epoch 74.305) train_loss=119.61031342 time/batch=0.51s
9036/10943 (epoch 74.313) train_loss=241.95301819 time/batch=0.83s
9037/10943 (epoch 74.321) train_loss=224.41711426 time/batch=0.85s
9038/10943 (epoch 74.329) train_loss=101.78356934 time/batch=0.40s
9039/10943 (epoch 74.338) train_loss=138.99621582 time/batch=0.49s
9040/10943 (epoch 74.346) train_loss=183.95623779 time/batch=0.67s
9041/10943 (epoch 74.354) train_loss=107.38481140 time/batch=0.41s
9042/10943 (epoch 74.362) train_loss=206.56311035 time/batch=0.73s
9043/10943 (epoch 74.371) train_loss=180.35226440 time/batch=0.68s
9044/10943 (epoch 74.379) train_loss=202.48760986 time/batch=0.80s
9045/10943 (epoch 74.387) train_loss=166.73367310 time/batch=0.63s
9046/10943 (epoch 74.395) train_loss=194.56103516 time/batch=0.74s
9047/10943 (epoch 74.403) train_loss=297.48934937 time/batch=1.04s
9048/10943 (epoch 74.412) train_loss=122.24207306 time/batch=0.51s
9049/10943 (epoch 74.420) train_loss=130.27171326 time/batch=0.46s
9050/10943 (epoch 74.428) train_loss=212.90211487 time/batch=0.78s
9051/10943 (epoch 74.436) train_loss=155.92163086 time/batch=0.62s
9052/10943 (epoch 74.445) train_loss=156.24478149 time/batch=0.55s
9053/10943 (epoch 74.453) train_loss=221.48550415 time/batch=0.76s
9054/10943 (epoch 74.461) train_loss=336.03503418 time/batch=1.08s
9055/10943 (epoch 74.469) train_loss=161.02818298 time/batch=0.63s
9056/10943 (epoch 74.478) train_loss=314.35424805 time/batch=1.08s
9057/10943 (epoch 74.486) train_loss=148.96310425 time/batch=0.61s
9058/10943 (epoch 74.494) train_loss=205.40444946 time/batch=0.77s
9059/10943 (epoch 74.502) train_loss=265.21459961 time/batch=0.97s
9060/10943 (epoch 74.510) train_loss=192.67843628 time/batch=0.73s
9061/10943 (epoch 74.519) train_loss=191.34954834 time/batch=0.70s
9062/10943 (epoch 74.527) train_loss=365.76742554 time/batch=1.27s
9063/10943 (epoch 74.535) train_loss=210.78712463 time/batch=0.80s
9064/10943 (epoch 74.543) train_loss=119.76702881 time/batch=0.43s
9065/10943 (epoch 74.552) train_loss=237.43571472 time/batch=0.79s
9066/10943 (epoch 74.560) train_loss=158.83871460 time/batch=0.59s
9067/10943 (epoch 74.568) train_loss=181.05236816 time/batch=0.64s
9068/10943 (epoch 74.576) train_loss=245.08648682 time/batch=0.88s
9069/10943 (epoch 74.584) train_loss=166.61358643 time/batch=0.63s
9070/10943 (epoch 74.593) train_loss=236.11669922 time/batch=0.82s
9071/10943 (epoch 74.601) train_loss=176.59950256 time/batch=0.65s
9072/10943 (epoch 74.609) train_loss=93.44584656 time/batch=0.38s
9073/10943 (epoch 74.617) train_loss=209.04043579 time/batch=0.74s
9074/10943 (epoch 74.626) train_loss=267.70065308 time/batch=0.98s
9075/10943 (epoch 74.634) train_loss=143.86587524 time/batch=0.58s
9076/10943 (epoch 74.642) train_loss=252.01727295 time/batch=0.94s
9077/10943 (epoch 74.650) train_loss=114.11000061 time/batch=0.48s
9078/10943 (epoch 74.658) train_loss=139.76083374 time/batch=0.51s
9079/10943 (epoch 74.667) train_loss=197.34085083 time/batch=0.72s
9080/10943 (epoch 74.675) train_loss=206.98358154 time/batch=0.78s
9081/10943 (epoch 74.683) train_loss=204.41159058 time/batch=0.72s
9082/10943 (epoch 74.691) train_loss=145.11657715 time/batch=0.52s
9083/10943 (epoch 74.700) train_loss=215.42901611 time/batch=0.77s
9084/10943 (epoch 74.708) train_loss=149.23335266 time/batch=0.58s
9085/10943 (epoch 74.716) train_loss=191.03855896 time/batch=0.64s
9086/10943 (epoch 74.724) train_loss=146.23986816 time/batch=0.52s
9087/10943 (epoch 74.732) train_loss=189.39727783 time/batch=0.68s
9088/10943 (epoch 74.741) train_loss=188.92263794 time/batch=0.67s
9089/10943 (epoch 74.749) train_loss=163.93008423 time/batch=0.61s
9090/10943 (epoch 74.757) train_loss=105.27527618 time/batch=0.38s
9091/10943 (epoch 74.765) train_loss=204.38728333 time/batch=0.74s
9092/10943 (epoch 74.774) train_loss=120.19894409 time/batch=0.46s
9093/10943 (epoch 74.782) train_loss=210.34912109 time/batch=0.69s
9094/10943 (epoch 74.790) train_loss=218.88848877 time/batch=0.83s
9095/10943 (epoch 74.798) train_loss=143.57116699 time/batch=0.54s
9096/10943 (epoch 74.806) train_loss=105.86065674 time/batch=0.43s
9097/10943 (epoch 74.815) train_loss=176.20553589 time/batch=0.61s
9098/10943 (epoch 74.823) train_loss=230.24127197 time/batch=0.87s
9099/10943 (epoch 74.831) train_loss=157.64807129 time/batch=0.61s
9100/10943 (epoch 74.839) train_loss=207.06712341 time/batch=0.71s
9101/10943 (epoch 74.848) train_loss=168.24406433 time/batch=0.60s
9102/10943 (epoch 74.856) train_loss=130.60000610 time/batch=0.46s
9103/10943 (epoch 74.864) train_loss=218.37275696 time/batch=0.77s
9104/10943 (epoch 74.872) train_loss=194.26344299 time/batch=0.74s
9105/10943 (epoch 74.880) train_loss=154.25297546 time/batch=0.59s
9106/10943 (epoch 74.889) train_loss=128.00334167 time/batch=0.47s
9107/10943 (epoch 74.897) train_loss=159.81732178 time/batch=0.60s
9108/10943 (epoch 74.905) train_loss=164.92063904 time/batch=0.60s
9109/10943 (epoch 74.913) train_loss=137.13491821 time/batch=0.49s
9110/10943 (epoch 74.922) train_loss=160.23376465 time/batch=0.60s
9111/10943 (epoch 74.930) train_loss=173.19299316 time/batch=0.72s
setting learning rate to 0.0022123
9112/10943 (epoch 74.938) train_loss=243.92733765 time/batch=0.90s
9113/10943 (epoch 74.946) train_loss=235.57540894 time/batch=0.92s
9114/10943 (epoch 74.955) train_loss=195.87664795 time/batch=0.75s
9115/10943 (epoch 74.963) train_loss=389.72784424 time/batch=1.40s
9116/10943 (epoch 74.971) train_loss=474.68792725 time/batch=1.61s
9117/10943 (epoch 74.979) train_loss=75.24458313 time/batch=0.38s
9118/10943 (epoch 74.987) train_loss=548.41186523 time/batch=1.70s
9119/10943 (epoch 74.996) train_loss=416.10052490 time/batch=1.87s
9120/10943 (epoch 75.004) train_loss=348.90649414 time/batch=1.25s
9121/10943 (epoch 75.012) train_loss=194.33074951 time/batch=0.76s
9122/10943 (epoch 75.020) train_loss=224.15695190 time/batch=0.84s
9123/10943 (epoch 75.029) train_loss=126.07038879 time/batch=0.50s
9124/10943 (epoch 75.037) train_loss=112.43623352 time/batch=0.44s
9125/10943 (epoch 75.045) train_loss=299.57211304 time/batch=1.02s
9126/10943 (epoch 75.053) train_loss=615.44696045 time/batch=3.11s
9127/10943 (epoch 75.061) train_loss=385.75927734 time/batch=1.53s
9128/10943 (epoch 75.070) train_loss=230.61968994 time/batch=0.91s
9129/10943 (epoch 75.078) train_loss=126.88145447 time/batch=0.52s
9130/10943 (epoch 75.086) train_loss=131.70722961 time/batch=0.48s
9131/10943 (epoch 75.094) train_loss=80.45169830 time/batch=0.29s
9132/10943 (epoch 75.103) train_loss=118.98918152 time/batch=0.41s
9133/10943 (epoch 75.111) train_loss=269.10552979 time/batch=0.92s
9134/10943 (epoch 75.119) train_loss=116.73240662 time/batch=0.48s
9135/10943 (epoch 75.127) train_loss=111.78622437 time/batch=0.39s
9136/10943 (epoch 75.135) train_loss=145.23506165 time/batch=0.53s
9137/10943 (epoch 75.144) train_loss=287.56988525 time/batch=0.98s
9138/10943 (epoch 75.152) train_loss=272.97204590 time/batch=0.96s
9139/10943 (epoch 75.160) train_loss=183.21519470 time/batch=0.71s
9140/10943 (epoch 75.168) train_loss=99.81501770 time/batch=0.37s
9141/10943 (epoch 75.177) train_loss=86.24698639 time/batch=0.30s
9142/10943 (epoch 75.185) train_loss=293.28637695 time/batch=0.98s
9143/10943 (epoch 75.193) train_loss=183.06637573 time/batch=0.73s
9144/10943 (epoch 75.201) train_loss=206.68275452 time/batch=0.76s
9145/10943 (epoch 75.209) train_loss=138.83517456 time/batch=0.53s
9146/10943 (epoch 75.218) train_loss=308.43939209 time/batch=1.07s
9147/10943 (epoch 75.226) train_loss=135.42866516 time/batch=0.59s
9148/10943 (epoch 75.234) train_loss=196.50027466 time/batch=0.72s
9149/10943 (epoch 75.242) train_loss=322.32501221 time/batch=1.09s
9150/10943 (epoch 75.251) train_loss=95.38772583 time/batch=0.41s
9151/10943 (epoch 75.259) train_loss=112.01605988 time/batch=0.42s
9152/10943 (epoch 75.267) train_loss=249.49768066 time/batch=0.85s
9153/10943 (epoch 75.275) train_loss=110.34800720 time/batch=0.49s
9154/10943 (epoch 75.283) train_loss=281.42169189 time/batch=0.98s
9155/10943 (epoch 75.292) train_loss=364.50225830 time/batch=1.30s
9156/10943 (epoch 75.300) train_loss=141.19284058 time/batch=0.60s
9157/10943 (epoch 75.308) train_loss=157.75381470 time/batch=0.57s
9158/10943 (epoch 75.316) train_loss=201.78909302 time/batch=0.78s
9159/10943 (epoch 75.325) train_loss=157.66149902 time/batch=0.59s
9160/10943 (epoch 75.333) train_loss=137.86007690 time/batch=0.52s
9161/10943 (epoch 75.341) train_loss=171.18278503 time/batch=0.66s
9162/10943 (epoch 75.349) train_loss=189.04931641 time/batch=0.74s
9163/10943 (epoch 75.357) train_loss=143.53363037 time/batch=0.52s
9164/10943 (epoch 75.366) train_loss=173.38429260 time/batch=0.67s
9165/10943 (epoch 75.374) train_loss=260.20007324 time/batch=0.96s
9166/10943 (epoch 75.382) train_loss=198.35623169 time/batch=0.81s
9167/10943 (epoch 75.390) train_loss=123.98905945 time/batch=0.49s
9168/10943 (epoch 75.399) train_loss=143.11483765 time/batch=0.55s
9169/10943 (epoch 75.407) train_loss=163.16989136 time/batch=0.59s
9170/10943 (epoch 75.415) train_loss=208.41259766 time/batch=0.76s
9171/10943 (epoch 75.423) train_loss=233.96447754 time/batch=0.85s
9172/10943 (epoch 75.432) train_loss=296.10824585 time/batch=1.03s
9173/10943 (epoch 75.440) train_loss=127.41116333 time/batch=0.52s
9174/10943 (epoch 75.448) train_loss=117.33007812 time/batch=0.46s
9175/10943 (epoch 75.456) train_loss=175.21975708 time/batch=0.62s
9176/10943 (epoch 75.464) train_loss=352.62762451 time/batch=1.18s
9177/10943 (epoch 75.473) train_loss=343.40213013 time/batch=1.22s
9178/10943 (epoch 75.481) train_loss=179.57928467 time/batch=0.67s
9179/10943 (epoch 75.489) train_loss=100.79860687 time/batch=0.38s
9180/10943 (epoch 75.497) train_loss=245.46154785 time/batch=0.87s
9181/10943 (epoch 75.506) train_loss=195.37942505 time/batch=0.73s
9182/10943 (epoch 75.514) train_loss=84.34731293 time/batch=0.35s
9183/10943 (epoch 75.522) train_loss=311.45495605 time/batch=1.07s
9184/10943 (epoch 75.530) train_loss=153.82308960 time/batch=0.60s
9185/10943 (epoch 75.538) train_loss=110.16321564 time/batch=0.38s
9186/10943 (epoch 75.547) train_loss=191.12310791 time/batch=0.70s
9187/10943 (epoch 75.555) train_loss=203.94084167 time/batch=0.75s
9188/10943 (epoch 75.563) train_loss=156.33782959 time/batch=0.60s
9189/10943 (epoch 75.571) train_loss=196.66296387 time/batch=0.77s
9190/10943 (epoch 75.580) train_loss=200.38116455 time/batch=0.77s
9191/10943 (epoch 75.588) train_loss=161.19169617 time/batch=0.63s
9192/10943 (epoch 75.596) train_loss=238.71295166 time/batch=0.85s
9193/10943 (epoch 75.604) train_loss=181.83700562 time/batch=0.68s
9194/10943 (epoch 75.612) train_loss=105.02211761 time/batch=0.40s
9195/10943 (epoch 75.621) train_loss=229.55155945 time/batch=0.79s
9196/10943 (epoch 75.629) train_loss=141.10209656 time/batch=0.57s
9197/10943 (epoch 75.637) train_loss=179.37985229 time/batch=0.63s
9198/10943 (epoch 75.645) train_loss=275.90661621 time/batch=0.94s
9199/10943 (epoch 75.654) train_loss=98.81311798 time/batch=0.39s
9200/10943 (epoch 75.662) train_loss=164.88739014 time/batch=0.59s
9201/10943 (epoch 75.670) train_loss=210.47348022 time/batch=0.79s
9202/10943 (epoch 75.678) train_loss=158.09970093 time/batch=0.62s
9203/10943 (epoch 75.686) train_loss=94.62512207 time/batch=0.33s
9204/10943 (epoch 75.695) train_loss=239.28744507 time/batch=0.88s
9205/10943 (epoch 75.703) train_loss=186.86935425 time/batch=0.70s
9206/10943 (epoch 75.711) train_loss=202.26019287 time/batch=0.76s
9207/10943 (epoch 75.719) train_loss=218.66632080 time/batch=0.86s
9208/10943 (epoch 75.728) train_loss=149.14404297 time/batch=0.60s
9209/10943 (epoch 75.736) train_loss=236.91345215 time/batch=0.84s
9210/10943 (epoch 75.744) train_loss=135.76518250 time/batch=0.52s
9211/10943 (epoch 75.752) train_loss=183.50695801 time/batch=0.66s
9212/10943 (epoch 75.760) train_loss=101.96566772 time/batch=0.38s
9213/10943 (epoch 75.769) train_loss=172.19772339 time/batch=0.60s
9214/10943 (epoch 75.777) train_loss=185.50590515 time/batch=0.67s
9215/10943 (epoch 75.785) train_loss=181.67665100 time/batch=0.68s
9216/10943 (epoch 75.793) train_loss=168.56649780 time/batch=0.65s
9217/10943 (epoch 75.802) train_loss=180.99150085 time/batch=0.70s
9218/10943 (epoch 75.810) train_loss=232.85638428 time/batch=0.86s
9219/10943 (epoch 75.818) train_loss=140.40093994 time/batch=0.58s
9220/10943 (epoch 75.826) train_loss=262.56091309 time/batch=0.94s
9221/10943 (epoch 75.834) train_loss=161.30235291 time/batch=0.63s
9222/10943 (epoch 75.843) train_loss=223.87188721 time/batch=0.80s
9223/10943 (epoch 75.851) train_loss=225.67893982 time/batch=1.06s
9224/10943 (epoch 75.859) train_loss=218.81732178 time/batch=0.84s
9225/10943 (epoch 75.867) train_loss=146.31788635 time/batch=0.59s
9226/10943 (epoch 75.876) train_loss=158.74192810 time/batch=0.58s
9227/10943 (epoch 75.884) train_loss=208.72247314 time/batch=0.79s
9228/10943 (epoch 75.892) train_loss=206.56002808 time/batch=0.72s
9229/10943 (epoch 75.900) train_loss=212.29249573 time/batch=0.80s
9230/10943 (epoch 75.909) train_loss=123.97159576 time/batch=0.63s
9231/10943 (epoch 75.917) train_loss=154.06414795 time/batch=0.62s
9232/10943 (epoch 75.925) train_loss=170.52355957 time/batch=0.71s
setting learning rate to 0.0021459
  saved to metadata/gru_no_dropout-9_nov_folkwiki-20181207-192453_epoch31.pkl
9233/10943 (epoch 75.933) train_loss=317.21661377 time/batch=1.14s
9234/10943 (epoch 75.941) train_loss=383.71127319 time/batch=1.45s
9235/10943 (epoch 75.950) train_loss=299.31933594 time/batch=1.07s
9236/10943 (epoch 75.958) train_loss=384.73251343 time/batch=1.33s
9237/10943 (epoch 75.966) train_loss=677.68920898 time/batch=3.14s
9238/10943 (epoch 75.974) train_loss=135.65367126 time/batch=0.80s
9239/10943 (epoch 75.983) train_loss=141.88308716 time/batch=0.54s
9240/10943 (epoch 75.991) train_loss=70.26016235 time/batch=0.27s
9241/10943 (epoch 75.999) train_loss=333.24707031 time/batch=1.09s
9242/10943 (epoch 76.007) train_loss=113.49135590 time/batch=0.49s
9243/10943 (epoch 76.015) train_loss=202.55981445 time/batch=0.71s
9244/10943 (epoch 76.024) train_loss=191.68986511 time/batch=0.80s
9245/10943 (epoch 76.032) train_loss=496.83288574 time/batch=1.67s
9246/10943 (epoch 76.040) train_loss=100.61473846 time/batch=0.50s
9247/10943 (epoch 76.048) train_loss=134.95066833 time/batch=0.48s
9248/10943 (epoch 76.057) train_loss=119.57839203 time/batch=0.44s
9249/10943 (epoch 76.065) train_loss=342.90191650 time/batch=1.19s
9250/10943 (epoch 76.073) train_loss=430.80218506 time/batch=1.58s
9251/10943 (epoch 76.081) train_loss=106.86833191 time/batch=0.52s
9252/10943 (epoch 76.089) train_loss=297.97018433 time/batch=1.03s
9253/10943 (epoch 76.098) train_loss=107.59417725 time/batch=0.47s
9254/10943 (epoch 76.106) train_loss=133.00672913 time/batch=0.49s
9255/10943 (epoch 76.114) train_loss=194.10873413 time/batch=0.78s
9256/10943 (epoch 76.122) train_loss=143.33447266 time/batch=0.62s
9257/10943 (epoch 76.131) train_loss=196.90199280 time/batch=0.75s
9258/10943 (epoch 76.139) train_loss=380.42535400 time/batch=1.34s
9259/10943 (epoch 76.147) train_loss=258.62713623 time/batch=1.05s
9260/10943 (epoch 76.155) train_loss=295.31109619 time/batch=1.05s
9261/10943 (epoch 76.163) train_loss=176.90399170 time/batch=0.70s
9262/10943 (epoch 76.172) train_loss=100.51657104 time/batch=0.37s
9263/10943 (epoch 76.180) train_loss=293.74542236 time/batch=1.06s
9264/10943 (epoch 76.188) train_loss=152.95190430 time/batch=0.69s
9265/10943 (epoch 76.196) train_loss=265.42590332 time/batch=0.95s
9266/10943 (epoch 76.205) train_loss=81.77483368 time/batch=0.35s
9267/10943 (epoch 76.213) train_loss=84.79547119 time/batch=0.29s
9268/10943 (epoch 76.221) train_loss=113.72944641 time/batch=0.42s
9269/10943 (epoch 76.229) train_loss=132.39297485 time/batch=0.48s
9270/10943 (epoch 76.237) train_loss=113.47219849 time/batch=0.44s
9271/10943 (epoch 76.246) train_loss=125.65030670 time/batch=0.46s
9272/10943 (epoch 76.254) train_loss=308.73980713 time/batch=1.11s
9273/10943 (epoch 76.262) train_loss=137.45578003 time/batch=0.54s
9274/10943 (epoch 76.270) train_loss=90.12625885 time/batch=0.32s
9275/10943 (epoch 76.279) train_loss=89.87168121 time/batch=0.32s
9276/10943 (epoch 76.287) train_loss=267.00250244 time/batch=0.91s
9277/10943 (epoch 76.295) train_loss=149.61401367 time/batch=0.61s
9278/10943 (epoch 76.303) train_loss=107.04734039 time/batch=0.39s
9279/10943 (epoch 76.311) train_loss=119.89932251 time/batch=0.42s
9280/10943 (epoch 76.320) train_loss=97.59112549 time/batch=0.36s
9281/10943 (epoch 76.328) train_loss=200.55993652 time/batch=0.69s
9282/10943 (epoch 76.336) train_loss=171.72021484 time/batch=0.70s
9283/10943 (epoch 76.344) train_loss=205.78517151 time/batch=0.77s
9284/10943 (epoch 76.353) train_loss=284.51843262 time/batch=1.04s
9285/10943 (epoch 76.361) train_loss=181.86694336 time/batch=0.70s
9286/10943 (epoch 76.369) train_loss=128.30429077 time/batch=0.49s
9287/10943 (epoch 76.377) train_loss=160.86073303 time/batch=0.61s
9288/10943 (epoch 76.386) train_loss=134.58163452 time/batch=0.51s
9289/10943 (epoch 76.394) train_loss=153.59197998 time/batch=0.56s
9290/10943 (epoch 76.402) train_loss=328.67065430 time/batch=1.15s
9291/10943 (epoch 76.410) train_loss=155.43588257 time/batch=0.60s
9292/10943 (epoch 76.418) train_loss=199.62634277 time/batch=0.72s
9293/10943 (epoch 76.427) train_loss=214.74398804 time/batch=0.86s
9294/10943 (epoch 76.435) train_loss=88.26795959 time/batch=0.35s
9295/10943 (epoch 76.443) train_loss=174.32202148 time/batch=0.64s
9296/10943 (epoch 76.451) train_loss=186.31587219 time/batch=0.74s
9297/10943 (epoch 76.460) train_loss=232.75036621 time/batch=0.88s
9298/10943 (epoch 76.468) train_loss=201.55537415 time/batch=0.78s
9299/10943 (epoch 76.476) train_loss=96.84309387 time/batch=0.40s
9300/10943 (epoch 76.484) train_loss=92.12680054 time/batch=0.36s
9301/10943 (epoch 76.492) train_loss=116.50627136 time/batch=0.48s
9302/10943 (epoch 76.501) train_loss=107.71138000 time/batch=0.41s
9303/10943 (epoch 76.509) train_loss=135.61779785 time/batch=0.49s
9304/10943 (epoch 76.517) train_loss=177.57591248 time/batch=0.66s
9305/10943 (epoch 76.525) train_loss=161.21809387 time/batch=0.62s
9306/10943 (epoch 76.534) train_loss=200.83523560 time/batch=0.76s
9307/10943 (epoch 76.542) train_loss=138.13813782 time/batch=0.56s
9308/10943 (epoch 76.550) train_loss=237.98410034 time/batch=0.86s
9309/10943 (epoch 76.558) train_loss=233.08682251 time/batch=0.85s
9310/10943 (epoch 76.566) train_loss=174.51144409 time/batch=0.66s
9311/10943 (epoch 76.575) train_loss=191.20835876 time/batch=0.70s
9312/10943 (epoch 76.583) train_loss=146.54754639 time/batch=0.58s
9313/10943 (epoch 76.591) train_loss=235.31283569 time/batch=0.90s
9314/10943 (epoch 76.599) train_loss=270.46179199 time/batch=0.95s
9315/10943 (epoch 76.608) train_loss=320.99987793 time/batch=1.19s
9316/10943 (epoch 76.616) train_loss=221.92118835 time/batch=0.87s
9317/10943 (epoch 76.624) train_loss=169.39898682 time/batch=0.65s
9318/10943 (epoch 76.632) train_loss=312.44717407 time/batch=1.17s
9319/10943 (epoch 76.640) train_loss=190.79876709 time/batch=0.74s
9320/10943 (epoch 76.649) train_loss=252.83743286 time/batch=0.93s
9321/10943 (epoch 76.657) train_loss=212.86593628 time/batch=0.84s
9322/10943 (epoch 76.665) train_loss=212.74209595 time/batch=0.80s
9323/10943 (epoch 76.673) train_loss=172.82936096 time/batch=0.66s
9324/10943 (epoch 76.682) train_loss=158.70281982 time/batch=0.61s
9325/10943 (epoch 76.690) train_loss=151.37272644 time/batch=0.63s
9326/10943 (epoch 76.698) train_loss=246.14892578 time/batch=0.95s
9327/10943 (epoch 76.706) train_loss=245.24519348 time/batch=0.92s
9328/10943 (epoch 76.714) train_loss=199.71954346 time/batch=0.73s
9329/10943 (epoch 76.723) train_loss=172.46365356 time/batch=0.66s
9330/10943 (epoch 76.731) train_loss=244.27799988 time/batch=0.87s
9331/10943 (epoch 76.739) train_loss=146.29338074 time/batch=0.56s
9332/10943 (epoch 76.747) train_loss=183.28425598 time/batch=0.53s
9333/10943 (epoch 76.756) train_loss=208.14253235 time/batch=0.79s
9334/10943 (epoch 76.764) train_loss=217.62100220 time/batch=0.84s
9335/10943 (epoch 76.772) train_loss=198.05181885 time/batch=0.80s
9336/10943 (epoch 76.780) train_loss=186.94860840 time/batch=0.79s
9337/10943 (epoch 76.788) train_loss=228.94123840 time/batch=0.84s
9338/10943 (epoch 76.797) train_loss=159.54632568 time/batch=0.62s
9339/10943 (epoch 76.805) train_loss=152.65933228 time/batch=0.57s
9340/10943 (epoch 76.813) train_loss=223.95062256 time/batch=0.83s
9341/10943 (epoch 76.821) train_loss=202.13972473 time/batch=0.82s
9342/10943 (epoch 76.830) train_loss=139.67573547 time/batch=0.57s
9343/10943 (epoch 76.838) train_loss=155.64489746 time/batch=0.57s
9344/10943 (epoch 76.846) train_loss=234.56549072 time/batch=0.87s
9345/10943 (epoch 76.854) train_loss=161.62847900 time/batch=0.63s
9346/10943 (epoch 76.863) train_loss=208.14614868 time/batch=0.81s
9347/10943 (epoch 76.871) train_loss=178.25912476 time/batch=0.71s
9348/10943 (epoch 76.879) train_loss=185.70376587 time/batch=0.70s
9349/10943 (epoch 76.887) train_loss=194.44375610 time/batch=0.82s
9350/10943 (epoch 76.895) train_loss=157.03015137 time/batch=0.62s
9351/10943 (epoch 76.904) train_loss=170.66653442 time/batch=0.63s
9352/10943 (epoch 76.912) train_loss=202.32687378 time/batch=0.71s
9353/10943 (epoch 76.920) train_loss=153.62068176 time/batch=0.62s
setting learning rate to 0.0020815
9354/10943 (epoch 76.928) train_loss=114.50775909 time/batch=0.44s
9355/10943 (epoch 76.937) train_loss=180.38357544 time/batch=0.76s
9356/10943 (epoch 76.945) train_loss=487.13732910 time/batch=1.67s
9357/10943 (epoch 76.953) train_loss=189.18426514 time/batch=0.83s
9358/10943 (epoch 76.961) train_loss=283.67517090 time/batch=0.98s
9359/10943 (epoch 76.969) train_loss=96.76815033 time/batch=0.38s
9360/10943 (epoch 76.978) train_loss=369.80825806 time/batch=1.24s
9361/10943 (epoch 76.986) train_loss=333.74163818 time/batch=1.19s
9362/10943 (epoch 76.994) train_loss=84.03923035 time/batch=0.37s
9363/10943 (epoch 77.002) train_loss=86.33375549 time/batch=0.32s
9364/10943 (epoch 77.011) train_loss=115.32286072 time/batch=0.43s
9365/10943 (epoch 77.019) train_loss=203.31362915 time/batch=0.81s
9366/10943 (epoch 77.027) train_loss=489.79812622 time/batch=1.93s
9367/10943 (epoch 77.035) train_loss=400.66949463 time/batch=1.57s
9368/10943 (epoch 77.043) train_loss=183.93478394 time/batch=0.76s
9369/10943 (epoch 77.052) train_loss=396.08331299 time/batch=2.00s
9370/10943 (epoch 77.060) train_loss=339.19512939 time/batch=1.35s
9371/10943 (epoch 77.068) train_loss=168.33436584 time/batch=0.74s
9372/10943 (epoch 77.076) train_loss=170.60546875 time/batch=0.65s
9373/10943 (epoch 77.085) train_loss=81.37912750 time/batch=0.32s
9374/10943 (epoch 77.093) train_loss=106.50521088 time/batch=0.38s
9375/10943 (epoch 77.101) train_loss=161.77168274 time/batch=0.62s
9376/10943 (epoch 77.109) train_loss=114.73124695 time/batch=0.46s
9377/10943 (epoch 77.117) train_loss=292.83898926 time/batch=1.06s
9378/10943 (epoch 77.126) train_loss=103.10276794 time/batch=0.46s
9379/10943 (epoch 77.134) train_loss=289.59503174 time/batch=1.02s
9380/10943 (epoch 77.142) train_loss=329.95831299 time/batch=1.25s
9381/10943 (epoch 77.150) train_loss=87.25067139 time/batch=0.39s
9382/10943 (epoch 77.159) train_loss=191.32376099 time/batch=0.67s
9383/10943 (epoch 77.167) train_loss=133.74761963 time/batch=0.52s
9384/10943 (epoch 77.175) train_loss=215.57234192 time/batch=0.80s
9385/10943 (epoch 77.183) train_loss=263.07525635 time/batch=0.94s
9386/10943 (epoch 77.191) train_loss=535.75415039 time/batch=3.08s
9387/10943 (epoch 77.200) train_loss=181.14639282 time/batch=0.91s
9388/10943 (epoch 77.208) train_loss=104.47036743 time/batch=0.40s
9389/10943 (epoch 77.216) train_loss=196.99218750 time/batch=0.74s
9390/10943 (epoch 77.224) train_loss=225.38958740 time/batch=0.91s
9391/10943 (epoch 77.233) train_loss=186.94577026 time/batch=0.74s
9392/10943 (epoch 77.241) train_loss=209.60801697 time/batch=0.86s
9393/10943 (epoch 77.249) train_loss=127.81391907 time/batch=0.51s
9394/10943 (epoch 77.257) train_loss=161.20773315 time/batch=0.60s
9395/10943 (epoch 77.265) train_loss=168.64004517 time/batch=0.67s
9396/10943 (epoch 77.274) train_loss=309.53933716 time/batch=1.07s
9397/10943 (epoch 77.282) train_loss=319.73474121 time/batch=1.26s
9398/10943 (epoch 77.290) train_loss=307.15576172 time/batch=1.17s
9399/10943 (epoch 77.298) train_loss=150.60922241 time/batch=0.62s
9400/10943 (epoch 77.307) train_loss=110.00127411 time/batch=0.42s
9401/10943 (epoch 77.315) train_loss=170.51654053 time/batch=0.66s
9402/10943 (epoch 77.323) train_loss=96.37223816 time/batch=0.38s
9403/10943 (epoch 77.331) train_loss=232.46783447 time/batch=0.89s
9404/10943 (epoch 77.340) train_loss=219.46264648 time/batch=0.87s
9405/10943 (epoch 77.348) train_loss=99.09684753 time/batch=0.38s
9406/10943 (epoch 77.356) train_loss=118.18128967 time/batch=0.44s
9407/10943 (epoch 77.364) train_loss=131.01464844 time/batch=0.50s
9408/10943 (epoch 77.372) train_loss=215.54762268 time/batch=0.79s
9409/10943 (epoch 77.381) train_loss=154.34906006 time/batch=0.63s
9410/10943 (epoch 77.389) train_loss=133.63751221 time/batch=0.51s
9411/10943 (epoch 77.397) train_loss=261.45428467 time/batch=0.93s
9412/10943 (epoch 77.405) train_loss=192.47404480 time/batch=0.82s
9413/10943 (epoch 77.414) train_loss=182.85160828 time/batch=0.77s
9414/10943 (epoch 77.422) train_loss=129.64678955 time/batch=0.51s
9415/10943 (epoch 77.430) train_loss=227.66760254 time/batch=0.86s
9416/10943 (epoch 77.438) train_loss=110.42068481 time/batch=0.45s
9417/10943 (epoch 77.446) train_loss=121.85401154 time/batch=0.45s
9418/10943 (epoch 77.455) train_loss=209.48347473 time/batch=0.80s
9419/10943 (epoch 77.463) train_loss=204.06724548 time/batch=0.78s
9420/10943 (epoch 77.471) train_loss=256.86437988 time/batch=0.97s
9421/10943 (epoch 77.479) train_loss=294.99621582 time/batch=1.18s
9422/10943 (epoch 77.488) train_loss=165.71139526 time/batch=0.68s
9423/10943 (epoch 77.496) train_loss=145.62980652 time/batch=0.56s
9424/10943 (epoch 77.504) train_loss=132.51579285 time/batch=0.55s
9425/10943 (epoch 77.512) train_loss=121.68305969 time/batch=0.48s
9426/10943 (epoch 77.520) train_loss=281.91546631 time/batch=0.98s
9427/10943 (epoch 77.529) train_loss=245.59669495 time/batch=0.94s
9428/10943 (epoch 77.537) train_loss=209.67709351 time/batch=0.82s
9429/10943 (epoch 77.545) train_loss=91.64120483 time/batch=0.38s
9430/10943 (epoch 77.553) train_loss=150.90353394 time/batch=0.56s
9431/10943 (epoch 77.562) train_loss=129.15371704 time/batch=0.50s
9432/10943 (epoch 77.570) train_loss=188.69171143 time/batch=0.70s
9433/10943 (epoch 77.578) train_loss=150.36958313 time/batch=0.56s
9434/10943 (epoch 77.586) train_loss=132.03756714 time/batch=0.52s
9435/10943 (epoch 77.594) train_loss=113.44186401 time/batch=0.47s
9436/10943 (epoch 77.603) train_loss=140.50869751 time/batch=0.53s
9437/10943 (epoch 77.611) train_loss=72.87205505 time/batch=0.32s
9438/10943 (epoch 77.619) train_loss=175.34959412 time/batch=0.63s
9439/10943 (epoch 77.627) train_loss=198.06529236 time/batch=0.79s
9440/10943 (epoch 77.636) train_loss=147.75018311 time/batch=0.63s
9441/10943 (epoch 77.644) train_loss=198.89498901 time/batch=0.72s
9442/10943 (epoch 77.652) train_loss=180.94500732 time/batch=0.70s
9443/10943 (epoch 77.660) train_loss=190.57995605 time/batch=0.71s
9444/10943 (epoch 77.668) train_loss=242.83705139 time/batch=0.92s
9445/10943 (epoch 77.677) train_loss=213.02989197 time/batch=0.84s
9446/10943 (epoch 77.685) train_loss=266.62875366 time/batch=1.00s
9447/10943 (epoch 77.693) train_loss=169.56814575 time/batch=0.68s
9448/10943 (epoch 77.701) train_loss=98.76201630 time/batch=0.43s
9449/10943 (epoch 77.710) train_loss=149.59191895 time/batch=0.57s
9450/10943 (epoch 77.718) train_loss=285.79223633 time/batch=1.00s
9451/10943 (epoch 77.726) train_loss=198.11120605 time/batch=0.78s
9452/10943 (epoch 77.734) train_loss=195.86003113 time/batch=0.75s
9453/10943 (epoch 77.742) train_loss=152.18856812 time/batch=0.59s
9454/10943 (epoch 77.751) train_loss=146.62234497 time/batch=0.61s
9455/10943 (epoch 77.759) train_loss=191.27850342 time/batch=0.73s
9456/10943 (epoch 77.767) train_loss=149.80334473 time/batch=0.59s
9457/10943 (epoch 77.775) train_loss=226.39315796 time/batch=0.85s
9458/10943 (epoch 77.784) train_loss=160.80937195 time/batch=0.63s
9459/10943 (epoch 77.792) train_loss=207.43319702 time/batch=0.82s
9460/10943 (epoch 77.800) train_loss=153.55502319 time/batch=0.61s
9461/10943 (epoch 77.808) train_loss=177.96575928 time/batch=0.67s
9462/10943 (epoch 77.816) train_loss=126.09866333 time/batch=0.50s
9463/10943 (epoch 77.825) train_loss=203.04716492 time/batch=0.84s
9464/10943 (epoch 77.833) train_loss=174.50712585 time/batch=0.72s
9465/10943 (epoch 77.841) train_loss=121.21983337 time/batch=0.55s
9466/10943 (epoch 77.849) train_loss=245.18501282 time/batch=0.98s
9467/10943 (epoch 77.858) train_loss=170.93936157 time/batch=0.69s
9468/10943 (epoch 77.866) train_loss=141.22656250 time/batch=0.56s
9469/10943 (epoch 77.874) train_loss=238.59277344 time/batch=0.99s
9470/10943 (epoch 77.882) train_loss=161.92965698 time/batch=0.66s
9471/10943 (epoch 77.891) train_loss=196.90898132 time/batch=0.75s
9472/10943 (epoch 77.899) train_loss=194.78976440 time/batch=0.79s
9473/10943 (epoch 77.907) train_loss=146.52488708 time/batch=0.64s
9474/10943 (epoch 77.915) train_loss=159.75529480 time/batch=0.77s
setting learning rate to 0.0020191
  saved to metadata/gru_no_dropout-9_nov_folkwiki-20181207-192453_epoch33.pkl
9475/10943 (epoch 77.923) train_loss=342.67178345 time/batch=1.30s
9476/10943 (epoch 77.932) train_loss=568.59973145 time/batch=2.21s
9477/10943 (epoch 77.940) train_loss=76.25819397 time/batch=0.46s
9478/10943 (epoch 77.948) train_loss=81.28258514 time/batch=0.29s
9479/10943 (epoch 77.956) train_loss=197.29757690 time/batch=0.74s
9480/10943 (epoch 77.965) train_loss=130.03477478 time/batch=0.54s
9481/10943 (epoch 77.973) train_loss=111.88908386 time/batch=0.41s
9482/10943 (epoch 77.981) train_loss=362.08093262 time/batch=1.25s
9483/10943 (epoch 77.989) train_loss=281.74267578 time/batch=1.04s
9484/10943 (epoch 77.997) train_loss=309.46255493 time/batch=1.16s
9485/10943 (epoch 78.006) train_loss=195.50769043 time/batch=0.86s
9486/10943 (epoch 78.014) train_loss=422.46212769 time/batch=1.55s
9487/10943 (epoch 78.022) train_loss=153.24835205 time/batch=0.71s
9488/10943 (epoch 78.030) train_loss=249.04928589 time/batch=0.94s
9489/10943 (epoch 78.039) train_loss=164.99850464 time/batch=0.68s
9490/10943 (epoch 78.047) train_loss=179.69076538 time/batch=0.73s
9491/10943 (epoch 78.055) train_loss=190.97573853 time/batch=0.81s
9492/10943 (epoch 78.063) train_loss=306.12908936 time/batch=1.09s
9493/10943 (epoch 78.071) train_loss=96.89166260 time/batch=0.43s
9494/10943 (epoch 78.080) train_loss=185.96315002 time/batch=0.69s
9495/10943 (epoch 78.088) train_loss=202.22175598 time/batch=0.82s
9496/10943 (epoch 78.096) train_loss=99.75753784 time/batch=0.43s
9497/10943 (epoch 78.104) train_loss=171.94198608 time/batch=0.63s
9498/10943 (epoch 78.113) train_loss=129.11538696 time/batch=0.53s
9499/10943 (epoch 78.121) train_loss=367.74581909 time/batch=1.35s
9500/10943 (epoch 78.129) train_loss=180.10684204 time/batch=0.81s
9501/10943 (epoch 78.137) train_loss=195.21093750 time/batch=0.81s
9502/10943 (epoch 78.145) train_loss=257.46539307 time/batch=0.96s
9503/10943 (epoch 78.154) train_loss=490.48693848 time/batch=2.19s
9504/10943 (epoch 78.162) train_loss=136.94642639 time/batch=0.67s
9505/10943 (epoch 78.170) train_loss=350.92999268 time/batch=1.27s
9506/10943 (epoch 78.178) train_loss=116.23236084 time/batch=0.53s
9507/10943 (epoch 78.187) train_loss=84.41639709 time/batch=0.30s
9508/10943 (epoch 78.195) train_loss=286.59399414 time/batch=1.04s
9509/10943 (epoch 78.203) train_loss=244.14962769 time/batch=1.03s
9510/10943 (epoch 78.211) train_loss=190.82182312 time/batch=0.75s
9511/10943 (epoch 78.219) train_loss=320.45153809 time/batch=1.17s
9512/10943 (epoch 78.228) train_loss=275.38708496 time/batch=1.09s
9513/10943 (epoch 78.236) train_loss=279.05410767 time/batch=1.04s
9514/10943 (epoch 78.244) train_loss=94.90081787 time/batch=0.40s
9515/10943 (epoch 78.252) train_loss=104.02378082 time/batch=0.36s
9516/10943 (epoch 78.261) train_loss=311.80148315 time/batch=1.10s
9517/10943 (epoch 78.269) train_loss=215.49031067 time/batch=0.90s
9518/10943 (epoch 78.277) train_loss=93.79838562 time/batch=0.39s
9519/10943 (epoch 78.285) train_loss=123.50906372 time/batch=0.51s
9520/10943 (epoch 78.293) train_loss=166.60165405 time/batch=0.66s
9521/10943 (epoch 78.302) train_loss=388.34997559 time/batch=3.05s
9522/10943 (epoch 78.310) train_loss=191.75405884 time/batch=0.98s
9523/10943 (epoch 78.318) train_loss=171.95065308 time/batch=0.65s
9524/10943 (epoch 78.326) train_loss=138.05703735 time/batch=0.56s
9525/10943 (epoch 78.335) train_loss=171.81817627 time/batch=0.68s
9526/10943 (epoch 78.343) train_loss=147.57575989 time/batch=0.55s
9527/10943 (epoch 78.351) train_loss=150.61842346 time/batch=0.61s
9528/10943 (epoch 78.359) train_loss=221.93087769 time/batch=0.90s
9529/10943 (epoch 78.368) train_loss=145.11880493 time/batch=0.62s
9530/10943 (epoch 78.376) train_loss=115.93441772 time/batch=0.44s
9531/10943 (epoch 78.384) train_loss=148.11114502 time/batch=0.59s
9532/10943 (epoch 78.392) train_loss=150.76881409 time/batch=0.62s
9533/10943 (epoch 78.400) train_loss=92.86618042 time/batch=0.37s
9534/10943 (epoch 78.409) train_loss=190.61286926 time/batch=0.73s
9535/10943 (epoch 78.417) train_loss=154.02656555 time/batch=0.63s
9536/10943 (epoch 78.425) train_loss=188.11029053 time/batch=0.74s
9537/10943 (epoch 78.433) train_loss=157.98480225 time/batch=0.65s
9538/10943 (epoch 78.442) train_loss=264.48077393 time/batch=0.98s
9539/10943 (epoch 78.450) train_loss=195.42170715 time/batch=0.84s
9540/10943 (epoch 78.458) train_loss=150.27322388 time/batch=0.62s
9541/10943 (epoch 78.466) train_loss=107.14063263 time/batch=0.41s
9542/10943 (epoch 78.474) train_loss=103.83523560 time/batch=0.40s
9543/10943 (epoch 78.483) train_loss=167.76193237 time/batch=0.65s
9544/10943 (epoch 78.491) train_loss=213.38566589 time/batch=0.83s
9545/10943 (epoch 78.499) train_loss=166.59291077 time/batch=0.69s
9546/10943 (epoch 78.507) train_loss=285.17587280 time/batch=1.07s
9547/10943 (epoch 78.516) train_loss=147.84358215 time/batch=0.67s
9548/10943 (epoch 78.524) train_loss=139.24343872 time/batch=0.57s
9549/10943 (epoch 78.532) train_loss=85.06594849 time/batch=0.33s
9550/10943 (epoch 78.540) train_loss=239.08506775 time/batch=0.85s
9551/10943 (epoch 78.548) train_loss=197.22875977 time/batch=0.79s
9552/10943 (epoch 78.557) train_loss=135.15853882 time/batch=0.56s
9553/10943 (epoch 78.565) train_loss=225.37825012 time/batch=0.87s
9554/10943 (epoch 78.573) train_loss=136.17053223 time/batch=0.58s
9555/10943 (epoch 78.581) train_loss=218.59667969 time/batch=0.82s
9556/10943 (epoch 78.590) train_loss=144.24267578 time/batch=0.61s
9557/10943 (epoch 78.598) train_loss=114.99008942 time/batch=0.46s
9558/10943 (epoch 78.606) train_loss=171.95745850 time/batch=0.66s
9559/10943 (epoch 78.614) train_loss=171.22456360 time/batch=0.64s
9560/10943 (epoch 78.622) train_loss=93.05273438 time/batch=0.39s
9561/10943 (epoch 78.631) train_loss=125.33440399 time/batch=0.45s
9562/10943 (epoch 78.639) train_loss=122.40237427 time/batch=0.47s
9563/10943 (epoch 78.647) train_loss=185.39822388 time/batch=0.77s
9564/10943 (epoch 78.655) train_loss=220.13398743 time/batch=0.87s
9565/10943 (epoch 78.664) train_loss=219.88870239 time/batch=0.88s
9566/10943 (epoch 78.672) train_loss=85.24731445 time/batch=0.36s
9567/10943 (epoch 78.680) train_loss=210.42880249 time/batch=0.80s
9568/10943 (epoch 78.688) train_loss=99.53898621 time/batch=0.45s
9569/10943 (epoch 78.696) train_loss=154.04287720 time/batch=0.55s
9570/10943 (epoch 78.705) train_loss=239.91354370 time/batch=0.89s
9571/10943 (epoch 78.713) train_loss=244.05807495 time/batch=0.95s
9572/10943 (epoch 78.721) train_loss=272.61761475 time/batch=1.10s
9573/10943 (epoch 78.729) train_loss=196.12237549 time/batch=0.74s
9574/10943 (epoch 78.738) train_loss=263.49942017 time/batch=1.09s
9575/10943 (epoch 78.746) train_loss=198.55390930 time/batch=0.86s
9576/10943 (epoch 78.754) train_loss=191.67996216 time/batch=0.75s
9577/10943 (epoch 78.762) train_loss=147.59078979 time/batch=0.59s
9578/10943 (epoch 78.770) train_loss=154.14953613 time/batch=0.60s
9579/10943 (epoch 78.779) train_loss=155.66235352 time/batch=0.63s
9580/10943 (epoch 78.787) train_loss=211.97097778 time/batch=0.82s
9581/10943 (epoch 78.795) train_loss=141.61616516 time/batch=0.60s
9582/10943 (epoch 78.803) train_loss=162.42317200 time/batch=0.69s
9583/10943 (epoch 78.812) train_loss=125.57408905 time/batch=0.51s
9584/10943 (epoch 78.820) train_loss=110.79869080 time/batch=0.44s
9585/10943 (epoch 78.828) train_loss=199.85392761 time/batch=0.79s
9586/10943 (epoch 78.836) train_loss=176.71209717 time/batch=0.70s
9587/10943 (epoch 78.845) train_loss=134.90637207 time/batch=0.51s
9588/10943 (epoch 78.853) train_loss=145.74617004 time/batch=0.57s
9589/10943 (epoch 78.861) train_loss=178.60568237 time/batch=0.75s
9590/10943 (epoch 78.869) train_loss=146.35333252 time/batch=0.61s
9591/10943 (epoch 78.877) train_loss=209.79130554 time/batch=0.80s
9592/10943 (epoch 78.886) train_loss=114.92762756 time/batch=0.49s
9593/10943 (epoch 78.894) train_loss=131.02798462 time/batch=0.49s
9594/10943 (epoch 78.902) train_loss=182.99906921 time/batch=0.68s
9595/10943 (epoch 78.910) train_loss=174.16345215 time/batch=0.74s
setting learning rate to 0.0019585
9596/10943 (epoch 78.919) train_loss=247.86590576 time/batch=0.95s
9597/10943 (epoch 78.927) train_loss=476.23892212 time/batch=1.69s
9598/10943 (epoch 78.935) train_loss=304.68185425 time/batch=1.21s
9599/10943 (epoch 78.943) train_loss=660.58264160 time/batch=3.10s
9600/10943 (epoch 78.951) train_loss=174.39657593 time/batch=0.92s
9601/10943 (epoch 78.960) train_loss=368.12747192 time/batch=1.27s
9602/10943 (epoch 78.968) train_loss=381.06066895 time/batch=1.53s
9603/10943 (epoch 78.976) train_loss=80.88456726 time/batch=0.41s
9604/10943 (epoch 78.984) train_loss=168.29925537 time/batch=0.64s
9605/10943 (epoch 78.993) train_loss=80.97625732 time/batch=0.33s
9606/10943 (epoch 79.001) train_loss=148.85015869 time/batch=0.60s
9607/10943 (epoch 79.009) train_loss=261.07116699 time/batch=1.02s
9608/10943 (epoch 79.017) train_loss=155.54138184 time/batch=0.73s
9609/10943 (epoch 79.025) train_loss=84.02748108 time/batch=0.36s
9610/10943 (epoch 79.034) train_loss=160.21652222 time/batch=0.64s
9611/10943 (epoch 79.042) train_loss=216.57983398 time/batch=0.87s
9612/10943 (epoch 79.050) train_loss=182.09356689 time/batch=0.77s
9613/10943 (epoch 79.058) train_loss=203.59495544 time/batch=0.86s
9614/10943 (epoch 79.067) train_loss=308.42648315 time/batch=1.15s
9615/10943 (epoch 79.075) train_loss=279.53582764 time/batch=1.09s
9616/10943 (epoch 79.083) train_loss=106.26262665 time/batch=0.49s
9617/10943 (epoch 79.091) train_loss=324.78369141 time/batch=1.18s
9618/10943 (epoch 79.099) train_loss=165.11074829 time/batch=0.73s
9619/10943 (epoch 79.108) train_loss=380.58239746 time/batch=1.51s
9620/10943 (epoch 79.116) train_loss=120.66137695 time/batch=0.61s
9621/10943 (epoch 79.124) train_loss=173.06953430 time/batch=0.68s
9622/10943 (epoch 79.132) train_loss=320.64761353 time/batch=1.18s
9623/10943 (epoch 79.141) train_loss=186.78800964 time/batch=0.76s
9624/10943 (epoch 79.149) train_loss=78.58247375 time/batch=0.34s
9625/10943 (epoch 79.157) train_loss=88.16755676 time/batch=0.33s
9626/10943 (epoch 79.165) train_loss=296.38513184 time/batch=1.10s
9627/10943 (epoch 79.173) train_loss=101.53187561 time/batch=0.49s
9628/10943 (epoch 79.182) train_loss=359.80914307 time/batch=1.50s
9629/10943 (epoch 79.190) train_loss=152.53558350 time/batch=0.71s
9630/10943 (epoch 79.198) train_loss=253.83383179 time/batch=0.94s
9631/10943 (epoch 79.206) train_loss=194.54922485 time/batch=0.84s
9632/10943 (epoch 79.215) train_loss=135.64587402 time/batch=0.58s
9633/10943 (epoch 79.223) train_loss=120.30651093 time/batch=0.48s
9634/10943 (epoch 79.231) train_loss=185.74133301 time/batch=0.72s
9635/10943 (epoch 79.239) train_loss=284.27569580 time/batch=1.06s
9636/10943 (epoch 79.247) train_loss=168.93499756 time/batch=0.74s
9637/10943 (epoch 79.256) train_loss=308.67864990 time/batch=1.15s
9638/10943 (epoch 79.264) train_loss=114.93106079 time/batch=0.52s
9639/10943 (epoch 79.272) train_loss=69.94097900 time/batch=0.31s
9640/10943 (epoch 79.280) train_loss=183.35223389 time/batch=0.73s
9641/10943 (epoch 79.289) train_loss=144.12231445 time/batch=0.62s
9642/10943 (epoch 79.297) train_loss=79.63664246 time/batch=0.33s
9643/10943 (epoch 79.305) train_loss=215.81471252 time/batch=0.80s
9644/10943 (epoch 79.313) train_loss=186.81605530 time/batch=0.73s
9645/10943 (epoch 79.322) train_loss=250.39898682 time/batch=0.97s
9646/10943 (epoch 79.330) train_loss=112.60720825 time/batch=0.48s
9647/10943 (epoch 79.338) train_loss=150.55923462 time/batch=0.60s
9648/10943 (epoch 79.346) train_loss=111.89108276 time/batch=0.45s
9649/10943 (epoch 79.354) train_loss=218.24754333 time/batch=0.87s
9650/10943 (epoch 79.363) train_loss=184.93148804 time/batch=0.80s
9651/10943 (epoch 79.371) train_loss=165.97383118 time/batch=0.66s
9652/10943 (epoch 79.379) train_loss=185.85275269 time/batch=0.72s
9653/10943 (epoch 79.387) train_loss=129.13887024 time/batch=0.53s
9654/10943 (epoch 79.396) train_loss=96.83118439 time/batch=0.38s
9655/10943 (epoch 79.404) train_loss=111.99069214 time/batch=0.43s
9656/10943 (epoch 79.412) train_loss=158.20239258 time/batch=0.61s
9657/10943 (epoch 79.420) train_loss=223.18450928 time/batch=0.92s
9658/10943 (epoch 79.428) train_loss=211.95559692 time/batch=0.86s
9659/10943 (epoch 79.437) train_loss=286.36358643 time/batch=1.02s
9660/10943 (epoch 79.445) train_loss=209.41241455 time/batch=0.88s
9661/10943 (epoch 79.453) train_loss=152.01733398 time/batch=0.59s
9662/10943 (epoch 79.461) train_loss=204.46772766 time/batch=0.80s
9663/10943 (epoch 79.470) train_loss=93.03221130 time/batch=0.41s
9664/10943 (epoch 79.478) train_loss=242.79750061 time/batch=0.92s
9665/10943 (epoch 79.486) train_loss=120.34649658 time/batch=0.52s
9666/10943 (epoch 79.494) train_loss=153.98648071 time/batch=0.59s
9667/10943 (epoch 79.502) train_loss=100.67823029 time/batch=0.37s
9668/10943 (epoch 79.511) train_loss=144.30130005 time/batch=0.52s
9669/10943 (epoch 79.519) train_loss=278.73156738 time/batch=1.20s
9670/10943 (epoch 79.527) train_loss=148.57279968 time/batch=0.66s
9671/10943 (epoch 79.535) train_loss=138.35758972 time/batch=0.55s
9672/10943 (epoch 79.544) train_loss=139.48623657 time/batch=0.61s
9673/10943 (epoch 79.552) train_loss=126.83258820 time/batch=0.53s
9674/10943 (epoch 79.560) train_loss=178.56857300 time/batch=0.69s
9675/10943 (epoch 79.568) train_loss=185.36389160 time/batch=0.73s
9676/10943 (epoch 79.576) train_loss=133.17564392 time/batch=0.59s
9677/10943 (epoch 79.585) train_loss=175.41604614 time/batch=0.64s
9678/10943 (epoch 79.593) train_loss=208.38836670 time/batch=0.82s
9679/10943 (epoch 79.601) train_loss=123.01938629 time/batch=0.50s
9680/10943 (epoch 79.609) train_loss=96.45082092 time/batch=0.37s
9681/10943 (epoch 79.618) train_loss=120.20692444 time/batch=0.47s
9682/10943 (epoch 79.626) train_loss=197.44805908 time/batch=0.77s
9683/10943 (epoch 79.634) train_loss=185.29695129 time/batch=0.75s
9684/10943 (epoch 79.642) train_loss=187.94216919 time/batch=0.78s
9685/10943 (epoch 79.650) train_loss=175.76281738 time/batch=0.68s
9686/10943 (epoch 79.659) train_loss=175.09588623 time/batch=0.75s
9687/10943 (epoch 79.667) train_loss=135.97294617 time/batch=0.54s
9688/10943 (epoch 79.675) train_loss=183.89343262 time/batch=0.71s
9689/10943 (epoch 79.683) train_loss=107.10346985 time/batch=0.42s
9690/10943 (epoch 79.692) train_loss=147.67221069 time/batch=0.57s
9691/10943 (epoch 79.700) train_loss=265.95989990 time/batch=0.97s
9692/10943 (epoch 79.708) train_loss=171.14624023 time/batch=0.69s
9693/10943 (epoch 79.716) train_loss=148.39892578 time/batch=0.61s
9694/10943 (epoch 79.724) train_loss=129.58514404 time/batch=0.50s
9695/10943 (epoch 79.733) train_loss=221.93753052 time/batch=0.86s
9696/10943 (epoch 79.741) train_loss=135.69175720 time/batch=0.58s
9697/10943 (epoch 79.749) train_loss=192.25239563 time/batch=0.79s
9698/10943 (epoch 79.757) train_loss=237.90943909 time/batch=0.94s
9699/10943 (epoch 79.766) train_loss=227.33978271 time/batch=0.91s
9700/10943 (epoch 79.774) train_loss=211.84988403 time/batch=0.84s
9701/10943 (epoch 79.782) train_loss=232.68899536 time/batch=0.95s
9702/10943 (epoch 79.790) train_loss=96.31493378 time/batch=0.40s
9703/10943 (epoch 79.799) train_loss=188.17248535 time/batch=0.73s
9704/10943 (epoch 79.807) train_loss=205.39578247 time/batch=0.87s
9705/10943 (epoch 79.815) train_loss=107.03918457 time/batch=0.47s
9706/10943 (epoch 79.823) train_loss=131.23065186 time/batch=0.49s
9707/10943 (epoch 79.831) train_loss=150.52847290 time/batch=0.60s
9708/10943 (epoch 79.840) train_loss=186.51300049 time/batch=0.80s
9709/10943 (epoch 79.848) train_loss=221.72756958 time/batch=0.99s
9710/10943 (epoch 79.856) train_loss=143.82217407 time/batch=0.69s
9711/10943 (epoch 79.864) train_loss=147.16412354 time/batch=0.59s
9712/10943 (epoch 79.873) train_loss=197.63934326 time/batch=0.77s
9713/10943 (epoch 79.881) train_loss=118.06335449 time/batch=0.54s
9714/10943 (epoch 79.889) train_loss=164.09793091 time/batch=0.66s
9715/10943 (epoch 79.897) train_loss=139.88662720 time/batch=0.59s
9716/10943 (epoch 79.905) train_loss=155.55558777 time/batch=0.74s
setting learning rate to 0.0018998
  saved to metadata/gru_no_dropout-9_nov_folkwiki-20181207-192453_epoch35.pkl
9717/10943 (epoch 79.914) train_loss=163.33630371 time/batch=0.74s
9718/10943 (epoch 79.922) train_loss=128.88546753 time/batch=0.60s
9719/10943 (epoch 79.930) train_loss=357.58981323 time/batch=1.28s
9720/10943 (epoch 79.938) train_loss=637.89666748 time/batch=3.13s
9721/10943 (epoch 79.947) train_loss=327.80798340 time/batch=1.39s
9722/10943 (epoch 79.955) train_loss=489.42712402 time/batch=1.71s
9723/10943 (epoch 79.963) train_loss=272.09823608 time/batch=1.06s
9724/10943 (epoch 79.971) train_loss=167.82620239 time/batch=0.69s
9725/10943 (epoch 79.979) train_loss=77.49528503 time/batch=0.30s
9726/10943 (epoch 79.988) train_loss=355.47702026 time/batch=1.29s
9727/10943 (epoch 79.996) train_loss=233.07833862 time/batch=1.05s
9728/10943 (epoch 80.004) train_loss=68.54850769 time/batch=0.35s
9729/10943 (epoch 80.012) train_loss=100.16607666 time/batch=0.44s
9730/10943 (epoch 80.021) train_loss=300.40716553 time/batch=1.12s
9731/10943 (epoch 80.029) train_loss=214.30931091 time/batch=0.96s
9732/10943 (epoch 80.037) train_loss=400.01950073 time/batch=1.54s
9733/10943 (epoch 80.045) train_loss=270.68045044 time/batch=1.14s
9734/10943 (epoch 80.053) train_loss=179.98968506 time/batch=0.83s
9735/10943 (epoch 80.062) train_loss=106.71604919 time/batch=0.47s
9736/10943 (epoch 80.070) train_loss=159.16795349 time/batch=0.63s
9737/10943 (epoch 80.078) train_loss=295.04110718 time/batch=1.14s
9738/10943 (epoch 80.086) train_loss=172.43707275 time/batch=0.77s
9739/10943 (epoch 80.095) train_loss=352.13513184 time/batch=1.67s
9740/10943 (epoch 80.103) train_loss=85.11170959 time/batch=0.45s
9741/10943 (epoch 80.111) train_loss=107.85450745 time/batch=0.41s
9742/10943 (epoch 80.119) train_loss=160.30979919 time/batch=0.62s
9743/10943 (epoch 80.127) train_loss=220.24243164 time/batch=0.88s
9744/10943 (epoch 80.136) train_loss=205.44757080 time/batch=0.88s
9745/10943 (epoch 80.144) train_loss=153.53393555 time/batch=0.66s
9746/10943 (epoch 80.152) train_loss=241.47222900 time/batch=0.98s
9747/10943 (epoch 80.160) train_loss=294.99005127 time/batch=1.11s
9748/10943 (epoch 80.169) train_loss=109.17010498 time/batch=0.51s
9749/10943 (epoch 80.177) train_loss=113.83303833 time/batch=0.46s
9750/10943 (epoch 80.185) train_loss=311.84753418 time/batch=1.16s
9751/10943 (epoch 80.193) train_loss=202.61032104 time/batch=0.90s
9752/10943 (epoch 80.201) train_loss=143.18054199 time/batch=0.60s
9753/10943 (epoch 80.210) train_loss=95.50804138 time/batch=0.35s
9754/10943 (epoch 80.218) train_loss=155.55126953 time/batch=0.66s
9755/10943 (epoch 80.226) train_loss=121.63563538 time/batch=0.50s
9756/10943 (epoch 80.234) train_loss=180.34701538 time/batch=0.78s
9757/10943 (epoch 80.243) train_loss=132.81071472 time/batch=0.64s
9758/10943 (epoch 80.251) train_loss=243.19633484 time/batch=0.95s
9759/10943 (epoch 80.259) train_loss=173.97338867 time/batch=0.74s
9760/10943 (epoch 80.267) train_loss=146.89523315 time/batch=0.64s
9761/10943 (epoch 80.276) train_loss=125.02326965 time/batch=0.56s
9762/10943 (epoch 80.284) train_loss=281.08456421 time/batch=1.14s
9763/10943 (epoch 80.292) train_loss=185.18128967 time/batch=0.79s
9764/10943 (epoch 80.300) train_loss=179.33250427 time/batch=0.78s
9765/10943 (epoch 80.308) train_loss=92.45962524 time/batch=0.39s
9766/10943 (epoch 80.317) train_loss=287.11355591 time/batch=1.15s
9767/10943 (epoch 80.325) train_loss=272.81375122 time/batch=1.07s
9768/10943 (epoch 80.333) train_loss=192.97702026 time/batch=0.79s
9769/10943 (epoch 80.341) train_loss=283.73904419 time/batch=1.21s
9770/10943 (epoch 80.350) train_loss=108.81529999 time/batch=0.50s
9771/10943 (epoch 80.358) train_loss=121.86204529 time/batch=0.48s
9772/10943 (epoch 80.366) train_loss=120.07896423 time/batch=0.49s
9773/10943 (epoch 80.374) train_loss=153.94107056 time/batch=0.61s
9774/10943 (epoch 80.382) train_loss=303.40936279 time/batch=1.22s
9775/10943 (epoch 80.391) train_loss=184.77830505 time/batch=0.84s
9776/10943 (epoch 80.399) train_loss=142.46557617 time/batch=0.62s
9777/10943 (epoch 80.407) train_loss=250.90087891 time/batch=0.92s
9778/10943 (epoch 80.415) train_loss=125.11486053 time/batch=0.57s
9779/10943 (epoch 80.424) train_loss=161.52482605 time/batch=0.63s
9780/10943 (epoch 80.432) train_loss=159.62960815 time/batch=0.68s
9781/10943 (epoch 80.440) train_loss=105.49557495 time/batch=0.47s
9782/10943 (epoch 80.448) train_loss=229.20971680 time/batch=0.85s
9783/10943 (epoch 80.456) train_loss=132.33609009 time/batch=0.58s
9784/10943 (epoch 80.465) train_loss=113.45708466 time/batch=0.47s
9785/10943 (epoch 80.473) train_loss=162.10031128 time/batch=0.63s
9786/10943 (epoch 80.481) train_loss=124.57234955 time/batch=0.54s
9787/10943 (epoch 80.489) train_loss=77.83268738 time/batch=0.33s
9788/10943 (epoch 80.498) train_loss=210.41729736 time/batch=0.87s
9789/10943 (epoch 80.506) train_loss=172.00677490 time/batch=0.72s
9790/10943 (epoch 80.514) train_loss=94.17027283 time/batch=0.38s
9791/10943 (epoch 80.522) train_loss=192.13369751 time/batch=0.73s
9792/10943 (epoch 80.530) train_loss=175.07759094 time/batch=0.71s
9793/10943 (epoch 80.539) train_loss=192.20474243 time/batch=0.79s
9794/10943 (epoch 80.547) train_loss=208.45388794 time/batch=0.88s
9795/10943 (epoch 80.555) train_loss=137.29293823 time/batch=0.58s
9796/10943 (epoch 80.563) train_loss=150.25979614 time/batch=0.59s
9797/10943 (epoch 80.572) train_loss=125.43752289 time/batch=0.51s
9798/10943 (epoch 80.580) train_loss=97.75912476 time/batch=0.39s
9799/10943 (epoch 80.588) train_loss=133.81835938 time/batch=0.52s
9800/10943 (epoch 80.596) train_loss=141.33741760 time/batch=0.57s
9801/10943 (epoch 80.604) train_loss=88.69560242 time/batch=0.34s
9802/10943 (epoch 80.613) train_loss=82.64692688 time/batch=0.34s
9803/10943 (epoch 80.621) train_loss=147.15777588 time/batch=0.58s
9804/10943 (epoch 80.629) train_loss=82.78183746 time/batch=0.38s
9805/10943 (epoch 80.637) train_loss=127.85871124 time/batch=0.49s
9806/10943 (epoch 80.646) train_loss=226.20860291 time/batch=0.95s
9807/10943 (epoch 80.654) train_loss=110.25909424 time/batch=0.45s
9808/10943 (epoch 80.662) train_loss=139.39794922 time/batch=0.54s
9809/10943 (epoch 80.670) train_loss=149.67974854 time/batch=0.59s
9810/10943 (epoch 80.678) train_loss=208.10641479 time/batch=0.80s
9811/10943 (epoch 80.687) train_loss=101.27917480 time/batch=0.44s
9812/10943 (epoch 80.695) train_loss=182.12431335 time/batch=0.72s
9813/10943 (epoch 80.703) train_loss=180.46350098 time/batch=0.73s
9814/10943 (epoch 80.711) train_loss=155.29930115 time/batch=0.63s
9815/10943 (epoch 80.720) train_loss=218.72134399 time/batch=0.91s
9816/10943 (epoch 80.728) train_loss=144.50514221 time/batch=0.57s
9817/10943 (epoch 80.736) train_loss=202.76315308 time/batch=0.79s
9818/10943 (epoch 80.744) train_loss=146.60876465 time/batch=0.63s
9819/10943 (epoch 80.753) train_loss=147.25360107 time/batch=0.62s
9820/10943 (epoch 80.761) train_loss=100.98191833 time/batch=0.39s
9821/10943 (epoch 80.769) train_loss=184.89865112 time/batch=0.73s
9822/10943 (epoch 80.777) train_loss=214.89747620 time/batch=0.85s
9823/10943 (epoch 80.785) train_loss=208.77731323 time/batch=0.87s
9824/10943 (epoch 80.794) train_loss=191.23635864 time/batch=0.73s
9825/10943 (epoch 80.802) train_loss=103.30619812 time/batch=0.45s
9826/10943 (epoch 80.810) train_loss=173.63592529 time/batch=0.72s
9827/10943 (epoch 80.818) train_loss=190.54545593 time/batch=0.81s
9828/10943 (epoch 80.827) train_loss=199.92335510 time/batch=0.80s
9829/10943 (epoch 80.835) train_loss=212.98609924 time/batch=0.84s
9830/10943 (epoch 80.843) train_loss=172.11723328 time/batch=0.70s
9831/10943 (epoch 80.851) train_loss=138.30079651 time/batch=0.59s
9832/10943 (epoch 80.859) train_loss=162.49765015 time/batch=0.67s
9833/10943 (epoch 80.868) train_loss=140.86444092 time/batch=0.68s
9834/10943 (epoch 80.876) train_loss=149.21974182 time/batch=0.70s
9835/10943 (epoch 80.884) train_loss=185.96641541 time/batch=0.78s
9836/10943 (epoch 80.892) train_loss=210.98312378 time/batch=0.84s
9837/10943 (epoch 80.901) train_loss=179.37486267 time/batch=0.83s
setting learning rate to 0.0018428
9838/10943 (epoch 80.909) train_loss=108.32427979 time/batch=0.47s
9839/10943 (epoch 80.917) train_loss=185.41444397 time/batch=0.78s
9840/10943 (epoch 80.925) train_loss=215.88345337 time/batch=0.88s
9841/10943 (epoch 80.933) train_loss=83.02674866 time/batch=0.37s
9842/10943 (epoch 80.942) train_loss=300.94598389 time/batch=1.04s
9843/10943 (epoch 80.950) train_loss=189.29071045 time/batch=0.89s
9844/10943 (epoch 80.958) train_loss=318.07833862 time/batch=1.25s
9845/10943 (epoch 80.966) train_loss=632.47973633 time/batch=3.13s
9846/10943 (epoch 80.975) train_loss=136.16534424 time/batch=0.76s
9847/10943 (epoch 80.983) train_loss=184.30390930 time/batch=0.70s
9848/10943 (epoch 80.991) train_loss=107.63452148 time/batch=0.47s
9849/10943 (epoch 80.999) train_loss=296.24835205 time/batch=1.09s
9850/10943 (epoch 81.007) train_loss=126.35341644 time/batch=0.56s
9851/10943 (epoch 81.016) train_loss=407.80926514 time/batch=1.52s
9852/10943 (epoch 81.024) train_loss=134.78646851 time/batch=0.69s
9853/10943 (epoch 81.032) train_loss=182.76446533 time/batch=0.73s
9854/10943 (epoch 81.040) train_loss=171.06289673 time/batch=0.76s
9855/10943 (epoch 81.049) train_loss=342.12957764 time/batch=1.37s
9856/10943 (epoch 81.057) train_loss=173.14646912 time/batch=0.82s
9857/10943 (epoch 81.065) train_loss=342.87997437 time/batch=1.30s
9858/10943 (epoch 81.073) train_loss=133.96807861 time/batch=0.70s
9859/10943 (epoch 81.081) train_loss=159.93328857 time/batch=0.65s
9860/10943 (epoch 81.090) train_loss=277.83593750 time/batch=1.08s
9861/10943 (epoch 81.098) train_loss=260.99057007 time/batch=1.02s
9862/10943 (epoch 81.106) train_loss=161.05407715 time/batch=0.72s
9863/10943 (epoch 81.114) train_loss=83.81462097 time/batch=0.33s
9864/10943 (epoch 81.123) train_loss=157.50167847 time/batch=0.65s
9865/10943 (epoch 81.131) train_loss=254.15675354 time/batch=1.04s
9866/10943 (epoch 81.139) train_loss=174.88967896 time/batch=0.75s
9867/10943 (epoch 81.147) train_loss=87.82791901 time/batch=0.39s
9868/10943 (epoch 81.155) train_loss=124.69986725 time/batch=0.55s
9869/10943 (epoch 81.164) train_loss=85.02497101 time/batch=0.37s
9870/10943 (epoch 81.172) train_loss=152.66531372 time/batch=0.62s
9871/10943 (epoch 81.180) train_loss=143.96778870 time/batch=0.64s
9872/10943 (epoch 81.188) train_loss=194.54598999 time/batch=0.83s
9873/10943 (epoch 81.197) train_loss=222.73985291 time/batch=0.91s
9874/10943 (epoch 81.205) train_loss=82.08702087 time/batch=0.36s
9875/10943 (epoch 81.213) train_loss=197.44375610 time/batch=0.82s
9876/10943 (epoch 81.221) train_loss=391.64428711 time/batch=1.61s
9877/10943 (epoch 81.230) train_loss=98.63748169 time/batch=0.48s
9878/10943 (epoch 81.238) train_loss=122.83052063 time/batch=0.51s
9879/10943 (epoch 81.246) train_loss=275.78002930 time/batch=1.07s
9880/10943 (epoch 81.254) train_loss=217.49295044 time/batch=0.97s
9881/10943 (epoch 81.262) train_loss=72.85520935 time/batch=0.37s
9882/10943 (epoch 81.271) train_loss=205.51718140 time/batch=0.87s
9883/10943 (epoch 81.279) train_loss=122.13394928 time/batch=0.55s
9884/10943 (epoch 81.287) train_loss=104.21702576 time/batch=0.41s
9885/10943 (epoch 81.295) train_loss=109.01340485 time/batch=0.42s
9886/10943 (epoch 81.304) train_loss=239.31469727 time/batch=0.96s
9887/10943 (epoch 81.312) train_loss=174.40509033 time/batch=0.76s
9888/10943 (epoch 81.320) train_loss=213.52694702 time/batch=0.89s
9889/10943 (epoch 81.328) train_loss=207.41567993 time/batch=0.88s
9890/10943 (epoch 81.336) train_loss=133.11395264 time/batch=0.60s
9891/10943 (epoch 81.345) train_loss=177.12271118 time/batch=0.73s
9892/10943 (epoch 81.353) train_loss=73.92079163 time/batch=0.36s
9893/10943 (epoch 81.361) train_loss=238.26316833 time/batch=0.92s
9894/10943 (epoch 81.369) train_loss=126.50054932 time/batch=0.54s
9895/10943 (epoch 81.378) train_loss=84.34606934 time/batch=0.33s
9896/10943 (epoch 81.386) train_loss=247.15969849 time/batch=0.92s
9897/10943 (epoch 81.394) train_loss=323.55282593 time/batch=1.27s
9898/10943 (epoch 81.402) train_loss=135.23809814 time/batch=0.62s
9899/10943 (epoch 81.410) train_loss=270.80227661 time/batch=1.00s
9900/10943 (epoch 81.419) train_loss=186.31137085 time/batch=0.83s
9901/10943 (epoch 81.427) train_loss=206.27438354 time/batch=0.85s
9902/10943 (epoch 81.435) train_loss=161.95960999 time/batch=0.69s
9903/10943 (epoch 81.443) train_loss=293.95477295 time/batch=1.14s
9904/10943 (epoch 81.452) train_loss=189.36277771 time/batch=0.86s
9905/10943 (epoch 81.460) train_loss=138.08352661 time/batch=0.56s
9906/10943 (epoch 81.468) train_loss=187.04464722 time/batch=0.78s
9907/10943 (epoch 81.476) train_loss=275.45758057 time/batch=1.16s
9908/10943 (epoch 81.484) train_loss=146.80023193 time/batch=0.67s
9909/10943 (epoch 81.493) train_loss=178.11398315 time/batch=0.76s
9910/10943 (epoch 81.501) train_loss=92.99302673 time/batch=0.40s
9911/10943 (epoch 81.509) train_loss=194.70816040 time/batch=0.78s
9912/10943 (epoch 81.517) train_loss=392.04336548 time/batch=1.66s
9913/10943 (epoch 81.526) train_loss=191.11254883 time/batch=0.92s
9914/10943 (epoch 81.534) train_loss=160.27590942 time/batch=0.66s
9915/10943 (epoch 81.542) train_loss=120.41673279 time/batch=0.55s
9916/10943 (epoch 81.550) train_loss=199.29446411 time/batch=0.83s
9917/10943 (epoch 81.558) train_loss=228.56964111 time/batch=0.94s
9918/10943 (epoch 81.567) train_loss=129.19900513 time/batch=0.57s
9919/10943 (epoch 81.575) train_loss=91.66445923 time/batch=0.39s
9920/10943 (epoch 81.583) train_loss=104.32453918 time/batch=0.38s
9921/10943 (epoch 81.591) train_loss=166.93600464 time/batch=0.71s
9922/10943 (epoch 81.600) train_loss=252.50097656 time/batch=0.96s
9923/10943 (epoch 81.608) train_loss=142.24058533 time/batch=0.60s
9924/10943 (epoch 81.616) train_loss=152.66146851 time/batch=0.62s
9925/10943 (epoch 81.624) train_loss=148.38961792 time/batch=0.58s
9926/10943 (epoch 81.632) train_loss=145.32789612 time/batch=0.61s
9927/10943 (epoch 81.641) train_loss=77.08640289 time/batch=0.39s
9928/10943 (epoch 81.649) train_loss=138.50335693 time/batch=0.56s
9929/10943 (epoch 81.657) train_loss=122.60066223 time/batch=0.49s
9930/10943 (epoch 81.665) train_loss=148.85360718 time/batch=0.60s
9931/10943 (epoch 81.674) train_loss=95.72671509 time/batch=0.41s
9932/10943 (epoch 81.682) train_loss=161.54830933 time/batch=0.67s
9933/10943 (epoch 81.690) train_loss=180.15112305 time/batch=0.78s
9934/10943 (epoch 81.698) train_loss=144.99728394 time/batch=0.63s
9935/10943 (epoch 81.707) train_loss=137.17915344 time/batch=0.58s
9936/10943 (epoch 81.715) train_loss=115.26208496 time/batch=0.46s
9937/10943 (epoch 81.723) train_loss=140.19201660 time/batch=0.57s
9938/10943 (epoch 81.731) train_loss=97.16789246 time/batch=0.43s
9939/10943 (epoch 81.739) train_loss=105.93853760 time/batch=0.42s
9940/10943 (epoch 81.748) train_loss=115.52658081 time/batch=0.46s
9941/10943 (epoch 81.756) train_loss=252.64262390 time/batch=1.13s
9942/10943 (epoch 81.764) train_loss=136.03486633 time/batch=0.65s
9943/10943 (epoch 81.772) train_loss=204.69044495 time/batch=0.91s
9944/10943 (epoch 81.781) train_loss=185.82975769 time/batch=0.79s
9945/10943 (epoch 81.789) train_loss=166.68768311 time/batch=0.70s
9946/10943 (epoch 81.797) train_loss=173.29765320 time/batch=0.67s
9947/10943 (epoch 81.805) train_loss=206.96116638 time/batch=1.66s
9948/10943 (epoch 81.813) train_loss=151.57601929 time/batch=0.72s
9949/10943 (epoch 81.822) train_loss=140.25100708 time/batch=0.59s
9950/10943 (epoch 81.830) train_loss=194.28164673 time/batch=0.76s
9951/10943 (epoch 81.838) train_loss=181.60913086 time/batch=0.72s
9952/10943 (epoch 81.846) train_loss=120.77493286 time/batch=0.51s
9953/10943 (epoch 81.855) train_loss=167.39163208 time/batch=0.63s
9954/10943 (epoch 81.863) train_loss=171.02581787 time/batch=0.70s
9955/10943 (epoch 81.871) train_loss=118.94940186 time/batch=0.63s
9956/10943 (epoch 81.879) train_loss=164.47935486 time/batch=0.66s
9957/10943 (epoch 81.887) train_loss=187.07778931 time/batch=0.78s
9958/10943 (epoch 81.896) train_loss=169.24920654 time/batch=0.72s
setting learning rate to 0.0017875
  saved to metadata/gru_no_dropout-9_nov_folkwiki-20181207-192453_epoch37.pkl
9959/10943 (epoch 81.904) train_loss=180.19467163 time/batch=0.86s
9960/10943 (epoch 81.912) train_loss=349.11840820 time/batch=1.36s
9961/10943 (epoch 81.920) train_loss=204.03366089 time/batch=0.89s
9962/10943 (epoch 81.929) train_loss=298.10681152 time/batch=1.12s
9963/10943 (epoch 81.937) train_loss=375.09942627 time/batch=1.51s
9964/10943 (epoch 81.945) train_loss=267.09381104 time/batch=1.13s
9965/10943 (epoch 81.953) train_loss=151.41467285 time/batch=0.71s
9966/10943 (epoch 81.961) train_loss=319.33190918 time/batch=1.25s
9967/10943 (epoch 81.970) train_loss=259.33056641 time/batch=1.11s
9968/10943 (epoch 81.978) train_loss=278.79635620 time/batch=1.09s
9969/10943 (epoch 81.986) train_loss=109.18495941 time/batch=0.51s
9970/10943 (epoch 81.994) train_loss=299.25625610 time/batch=1.22s
9971/10943 (epoch 82.003) train_loss=97.42309570 time/batch=0.49s
9972/10943 (epoch 82.011) train_loss=333.19512939 time/batch=1.33s
9973/10943 (epoch 82.019) train_loss=488.86364746 time/batch=2.02s
9974/10943 (epoch 82.027) train_loss=290.86044312 time/batch=1.23s
9975/10943 (epoch 82.035) train_loss=130.73171997 time/batch=0.62s
9976/10943 (epoch 82.044) train_loss=197.97357178 time/batch=0.85s
9977/10943 (epoch 82.052) train_loss=169.97470093 time/batch=0.78s
9978/10943 (epoch 82.060) train_loss=84.50381470 time/batch=0.36s
9979/10943 (epoch 82.068) train_loss=104.64389801 time/batch=0.44s
9980/10943 (epoch 82.077) train_loss=100.58203125 time/batch=0.43s
9981/10943 (epoch 82.085) train_loss=253.63578796 time/batch=0.95s
9982/10943 (epoch 82.093) train_loss=160.41290283 time/batch=0.69s
9983/10943 (epoch 82.101) train_loss=270.07519531 time/batch=1.06s
9984/10943 (epoch 82.109) train_loss=334.30725098 time/batch=1.54s
9985/10943 (epoch 82.118) train_loss=246.58914185 time/batch=1.04s
9986/10943 (epoch 82.126) train_loss=428.87573242 time/batch=2.08s
9987/10943 (epoch 82.134) train_loss=68.41925049 time/batch=0.45s
9988/10943 (epoch 82.142) train_loss=77.37686920 time/batch=0.29s
9989/10943 (epoch 82.151) train_loss=173.30560303 time/batch=0.72s
9990/10943 (epoch 82.159) train_loss=134.22131348 time/batch=0.62s
9991/10943 (epoch 82.167) train_loss=198.27835083 time/batch=0.83s
9992/10943 (epoch 82.175) train_loss=127.58089447 time/batch=0.58s
9993/10943 (epoch 82.184) train_loss=206.12884521 time/batch=0.90s
9994/10943 (epoch 82.192) train_loss=78.62092590 time/batch=0.35s
9995/10943 (epoch 82.200) train_loss=290.46743774 time/batch=1.12s
9996/10943 (epoch 82.208) train_loss=142.39465332 time/batch=0.69s
9997/10943 (epoch 82.216) train_loss=105.89897919 time/batch=0.46s
9998/10943 (epoch 82.225) train_loss=199.46444702 time/batch=0.82s
9999/10943 (epoch 82.233) train_loss=86.73010254 time/batch=0.39s
Validating
    loss:	277.591527

10000/10943 (epoch 82.241) train_loss=118.84004211 time/batch=2.18s
10001/10943 (epoch 82.249) train_loss=208.96011353 time/batch=0.86s
10002/10943 (epoch 82.258) train_loss=155.26664734 time/batch=0.72s
10003/10943 (epoch 82.266) train_loss=223.80499268 time/batch=0.99s
10004/10943 (epoch 82.274) train_loss=333.54541016 time/batch=2.18s
10005/10943 (epoch 82.282) train_loss=157.00817871 time/batch=0.84s
10006/10943 (epoch 82.290) train_loss=166.92123413 time/batch=0.74s
10007/10943 (epoch 82.299) train_loss=144.61676025 time/batch=0.63s
10008/10943 (epoch 82.307) train_loss=178.55557251 time/batch=0.79s
10009/10943 (epoch 82.315) train_loss=88.31846619 time/batch=0.41s
10010/10943 (epoch 82.323) train_loss=116.17597961 time/batch=0.46s
10011/10943 (epoch 82.332) train_loss=173.41616821 time/batch=0.69s
10012/10943 (epoch 82.340) train_loss=131.98953247 time/batch=0.55s
10013/10943 (epoch 82.348) train_loss=154.80398560 time/batch=0.63s
10014/10943 (epoch 82.356) train_loss=76.23506165 time/batch=0.34s
10015/10943 (epoch 82.364) train_loss=240.88906860 time/batch=0.92s
10016/10943 (epoch 82.373) train_loss=97.72589874 time/batch=0.45s
10017/10943 (epoch 82.381) train_loss=161.86746216 time/batch=0.62s
10018/10943 (epoch 82.389) train_loss=164.68634033 time/batch=0.68s
10019/10943 (epoch 82.397) train_loss=132.81021118 time/batch=0.58s
10020/10943 (epoch 82.406) train_loss=93.88499451 time/batch=0.40s
10021/10943 (epoch 82.414) train_loss=156.34240723 time/batch=0.65s
10022/10943 (epoch 82.422) train_loss=206.13856506 time/batch=0.83s
10023/10943 (epoch 82.430) train_loss=230.09793091 time/batch=0.97s
10024/10943 (epoch 82.438) train_loss=250.36074829 time/batch=1.02s
10025/10943 (epoch 82.447) train_loss=145.88433838 time/batch=0.65s
10026/10943 (epoch 82.455) train_loss=155.90272522 time/batch=0.64s
10027/10943 (epoch 82.463) train_loss=88.43349457 time/batch=0.37s
10028/10943 (epoch 82.471) train_loss=108.45094299 time/batch=0.45s
10029/10943 (epoch 82.480) train_loss=182.61621094 time/batch=0.77s
10030/10943 (epoch 82.488) train_loss=177.12951660 time/batch=0.80s
10031/10943 (epoch 82.496) train_loss=181.74858093 time/batch=0.79s
10032/10943 (epoch 82.504) train_loss=149.94937134 time/batch=0.65s
10033/10943 (epoch 82.512) train_loss=215.57839966 time/batch=0.91s
10034/10943 (epoch 82.521) train_loss=120.27085114 time/batch=0.55s
10035/10943 (epoch 82.529) train_loss=379.34274292 time/batch=3.04s
10036/10943 (epoch 82.537) train_loss=160.14855957 time/batch=0.96s
10037/10943 (epoch 82.545) train_loss=198.29618835 time/batch=0.83s
10038/10943 (epoch 82.554) train_loss=177.57252502 time/batch=0.75s
10039/10943 (epoch 82.562) train_loss=86.74285889 time/batch=0.38s
10040/10943 (epoch 82.570) train_loss=125.64381409 time/batch=0.50s
10041/10943 (epoch 82.578) train_loss=187.78591919 time/batch=0.79s
10042/10943 (epoch 82.586) train_loss=95.69147491 time/batch=0.45s
10043/10943 (epoch 82.595) train_loss=203.31800842 time/batch=0.83s
10044/10943 (epoch 82.603) train_loss=176.59983826 time/batch=0.81s
10045/10943 (epoch 82.611) train_loss=141.73986816 time/batch=0.62s
10046/10943 (epoch 82.619) train_loss=126.84628296 time/batch=0.55s
10047/10943 (epoch 82.628) train_loss=96.92478180 time/batch=0.41s
10048/10943 (epoch 82.636) train_loss=136.14271545 time/batch=0.56s
10049/10943 (epoch 82.644) train_loss=106.55675507 time/batch=0.47s
10050/10943 (epoch 82.652) train_loss=182.01989746 time/batch=0.81s
10051/10943 (epoch 82.660) train_loss=197.85888672 time/batch=0.84s
10052/10943 (epoch 82.669) train_loss=222.96011353 time/batch=0.94s
10053/10943 (epoch 82.677) train_loss=132.84365845 time/batch=0.56s
10054/10943 (epoch 82.685) train_loss=196.66531372 time/batch=0.85s
10055/10943 (epoch 82.693) train_loss=144.76965332 time/batch=0.65s
10056/10943 (epoch 82.702) train_loss=96.14055634 time/batch=0.41s
10057/10943 (epoch 82.710) train_loss=147.14245605 time/batch=0.60s
10058/10943 (epoch 82.718) train_loss=122.21204376 time/batch=0.55s
10059/10943 (epoch 82.726) train_loss=159.58613586 time/batch=0.67s
10060/10943 (epoch 82.735) train_loss=118.52996063 time/batch=0.51s
10061/10943 (epoch 82.743) train_loss=112.96263123 time/batch=0.47s
10062/10943 (epoch 82.751) train_loss=179.93695068 time/batch=0.73s
10063/10943 (epoch 82.759) train_loss=116.03588104 time/batch=0.51s
10064/10943 (epoch 82.767) train_loss=100.95851898 time/batch=0.46s
10065/10943 (epoch 82.776) train_loss=140.67671204 time/batch=0.60s
10066/10943 (epoch 82.784) train_loss=140.15019226 time/batch=0.58s
10067/10943 (epoch 82.792) train_loss=135.37171936 time/batch=0.58s
10068/10943 (epoch 82.800) train_loss=137.76074219 time/batch=0.62s
10069/10943 (epoch 82.809) train_loss=182.13540649 time/batch=0.73s
10070/10943 (epoch 82.817) train_loss=184.34698486 time/batch=0.77s
10071/10943 (epoch 82.825) train_loss=155.05825806 time/batch=0.67s
10072/10943 (epoch 82.833) train_loss=170.59567261 time/batch=0.70s
10073/10943 (epoch 82.841) train_loss=180.16108704 time/batch=0.71s
10074/10943 (epoch 82.850) train_loss=197.85733032 time/batch=0.92s
10075/10943 (epoch 82.858) train_loss=184.97540283 time/batch=0.81s
10076/10943 (epoch 82.866) train_loss=139.42236328 time/batch=0.59s
10077/10943 (epoch 82.874) train_loss=129.44146729 time/batch=0.58s
10078/10943 (epoch 82.883) train_loss=177.87368774 time/batch=0.72s
10079/10943 (epoch 82.891) train_loss=125.75724030 time/batch=0.69s
setting learning rate to 0.0017339
10080/10943 (epoch 82.899) train_loss=336.43780518 time/batch=1.42s
10081/10943 (epoch 82.907) train_loss=103.67607117 time/batch=0.52s
10082/10943 (epoch 82.915) train_loss=69.61326599 time/batch=0.31s
10083/10943 (epoch 82.924) train_loss=244.59387207 time/batch=1.01s
10084/10943 (epoch 82.932) train_loss=367.07382202 time/batch=1.51s
10085/10943 (epoch 82.940) train_loss=175.36541748 time/batch=0.85s
10086/10943 (epoch 82.948) train_loss=126.72985077 time/batch=0.58s
10087/10943 (epoch 82.957) train_loss=118.51617432 time/batch=0.51s
10088/10943 (epoch 82.965) train_loss=154.67803955 time/batch=0.68s
10089/10943 (epoch 82.973) train_loss=174.63815308 time/batch=0.85s
10090/10943 (epoch 82.981) train_loss=295.27413940 time/batch=1.20s
10091/10943 (epoch 82.989) train_loss=368.55035400 time/batch=1.55s
10092/10943 (epoch 82.998) train_loss=624.39758301 time/batch=3.15s
10093/10943 (epoch 83.006) train_loss=243.51617432 time/batch=1.19s
10094/10943 (epoch 83.014) train_loss=182.30319214 time/batch=0.82s
10095/10943 (epoch 83.022) train_loss=201.49815369 time/batch=0.88s
10096/10943 (epoch 83.031) train_loss=287.03723145 time/batch=1.15s
10097/10943 (epoch 83.039) train_loss=297.02700806 time/batch=1.25s
10098/10943 (epoch 83.047) train_loss=149.43130493 time/batch=0.73s
10099/10943 (epoch 83.055) train_loss=431.54394531 time/batch=1.66s
10100/10943 (epoch 83.063) train_loss=251.34611511 time/batch=1.12s
10101/10943 (epoch 83.072) train_loss=93.27879333 time/batch=0.45s
10102/10943 (epoch 83.080) train_loss=259.61727905 time/batch=0.99s
10103/10943 (epoch 83.088) train_loss=105.28073883 time/batch=0.48s
10104/10943 (epoch 83.096) train_loss=233.75122070 time/batch=0.92s
10105/10943 (epoch 83.105) train_loss=265.69238281 time/batch=1.09s
10106/10943 (epoch 83.113) train_loss=143.79612732 time/batch=0.69s
10107/10943 (epoch 83.121) train_loss=202.12994385 time/batch=0.87s
10108/10943 (epoch 83.129) train_loss=159.81158447 time/batch=0.74s
10109/10943 (epoch 83.137) train_loss=85.47549438 time/batch=0.45s
10110/10943 (epoch 83.146) train_loss=63.51605225 time/batch=0.26s
10111/10943 (epoch 83.154) train_loss=107.17755127 time/batch=0.45s
10112/10943 (epoch 83.162) train_loss=103.90881348 time/batch=0.44s
10113/10943 (epoch 83.170) train_loss=273.08349609 time/batch=1.07s
10114/10943 (epoch 83.179) train_loss=334.80130005 time/batch=1.30s
10115/10943 (epoch 83.187) train_loss=300.86529541 time/batch=1.29s
10116/10943 (epoch 83.195) train_loss=115.22872925 time/batch=0.55s
10117/10943 (epoch 83.203) train_loss=285.04345703 time/batch=1.05s
10118/10943 (epoch 83.212) train_loss=211.22679138 time/batch=0.95s
10119/10943 (epoch 83.220) train_loss=146.26971436 time/batch=0.68s
10120/10943 (epoch 83.228) train_loss=80.16902161 time/batch=0.32s
10121/10943 (epoch 83.236) train_loss=189.31857300 time/batch=0.78s
10122/10943 (epoch 83.244) train_loss=223.86895752 time/batch=0.95s
10123/10943 (epoch 83.253) train_loss=73.86566162 time/batch=0.36s
10124/10943 (epoch 83.261) train_loss=227.05883789 time/batch=0.91s
10125/10943 (epoch 83.269) train_loss=158.11627197 time/batch=0.71s
10126/10943 (epoch 83.277) train_loss=130.93218994 time/batch=0.59s
10127/10943 (epoch 83.286) train_loss=165.93251038 time/batch=0.70s
10128/10943 (epoch 83.294) train_loss=101.09510803 time/batch=0.46s
10129/10943 (epoch 83.302) train_loss=77.73939514 time/batch=0.33s
10130/10943 (epoch 83.310) train_loss=296.20056152 time/batch=1.49s
10131/10943 (epoch 83.318) train_loss=179.96992493 time/batch=0.84s
10132/10943 (epoch 83.327) train_loss=171.59262085 time/batch=0.72s
10133/10943 (epoch 83.335) train_loss=155.66003418 time/batch=0.67s
10134/10943 (epoch 83.343) train_loss=91.05594635 time/batch=0.36s
10135/10943 (epoch 83.351) train_loss=80.81173706 time/batch=0.31s
10136/10943 (epoch 83.360) train_loss=155.60124207 time/batch=0.65s
10137/10943 (epoch 83.368) train_loss=200.18130493 time/batch=0.87s
10138/10943 (epoch 83.376) train_loss=202.48286438 time/batch=0.86s
10139/10943 (epoch 83.384) train_loss=227.98515320 time/batch=0.97s
10140/10943 (epoch 83.392) train_loss=141.02120972 time/batch=0.65s
10141/10943 (epoch 83.401) train_loss=225.26693726 time/batch=0.95s
10142/10943 (epoch 83.409) train_loss=167.56648254 time/batch=0.81s
10143/10943 (epoch 83.417) train_loss=188.41973877 time/batch=0.88s
10144/10943 (epoch 83.425) train_loss=136.38546753 time/batch=0.63s
10145/10943 (epoch 83.434) train_loss=177.16793823 time/batch=0.77s
10146/10943 (epoch 83.442) train_loss=205.56808472 time/batch=0.90s
10147/10943 (epoch 83.450) train_loss=154.13787842 time/batch=0.72s
10148/10943 (epoch 83.458) train_loss=115.63636780 time/batch=0.51s
10149/10943 (epoch 83.466) train_loss=182.57168579 time/batch=0.75s
10150/10943 (epoch 83.475) train_loss=129.87205505 time/batch=0.57s
10151/10943 (epoch 83.483) train_loss=110.53575134 time/batch=0.49s
10152/10943 (epoch 83.491) train_loss=134.97222900 time/batch=0.59s
10153/10943 (epoch 83.499) train_loss=174.50187683 time/batch=0.74s
10154/10943 (epoch 83.508) train_loss=110.50877380 time/batch=0.49s
10155/10943 (epoch 83.516) train_loss=135.28146362 time/batch=0.54s
10156/10943 (epoch 83.524) train_loss=167.24853516 time/batch=0.78s
10157/10943 (epoch 83.532) train_loss=123.23989105 time/batch=0.59s
10158/10943 (epoch 83.540) train_loss=105.41885376 time/batch=0.47s
10159/10943 (epoch 83.549) train_loss=138.26884460 time/batch=0.59s
10160/10943 (epoch 83.557) train_loss=158.98422241 time/batch=0.67s
10161/10943 (epoch 83.565) train_loss=174.57522583 time/batch=0.81s
10162/10943 (epoch 83.573) train_loss=136.36323547 time/batch=0.60s
10163/10943 (epoch 83.582) train_loss=132.69537354 time/batch=0.59s
10164/10943 (epoch 83.590) train_loss=139.71556091 time/batch=0.61s
10165/10943 (epoch 83.598) train_loss=121.05194855 time/batch=0.53s
10166/10943 (epoch 83.606) train_loss=248.01286316 time/batch=0.95s
10167/10943 (epoch 83.614) train_loss=126.74192810 time/batch=0.59s
10168/10943 (epoch 83.623) train_loss=103.65405273 time/batch=0.44s
10169/10943 (epoch 83.631) train_loss=118.13449097 time/batch=0.50s
10170/10943 (epoch 83.639) train_loss=210.29362488 time/batch=0.96s
10171/10943 (epoch 83.647) train_loss=163.56115723 time/batch=0.73s
10172/10943 (epoch 83.656) train_loss=136.79895020 time/batch=0.56s
10173/10943 (epoch 83.664) train_loss=150.11079407 time/batch=0.63s
10174/10943 (epoch 83.672) train_loss=135.90969849 time/batch=0.60s
10175/10943 (epoch 83.680) train_loss=132.73162842 time/batch=0.61s
10176/10943 (epoch 83.689) train_loss=92.20410919 time/batch=0.37s
10177/10943 (epoch 83.697) train_loss=189.09085083 time/batch=0.76s
10178/10943 (epoch 83.705) train_loss=148.33726501 time/batch=0.65s
10179/10943 (epoch 83.713) train_loss=97.43959045 time/batch=0.39s
10180/10943 (epoch 83.721) train_loss=174.03753662 time/batch=0.72s
10181/10943 (epoch 83.730) train_loss=90.24931335 time/batch=0.42s
10182/10943 (epoch 83.738) train_loss=171.07238770 time/batch=0.72s
10183/10943 (epoch 83.746) train_loss=87.68090057 time/batch=0.38s
10184/10943 (epoch 83.754) train_loss=182.22167969 time/batch=0.68s
10185/10943 (epoch 83.763) train_loss=92.68663025 time/batch=0.46s
10186/10943 (epoch 83.771) train_loss=126.89340210 time/batch=0.56s
10187/10943 (epoch 83.779) train_loss=174.49395752 time/batch=0.74s
10188/10943 (epoch 83.787) train_loss=206.58572388 time/batch=0.83s
10189/10943 (epoch 83.795) train_loss=129.18028259 time/batch=0.54s
10190/10943 (epoch 83.804) train_loss=201.17466736 time/batch=0.80s
10191/10943 (epoch 83.812) train_loss=176.94680786 time/batch=0.80s
10192/10943 (epoch 83.820) train_loss=194.75466919 time/batch=0.82s
10193/10943 (epoch 83.828) train_loss=178.55783081 time/batch=0.78s
10194/10943 (epoch 83.837) train_loss=177.89187622 time/batch=0.83s
10195/10943 (epoch 83.845) train_loss=101.75355530 time/batch=0.48s
10196/10943 (epoch 83.853) train_loss=121.43219757 time/batch=0.49s
10197/10943 (epoch 83.861) train_loss=134.52590942 time/batch=0.57s
10198/10943 (epoch 83.869) train_loss=155.94949341 time/batch=0.69s
10199/10943 (epoch 83.878) train_loss=136.01150513 time/batch=0.64s
10200/10943 (epoch 83.886) train_loss=165.26884460 time/batch=0.65s
setting learning rate to 0.0016818
  saved to metadata/gru_no_dropout-9_nov_folkwiki-20181207-192453_epoch39.pkl
10201/10943 (epoch 83.894) train_loss=417.54962158 time/batch=1.65s
10202/10943 (epoch 83.902) train_loss=112.49681091 time/batch=0.61s
10203/10943 (epoch 83.911) train_loss=155.18124390 time/batch=0.76s
10204/10943 (epoch 83.919) train_loss=290.86187744 time/batch=1.19s
10205/10943 (epoch 83.927) train_loss=89.16887665 time/batch=0.47s
10206/10943 (epoch 83.935) train_loss=334.64944458 time/batch=1.26s
10207/10943 (epoch 83.943) train_loss=291.88684082 time/batch=1.17s
10208/10943 (epoch 83.952) train_loss=163.34715271 time/batch=0.77s
10209/10943 (epoch 83.960) train_loss=209.35368347 time/batch=0.92s
10210/10943 (epoch 83.968) train_loss=198.48278809 time/batch=0.89s
10211/10943 (epoch 83.976) train_loss=284.28286743 time/batch=1.09s
10212/10943 (epoch 83.985) train_loss=112.50524902 time/batch=0.56s
10213/10943 (epoch 83.993) train_loss=182.58944702 time/batch=0.80s
10214/10943 (epoch 84.001) train_loss=168.51263428 time/batch=0.72s
10215/10943 (epoch 84.009) train_loss=269.97528076 time/batch=1.09s
10216/10943 (epoch 84.017) train_loss=89.53602600 time/batch=0.41s
10217/10943 (epoch 84.026) train_loss=383.36312866 time/batch=1.58s
10218/10943 (epoch 84.034) train_loss=134.30975342 time/batch=0.74s
10219/10943 (epoch 84.042) train_loss=192.68246460 time/batch=0.84s
10220/10943 (epoch 84.050) train_loss=82.92119598 time/batch=0.39s
10221/10943 (epoch 84.059) train_loss=146.06719971 time/batch=0.63s
10222/10943 (epoch 84.067) train_loss=147.94157410 time/batch=0.65s
10223/10943 (epoch 84.075) train_loss=145.59582520 time/batch=0.65s
10224/10943 (epoch 84.083) train_loss=87.73133850 time/batch=0.39s
10225/10943 (epoch 84.091) train_loss=240.21542358 time/batch=1.01s
10226/10943 (epoch 84.100) train_loss=340.07928467 time/batch=1.38s
10227/10943 (epoch 84.108) train_loss=251.61587524 time/batch=1.02s
10228/10943 (epoch 84.116) train_loss=301.02261353 time/batch=1.16s
10229/10943 (epoch 84.124) train_loss=180.96240234 time/batch=0.83s
10230/10943 (epoch 84.133) train_loss=588.24871826 time/batch=3.08s
10231/10943 (epoch 84.141) train_loss=102.73881531 time/batch=0.68s
10232/10943 (epoch 84.149) train_loss=107.39900970 time/batch=0.42s
10233/10943 (epoch 84.157) train_loss=200.43658447 time/batch=0.85s
10234/10943 (epoch 84.166) train_loss=233.92793274 time/batch=1.01s
10235/10943 (epoch 84.174) train_loss=167.35226440 time/batch=0.79s
10236/10943 (epoch 84.182) train_loss=258.53167725 time/batch=1.14s
10237/10943 (epoch 84.190) train_loss=155.15391541 time/batch=0.72s
10238/10943 (epoch 84.198) train_loss=309.18392944 time/batch=1.35s
10239/10943 (epoch 84.207) train_loss=72.50751495 time/batch=0.39s
10240/10943 (epoch 84.215) train_loss=101.42840576 time/batch=0.44s
10241/10943 (epoch 84.223) train_loss=133.55096436 time/batch=0.58s
10242/10943 (epoch 84.231) train_loss=248.27243042 time/batch=0.99s
10243/10943 (epoch 84.240) train_loss=163.55331421 time/batch=0.82s
10244/10943 (epoch 84.248) train_loss=155.24833679 time/batch=0.80s
10245/10943 (epoch 84.256) train_loss=221.80621338 time/batch=0.96s
10246/10943 (epoch 84.264) train_loss=81.93484497 time/batch=0.37s
10247/10943 (epoch 84.272) train_loss=103.88326263 time/batch=0.44s
10248/10943 (epoch 84.281) train_loss=206.15686035 time/batch=0.84s
10249/10943 (epoch 84.289) train_loss=177.26654053 time/batch=0.84s
10250/10943 (epoch 84.297) train_loss=153.56773376 time/batch=0.68s
10251/10943 (epoch 84.305) train_loss=147.19140625 time/batch=0.66s
10252/10943 (epoch 84.314) train_loss=109.23275757 time/batch=0.49s
10253/10943 (epoch 84.322) train_loss=121.95597839 time/batch=0.55s
10254/10943 (epoch 84.330) train_loss=140.09759521 time/batch=0.61s
10255/10943 (epoch 84.338) train_loss=112.28387451 time/batch=0.53s
10256/10943 (epoch 84.346) train_loss=205.10220337 time/batch=0.87s
10257/10943 (epoch 84.355) train_loss=82.93504333 time/batch=0.44s
10258/10943 (epoch 84.363) train_loss=155.47692871 time/batch=0.63s
10259/10943 (epoch 84.371) train_loss=80.19683838 time/batch=0.37s
10260/10943 (epoch 84.379) train_loss=94.72893524 time/batch=0.39s
10261/10943 (epoch 84.388) train_loss=165.73455811 time/batch=0.78s
10262/10943 (epoch 84.396) train_loss=164.57032776 time/batch=0.75s
10263/10943 (epoch 84.404) train_loss=169.04597473 time/batch=0.73s
10264/10943 (epoch 84.412) train_loss=149.45202637 time/batch=0.66s
10265/10943 (epoch 84.420) train_loss=102.11331940 time/batch=0.45s
10266/10943 (epoch 84.429) train_loss=171.77917480 time/batch=0.71s
10267/10943 (epoch 84.437) train_loss=191.69909668 time/batch=0.86s
10268/10943 (epoch 84.445) train_loss=126.23935699 time/batch=0.59s
10269/10943 (epoch 84.453) train_loss=312.59420776 time/batch=1.60s
10270/10943 (epoch 84.462) train_loss=139.16252136 time/batch=0.70s
10271/10943 (epoch 84.470) train_loss=168.23115540 time/batch=0.71s
10272/10943 (epoch 84.478) train_loss=126.29682159 time/batch=0.59s
10273/10943 (epoch 84.486) train_loss=222.47314453 time/batch=0.95s
10274/10943 (epoch 84.494) train_loss=173.51002502 time/batch=0.76s
10275/10943 (epoch 84.503) train_loss=141.88523865 time/batch=0.63s
10276/10943 (epoch 84.511) train_loss=194.27830505 time/batch=0.89s
10277/10943 (epoch 84.519) train_loss=236.10917664 time/batch=0.99s
10278/10943 (epoch 84.527) train_loss=70.21324921 time/batch=0.35s
10279/10943 (epoch 84.536) train_loss=174.20149231 time/batch=0.75s
10280/10943 (epoch 84.544) train_loss=313.82650757 time/batch=1.67s
10281/10943 (epoch 84.552) train_loss=252.73591614 time/batch=1.08s
10282/10943 (epoch 84.560) train_loss=169.52084351 time/batch=0.74s
10283/10943 (epoch 84.568) train_loss=99.95794678 time/batch=0.44s
10284/10943 (epoch 84.577) train_loss=132.74264526 time/batch=0.59s
10285/10943 (epoch 84.585) train_loss=92.12574005 time/batch=0.43s
10286/10943 (epoch 84.593) train_loss=187.27297974 time/batch=0.87s
10287/10943 (epoch 84.601) train_loss=75.92068481 time/batch=0.37s
10288/10943 (epoch 84.610) train_loss=80.39105225 time/batch=0.35s
10289/10943 (epoch 84.618) train_loss=164.68955994 time/batch=0.71s
10290/10943 (epoch 84.626) train_loss=129.48207092 time/batch=0.61s
10291/10943 (epoch 84.634) train_loss=111.88285828 time/batch=0.48s
10292/10943 (epoch 84.643) train_loss=122.35720825 time/batch=0.51s
10293/10943 (epoch 84.651) train_loss=154.53190613 time/batch=0.65s
10294/10943 (epoch 84.659) train_loss=127.07446289 time/batch=0.58s
10295/10943 (epoch 84.667) train_loss=126.66981506 time/batch=0.53s
10296/10943 (epoch 84.675) train_loss=108.59604645 time/batch=0.46s
10297/10943 (epoch 84.684) train_loss=127.97608185 time/batch=0.53s
10298/10943 (epoch 84.692) train_loss=175.66387939 time/batch=0.75s
10299/10943 (epoch 84.700) train_loss=197.01664734 time/batch=0.83s
10300/10943 (epoch 84.708) train_loss=163.88705444 time/batch=0.70s
10301/10943 (epoch 84.717) train_loss=175.83000183 time/batch=0.80s
10302/10943 (epoch 84.725) train_loss=141.71606445 time/batch=0.68s
10303/10943 (epoch 84.733) train_loss=119.79981995 time/batch=0.55s
10304/10943 (epoch 84.741) train_loss=174.82180786 time/batch=0.74s
10305/10943 (epoch 84.749) train_loss=115.64125061 time/batch=0.52s
10306/10943 (epoch 84.758) train_loss=179.53222656 time/batch=0.78s
10307/10943 (epoch 84.766) train_loss=118.82868958 time/batch=0.54s
10308/10943 (epoch 84.774) train_loss=155.30792236 time/batch=0.66s
10309/10943 (epoch 84.782) train_loss=150.86758423 time/batch=0.69s
10310/10943 (epoch 84.791) train_loss=128.26129150 time/batch=0.57s
10311/10943 (epoch 84.799) train_loss=187.20500183 time/batch=0.81s
10312/10943 (epoch 84.807) train_loss=141.91955566 time/batch=0.61s
10313/10943 (epoch 84.815) train_loss=253.26091003 time/batch=0.99s
10314/10943 (epoch 84.823) train_loss=129.95654297 time/batch=0.62s
10315/10943 (epoch 84.832) train_loss=132.39637756 time/batch=0.62s
10316/10943 (epoch 84.840) train_loss=77.16513062 time/batch=0.32s
10317/10943 (epoch 84.848) train_loss=187.05561829 time/batch=0.87s
10318/10943 (epoch 84.856) train_loss=176.72103882 time/batch=0.86s
10319/10943 (epoch 84.865) train_loss=104.70314026 time/batch=0.61s
10320/10943 (epoch 84.873) train_loss=143.48370361 time/batch=0.69s
10321/10943 (epoch 84.881) train_loss=134.33410645 time/batch=0.61s
setting learning rate to 0.0016314
10322/10943 (epoch 84.889) train_loss=128.45674133 time/batch=0.59s
10323/10943 (epoch 84.897) train_loss=89.56116486 time/batch=0.40s
10324/10943 (epoch 84.906) train_loss=246.69155884 time/batch=0.97s
10325/10943 (epoch 84.914) train_loss=289.77624512 time/batch=1.16s
10326/10943 (epoch 84.922) train_loss=176.35464478 time/batch=0.82s
10327/10943 (epoch 84.930) train_loss=61.44776917 time/batch=0.30s
10328/10943 (epoch 84.939) train_loss=284.82574463 time/batch=1.04s
10329/10943 (epoch 84.947) train_loss=331.38317871 time/batch=1.46s
10330/10943 (epoch 84.955) train_loss=76.24595642 time/batch=0.42s
10331/10943 (epoch 84.963) train_loss=221.13943481 time/batch=0.93s
10332/10943 (epoch 84.971) train_loss=455.54864502 time/batch=1.77s
10333/10943 (epoch 84.980) train_loss=404.02081299 time/batch=1.67s
10334/10943 (epoch 84.988) train_loss=351.07275391 time/batch=1.36s
10335/10943 (epoch 84.996) train_loss=301.90283203 time/batch=1.25s
10336/10943 (epoch 85.004) train_loss=277.23461914 time/batch=1.16s
10337/10943 (epoch 85.013) train_loss=270.86709595 time/batch=1.16s
10338/10943 (epoch 85.021) train_loss=232.78134155 time/batch=0.99s
10339/10943 (epoch 85.029) train_loss=198.23040771 time/batch=0.94s
10340/10943 (epoch 85.037) train_loss=545.39215088 time/batch=3.08s
10341/10943 (epoch 85.045) train_loss=268.90759277 time/batch=1.37s
10342/10943 (epoch 85.054) train_loss=91.04959106 time/batch=0.46s
10343/10943 (epoch 85.062) train_loss=152.69097900 time/batch=0.65s
10344/10943 (epoch 85.070) train_loss=96.09975433 time/batch=0.46s
10345/10943 (epoch 85.078) train_loss=107.31959534 time/batch=0.45s
10346/10943 (epoch 85.087) train_loss=171.00892639 time/batch=0.83s
10347/10943 (epoch 85.095) train_loss=79.38782501 time/batch=0.38s
10348/10943 (epoch 85.103) train_loss=103.88468933 time/batch=0.42s
10349/10943 (epoch 85.111) train_loss=140.47335815 time/batch=0.67s
10350/10943 (epoch 85.120) train_loss=151.62042236 time/batch=0.67s
10351/10943 (epoch 85.128) train_loss=156.53475952 time/batch=0.78s
10352/10943 (epoch 85.136) train_loss=196.07809448 time/batch=0.91s
10353/10943 (epoch 85.144) train_loss=126.19985962 time/batch=0.63s
10354/10943 (epoch 85.152) train_loss=156.92434692 time/batch=0.74s
10355/10943 (epoch 85.161) train_loss=89.65660095 time/batch=0.45s
10356/10943 (epoch 85.169) train_loss=241.08860779 time/batch=1.15s
10357/10943 (epoch 85.177) train_loss=130.31582642 time/batch=0.67s
10358/10943 (epoch 85.185) train_loss=71.73515320 time/batch=0.30s
10359/10943 (epoch 85.194) train_loss=170.85728455 time/batch=0.76s
10360/10943 (epoch 85.202) train_loss=115.64282990 time/batch=0.57s
10361/10943 (epoch 85.210) train_loss=224.94079590 time/batch=0.95s
10362/10943 (epoch 85.218) train_loss=102.03269958 time/batch=0.49s
10363/10943 (epoch 85.226) train_loss=146.42372131 time/batch=0.66s
10364/10943 (epoch 85.235) train_loss=318.28253174 time/batch=1.32s
10365/10943 (epoch 85.243) train_loss=158.15377808 time/batch=0.76s
10366/10943 (epoch 85.251) train_loss=222.56530762 time/batch=0.93s
10367/10943 (epoch 85.259) train_loss=179.13043213 time/batch=0.84s
10368/10943 (epoch 85.268) train_loss=248.58407593 time/batch=1.03s
10369/10943 (epoch 85.276) train_loss=217.88919067 time/batch=0.97s
10370/10943 (epoch 85.284) train_loss=75.82995605 time/batch=0.37s
10371/10943 (epoch 85.292) train_loss=93.48182678 time/batch=0.39s
10372/10943 (epoch 85.300) train_loss=299.83441162 time/batch=1.30s
10373/10943 (epoch 85.309) train_loss=193.29818726 time/batch=0.90s
10374/10943 (epoch 85.317) train_loss=176.83029175 time/batch=0.76s
10375/10943 (epoch 85.325) train_loss=207.11627197 time/batch=0.88s
10376/10943 (epoch 85.333) train_loss=156.43283081 time/batch=0.69s
10377/10943 (epoch 85.342) train_loss=100.64270020 time/batch=0.47s
10378/10943 (epoch 85.350) train_loss=124.08814240 time/batch=0.51s
10379/10943 (epoch 85.358) train_loss=101.99810028 time/batch=0.47s
10380/10943 (epoch 85.366) train_loss=82.30476379 time/batch=0.35s
10381/10943 (epoch 85.374) train_loss=159.75840759 time/batch=0.69s
10382/10943 (epoch 85.383) train_loss=167.94361877 time/batch=0.74s
10383/10943 (epoch 85.391) train_loss=118.54461670 time/batch=0.54s
10384/10943 (epoch 85.399) train_loss=197.63388062 time/batch=0.86s
10385/10943 (epoch 85.407) train_loss=199.57046509 time/batch=0.88s
10386/10943 (epoch 85.416) train_loss=121.77776337 time/batch=0.58s
10387/10943 (epoch 85.424) train_loss=154.77856445 time/batch=0.69s
10388/10943 (epoch 85.432) train_loss=121.52401733 time/batch=0.58s
10389/10943 (epoch 85.440) train_loss=148.33316040 time/batch=0.63s
10390/10943 (epoch 85.448) train_loss=168.76246643 time/batch=0.71s
10391/10943 (epoch 85.457) train_loss=123.07299805 time/batch=0.58s
10392/10943 (epoch 85.465) train_loss=153.43569946 time/batch=0.65s
10393/10943 (epoch 85.473) train_loss=144.40788269 time/batch=0.65s
10394/10943 (epoch 85.481) train_loss=111.47050476 time/batch=0.49s
10395/10943 (epoch 85.490) train_loss=168.52354431 time/batch=0.69s
10396/10943 (epoch 85.498) train_loss=168.81170654 time/batch=0.76s
10397/10943 (epoch 85.506) train_loss=179.78929138 time/batch=0.83s
10398/10943 (epoch 85.514) train_loss=126.99480438 time/batch=0.60s
10399/10943 (epoch 85.522) train_loss=101.69766998 time/batch=0.47s
10400/10943 (epoch 85.531) train_loss=111.79788208 time/batch=0.49s
10401/10943 (epoch 85.539) train_loss=165.78211975 time/batch=0.72s
10402/10943 (epoch 85.547) train_loss=75.68576050 time/batch=0.35s
10403/10943 (epoch 85.555) train_loss=172.10264587 time/batch=0.69s
10404/10943 (epoch 85.564) train_loss=235.99627686 time/batch=1.00s
10405/10943 (epoch 85.572) train_loss=86.17170715 time/batch=0.39s
10406/10943 (epoch 85.580) train_loss=104.46090698 time/batch=0.45s
10407/10943 (epoch 85.588) train_loss=246.83767700 time/batch=0.97s
10408/10943 (epoch 85.597) train_loss=161.45071411 time/batch=0.74s
10409/10943 (epoch 85.605) train_loss=129.06289673 time/batch=0.60s
10410/10943 (epoch 85.613) train_loss=167.31454468 time/batch=0.76s
10411/10943 (epoch 85.621) train_loss=110.46826172 time/batch=0.51s
10412/10943 (epoch 85.629) train_loss=232.00379944 time/batch=1.16s
10413/10943 (epoch 85.638) train_loss=127.25811005 time/batch=0.68s
10414/10943 (epoch 85.646) train_loss=157.21324158 time/batch=0.73s
10415/10943 (epoch 85.654) train_loss=195.83210754 time/batch=0.85s
10416/10943 (epoch 85.662) train_loss=87.88536072 time/batch=0.39s
10417/10943 (epoch 85.671) train_loss=136.19508362 time/batch=0.59s
10418/10943 (epoch 85.679) train_loss=208.18472290 time/batch=1.19s
10419/10943 (epoch 85.687) train_loss=109.08840942 time/batch=0.57s
10420/10943 (epoch 85.695) train_loss=130.63992310 time/batch=0.58s
10421/10943 (epoch 85.703) train_loss=138.36767578 time/batch=0.62s
10422/10943 (epoch 85.712) train_loss=120.97422028 time/batch=0.51s
10423/10943 (epoch 85.720) train_loss=102.67919159 time/batch=0.49s
10424/10943 (epoch 85.728) train_loss=161.93743896 time/batch=0.76s
10425/10943 (epoch 85.736) train_loss=138.79537964 time/batch=0.64s
10426/10943 (epoch 85.745) train_loss=181.65892029 time/batch=0.77s
10427/10943 (epoch 85.753) train_loss=175.36808777 time/batch=0.82s
10428/10943 (epoch 85.761) train_loss=154.50082397 time/batch=0.78s
10429/10943 (epoch 85.769) train_loss=194.66256714 time/batch=0.84s
10430/10943 (epoch 85.777) train_loss=115.92877197 time/batch=0.56s
10431/10943 (epoch 85.786) train_loss=180.90350342 time/batch=0.82s
10432/10943 (epoch 85.794) train_loss=121.49049377 time/batch=0.55s
10433/10943 (epoch 85.802) train_loss=181.90164185 time/batch=0.79s
10434/10943 (epoch 85.810) train_loss=86.78902435 time/batch=0.40s
10435/10943 (epoch 85.819) train_loss=133.83082581 time/batch=0.59s
10436/10943 (epoch 85.827) train_loss=129.29745483 time/batch=0.57s
10437/10943 (epoch 85.835) train_loss=172.32891846 time/batch=0.79s
10438/10943 (epoch 85.843) train_loss=144.23034668 time/batch=0.66s
10439/10943 (epoch 85.851) train_loss=128.66192627 time/batch=0.58s
10440/10943 (epoch 85.860) train_loss=123.99205017 time/batch=0.62s
10441/10943 (epoch 85.868) train_loss=156.26490784 time/batch=0.80s
10442/10943 (epoch 85.876) train_loss=146.56358337 time/batch=0.65s
setting learning rate to 0.0015824
  saved to metadata/gru_no_dropout-9_nov_folkwiki-20181207-192453_epoch41.pkl
10443/10943 (epoch 85.884) train_loss=323.17623901 time/batch=1.32s
10444/10943 (epoch 85.893) train_loss=591.41101074 time/batch=3.14s
10445/10943 (epoch 85.901) train_loss=283.34826660 time/batch=1.30s
10446/10943 (epoch 85.909) train_loss=78.76701355 time/batch=0.39s
10447/10943 (epoch 85.917) train_loss=123.06835938 time/batch=0.51s
10448/10943 (epoch 85.925) train_loss=167.74111938 time/batch=0.82s
10449/10943 (epoch 85.934) train_loss=218.30880737 time/batch=1.00s
10450/10943 (epoch 85.942) train_loss=285.47415161 time/batch=1.16s
10451/10943 (epoch 85.950) train_loss=73.03073120 time/batch=0.36s
10452/10943 (epoch 85.958) train_loss=231.83276367 time/batch=0.90s
10453/10943 (epoch 85.967) train_loss=93.07814789 time/batch=0.46s
10454/10943 (epoch 85.975) train_loss=193.76612854 time/batch=0.87s
10455/10943 (epoch 85.983) train_loss=160.76342773 time/batch=0.78s
10456/10943 (epoch 85.991) train_loss=268.96728516 time/batch=1.10s
10457/10943 (epoch 85.999) train_loss=162.70147705 time/batch=0.82s
10458/10943 (epoch 86.008) train_loss=127.23993683 time/batch=0.60s
10459/10943 (epoch 86.016) train_loss=145.81239319 time/batch=0.68s
10460/10943 (epoch 86.024) train_loss=195.06977844 time/batch=0.87s
10461/10943 (epoch 86.032) train_loss=93.77770233 time/batch=0.45s
10462/10943 (epoch 86.041) train_loss=281.95202637 time/batch=1.16s
10463/10943 (epoch 86.049) train_loss=321.32220459 time/batch=1.42s
10464/10943 (epoch 86.057) train_loss=133.02326965 time/batch=0.72s
10465/10943 (epoch 86.065) train_loss=183.62194824 time/batch=0.83s
10466/10943 (epoch 86.074) train_loss=426.31759644 time/batch=1.68s
10467/10943 (epoch 86.082) train_loss=109.23857117 time/batch=0.61s
10468/10943 (epoch 86.090) train_loss=366.78564453 time/batch=1.50s
10469/10943 (epoch 86.098) train_loss=304.65512085 time/batch=1.37s
10470/10943 (epoch 86.106) train_loss=133.51571655 time/batch=0.71s
10471/10943 (epoch 86.115) train_loss=125.12582397 time/batch=0.59s
10472/10943 (epoch 86.123) train_loss=98.38668823 time/batch=0.43s
10473/10943 (epoch 86.131) train_loss=282.28878784 time/batch=1.26s
10474/10943 (epoch 86.139) train_loss=133.25213623 time/batch=0.69s
10475/10943 (epoch 86.148) train_loss=299.42910767 time/batch=1.40s
10476/10943 (epoch 86.156) train_loss=236.82051086 time/batch=1.12s
10477/10943 (epoch 86.164) train_loss=117.09327698 time/batch=0.56s
10478/10943 (epoch 86.172) train_loss=273.85699463 time/batch=1.08s
10479/10943 (epoch 86.180) train_loss=163.20970154 time/batch=0.84s
10480/10943 (epoch 86.189) train_loss=95.62463379 time/batch=0.46s
10481/10943 (epoch 86.197) train_loss=187.25762939 time/batch=0.86s
10482/10943 (epoch 86.205) train_loss=123.32640076 time/batch=0.63s
10483/10943 (epoch 86.213) train_loss=263.11962891 time/batch=1.05s
10484/10943 (epoch 86.222) train_loss=110.89305115 time/batch=0.57s
10485/10943 (epoch 86.230) train_loss=235.35528564 time/batch=0.98s
10486/10943 (epoch 86.238) train_loss=77.45594025 time/batch=0.39s
10487/10943 (epoch 86.246) train_loss=163.56198120 time/batch=0.73s
10488/10943 (epoch 86.254) train_loss=84.70914459 time/batch=0.38s
10489/10943 (epoch 86.263) train_loss=268.10589600 time/batch=1.04s
10490/10943 (epoch 86.271) train_loss=169.53659058 time/batch=0.84s
10491/10943 (epoch 86.279) train_loss=225.50968933 time/batch=0.95s
10492/10943 (epoch 86.287) train_loss=169.26959229 time/batch=0.82s
10493/10943 (epoch 86.296) train_loss=168.62916565 time/batch=0.75s
10494/10943 (epoch 86.304) train_loss=131.04992676 time/batch=0.61s
10495/10943 (epoch 86.312) train_loss=144.59992981 time/batch=0.66s
10496/10943 (epoch 86.320) train_loss=120.77877808 time/batch=0.57s
10497/10943 (epoch 86.328) train_loss=117.37675476 time/batch=0.53s
10498/10943 (epoch 86.337) train_loss=116.68586731 time/batch=0.55s
10499/10943 (epoch 86.345) train_loss=157.60577393 time/batch=0.71s
10500/10943 (epoch 86.353) train_loss=154.43136597 time/batch=0.72s
10501/10943 (epoch 86.361) train_loss=85.93525696 time/batch=0.40s
10502/10943 (epoch 86.370) train_loss=144.81556702 time/batch=0.65s
10503/10943 (epoch 86.378) train_loss=159.00013733 time/batch=0.78s
10504/10943 (epoch 86.386) train_loss=174.85638428 time/batch=0.85s
10505/10943 (epoch 86.394) train_loss=207.03584290 time/batch=0.94s
10506/10943 (epoch 86.402) train_loss=117.83779907 time/batch=0.56s
10507/10943 (epoch 86.411) train_loss=215.90499878 time/batch=0.91s
10508/10943 (epoch 86.419) train_loss=74.92041016 time/batch=0.35s
10509/10943 (epoch 86.427) train_loss=83.56677246 time/batch=0.34s
10510/10943 (epoch 86.435) train_loss=98.47867584 time/batch=0.43s
10511/10943 (epoch 86.444) train_loss=159.69712830 time/batch=0.75s
10512/10943 (epoch 86.452) train_loss=131.17895508 time/batch=0.63s
10513/10943 (epoch 86.460) train_loss=215.39779663 time/batch=0.97s
10514/10943 (epoch 86.468) train_loss=76.97718048 time/batch=0.36s
10515/10943 (epoch 86.476) train_loss=161.97271729 time/batch=0.71s
10516/10943 (epoch 86.485) train_loss=112.05255127 time/batch=0.54s
10517/10943 (epoch 86.493) train_loss=202.88777161 time/batch=0.93s
10518/10943 (epoch 86.501) train_loss=114.35798645 time/batch=0.59s
10519/10943 (epoch 86.509) train_loss=163.63610840 time/batch=0.71s
10520/10943 (epoch 86.518) train_loss=132.07646179 time/batch=0.64s
10521/10943 (epoch 86.526) train_loss=174.69606018 time/batch=0.78s
10522/10943 (epoch 86.534) train_loss=206.92286682 time/batch=0.97s
10523/10943 (epoch 86.542) train_loss=161.01121521 time/batch=0.71s
10524/10943 (epoch 86.551) train_loss=157.13018799 time/batch=0.66s
10525/10943 (epoch 86.559) train_loss=149.26980591 time/batch=0.66s
10526/10943 (epoch 86.567) train_loss=98.05085754 time/batch=0.48s
10527/10943 (epoch 86.575) train_loss=108.71767426 time/batch=0.49s
10528/10943 (epoch 86.583) train_loss=83.25450897 time/batch=0.36s
10529/10943 (epoch 86.592) train_loss=179.68392944 time/batch=0.81s
10530/10943 (epoch 86.600) train_loss=77.02148438 time/batch=0.41s
10531/10943 (epoch 86.608) train_loss=107.25135803 time/batch=0.45s
10532/10943 (epoch 86.616) train_loss=144.04867554 time/batch=0.62s
10533/10943 (epoch 86.625) train_loss=122.34201813 time/batch=0.61s
10534/10943 (epoch 86.633) train_loss=161.78704834 time/batch=0.79s
10535/10943 (epoch 86.641) train_loss=126.39916229 time/batch=0.60s
10536/10943 (epoch 86.649) train_loss=123.69029236 time/batch=0.57s
10537/10943 (epoch 86.657) train_loss=190.42968750 time/batch=0.85s
10538/10943 (epoch 86.666) train_loss=157.38438416 time/batch=0.70s
10539/10943 (epoch 86.674) train_loss=198.89776611 time/batch=0.86s
10540/10943 (epoch 86.682) train_loss=115.30487061 time/batch=0.51s
10541/10943 (epoch 86.690) train_loss=69.31796265 time/batch=0.36s
10542/10943 (epoch 86.699) train_loss=191.65295410 time/batch=0.84s
10543/10943 (epoch 86.707) train_loss=182.43995667 time/batch=0.83s
10544/10943 (epoch 86.715) train_loss=165.83372498 time/batch=0.75s
10545/10943 (epoch 86.723) train_loss=133.97416687 time/batch=0.64s
10546/10943 (epoch 86.731) train_loss=147.36488342 time/batch=0.64s
10547/10943 (epoch 86.740) train_loss=134.18197632 time/batch=0.60s
10548/10943 (epoch 86.748) train_loss=124.96974945 time/batch=0.60s
10549/10943 (epoch 86.756) train_loss=109.62726593 time/batch=0.49s
10550/10943 (epoch 86.764) train_loss=145.69357300 time/batch=0.64s
10551/10943 (epoch 86.773) train_loss=92.83401489 time/batch=0.39s
10552/10943 (epoch 86.781) train_loss=172.93051147 time/batch=0.77s
10553/10943 (epoch 86.789) train_loss=109.75199890 time/batch=0.58s
10554/10943 (epoch 86.797) train_loss=159.71649170 time/batch=0.73s
10555/10943 (epoch 86.805) train_loss=107.17945862 time/batch=0.58s
10556/10943 (epoch 86.814) train_loss=173.96798706 time/batch=0.80s
10557/10943 (epoch 86.822) train_loss=176.00115967 time/batch=0.83s
10558/10943 (epoch 86.830) train_loss=93.38976288 time/batch=0.44s
10559/10943 (epoch 86.838) train_loss=173.47692871 time/batch=0.67s
10560/10943 (epoch 86.847) train_loss=93.13470459 time/batch=0.58s
10561/10943 (epoch 86.855) train_loss=157.49645996 time/batch=0.66s
10562/10943 (epoch 86.863) train_loss=127.09780884 time/batch=0.58s
10563/10943 (epoch 86.871) train_loss=141.92147827 time/batch=0.68s
setting learning rate to 0.0015350
10564/10943 (epoch 86.879) train_loss=189.35537720 time/batch=0.92s
10565/10943 (epoch 86.888) train_loss=281.39065552 time/batch=1.11s
10566/10943 (epoch 86.896) train_loss=482.34887695 time/batch=1.92s
10567/10943 (epoch 86.904) train_loss=181.20538330 time/batch=0.91s
10568/10943 (epoch 86.912) train_loss=198.57406616 time/batch=0.89s
10569/10943 (epoch 86.921) train_loss=309.62707520 time/batch=1.26s
10570/10943 (epoch 86.929) train_loss=321.48208618 time/batch=1.38s
10571/10943 (epoch 86.937) train_loss=280.57897949 time/batch=1.23s
10572/10943 (epoch 86.945) train_loss=325.03985596 time/batch=1.41s
10573/10943 (epoch 86.953) train_loss=173.63668823 time/batch=0.86s
10574/10943 (epoch 86.962) train_loss=71.22399139 time/batch=0.32s
10575/10943 (epoch 86.970) train_loss=247.80215454 time/batch=1.01s
10576/10943 (epoch 86.978) train_loss=277.87835693 time/batch=1.18s
10577/10943 (epoch 86.986) train_loss=334.37628174 time/batch=1.53s
10578/10943 (epoch 86.995) train_loss=225.88241577 time/batch=1.08s
10579/10943 (epoch 87.003) train_loss=285.16680908 time/batch=1.23s
10580/10943 (epoch 87.011) train_loss=142.84916687 time/batch=0.73s
10581/10943 (epoch 87.019) train_loss=85.05614471 time/batch=0.43s
10582/10943 (epoch 87.027) train_loss=79.09487915 time/batch=0.36s
10583/10943 (epoch 87.036) train_loss=144.26522827 time/batch=0.63s
10584/10943 (epoch 87.044) train_loss=524.12097168 time/batch=3.08s
10585/10943 (epoch 87.052) train_loss=82.41988373 time/batch=0.65s
10586/10943 (epoch 87.060) train_loss=156.51211548 time/batch=0.67s
10587/10943 (epoch 87.069) train_loss=88.74645996 time/batch=0.38s
10588/10943 (epoch 87.077) train_loss=213.67173767 time/batch=0.92s
10589/10943 (epoch 87.085) train_loss=103.23688507 time/batch=0.54s
10590/10943 (epoch 87.093) train_loss=133.10354614 time/batch=0.64s
10591/10943 (epoch 87.102) train_loss=136.98103333 time/batch=0.67s
10592/10943 (epoch 87.110) train_loss=317.73449707 time/batch=1.53s
10593/10943 (epoch 87.118) train_loss=212.47283936 time/batch=1.06s
10594/10943 (epoch 87.126) train_loss=188.85932922 time/batch=0.89s
10595/10943 (epoch 87.134) train_loss=145.21147156 time/batch=0.69s
10596/10943 (epoch 87.143) train_loss=151.83911133 time/batch=0.73s
10597/10943 (epoch 87.151) train_loss=109.31953430 time/batch=0.59s
10598/10943 (epoch 87.159) train_loss=150.26707458 time/batch=0.71s
10599/10943 (epoch 87.167) train_loss=254.97018433 time/batch=1.10s
10600/10943 (epoch 87.176) train_loss=181.80654907 time/batch=0.90s
10601/10943 (epoch 87.184) train_loss=120.31430054 time/batch=0.63s
10602/10943 (epoch 87.192) train_loss=144.80087280 time/batch=0.67s
10603/10943 (epoch 87.200) train_loss=107.18366241 time/batch=0.52s
10604/10943 (epoch 87.208) train_loss=69.63752747 time/batch=0.31s
10605/10943 (epoch 87.217) train_loss=92.64547729 time/batch=0.42s
10606/10943 (epoch 87.225) train_loss=166.26457214 time/batch=0.71s
10607/10943 (epoch 87.233) train_loss=257.96887207 time/batch=1.12s
10608/10943 (epoch 87.241) train_loss=111.49388885 time/batch=0.59s
10609/10943 (epoch 87.250) train_loss=98.24452209 time/batch=0.48s
10610/10943 (epoch 87.258) train_loss=95.29704285 time/batch=0.42s
10611/10943 (epoch 87.266) train_loss=139.10215759 time/batch=0.66s
10612/10943 (epoch 87.274) train_loss=124.33218384 time/batch=0.60s
10613/10943 (epoch 87.282) train_loss=93.51979065 time/batch=0.46s
10614/10943 (epoch 87.291) train_loss=117.41806793 time/batch=0.55s
10615/10943 (epoch 87.299) train_loss=214.50436401 time/batch=0.92s
10616/10943 (epoch 87.307) train_loss=239.90191650 time/batch=1.01s
10617/10943 (epoch 87.315) train_loss=144.55451965 time/batch=0.73s
10618/10943 (epoch 87.324) train_loss=236.95162964 time/batch=1.01s
10619/10943 (epoch 87.332) train_loss=119.87469482 time/batch=0.61s
10620/10943 (epoch 87.340) train_loss=113.65857697 time/batch=0.53s
10621/10943 (epoch 87.348) train_loss=148.90165710 time/batch=0.76s
10622/10943 (epoch 87.356) train_loss=98.64033508 time/batch=0.48s
10623/10943 (epoch 87.365) train_loss=158.90563965 time/batch=0.78s
10624/10943 (epoch 87.373) train_loss=71.15430450 time/batch=0.34s
10625/10943 (epoch 87.381) train_loss=170.00344849 time/batch=0.74s
10626/10943 (epoch 87.389) train_loss=163.08709717 time/batch=0.76s
10627/10943 (epoch 87.398) train_loss=180.31083679 time/batch=0.82s
10628/10943 (epoch 87.406) train_loss=172.22451782 time/batch=0.77s
10629/10943 (epoch 87.414) train_loss=69.91505432 time/batch=0.35s
10630/10943 (epoch 87.422) train_loss=242.37954712 time/batch=0.96s
10631/10943 (epoch 87.430) train_loss=108.28504944 time/batch=0.53s
10632/10943 (epoch 87.439) train_loss=237.26693726 time/batch=1.00s
10633/10943 (epoch 87.447) train_loss=181.02685547 time/batch=0.85s
10634/10943 (epoch 87.455) train_loss=163.35577393 time/batch=0.72s
10635/10943 (epoch 87.463) train_loss=82.14668274 time/batch=0.38s
10636/10943 (epoch 87.472) train_loss=66.91131592 time/batch=0.31s
10637/10943 (epoch 87.480) train_loss=112.75805664 time/batch=0.49s
10638/10943 (epoch 87.488) train_loss=126.53179169 time/batch=0.58s
10639/10943 (epoch 87.496) train_loss=204.71014404 time/batch=0.91s
10640/10943 (epoch 87.504) train_loss=127.37731934 time/batch=0.61s
10641/10943 (epoch 87.513) train_loss=216.80609131 time/batch=0.92s
10642/10943 (epoch 87.521) train_loss=150.32278442 time/batch=0.72s
10643/10943 (epoch 87.529) train_loss=142.31121826 time/batch=0.67s
10644/10943 (epoch 87.537) train_loss=78.24726868 time/batch=0.38s
10645/10943 (epoch 87.546) train_loss=106.04534149 time/batch=0.44s
10646/10943 (epoch 87.554) train_loss=97.71238708 time/batch=0.42s
10647/10943 (epoch 87.562) train_loss=142.72161865 time/batch=0.66s
10648/10943 (epoch 87.570) train_loss=81.97726440 time/batch=0.38s
10649/10943 (epoch 87.579) train_loss=130.93542480 time/batch=0.59s
10650/10943 (epoch 87.587) train_loss=201.75880432 time/batch=0.85s
10651/10943 (epoch 87.595) train_loss=139.12738037 time/batch=0.65s
10652/10943 (epoch 87.603) train_loss=155.43063354 time/batch=0.74s
10653/10943 (epoch 87.611) train_loss=104.25711823 time/batch=0.49s
10654/10943 (epoch 87.620) train_loss=140.95977783 time/batch=0.61s
10655/10943 (epoch 87.628) train_loss=122.19239807 time/batch=0.62s
10656/10943 (epoch 87.636) train_loss=103.79286194 time/batch=0.47s
10657/10943 (epoch 87.644) train_loss=186.13595581 time/batch=0.84s
10658/10943 (epoch 87.653) train_loss=116.18904114 time/batch=0.55s
10659/10943 (epoch 87.661) train_loss=160.18093872 time/batch=0.70s
10660/10943 (epoch 87.669) train_loss=133.35351562 time/batch=0.62s
10661/10943 (epoch 87.677) train_loss=160.71368408 time/batch=0.71s
10662/10943 (epoch 87.685) train_loss=132.02093506 time/batch=0.61s
10663/10943 (epoch 87.694) train_loss=113.56930542 time/batch=0.53s
10664/10943 (epoch 87.702) train_loss=159.53900146 time/batch=0.77s
10665/10943 (epoch 87.710) train_loss=140.11102295 time/batch=0.67s
10666/10943 (epoch 87.718) train_loss=128.45007324 time/batch=0.55s
10667/10943 (epoch 87.727) train_loss=164.63861084 time/batch=0.77s
10668/10943 (epoch 87.735) train_loss=119.94129944 time/batch=0.58s
10669/10943 (epoch 87.743) train_loss=89.52217865 time/batch=0.39s
10670/10943 (epoch 87.751) train_loss=190.82670593 time/batch=0.80s
10671/10943 (epoch 87.759) train_loss=124.62934875 time/batch=0.60s
10672/10943 (epoch 87.768) train_loss=165.20800781 time/batch=0.78s
10673/10943 (epoch 87.776) train_loss=133.36087036 time/batch=0.63s
10674/10943 (epoch 87.784) train_loss=193.30413818 time/batch=0.88s
10675/10943 (epoch 87.792) train_loss=180.68136597 time/batch=0.83s
10676/10943 (epoch 87.801) train_loss=91.90598297 time/batch=0.42s
10677/10943 (epoch 87.809) train_loss=91.21952820 time/batch=0.52s
10678/10943 (epoch 87.817) train_loss=181.63018799 time/batch=0.81s
10679/10943 (epoch 87.825) train_loss=177.80957031 time/batch=0.86s
10680/10943 (epoch 87.833) train_loss=175.31703186 time/batch=0.83s
10681/10943 (epoch 87.842) train_loss=192.19659424 time/batch=0.86s
10682/10943 (epoch 87.850) train_loss=119.63647461 time/batch=0.62s
10683/10943 (epoch 87.858) train_loss=127.92739868 time/batch=0.60s
10684/10943 (epoch 87.866) train_loss=136.99929810 time/batch=0.63s
setting learning rate to 0.0014889
  saved to metadata/gru_no_dropout-9_nov_folkwiki-20181207-192453_epoch43.pkl
10685/10943 (epoch 87.875) train_loss=85.54817200 time/batch=0.49s
10686/10943 (epoch 87.883) train_loss=169.98962402 time/batch=0.81s
10687/10943 (epoch 87.891) train_loss=308.69384766 time/batch=1.35s
10688/10943 (epoch 87.899) train_loss=577.04162598 time/batch=3.15s
10689/10943 (epoch 87.907) train_loss=377.03982544 time/batch=1.76s
10690/10943 (epoch 87.916) train_loss=260.06213379 time/batch=1.08s
10691/10943 (epoch 87.924) train_loss=75.22526550 time/batch=0.37s
10692/10943 (epoch 87.932) train_loss=294.72518921 time/batch=1.17s
10693/10943 (epoch 87.940) train_loss=316.92739868 time/batch=1.52s
10694/10943 (epoch 87.949) train_loss=92.95657349 time/batch=0.57s
10695/10943 (epoch 87.957) train_loss=226.95983887 time/batch=1.00s
10696/10943 (epoch 87.965) train_loss=61.33687592 time/batch=0.33s
10697/10943 (epoch 87.973) train_loss=276.52069092 time/batch=1.14s
10698/10943 (epoch 87.981) train_loss=188.18287659 time/batch=0.93s
10699/10943 (epoch 87.990) train_loss=273.71124268 time/batch=1.17s
10700/10943 (epoch 87.998) train_loss=83.19930267 time/batch=0.45s
10701/10943 (epoch 88.006) train_loss=94.07827759 time/batch=0.43s
10702/10943 (epoch 88.014) train_loss=229.31025696 time/batch=0.98s
10703/10943 (epoch 88.023) train_loss=147.45367432 time/batch=0.76s
10704/10943 (epoch 88.031) train_loss=406.22402954 time/batch=1.67s
10705/10943 (epoch 88.039) train_loss=146.14837646 time/batch=0.82s
10706/10943 (epoch 88.047) train_loss=75.00745392 time/batch=0.35s
10707/10943 (epoch 88.056) train_loss=110.41942596 time/batch=0.52s
10708/10943 (epoch 88.064) train_loss=180.29313660 time/batch=0.86s
10709/10943 (epoch 88.072) train_loss=105.04863739 time/batch=0.53s
10710/10943 (epoch 88.080) train_loss=138.22305298 time/batch=0.66s
10711/10943 (epoch 88.088) train_loss=202.98403931 time/batch=0.93s
10712/10943 (epoch 88.097) train_loss=206.78546143 time/batch=0.99s
10713/10943 (epoch 88.105) train_loss=70.69898224 time/batch=0.35s
10714/10943 (epoch 88.113) train_loss=257.28167725 time/batch=1.06s
10715/10943 (epoch 88.121) train_loss=155.97514343 time/batch=0.76s
10716/10943 (epoch 88.130) train_loss=108.85545349 time/batch=0.54s
10717/10943 (epoch 88.138) train_loss=190.30537415 time/batch=0.89s
10718/10943 (epoch 88.146) train_loss=211.25973511 time/batch=1.00s
10719/10943 (epoch 88.154) train_loss=112.14212036 time/batch=0.58s
10720/10943 (epoch 88.162) train_loss=263.56225586 time/batch=1.07s
10721/10943 (epoch 88.171) train_loss=154.92071533 time/batch=0.81s
10722/10943 (epoch 88.179) train_loss=345.47299194 time/batch=1.54s
10723/10943 (epoch 88.187) train_loss=273.20391846 time/batch=1.22s
10724/10943 (epoch 88.195) train_loss=170.41687012 time/batch=0.80s
10725/10943 (epoch 88.204) train_loss=109.70488739 time/batch=0.54s
10726/10943 (epoch 88.212) train_loss=109.68774414 time/batch=0.54s
10727/10943 (epoch 88.220) train_loss=243.63342285 time/batch=1.14s
10728/10943 (epoch 88.228) train_loss=90.90117645 time/batch=0.49s
10729/10943 (epoch 88.236) train_loss=150.04153442 time/batch=0.76s
10730/10943 (epoch 88.245) train_loss=142.91632080 time/batch=0.68s
10731/10943 (epoch 88.253) train_loss=66.96979523 time/batch=0.34s
10732/10943 (epoch 88.261) train_loss=120.08040619 time/batch=0.55s
10733/10943 (epoch 88.269) train_loss=168.74780273 time/batch=0.82s
10734/10943 (epoch 88.278) train_loss=167.10009766 time/batch=0.82s
10735/10943 (epoch 88.286) train_loss=195.46578979 time/batch=0.90s
10736/10943 (epoch 88.294) train_loss=178.46011353 time/batch=0.85s
10737/10943 (epoch 88.302) train_loss=160.43823242 time/batch=0.77s
10738/10943 (epoch 88.310) train_loss=159.08547974 time/batch=0.81s
10739/10943 (epoch 88.319) train_loss=89.44105530 time/batch=0.45s
10740/10943 (epoch 88.327) train_loss=152.94610596 time/batch=0.77s
10741/10943 (epoch 88.335) train_loss=73.33392334 time/batch=0.37s
10742/10943 (epoch 88.343) train_loss=121.73115540 time/batch=0.57s
10743/10943 (epoch 88.352) train_loss=102.38777161 time/batch=0.48s
10744/10943 (epoch 88.360) train_loss=122.30706024 time/batch=0.61s
10745/10943 (epoch 88.368) train_loss=118.67921448 time/batch=0.59s
10746/10943 (epoch 88.376) train_loss=102.87630463 time/batch=0.49s
10747/10943 (epoch 88.384) train_loss=167.05239868 time/batch=0.76s
10748/10943 (epoch 88.393) train_loss=175.72583008 time/batch=0.84s
10749/10943 (epoch 88.401) train_loss=82.35374451 time/batch=0.42s
10750/10943 (epoch 88.409) train_loss=106.77220154 time/batch=0.47s
10751/10943 (epoch 88.417) train_loss=142.68679810 time/batch=0.65s
10752/10943 (epoch 88.426) train_loss=84.05172729 time/batch=0.41s
10753/10943 (epoch 88.434) train_loss=169.58821106 time/batch=0.72s
10754/10943 (epoch 88.442) train_loss=197.89270020 time/batch=0.94s
10755/10943 (epoch 88.450) train_loss=255.97079468 time/batch=1.04s
10756/10943 (epoch 88.458) train_loss=228.31756592 time/batch=1.04s
10757/10943 (epoch 88.467) train_loss=161.92739868 time/batch=0.77s
10758/10943 (epoch 88.475) train_loss=250.92358398 time/batch=1.18s
10759/10943 (epoch 88.483) train_loss=222.66645813 time/batch=1.27s
10760/10943 (epoch 88.491) train_loss=151.76091003 time/batch=0.83s
10761/10943 (epoch 88.500) train_loss=155.97917175 time/batch=0.79s
10762/10943 (epoch 88.508) train_loss=117.41300201 time/batch=0.63s
10763/10943 (epoch 88.516) train_loss=96.49750519 time/batch=0.45s
10764/10943 (epoch 88.524) train_loss=106.34097290 time/batch=0.45s
10765/10943 (epoch 88.533) train_loss=85.30228424 time/batch=0.34s
10766/10943 (epoch 88.541) train_loss=149.29949951 time/batch=0.63s
10767/10943 (epoch 88.549) train_loss=135.64807129 time/batch=0.63s
10768/10943 (epoch 88.557) train_loss=140.80499268 time/batch=0.64s
10769/10943 (epoch 88.565) train_loss=165.00646973 time/batch=0.80s
10770/10943 (epoch 88.574) train_loss=143.50167847 time/batch=0.71s
10771/10943 (epoch 88.582) train_loss=156.41635132 time/batch=0.73s
10772/10943 (epoch 88.590) train_loss=103.48345947 time/batch=0.50s
10773/10943 (epoch 88.598) train_loss=174.19461060 time/batch=0.82s
10774/10943 (epoch 88.607) train_loss=75.53198242 time/batch=0.38s
10775/10943 (epoch 88.615) train_loss=123.17878723 time/batch=0.52s
10776/10943 (epoch 88.623) train_loss=131.80145264 time/batch=0.62s
10777/10943 (epoch 88.631) train_loss=105.49987793 time/batch=0.55s
10778/10943 (epoch 88.639) train_loss=110.81440735 time/batch=0.54s
10779/10943 (epoch 88.648) train_loss=196.38552856 time/batch=0.86s
10780/10943 (epoch 88.656) train_loss=105.32450867 time/batch=0.53s
10781/10943 (epoch 88.664) train_loss=173.21061707 time/batch=0.82s
10782/10943 (epoch 88.672) train_loss=130.68545532 time/batch=0.64s
10783/10943 (epoch 88.681) train_loss=84.42840576 time/batch=0.37s
10784/10943 (epoch 88.689) train_loss=139.57437134 time/batch=0.62s
10785/10943 (epoch 88.697) train_loss=166.84309387 time/batch=0.83s
10786/10943 (epoch 88.705) train_loss=114.00842285 time/batch=0.54s
10787/10943 (epoch 88.713) train_loss=159.16687012 time/batch=0.68s
10788/10943 (epoch 88.722) train_loss=165.30442810 time/batch=0.76s
10789/10943 (epoch 88.730) train_loss=126.93852234 time/batch=0.61s
10790/10943 (epoch 88.738) train_loss=162.17402649 time/batch=0.69s
10791/10943 (epoch 88.746) train_loss=116.42436218 time/batch=0.58s
10792/10943 (epoch 88.755) train_loss=127.13989258 time/batch=0.58s
10793/10943 (epoch 88.763) train_loss=164.02474976 time/batch=0.79s
10794/10943 (epoch 88.771) train_loss=144.54476929 time/batch=0.71s
10795/10943 (epoch 88.779) train_loss=172.56512451 time/batch=0.73s
10796/10943 (epoch 88.787) train_loss=147.15306091 time/batch=0.67s
10797/10943 (epoch 88.796) train_loss=149.59371948 time/batch=0.71s
10798/10943 (epoch 88.804) train_loss=164.71046448 time/batch=0.86s
10799/10943 (epoch 88.812) train_loss=123.12062073 time/batch=0.60s
10800/10943 (epoch 88.820) train_loss=91.43757629 time/batch=0.56s
10801/10943 (epoch 88.829) train_loss=137.33908081 time/batch=0.65s
10802/10943 (epoch 88.837) train_loss=127.18791199 time/batch=0.58s
10803/10943 (epoch 88.845) train_loss=116.43990326 time/batch=0.58s
10804/10943 (epoch 88.853) train_loss=98.50129700 time/batch=0.59s
10805/10943 (epoch 88.861) train_loss=129.66531372 time/batch=0.60s
setting learning rate to 0.0014443
10806/10943 (epoch 88.870) train_loss=87.21286011 time/batch=0.45s
10807/10943 (epoch 88.878) train_loss=72.31650543 time/batch=0.34s
10808/10943 (epoch 88.886) train_loss=158.47637939 time/batch=0.77s
10809/10943 (epoch 88.894) train_loss=229.44375610 time/batch=1.05s
10810/10943 (epoch 88.903) train_loss=157.29077148 time/batch=0.79s
10811/10943 (epoch 88.911) train_loss=187.19088745 time/batch=0.88s
10812/10943 (epoch 88.919) train_loss=155.56153870 time/batch=0.73s
10813/10943 (epoch 88.927) train_loss=87.75908661 time/batch=0.45s
10814/10943 (epoch 88.935) train_loss=566.73596191 time/batch=3.02s
10815/10943 (epoch 88.944) train_loss=452.15460205 time/batch=1.83s
10816/10943 (epoch 88.952) train_loss=95.11685944 time/batch=0.51s
10817/10943 (epoch 88.960) train_loss=201.95451355 time/batch=0.89s
10818/10943 (epoch 88.968) train_loss=85.71183777 time/batch=0.40s
10819/10943 (epoch 88.977) train_loss=306.52471924 time/batch=1.21s
10820/10943 (epoch 88.985) train_loss=249.56573486 time/batch=1.14s
10821/10943 (epoch 88.993) train_loss=362.67855835 time/batch=1.65s
10822/10943 (epoch 89.001) train_loss=168.77679443 time/batch=0.95s
10823/10943 (epoch 89.010) train_loss=190.94136047 time/batch=0.93s
10824/10943 (epoch 89.018) train_loss=92.57563782 time/batch=0.46s
10825/10943 (epoch 89.026) train_loss=147.20382690 time/batch=0.67s
10826/10943 (epoch 89.034) train_loss=262.47747803 time/batch=1.11s
10827/10943 (epoch 89.042) train_loss=74.49078369 time/batch=0.38s
10828/10943 (epoch 89.051) train_loss=195.84661865 time/batch=0.83s
10829/10943 (epoch 89.059) train_loss=160.73663330 time/batch=0.83s
10830/10943 (epoch 89.067) train_loss=216.65847778 time/batch=1.01s
10831/10943 (epoch 89.075) train_loss=335.55133057 time/batch=1.69s
10832/10943 (epoch 89.084) train_loss=117.50988770 time/batch=0.71s
10833/10943 (epoch 89.092) train_loss=59.91887665 time/batch=0.28s
10834/10943 (epoch 89.100) train_loss=81.19693756 time/batch=0.38s
10835/10943 (epoch 89.108) train_loss=120.90933228 time/batch=0.59s
10836/10943 (epoch 89.116) train_loss=114.99916077 time/batch=0.57s
10837/10943 (epoch 89.125) train_loss=67.95016479 time/batch=0.30s
10838/10943 (epoch 89.133) train_loss=177.44531250 time/batch=0.79s
10839/10943 (epoch 89.141) train_loss=271.74807739 time/batch=1.16s
10840/10943 (epoch 89.149) train_loss=222.90573120 time/batch=1.00s
10841/10943 (epoch 89.158) train_loss=104.52761078 time/batch=0.51s
10842/10943 (epoch 89.166) train_loss=204.45993042 time/batch=0.93s
10843/10943 (epoch 89.174) train_loss=249.57698059 time/batch=1.18s
10844/10943 (epoch 89.182) train_loss=77.28036499 time/batch=0.41s
10845/10943 (epoch 89.190) train_loss=84.73870087 time/batch=0.39s
10846/10943 (epoch 89.199) train_loss=141.18984985 time/batch=0.65s
10847/10943 (epoch 89.207) train_loss=108.27912903 time/batch=0.58s
10848/10943 (epoch 89.215) train_loss=157.72193909 time/batch=0.75s
10849/10943 (epoch 89.223) train_loss=187.87442017 time/batch=0.90s
10850/10943 (epoch 89.232) train_loss=114.66640472 time/batch=0.57s
10851/10943 (epoch 89.240) train_loss=262.12457275 time/batch=1.05s
10852/10943 (epoch 89.248) train_loss=108.03057861 time/batch=0.58s
10853/10943 (epoch 89.256) train_loss=110.22846222 time/batch=0.53s
10854/10943 (epoch 89.264) train_loss=158.80354309 time/batch=0.74s
10855/10943 (epoch 89.273) train_loss=150.21032715 time/batch=0.80s
10856/10943 (epoch 89.281) train_loss=311.53613281 time/batch=1.29s
10857/10943 (epoch 89.289) train_loss=321.48922729 time/batch=1.39s
10858/10943 (epoch 89.297) train_loss=188.79943848 time/batch=0.89s
10859/10943 (epoch 89.306) train_loss=157.63369751 time/batch=0.80s
10860/10943 (epoch 89.314) train_loss=149.83662415 time/batch=0.77s
10861/10943 (epoch 89.322) train_loss=157.25019836 time/batch=0.82s
10862/10943 (epoch 89.330) train_loss=107.68215942 time/batch=0.53s
10863/10943 (epoch 89.338) train_loss=235.85914612 time/batch=0.97s
10864/10943 (epoch 89.347) train_loss=128.41194153 time/batch=0.66s
10865/10943 (epoch 89.355) train_loss=278.55758667 time/batch=1.18s
10866/10943 (epoch 89.363) train_loss=95.28613281 time/batch=0.51s
10867/10943 (epoch 89.371) train_loss=95.44350433 time/batch=0.43s
10868/10943 (epoch 89.380) train_loss=145.38090515 time/batch=0.75s
10869/10943 (epoch 89.388) train_loss=250.76443481 time/batch=1.20s
10870/10943 (epoch 89.396) train_loss=141.95520020 time/batch=0.74s
10871/10943 (epoch 89.404) train_loss=211.43936157 time/batch=0.94s
10872/10943 (epoch 89.412) train_loss=78.61086273 time/batch=0.41s
10873/10943 (epoch 89.421) train_loss=141.08804321 time/batch=0.63s
10874/10943 (epoch 89.429) train_loss=123.51029205 time/batch=0.64s
10875/10943 (epoch 89.437) train_loss=145.90275574 time/batch=0.71s
10876/10943 (epoch 89.445) train_loss=174.33071899 time/batch=0.84s
10877/10943 (epoch 89.454) train_loss=115.38511658 time/batch=0.64s
10878/10943 (epoch 89.462) train_loss=173.32656860 time/batch=0.83s
10879/10943 (epoch 89.470) train_loss=157.08726501 time/batch=0.73s
10880/10943 (epoch 89.478) train_loss=150.73947144 time/batch=0.72s
10881/10943 (epoch 89.487) train_loss=126.87789917 time/batch=0.62s
10882/10943 (epoch 89.495) train_loss=144.59704590 time/batch=0.78s
10883/10943 (epoch 89.503) train_loss=128.23303223 time/batch=0.65s
10884/10943 (epoch 89.511) train_loss=74.43905640 time/batch=0.35s
10885/10943 (epoch 89.519) train_loss=65.71154785 time/batch=0.34s
10886/10943 (epoch 89.528) train_loss=70.45938110 time/batch=0.35s
10887/10943 (epoch 89.536) train_loss=188.65081787 time/batch=0.85s
10888/10943 (epoch 89.544) train_loss=100.64021301 time/batch=0.54s
10889/10943 (epoch 89.552) train_loss=154.62265015 time/batch=0.71s
10890/10943 (epoch 89.561) train_loss=152.00463867 time/batch=0.80s
10891/10943 (epoch 89.569) train_loss=88.12783813 time/batch=0.45s
10892/10943 (epoch 89.577) train_loss=108.70627594 time/batch=0.53s
10893/10943 (epoch 89.585) train_loss=115.88514709 time/batch=0.56s
10894/10943 (epoch 89.593) train_loss=95.88550568 time/batch=0.45s
10895/10943 (epoch 89.602) train_loss=120.76016998 time/batch=0.58s
10896/10943 (epoch 89.610) train_loss=176.59558105 time/batch=0.85s
10897/10943 (epoch 89.618) train_loss=146.88937378 time/batch=0.68s
10898/10943 (epoch 89.626) train_loss=143.19683838 time/batch=0.64s
10899/10943 (epoch 89.635) train_loss=173.94903564 time/batch=0.85s
10900/10943 (epoch 89.643) train_loss=106.84101105 time/batch=0.51s
10901/10943 (epoch 89.651) train_loss=116.46459198 time/batch=0.54s
10902/10943 (epoch 89.659) train_loss=178.18188477 time/batch=0.88s
10903/10943 (epoch 89.667) train_loss=108.92401123 time/batch=0.61s
10904/10943 (epoch 89.676) train_loss=103.72508240 time/batch=0.48s
10905/10943 (epoch 89.684) train_loss=111.18109131 time/batch=0.49s
10906/10943 (epoch 89.692) train_loss=100.47058105 time/batch=0.47s
10907/10943 (epoch 89.700) train_loss=135.47085571 time/batch=0.62s
10908/10943 (epoch 89.709) train_loss=211.34971619 time/batch=0.99s
10909/10943 (epoch 89.717) train_loss=172.86074829 time/batch=0.77s
10910/10943 (epoch 89.725) train_loss=150.82315063 time/batch=0.70s
10911/10943 (epoch 89.733) train_loss=126.19773102 time/batch=0.59s
10912/10943 (epoch 89.741) train_loss=122.64529419 time/batch=0.58s
10913/10943 (epoch 89.750) train_loss=97.10226440 time/batch=0.49s
10914/10943 (epoch 89.758) train_loss=142.58665466 time/batch=0.63s
10915/10943 (epoch 89.766) train_loss=153.66712952 time/batch=0.73s
10916/10943 (epoch 89.774) train_loss=171.49316406 time/batch=0.91s
10917/10943 (epoch 89.783) train_loss=122.45676422 time/batch=0.63s
10918/10943 (epoch 89.791) train_loss=138.97724915 time/batch=0.73s
10919/10943 (epoch 89.799) train_loss=137.00234985 time/batch=0.65s
10920/10943 (epoch 89.807) train_loss=198.04904175 time/batch=1.00s
10921/10943 (epoch 89.815) train_loss=128.79467773 time/batch=0.63s
10922/10943 (epoch 89.824) train_loss=105.71012878 time/batch=0.51s
10923/10943 (epoch 89.832) train_loss=235.78721619 time/batch=0.98s
10924/10943 (epoch 89.840) train_loss=123.50714111 time/batch=0.65s
10925/10943 (epoch 89.848) train_loss=151.78686523 time/batch=0.65s
10926/10943 (epoch 89.857) train_loss=140.22189331 time/batch=0.67s
setting learning rate to 0.0014009
  saved to metadata/gru_no_dropout-9_nov_folkwiki-20181207-192453_epoch45.pkl
10927/10943 (epoch 89.865) train_loss=378.25927734 time/batch=1.65s
10928/10943 (epoch 89.873) train_loss=122.67243958 time/batch=0.71s
10929/10943 (epoch 89.881) train_loss=312.10937500 time/batch=1.26s
10930/10943 (epoch 89.889) train_loss=364.46502686 time/batch=1.64s
10931/10943 (epoch 89.898) train_loss=73.94342804 time/batch=0.45s
10932/10943 (epoch 89.906) train_loss=63.31515503 time/batch=0.26s
10933/10943 (epoch 89.914) train_loss=217.97076416 time/batch=0.95s
10934/10943 (epoch 89.922) train_loss=297.78607178 time/batch=1.38s
10935/10943 (epoch 89.931) train_loss=235.27197266 time/batch=1.07s
10936/10943 (epoch 89.939) train_loss=172.61450195 time/batch=0.89s
10937/10943 (epoch 89.947) train_loss=88.21821594 time/batch=0.46s
10938/10943 (epoch 89.955) train_loss=114.68672943 time/batch=0.58s
10939/10943 (epoch 89.964) train_loss=553.46807861 time/batch=3.07s
10940/10943 (epoch 89.972) train_loss=160.99331665 time/batch=1.01s
10941/10943 (epoch 89.980) train_loss=170.37854004 time/batch=0.81s
10942/10943 (epoch 89.988) train_loss=74.71220398 time/batch=0.38s
10943/10943 (epoch 89.996) train_loss=73.70378876 time/batch=0.33s
10944/10943 (epoch 90.005) train_loss=107.05967712 time/batch=0.53s
10945/10943 (epoch 90.013) train_loss=198.45628357 time/batch=0.95s
10946/10943 (epoch 90.021) train_loss=69.49934387 time/batch=0.34s
10947/10943 (epoch 90.029) train_loss=173.95300293 time/batch=0.79s
10948/10943 (epoch 90.038) train_loss=67.39259338 time/batch=0.34s
10949/10943 (epoch 90.046) train_loss=114.79832458 time/batch=0.53s
10950/10943 (epoch 90.054) train_loss=185.19168091 time/batch=0.90s
10951/10943 (epoch 90.062) train_loss=125.42587280 time/batch=0.66s
10952/10943 (epoch 90.070) train_loss=259.76916504 time/batch=1.15s
10953/10943 (epoch 90.079) train_loss=153.48863220 time/batch=0.78s
10954/10943 (epoch 90.087) train_loss=204.60102844 time/batch=0.92s
10955/10943 (epoch 90.095) train_loss=115.74395752 time/batch=0.62s
10956/10943 (epoch 90.103) train_loss=166.69480896 time/batch=0.80s
10957/10943 (epoch 90.112) train_loss=264.98425293 time/batch=1.14s
10958/10943 (epoch 90.120) train_loss=104.23161316 time/batch=0.53s
10959/10943 (epoch 90.128) train_loss=242.41664124 time/batch=1.04s
10960/10943 (epoch 90.136) train_loss=76.09356689 time/batch=0.43s
10961/10943 (epoch 90.144) train_loss=128.31393433 time/batch=0.66s
10962/10943 (epoch 90.153) train_loss=80.57733154 time/batch=0.40s
10963/10943 (epoch 90.161) train_loss=104.96737671 time/batch=0.50s
10964/10943 (epoch 90.169) train_loss=239.43179321 time/batch=1.08s
10965/10943 (epoch 90.177) train_loss=303.90515137 time/batch=1.41s
10966/10943 (epoch 90.186) train_loss=145.13581848 time/batch=0.77s
10967/10943 (epoch 90.194) train_loss=112.33825684 time/batch=0.57s
10968/10943 (epoch 90.202) train_loss=118.93147278 time/batch=0.60s
10969/10943 (epoch 90.210) train_loss=159.86482239 time/batch=0.83s
10970/10943 (epoch 90.218) train_loss=138.14622498 time/batch=0.70s
10971/10943 (epoch 90.227) train_loss=87.85325623 time/batch=0.42s
10972/10943 (epoch 90.235) train_loss=66.49465179 time/batch=0.30s
10973/10943 (epoch 90.243) train_loss=152.48748779 time/batch=0.73s
10974/10943 (epoch 90.251) train_loss=125.97609711 time/batch=0.65s
10975/10943 (epoch 90.260) train_loss=79.34403229 time/batch=0.40s
10976/10943 (epoch 90.268) train_loss=120.73129272 time/batch=0.59s
10977/10943 (epoch 90.276) train_loss=113.96477509 time/batch=0.54s
10978/10943 (epoch 90.284) train_loss=192.95324707 time/batch=0.85s
10979/10943 (epoch 90.292) train_loss=103.57553101 time/batch=0.51s
10980/10943 (epoch 90.301) train_loss=138.47180176 time/batch=0.65s
10981/10943 (epoch 90.309) train_loss=185.99819946 time/batch=0.89s
10982/10943 (epoch 90.317) train_loss=341.84332275 time/batch=1.69s
10983/10943 (epoch 90.325) train_loss=168.18855286 time/batch=0.91s
10984/10943 (epoch 90.334) train_loss=215.91615295 time/batch=1.01s
10985/10943 (epoch 90.342) train_loss=99.32638550 time/batch=0.50s
10986/10943 (epoch 90.350) train_loss=124.02760315 time/batch=0.60s
10987/10943 (epoch 90.358) train_loss=156.49098206 time/batch=0.76s
10988/10943 (epoch 90.366) train_loss=247.05000305 time/batch=1.06s
10989/10943 (epoch 90.375) train_loss=146.36880493 time/batch=0.72s
10990/10943 (epoch 90.383) train_loss=144.08195496 time/batch=0.74s
10991/10943 (epoch 90.391) train_loss=111.51167297 time/batch=0.59s
10992/10943 (epoch 90.399) train_loss=105.25497437 time/batch=0.52s
10993/10943 (epoch 90.408) train_loss=91.72012329 time/batch=0.40s
10994/10943 (epoch 90.416) train_loss=144.13612366 time/batch=0.67s
10995/10943 (epoch 90.424) train_loss=80.18170929 time/batch=0.38s
10996/10943 (epoch 90.432) train_loss=90.33016205 time/batch=0.40s
10997/10943 (epoch 90.441) train_loss=89.46701813 time/batch=0.42s
10998/10943 (epoch 90.449) train_loss=152.65852356 time/batch=0.73s
10999/10943 (epoch 90.457) train_loss=109.22651672 time/batch=0.56s
Validating
    loss:	299.250476

11000/10943 (epoch 90.465) train_loss=101.06543732 time/batch=2.35s
11001/10943 (epoch 90.473) train_loss=79.38798523 time/batch=0.35s
11002/10943 (epoch 90.482) train_loss=91.80923462 time/batch=0.42s
11003/10943 (epoch 90.490) train_loss=169.36225891 time/batch=0.80s
11004/10943 (epoch 90.498) train_loss=176.66906738 time/batch=0.87s
11005/10943 (epoch 90.506) train_loss=154.08456421 time/batch=0.79s
11006/10943 (epoch 90.515) train_loss=157.08828735 time/batch=0.80s
11007/10943 (epoch 90.523) train_loss=236.86387634 time/batch=1.04s
11008/10943 (epoch 90.531) train_loss=282.38232422 time/batch=1.23s
11009/10943 (epoch 90.539) train_loss=112.01222992 time/batch=0.58s
11010/10943 (epoch 90.547) train_loss=226.17694092 time/batch=1.01s
11011/10943 (epoch 90.556) train_loss=237.02593994 time/batch=1.10s
11012/10943 (epoch 90.564) train_loss=125.22750854 time/batch=0.62s
11013/10943 (epoch 90.572) train_loss=126.00138855 time/batch=0.61s
11014/10943 (epoch 90.580) train_loss=97.63924408 time/batch=0.46s
11015/10943 (epoch 90.589) train_loss=211.51156616 time/batch=0.91s
11016/10943 (epoch 90.597) train_loss=146.34848022 time/batch=0.70s
11017/10943 (epoch 90.605) train_loss=149.44892883 time/batch=0.69s
11018/10943 (epoch 90.613) train_loss=122.42335510 time/batch=0.60s
11019/10943 (epoch 90.621) train_loss=174.70770264 time/batch=0.84s
11020/10943 (epoch 90.630) train_loss=133.02722168 time/batch=0.65s
11021/10943 (epoch 90.638) train_loss=141.35351562 time/batch=0.65s
11022/10943 (epoch 90.646) train_loss=177.89248657 time/batch=0.87s
11023/10943 (epoch 90.654) train_loss=234.36801147 time/batch=1.11s
11024/10943 (epoch 90.663) train_loss=229.54541016 time/batch=1.23s
11025/10943 (epoch 90.671) train_loss=165.19549561 time/batch=0.86s
11026/10943 (epoch 90.679) train_loss=121.64201355 time/batch=0.64s
11027/10943 (epoch 90.687) train_loss=93.59845734 time/batch=0.47s
11028/10943 (epoch 90.695) train_loss=100.56950378 time/batch=0.48s
11029/10943 (epoch 90.704) train_loss=158.29800415 time/batch=0.71s
11030/10943 (epoch 90.712) train_loss=135.79338074 time/batch=0.66s
11031/10943 (epoch 90.720) train_loss=104.68450928 time/batch=0.56s
11032/10943 (epoch 90.728) train_loss=139.68122864 time/batch=0.68s
11033/10943 (epoch 90.737) train_loss=102.81250000 time/batch=0.50s
11034/10943 (epoch 90.745) train_loss=110.97698975 time/batch=0.50s
11035/10943 (epoch 90.753) train_loss=150.81610107 time/batch=0.69s
11036/10943 (epoch 90.761) train_loss=97.76487732 time/batch=0.57s
11037/10943 (epoch 90.769) train_loss=158.43664551 time/batch=0.69s
11038/10943 (epoch 90.778) train_loss=117.68334961 time/batch=0.59s
11039/10943 (epoch 90.786) train_loss=185.55004883 time/batch=0.88s
11040/10943 (epoch 90.794) train_loss=154.91175842 time/batch=0.73s
11041/10943 (epoch 90.802) train_loss=131.65716553 time/batch=0.66s
11042/10943 (epoch 90.811) train_loss=165.66690063 time/batch=0.78s
11043/10943 (epoch 90.819) train_loss=161.63928223 time/batch=0.90s
11044/10943 (epoch 90.827) train_loss=167.95021057 time/batch=0.82s
11045/10943 (epoch 90.835) train_loss=155.93551636 time/batch=0.75s
11046/10943 (epoch 90.843) train_loss=163.75546265 time/batch=0.80s
11047/10943 (epoch 90.852) train_loss=127.38756561 time/batch=0.75s
setting learning rate to 0.0013589
11048/10943 (epoch 90.860) train_loss=221.69290161 time/batch=0.99s
11049/10943 (epoch 90.868) train_loss=202.32037354 time/batch=0.97s
11050/10943 (epoch 90.876) train_loss=559.06250000 time/batch=3.08s
11051/10943 (epoch 90.885) train_loss=111.02854919 time/batch=0.79s
11052/10943 (epoch 90.893) train_loss=145.18533325 time/batch=0.73s
11053/10943 (epoch 90.901) train_loss=107.83006287 time/batch=0.57s
11054/10943 (epoch 90.909) train_loss=250.34423828 time/batch=1.09s
11055/10943 (epoch 90.918) train_loss=310.51678467 time/batch=1.39s
11056/10943 (epoch 90.926) train_loss=263.44311523 time/batch=1.16s
11057/10943 (epoch 90.934) train_loss=201.93595886 time/batch=1.00s
11058/10943 (epoch 90.942) train_loss=117.57603455 time/batch=0.60s
11059/10943 (epoch 90.950) train_loss=167.76289368 time/batch=0.82s
11060/10943 (epoch 90.959) train_loss=143.44601440 time/batch=0.72s
11061/10943 (epoch 90.967) train_loss=139.13092041 time/batch=0.79s
11062/10943 (epoch 90.975) train_loss=181.51869202 time/batch=0.89s
11063/10943 (epoch 90.983) train_loss=145.41400146 time/batch=0.78s
11064/10943 (epoch 90.992) train_loss=203.47143555 time/batch=0.96s
11065/10943 (epoch 91.000) train_loss=91.53465271 time/batch=0.53s
11066/10943 (epoch 91.008) train_loss=140.79638672 time/batch=0.74s
11067/10943 (epoch 91.016) train_loss=338.98376465 time/batch=1.51s
11068/10943 (epoch 91.024) train_loss=116.61776733 time/batch=0.70s
11069/10943 (epoch 91.033) train_loss=142.34109497 time/batch=0.70s
11070/10943 (epoch 91.041) train_loss=143.44297791 time/batch=0.81s
11071/10943 (epoch 91.049) train_loss=100.24030304 time/batch=0.59s
11072/10943 (epoch 91.057) train_loss=256.77740479 time/batch=1.12s
11073/10943 (epoch 91.066) train_loss=108.45138550 time/batch=0.66s
11074/10943 (epoch 91.074) train_loss=206.52684021 time/batch=0.97s
11075/10943 (epoch 91.082) train_loss=128.10289001 time/batch=0.70s
11076/10943 (epoch 91.090) train_loss=129.39442444 time/batch=0.66s
11077/10943 (epoch 91.098) train_loss=81.55693054 time/batch=0.44s
11078/10943 (epoch 91.107) train_loss=210.57693481 time/batch=0.95s
11079/10943 (epoch 91.115) train_loss=264.59057617 time/batch=1.22s
11080/10943 (epoch 91.123) train_loss=183.72116089 time/batch=0.90s
11081/10943 (epoch 91.131) train_loss=222.28540039 time/batch=1.00s
11082/10943 (epoch 91.140) train_loss=114.00556946 time/batch=0.60s
11083/10943 (epoch 91.148) train_loss=115.99156189 time/batch=0.54s
11084/10943 (epoch 91.156) train_loss=65.71003723 time/batch=0.30s
11085/10943 (epoch 91.164) train_loss=115.04090118 time/batch=0.55s
11086/10943 (epoch 91.172) train_loss=159.24859619 time/batch=0.84s
11087/10943 (epoch 91.181) train_loss=212.77487183 time/batch=1.06s
11088/10943 (epoch 91.189) train_loss=60.09212494 time/batch=0.33s
11089/10943 (epoch 91.197) train_loss=87.64018250 time/batch=0.39s
11090/10943 (epoch 91.205) train_loss=118.39468384 time/batch=0.58s
11091/10943 (epoch 91.214) train_loss=73.03910828 time/batch=0.35s
11092/10943 (epoch 91.222) train_loss=244.33561707 time/batch=1.11s
11093/10943 (epoch 91.230) train_loss=144.61091614 time/batch=0.72s
11094/10943 (epoch 91.238) train_loss=72.17508698 time/batch=0.33s
11095/10943 (epoch 91.246) train_loss=351.15921021 time/batch=1.54s
11096/10943 (epoch 91.255) train_loss=129.66571045 time/batch=0.74s
11097/10943 (epoch 91.263) train_loss=183.63581848 time/batch=0.89s
11098/10943 (epoch 91.271) train_loss=73.39675140 time/batch=0.37s
11099/10943 (epoch 91.279) train_loss=155.45678711 time/batch=0.76s
11100/10943 (epoch 91.288) train_loss=316.11975098 time/batch=1.28s
11101/10943 (epoch 91.296) train_loss=193.58908081 time/batch=0.94s
11102/10943 (epoch 91.304) train_loss=91.79525757 time/batch=0.48s
11103/10943 (epoch 91.312) train_loss=75.93588257 time/batch=0.36s
11104/10943 (epoch 91.320) train_loss=97.94960022 time/batch=0.47s
11105/10943 (epoch 91.329) train_loss=98.31433105 time/batch=0.49s
11106/10943 (epoch 91.337) train_loss=122.60250854 time/batch=0.61s
11107/10943 (epoch 91.345) train_loss=360.91522217 time/batch=1.65s
11108/10943 (epoch 91.353) train_loss=97.30337524 time/batch=0.58s
11109/10943 (epoch 91.362) train_loss=289.68750000 time/batch=1.20s
11110/10943 (epoch 91.370) train_loss=202.00048828 time/batch=0.99s
11111/10943 (epoch 91.378) train_loss=157.46000671 time/batch=0.80s
11112/10943 (epoch 91.386) train_loss=148.72569275 time/batch=0.74s
11113/10943 (epoch 91.395) train_loss=186.76736450 time/batch=0.88s
11114/10943 (epoch 91.403) train_loss=164.24801636 time/batch=0.79s
11115/10943 (epoch 91.411) train_loss=94.95321655 time/batch=0.48s
11116/10943 (epoch 91.419) train_loss=138.53759766 time/batch=0.64s
11117/10943 (epoch 91.427) train_loss=132.40634155 time/batch=0.69s
11118/10943 (epoch 91.436) train_loss=247.43548584 time/batch=1.17s
11119/10943 (epoch 91.444) train_loss=202.27992249 time/batch=1.05s
11120/10943 (epoch 91.452) train_loss=247.19589233 time/batch=1.08s
11121/10943 (epoch 91.460) train_loss=111.72682190 time/batch=0.56s
11122/10943 (epoch 91.469) train_loss=112.62184906 time/batch=0.57s
11123/10943 (epoch 91.477) train_loss=167.21794128 time/batch=0.85s
11124/10943 (epoch 91.485) train_loss=156.36975098 time/batch=0.75s
11125/10943 (epoch 91.493) train_loss=103.43151093 time/batch=0.54s
11126/10943 (epoch 91.501) train_loss=151.07559204 time/batch=0.77s
11127/10943 (epoch 91.510) train_loss=172.15649414 time/batch=0.87s
11128/10943 (epoch 91.518) train_loss=120.36325073 time/batch=0.61s
11129/10943 (epoch 91.526) train_loss=124.72099304 time/batch=0.60s
11130/10943 (epoch 91.534) train_loss=74.49485779 time/batch=0.38s
11131/10943 (epoch 91.543) train_loss=157.01855469 time/batch=0.77s
11132/10943 (epoch 91.551) train_loss=128.31370544 time/batch=0.65s
11133/10943 (epoch 91.559) train_loss=65.85887909 time/batch=0.33s
11134/10943 (epoch 91.567) train_loss=148.75363159 time/batch=0.70s
11135/10943 (epoch 91.575) train_loss=131.85859680 time/batch=0.66s
11136/10943 (epoch 91.584) train_loss=108.99965668 time/batch=0.58s
11137/10943 (epoch 91.592) train_loss=153.30535889 time/batch=0.75s
11138/10943 (epoch 91.600) train_loss=173.27316284 time/batch=0.83s
11139/10943 (epoch 91.608) train_loss=106.68344116 time/batch=0.50s
11140/10943 (epoch 91.617) train_loss=165.31878662 time/batch=0.81s
11141/10943 (epoch 91.625) train_loss=106.59513855 time/batch=0.55s
11142/10943 (epoch 91.633) train_loss=81.97100830 time/batch=0.34s
11143/10943 (epoch 91.641) train_loss=156.40765381 time/batch=0.70s
11144/10943 (epoch 91.649) train_loss=124.93217468 time/batch=0.62s
11145/10943 (epoch 91.658) train_loss=82.41648865 time/batch=0.40s
11146/10943 (epoch 91.666) train_loss=83.10105896 time/batch=0.38s
11147/10943 (epoch 91.674) train_loss=103.05368042 time/batch=0.50s
11148/10943 (epoch 91.682) train_loss=138.41720581 time/batch=0.67s
11149/10943 (epoch 91.691) train_loss=140.25692749 time/batch=0.67s
11150/10943 (epoch 91.699) train_loss=162.91485596 time/batch=0.80s
11151/10943 (epoch 91.707) train_loss=117.59315491 time/batch=0.63s
11152/10943 (epoch 91.715) train_loss=136.85189819 time/batch=0.65s
11153/10943 (epoch 91.723) train_loss=148.89916992 time/batch=0.67s
11154/10943 (epoch 91.732) train_loss=83.38801575 time/batch=0.37s
11155/10943 (epoch 91.740) train_loss=79.62257385 time/batch=0.36s
11156/10943 (epoch 91.748) train_loss=122.90007019 time/batch=0.56s
11157/10943 (epoch 91.756) train_loss=86.56311035 time/batch=0.42s
11158/10943 (epoch 91.765) train_loss=172.01643372 time/batch=0.78s
11159/10943 (epoch 91.773) train_loss=145.00048828 time/batch=0.70s
11160/10943 (epoch 91.781) train_loss=94.89637756 time/batch=0.48s
11161/10943 (epoch 91.789) train_loss=180.59741211 time/batch=0.98s
11162/10943 (epoch 91.797) train_loss=113.38335419 time/batch=0.62s
11163/10943 (epoch 91.806) train_loss=148.72775269 time/batch=0.70s
11164/10943 (epoch 91.814) train_loss=132.07055664 time/batch=0.64s
11165/10943 (epoch 91.822) train_loss=153.04922485 time/batch=0.81s
11166/10943 (epoch 91.830) train_loss=102.90299988 time/batch=0.65s
11167/10943 (epoch 91.839) train_loss=92.03652954 time/batch=0.44s
11168/10943 (epoch 91.847) train_loss=125.95294189 time/batch=0.66s
setting learning rate to 0.0013181
  saved to metadata/gru_no_dropout-9_nov_folkwiki-20181207-192453_epoch47.pkl
11169/10943 (epoch 91.855) train_loss=74.29473877 time/batch=0.44s
11170/10943 (epoch 91.863) train_loss=248.32939148 time/batch=1.08s
11171/10943 (epoch 91.871) train_loss=73.26371002 time/batch=0.40s
11172/10943 (epoch 91.880) train_loss=235.22647095 time/batch=1.03s
11173/10943 (epoch 91.888) train_loss=118.48991394 time/batch=0.64s
11174/10943 (epoch 91.896) train_loss=113.48046112 time/batch=0.60s
11175/10943 (epoch 91.904) train_loss=300.47280884 time/batch=1.40s
11176/10943 (epoch 91.913) train_loss=168.11904907 time/batch=0.89s
11177/10943 (epoch 91.921) train_loss=217.73687744 time/batch=0.97s
11178/10943 (epoch 91.929) train_loss=213.99011230 time/batch=0.98s
11179/10943 (epoch 91.937) train_loss=259.84136963 time/batch=1.16s
11180/10943 (epoch 91.946) train_loss=116.25370789 time/batch=0.69s
11181/10943 (epoch 91.954) train_loss=265.38769531 time/batch=1.18s
11182/10943 (epoch 91.962) train_loss=295.98281860 time/batch=1.35s
11183/10943 (epoch 91.970) train_loss=344.04528809 time/batch=1.59s
11184/10943 (epoch 91.978) train_loss=204.99681091 time/batch=1.06s
11185/10943 (epoch 91.987) train_loss=220.45729065 time/batch=1.07s
11186/10943 (epoch 91.995) train_loss=330.18005371 time/batch=1.59s
11187/10943 (epoch 92.003) train_loss=70.81537628 time/batch=0.42s
11188/10943 (epoch 92.011) train_loss=430.37368774 time/batch=1.85s
11189/10943 (epoch 92.020) train_loss=80.92303467 time/batch=0.52s
11190/10943 (epoch 92.028) train_loss=130.76814270 time/batch=0.65s
11191/10943 (epoch 92.036) train_loss=88.86476135 time/batch=0.46s
11192/10943 (epoch 92.044) train_loss=495.10708618 time/batch=3.04s
11193/10943 (epoch 92.052) train_loss=165.31465149 time/batch=0.97s
11194/10943 (epoch 92.061) train_loss=108.12863159 time/batch=0.57s
11195/10943 (epoch 92.069) train_loss=137.33337402 time/batch=0.68s
11196/10943 (epoch 92.077) train_loss=148.94076538 time/batch=0.79s
11197/10943 (epoch 92.085) train_loss=210.12423706 time/batch=1.00s
11198/10943 (epoch 92.094) train_loss=72.03651428 time/batch=0.41s
11199/10943 (epoch 92.102) train_loss=148.78610229 time/batch=0.72s
11200/10943 (epoch 92.110) train_loss=80.92906189 time/batch=0.43s
11201/10943 (epoch 92.118) train_loss=143.57420349 time/batch=0.69s
11202/10943 (epoch 92.126) train_loss=98.94718933 time/batch=0.55s
11203/10943 (epoch 92.135) train_loss=76.48295593 time/batch=0.37s
11204/10943 (epoch 92.143) train_loss=125.23316193 time/batch=0.61s
11205/10943 (epoch 92.151) train_loss=114.57939148 time/batch=0.55s
11206/10943 (epoch 92.159) train_loss=62.24973679 time/batch=0.30s
11207/10943 (epoch 92.168) train_loss=175.78987122 time/batch=0.85s
11208/10943 (epoch 92.176) train_loss=217.67614746 time/batch=1.00s
11209/10943 (epoch 92.184) train_loss=91.21523285 time/batch=0.49s
11210/10943 (epoch 92.192) train_loss=111.22325134 time/batch=0.57s
11211/10943 (epoch 92.200) train_loss=89.81179047 time/batch=0.47s
11212/10943 (epoch 92.209) train_loss=73.85614014 time/batch=0.38s
11213/10943 (epoch 92.217) train_loss=249.12367249 time/batch=1.05s
11214/10943 (epoch 92.225) train_loss=90.82495117 time/batch=0.49s
11215/10943 (epoch 92.233) train_loss=115.40191650 time/batch=0.55s
11216/10943 (epoch 92.242) train_loss=121.83253479 time/batch=0.62s
11217/10943 (epoch 92.250) train_loss=73.24891663 time/batch=0.37s
11218/10943 (epoch 92.258) train_loss=265.75207520 time/batch=1.18s
11219/10943 (epoch 92.266) train_loss=166.79302979 time/batch=0.88s
11220/10943 (epoch 92.274) train_loss=170.27005005 time/batch=0.86s
11221/10943 (epoch 92.283) train_loss=116.38575745 time/batch=0.59s
11222/10943 (epoch 92.291) train_loss=64.39421844 time/batch=0.32s
11223/10943 (epoch 92.299) train_loss=172.63694763 time/batch=0.82s
11224/10943 (epoch 92.307) train_loss=166.97610474 time/batch=0.84s
11225/10943 (epoch 92.316) train_loss=94.09173584 time/batch=0.50s
11226/10943 (epoch 92.324) train_loss=169.72825623 time/batch=0.81s
11227/10943 (epoch 92.332) train_loss=207.08526611 time/batch=1.02s
11228/10943 (epoch 92.340) train_loss=138.45275879 time/batch=0.74s
11229/10943 (epoch 92.348) train_loss=262.45639038 time/batch=1.22s
11230/10943 (epoch 92.357) train_loss=148.43887329 time/batch=0.74s
11231/10943 (epoch 92.365) train_loss=110.65307617 time/batch=0.57s
11232/10943 (epoch 92.373) train_loss=156.52189636 time/batch=0.80s
11233/10943 (epoch 92.381) train_loss=242.31521606 time/batch=1.10s
11234/10943 (epoch 92.390) train_loss=111.49160767 time/batch=0.60s
11235/10943 (epoch 92.398) train_loss=172.65597534 time/batch=0.84s
11236/10943 (epoch 92.406) train_loss=97.50227356 time/batch=0.53s
11237/10943 (epoch 92.414) train_loss=146.12998962 time/batch=0.76s
11238/10943 (epoch 92.423) train_loss=208.92578125 time/batch=1.01s
11239/10943 (epoch 92.431) train_loss=118.42977142 time/batch=0.64s
11240/10943 (epoch 92.439) train_loss=131.65759277 time/batch=0.65s
11241/10943 (epoch 92.447) train_loss=82.74578857 time/batch=0.43s
11242/10943 (epoch 92.455) train_loss=98.98852539 time/batch=0.50s
11243/10943 (epoch 92.464) train_loss=184.80772400 time/batch=0.88s
11244/10943 (epoch 92.472) train_loss=99.17790222 time/batch=0.53s
11245/10943 (epoch 92.480) train_loss=159.96173096 time/batch=0.80s
11246/10943 (epoch 92.488) train_loss=153.01538086 time/batch=0.78s
11247/10943 (epoch 92.497) train_loss=67.39108276 time/batch=0.35s
11248/10943 (epoch 92.505) train_loss=108.49865723 time/batch=0.49s
11249/10943 (epoch 92.513) train_loss=81.68218231 time/batch=0.40s
11250/10943 (epoch 92.521) train_loss=152.31353760 time/batch=0.70s
11251/10943 (epoch 92.529) train_loss=103.81480408 time/batch=0.52s
11252/10943 (epoch 92.538) train_loss=118.53378296 time/batch=0.58s
11253/10943 (epoch 92.546) train_loss=143.15568542 time/batch=0.71s
11254/10943 (epoch 92.554) train_loss=126.84317017 time/batch=0.64s
11255/10943 (epoch 92.562) train_loss=132.16967773 time/batch=0.65s
11256/10943 (epoch 92.571) train_loss=137.52114868 time/batch=0.67s
11257/10943 (epoch 92.579) train_loss=101.07274628 time/batch=0.57s
11258/10943 (epoch 92.587) train_loss=102.75645447 time/batch=0.50s
11259/10943 (epoch 92.595) train_loss=151.28283691 time/batch=0.69s
11260/10943 (epoch 92.603) train_loss=225.53509521 time/batch=1.02s
11261/10943 (epoch 92.612) train_loss=152.95207214 time/batch=0.82s
11262/10943 (epoch 92.620) train_loss=139.52630615 time/batch=0.70s
11263/10943 (epoch 92.628) train_loss=149.90319824 time/batch=0.77s
11264/10943 (epoch 92.636) train_loss=114.03308105 time/batch=0.64s
11265/10943 (epoch 92.645) train_loss=97.27470398 time/batch=0.47s
11266/10943 (epoch 92.653) train_loss=185.51536560 time/batch=0.85s
11267/10943 (epoch 92.661) train_loss=175.95332336 time/batch=0.86s
11268/10943 (epoch 92.669) train_loss=139.00506592 time/batch=0.72s
11269/10943 (epoch 92.677) train_loss=149.41464233 time/batch=0.75s
11270/10943 (epoch 92.686) train_loss=187.00277710 time/batch=0.93s
11271/10943 (epoch 92.694) train_loss=190.89089966 time/batch=0.89s
11272/10943 (epoch 92.702) train_loss=104.70281219 time/batch=0.52s
11273/10943 (epoch 92.710) train_loss=123.60302734 time/batch=0.58s
11274/10943 (epoch 92.719) train_loss=128.55319214 time/batch=0.60s
11275/10943 (epoch 92.727) train_loss=104.39710236 time/batch=0.57s
11276/10943 (epoch 92.735) train_loss=84.67126465 time/batch=0.46s
11277/10943 (epoch 92.743) train_loss=153.55952454 time/batch=0.82s
11278/10943 (epoch 92.751) train_loss=121.10478210 time/batch=0.66s
11279/10943 (epoch 92.760) train_loss=73.02453613 time/batch=0.35s
11280/10943 (epoch 92.768) train_loss=148.03953552 time/batch=0.69s
11281/10943 (epoch 92.776) train_loss=137.58236694 time/batch=0.68s
11282/10943 (epoch 92.784) train_loss=111.29077911 time/batch=0.61s
11283/10943 (epoch 92.793) train_loss=147.95227051 time/batch=0.70s
11284/10943 (epoch 92.801) train_loss=166.65287781 time/batch=0.80s
11285/10943 (epoch 92.809) train_loss=140.42904663 time/batch=0.68s
11286/10943 (epoch 92.817) train_loss=154.24195862 time/batch=0.77s
11287/10943 (epoch 92.825) train_loss=157.52053833 time/batch=0.81s
11288/10943 (epoch 92.834) train_loss=133.63816833 time/batch=0.74s
11289/10943 (epoch 92.842) train_loss=150.12454224 time/batch=0.80s
setting learning rate to 0.0012786
11290/10943 (epoch 92.850) train_loss=288.38665771 time/batch=1.25s
11291/10943 (epoch 92.858) train_loss=369.57104492 time/batch=1.60s
11292/10943 (epoch 92.867) train_loss=155.31292725 time/batch=0.88s
11293/10943 (epoch 92.875) train_loss=168.94616699 time/batch=0.84s
11294/10943 (epoch 92.883) train_loss=61.36051941 time/batch=0.31s
11295/10943 (epoch 92.891) train_loss=252.26458740 time/batch=1.20s
11296/10943 (epoch 92.900) train_loss=247.20498657 time/batch=1.23s
11297/10943 (epoch 92.908) train_loss=181.64512634 time/batch=0.95s
11298/10943 (epoch 92.916) train_loss=402.49969482 time/batch=1.78s
11299/10943 (epoch 92.924) train_loss=545.00280762 time/batch=3.20s
11300/10943 (epoch 92.932) train_loss=116.92578888 time/batch=0.82s
11301/10943 (epoch 92.941) train_loss=299.92147827 time/batch=1.28s
11302/10943 (epoch 92.949) train_loss=112.57572174 time/batch=0.67s
11303/10943 (epoch 92.957) train_loss=66.06141663 time/batch=0.33s
11304/10943 (epoch 92.965) train_loss=296.12960815 time/batch=1.36s
11305/10943 (epoch 92.974) train_loss=82.49441528 time/batch=0.50s
11306/10943 (epoch 92.982) train_loss=183.10351562 time/batch=0.88s
11307/10943 (epoch 92.990) train_loss=217.72731018 time/batch=1.02s
11308/10943 (epoch 92.998) train_loss=109.05570984 time/batch=0.60s
11309/10943 (epoch 93.006) train_loss=78.06375122 time/batch=0.36s
11310/10943 (epoch 93.015) train_loss=67.08480835 time/batch=0.28s
11311/10943 (epoch 93.023) train_loss=96.89265442 time/batch=0.49s
11312/10943 (epoch 93.031) train_loss=172.80923462 time/batch=0.89s
11313/10943 (epoch 93.039) train_loss=82.74070740 time/batch=0.45s
11314/10943 (epoch 93.048) train_loss=141.09902954 time/batch=0.71s
11315/10943 (epoch 93.056) train_loss=208.76068115 time/batch=0.98s
11316/10943 (epoch 93.064) train_loss=90.67209625 time/batch=0.52s
11317/10943 (epoch 93.072) train_loss=197.96340942 time/batch=0.94s
11318/10943 (epoch 93.080) train_loss=206.82989502 time/batch=0.98s
11319/10943 (epoch 93.089) train_loss=86.55358887 time/batch=0.50s
11320/10943 (epoch 93.097) train_loss=99.87953949 time/batch=0.53s
11321/10943 (epoch 93.105) train_loss=290.75457764 time/batch=1.32s
11322/10943 (epoch 93.113) train_loss=115.15156555 time/batch=0.65s
11323/10943 (epoch 93.122) train_loss=202.13589478 time/batch=0.92s
11324/10943 (epoch 93.130) train_loss=149.73107910 time/batch=0.76s
11325/10943 (epoch 93.138) train_loss=242.04394531 time/batch=1.09s
11326/10943 (epoch 93.146) train_loss=253.78485107 time/batch=1.16s
11327/10943 (epoch 93.154) train_loss=280.34106445 time/batch=1.18s
11328/10943 (epoch 93.163) train_loss=119.98237610 time/batch=0.63s
11329/10943 (epoch 93.171) train_loss=137.76263428 time/batch=0.74s
11330/10943 (epoch 93.179) train_loss=223.18536377 time/batch=1.02s
11331/10943 (epoch 93.187) train_loss=157.10971069 time/batch=0.86s
11332/10943 (epoch 93.196) train_loss=165.89286804 time/batch=0.88s
11333/10943 (epoch 93.204) train_loss=180.74157715 time/batch=0.94s
11334/10943 (epoch 93.212) train_loss=235.54112244 time/batch=1.08s
11335/10943 (epoch 93.220) train_loss=104.46750641 time/batch=0.56s
11336/10943 (epoch 93.228) train_loss=63.58037567 time/batch=0.30s
11337/10943 (epoch 93.237) train_loss=128.48007202 time/batch=0.61s
11338/10943 (epoch 93.245) train_loss=144.10269165 time/batch=0.78s
11339/10943 (epoch 93.253) train_loss=202.30610657 time/batch=1.03s
11340/10943 (epoch 93.261) train_loss=193.31871033 time/batch=0.98s
11341/10943 (epoch 93.270) train_loss=86.89102173 time/batch=0.46s
11342/10943 (epoch 93.278) train_loss=140.73600769 time/batch=0.70s
11343/10943 (epoch 93.286) train_loss=116.01341248 time/batch=0.62s
11344/10943 (epoch 93.294) train_loss=131.93905640 time/batch=0.69s
11345/10943 (epoch 93.302) train_loss=152.17893982 time/batch=0.84s
11346/10943 (epoch 93.311) train_loss=149.13491821 time/batch=0.76s
11347/10943 (epoch 93.319) train_loss=115.27100372 time/batch=0.60s
11348/10943 (epoch 93.327) train_loss=165.79379272 time/batch=0.85s
11349/10943 (epoch 93.335) train_loss=77.85210419 time/batch=0.43s
11350/10943 (epoch 93.344) train_loss=88.51680756 time/batch=0.43s
11351/10943 (epoch 93.352) train_loss=91.42457581 time/batch=0.43s
11352/10943 (epoch 93.360) train_loss=149.16574097 time/batch=0.76s
11353/10943 (epoch 93.368) train_loss=79.60409546 time/batch=0.44s
11354/10943 (epoch 93.377) train_loss=132.02482605 time/batch=0.64s
11355/10943 (epoch 93.385) train_loss=230.46276855 time/batch=1.07s
11356/10943 (epoch 93.393) train_loss=148.98587036 time/batch=0.76s
11357/10943 (epoch 93.401) train_loss=161.16467285 time/batch=0.81s
11358/10943 (epoch 93.409) train_loss=104.51153564 time/batch=0.56s
11359/10943 (epoch 93.418) train_loss=71.28739929 time/batch=0.33s
11360/10943 (epoch 93.426) train_loss=142.23556519 time/batch=0.72s
11361/10943 (epoch 93.434) train_loss=118.09996033 time/batch=0.58s
11362/10943 (epoch 93.442) train_loss=67.65197754 time/batch=0.33s
11363/10943 (epoch 93.451) train_loss=140.32192993 time/batch=0.73s
11364/10943 (epoch 93.459) train_loss=77.21669006 time/batch=0.40s
11365/10943 (epoch 93.467) train_loss=119.38301086 time/batch=0.58s
11366/10943 (epoch 93.475) train_loss=98.91794586 time/batch=0.51s
11367/10943 (epoch 93.483) train_loss=93.76762390 time/batch=0.47s
11368/10943 (epoch 93.492) train_loss=168.52380371 time/batch=0.83s
11369/10943 (epoch 93.500) train_loss=119.73802185 time/batch=0.63s
11370/10943 (epoch 93.508) train_loss=130.54486084 time/batch=0.67s
11371/10943 (epoch 93.516) train_loss=142.89025879 time/batch=0.80s
11372/10943 (epoch 93.525) train_loss=155.49673462 time/batch=0.78s
11373/10943 (epoch 93.533) train_loss=97.33924866 time/batch=0.52s
11374/10943 (epoch 93.541) train_loss=196.98883057 time/batch=0.95s
11375/10943 (epoch 93.549) train_loss=112.20801544 time/batch=0.67s
11376/10943 (epoch 93.557) train_loss=153.18225098 time/batch=0.71s
11377/10943 (epoch 93.566) train_loss=146.96868896 time/batch=0.70s
11378/10943 (epoch 93.574) train_loss=132.72247314 time/batch=0.66s
11379/10943 (epoch 93.582) train_loss=111.01704407 time/batch=0.57s
11380/10943 (epoch 93.590) train_loss=150.16058350 time/batch=0.77s
11381/10943 (epoch 93.599) train_loss=75.88386536 time/batch=0.39s
11382/10943 (epoch 93.607) train_loss=72.52834320 time/batch=0.33s
11383/10943 (epoch 93.615) train_loss=80.38998413 time/batch=0.40s
11384/10943 (epoch 93.623) train_loss=181.84294128 time/batch=0.83s
11385/10943 (epoch 93.631) train_loss=168.90748596 time/batch=0.84s
11386/10943 (epoch 93.640) train_loss=119.31020355 time/batch=0.61s
11387/10943 (epoch 93.648) train_loss=93.03435516 time/batch=0.46s
11388/10943 (epoch 93.656) train_loss=137.63586426 time/batch=0.65s
11389/10943 (epoch 93.664) train_loss=128.92477417 time/batch=0.63s
11390/10943 (epoch 93.673) train_loss=87.46139526 time/batch=0.46s
11391/10943 (epoch 93.681) train_loss=115.11170959 time/batch=0.58s
11392/10943 (epoch 93.689) train_loss=120.51346588 time/batch=0.63s
11393/10943 (epoch 93.697) train_loss=131.04132080 time/batch=0.63s
11394/10943 (epoch 93.705) train_loss=108.17089844 time/batch=0.52s
11395/10943 (epoch 93.714) train_loss=117.98054504 time/batch=0.61s
11396/10943 (epoch 93.722) train_loss=133.57662964 time/batch=0.65s
11397/10943 (epoch 93.730) train_loss=101.41978455 time/batch=0.50s
11398/10943 (epoch 93.738) train_loss=162.22030640 time/batch=0.77s
11399/10943 (epoch 93.747) train_loss=148.61822510 time/batch=0.68s
11400/10943 (epoch 93.755) train_loss=152.09976196 time/batch=0.80s
11401/10943 (epoch 93.763) train_loss=143.60929871 time/batch=0.70s
11402/10943 (epoch 93.771) train_loss=105.89916992 time/batch=0.58s
11403/10943 (epoch 93.779) train_loss=154.28558350 time/batch=0.80s
11404/10943 (epoch 93.788) train_loss=127.29783630 time/batch=0.69s
11405/10943 (epoch 93.796) train_loss=152.44842529 time/batch=0.81s
11406/10943 (epoch 93.804) train_loss=171.52053833 time/batch=0.84s
11407/10943 (epoch 93.812) train_loss=119.59085846 time/batch=0.63s
11408/10943 (epoch 93.821) train_loss=128.37960815 time/batch=0.66s
11409/10943 (epoch 93.829) train_loss=136.82492065 time/batch=0.70s
11410/10943 (epoch 93.837) train_loss=127.34876251 time/batch=0.71s
setting learning rate to 0.0012402
  saved to metadata/gru_no_dropout-9_nov_folkwiki-20181207-192453_epoch49.pkl
11411/10943 (epoch 93.845) train_loss=92.01615143 time/batch=0.58s
11412/10943 (epoch 93.854) train_loss=150.76699829 time/batch=0.82s
11413/10943 (epoch 93.862) train_loss=180.82403564 time/batch=0.91s
11414/10943 (epoch 93.870) train_loss=463.10330200 time/batch=2.07s
11415/10943 (epoch 93.878) train_loss=91.57727814 time/batch=0.54s
11416/10943 (epoch 93.886) train_loss=68.21398926 time/batch=0.28s
11417/10943 (epoch 93.895) train_loss=309.44110107 time/batch=1.22s
11418/10943 (epoch 93.903) train_loss=78.71815491 time/batch=0.43s
11419/10943 (epoch 93.911) train_loss=201.02719116 time/batch=0.88s
11420/10943 (epoch 93.919) train_loss=123.39355469 time/batch=0.71s
11421/10943 (epoch 93.928) train_loss=76.48593140 time/batch=0.40s
11422/10943 (epoch 93.936) train_loss=227.22874451 time/batch=1.02s
11423/10943 (epoch 93.944) train_loss=316.59082031 time/batch=1.51s
11424/10943 (epoch 93.952) train_loss=151.20205688 time/batch=0.82s
11425/10943 (epoch 93.960) train_loss=245.10491943 time/batch=1.12s
11426/10943 (epoch 93.969) train_loss=283.27203369 time/batch=1.33s
11427/10943 (epoch 93.977) train_loss=231.24058533 time/batch=1.08s
11428/10943 (epoch 93.985) train_loss=108.40748596 time/batch=0.62s
11429/10943 (epoch 93.993) train_loss=143.02603149 time/batch=0.79s
11430/10943 (epoch 94.002) train_loss=133.97702026 time/batch=0.76s
11431/10943 (epoch 94.010) train_loss=168.04200745 time/batch=0.88s
11432/10943 (epoch 94.018) train_loss=233.93234253 time/batch=1.10s
11433/10943 (epoch 94.026) train_loss=98.77243805 time/batch=0.57s
11434/10943 (epoch 94.034) train_loss=334.82971191 time/batch=1.54s
11435/10943 (epoch 94.043) train_loss=156.03240967 time/batch=0.92s
11436/10943 (epoch 94.051) train_loss=224.58172607 time/batch=1.09s
11437/10943 (epoch 94.059) train_loss=82.04975128 time/batch=0.46s
11438/10943 (epoch 94.067) train_loss=149.18013000 time/batch=0.71s
11439/10943 (epoch 94.076) train_loss=128.12045288 time/batch=0.66s
11440/10943 (epoch 94.084) train_loss=129.45584106 time/batch=0.67s
11441/10943 (epoch 94.092) train_loss=145.98605347 time/batch=0.72s
11442/10943 (epoch 94.100) train_loss=129.73915100 time/batch=0.78s
11443/10943 (epoch 94.108) train_loss=68.69810486 time/batch=0.34s
11444/10943 (epoch 94.117) train_loss=136.38554382 time/batch=0.69s
11445/10943 (epoch 94.125) train_loss=142.58613586 time/batch=0.74s
11446/10943 (epoch 94.133) train_loss=167.12210083 time/batch=0.87s
11447/10943 (epoch 94.141) train_loss=102.76335907 time/batch=0.60s
11448/10943 (epoch 94.150) train_loss=85.54299927 time/batch=0.44s
11449/10943 (epoch 94.158) train_loss=284.12835693 time/batch=1.31s
11450/10943 (epoch 94.166) train_loss=245.94610596 time/batch=1.20s
11451/10943 (epoch 94.174) train_loss=253.32089233 time/batch=1.20s
11452/10943 (epoch 94.182) train_loss=89.32263947 time/batch=0.50s
11453/10943 (epoch 94.191) train_loss=263.90753174 time/batch=1.15s
11454/10943 (epoch 94.199) train_loss=71.01189423 time/batch=0.40s
11455/10943 (epoch 94.207) train_loss=103.74384308 time/batch=0.49s
11456/10943 (epoch 94.215) train_loss=203.91316223 time/batch=0.94s
11457/10943 (epoch 94.224) train_loss=115.34941101 time/batch=0.64s
11458/10943 (epoch 94.232) train_loss=119.83860779 time/batch=0.61s
11459/10943 (epoch 94.240) train_loss=152.67576599 time/batch=0.76s
11460/10943 (epoch 94.248) train_loss=218.35733032 time/batch=1.01s
11461/10943 (epoch 94.256) train_loss=208.33425903 time/batch=1.02s
11462/10943 (epoch 94.265) train_loss=115.52172852 time/batch=0.63s
11463/10943 (epoch 94.273) train_loss=99.14385223 time/batch=0.53s
11464/10943 (epoch 94.281) train_loss=81.88858032 time/batch=0.43s
11465/10943 (epoch 94.289) train_loss=168.31161499 time/batch=0.81s
11466/10943 (epoch 94.298) train_loss=108.69171906 time/batch=0.59s
11467/10943 (epoch 94.306) train_loss=93.68920135 time/batch=0.48s
11468/10943 (epoch 94.314) train_loss=461.71289062 time/batch=3.05s
11469/10943 (epoch 94.322) train_loss=141.19808960 time/batch=0.94s
11470/10943 (epoch 94.331) train_loss=159.51525879 time/batch=0.84s
11471/10943 (epoch 94.339) train_loss=113.03183746 time/batch=0.62s
11472/10943 (epoch 94.347) train_loss=197.34922791 time/batch=0.95s
11473/10943 (epoch 94.355) train_loss=78.50967407 time/batch=0.42s
11474/10943 (epoch 94.363) train_loss=246.72317505 time/batch=1.15s
11475/10943 (epoch 94.372) train_loss=130.53706360 time/batch=0.71s
11476/10943 (epoch 94.380) train_loss=183.34963989 time/batch=0.91s
11477/10943 (epoch 94.388) train_loss=106.54136658 time/batch=0.56s
11478/10943 (epoch 94.396) train_loss=161.76943970 time/batch=0.83s
11479/10943 (epoch 94.405) train_loss=113.59399414 time/batch=0.65s
11480/10943 (epoch 94.413) train_loss=138.62905884 time/batch=0.71s
11481/10943 (epoch 94.421) train_loss=157.63453674 time/batch=0.86s
11482/10943 (epoch 94.429) train_loss=88.02953339 time/batch=0.44s
11483/10943 (epoch 94.437) train_loss=113.05383301 time/batch=0.56s
11484/10943 (epoch 94.446) train_loss=57.37851334 time/batch=0.28s
11485/10943 (epoch 94.454) train_loss=143.70614624 time/batch=0.74s
11486/10943 (epoch 94.462) train_loss=132.98300171 time/batch=0.70s
11487/10943 (epoch 94.470) train_loss=188.57913208 time/batch=0.89s
11488/10943 (epoch 94.479) train_loss=97.12072754 time/batch=0.49s
11489/10943 (epoch 94.487) train_loss=100.39457703 time/batch=0.53s
11490/10943 (epoch 94.495) train_loss=90.64848328 time/batch=0.49s
11491/10943 (epoch 94.503) train_loss=126.44213867 time/batch=0.67s
11492/10943 (epoch 94.511) train_loss=135.26330566 time/batch=0.69s
11493/10943 (epoch 94.520) train_loss=206.05819702 time/batch=0.94s
11494/10943 (epoch 94.528) train_loss=159.19908142 time/batch=0.78s
11495/10943 (epoch 94.536) train_loss=176.21170044 time/batch=0.92s
11496/10943 (epoch 94.544) train_loss=151.01531982 time/batch=0.82s
11497/10943 (epoch 94.553) train_loss=135.27917480 time/batch=0.71s
11498/10943 (epoch 94.561) train_loss=121.56806946 time/batch=0.64s
11499/10943 (epoch 94.569) train_loss=124.91110992 time/batch=0.64s
11500/10943 (epoch 94.577) train_loss=67.75268555 time/batch=0.34s
11501/10943 (epoch 94.585) train_loss=131.19921875 time/batch=0.62s
11502/10943 (epoch 94.594) train_loss=153.09193420 time/batch=0.80s
11503/10943 (epoch 94.602) train_loss=76.85060883 time/batch=0.39s
11504/10943 (epoch 94.610) train_loss=111.88657379 time/batch=0.59s
11505/10943 (epoch 94.618) train_loss=112.75913239 time/batch=0.58s
11506/10943 (epoch 94.627) train_loss=108.29408264 time/batch=0.54s
11507/10943 (epoch 94.635) train_loss=84.14862061 time/batch=0.44s
11508/10943 (epoch 94.643) train_loss=133.30538940 time/batch=0.66s
11509/10943 (epoch 94.651) train_loss=118.41268921 time/batch=0.63s
11510/10943 (epoch 94.659) train_loss=95.22228241 time/batch=0.48s
11511/10943 (epoch 94.668) train_loss=69.35905457 time/batch=0.33s
11512/10943 (epoch 94.676) train_loss=106.03988647 time/batch=0.49s
11513/10943 (epoch 94.684) train_loss=121.32919312 time/batch=0.56s
11514/10943 (epoch 94.692) train_loss=97.83363342 time/batch=0.49s
11515/10943 (epoch 94.701) train_loss=157.82763672 time/batch=0.79s
11516/10943 (epoch 94.709) train_loss=106.40600586 time/batch=0.57s
11517/10943 (epoch 94.717) train_loss=182.56161499 time/batch=0.94s
11518/10943 (epoch 94.725) train_loss=156.26367188 time/batch=0.82s
11519/10943 (epoch 94.733) train_loss=176.02728271 time/batch=0.84s
11520/10943 (epoch 94.742) train_loss=129.30845642 time/batch=0.65s
11521/10943 (epoch 94.750) train_loss=91.07922363 time/batch=0.47s
11522/10943 (epoch 94.758) train_loss=149.13743591 time/batch=0.77s
11523/10943 (epoch 94.766) train_loss=148.62339783 time/batch=0.72s
11524/10943 (epoch 94.775) train_loss=112.24272156 time/batch=0.57s
11525/10943 (epoch 94.783) train_loss=155.40521240 time/batch=0.78s
11526/10943 (epoch 94.791) train_loss=139.56402588 time/batch=0.72s
11527/10943 (epoch 94.799) train_loss=112.00071716 time/batch=0.61s
11528/10943 (epoch 94.808) train_loss=76.07193756 time/batch=0.38s
11529/10943 (epoch 94.816) train_loss=81.92333984 time/batch=0.57s
11530/10943 (epoch 94.824) train_loss=126.76448059 time/batch=0.71s
11531/10943 (epoch 94.832) train_loss=138.88316345 time/batch=0.80s
setting learning rate to 0.0012030
11532/10943 (epoch 94.840) train_loss=287.72830200 time/batch=1.29s
11533/10943 (epoch 94.849) train_loss=182.65615845 time/batch=0.99s
11534/10943 (epoch 94.857) train_loss=199.30232239 time/batch=0.95s
11535/10943 (epoch 94.865) train_loss=290.22760010 time/batch=1.39s
11536/10943 (epoch 94.873) train_loss=145.25366211 time/batch=0.85s
11537/10943 (epoch 94.882) train_loss=166.57792664 time/batch=0.93s
11538/10943 (epoch 94.890) train_loss=330.75665283 time/batch=1.56s
11539/10943 (epoch 94.898) train_loss=225.24954224 time/batch=1.16s
11540/10943 (epoch 94.906) train_loss=97.01222229 time/batch=0.57s
11541/10943 (epoch 94.914) train_loss=98.74018097 time/batch=0.51s
11542/10943 (epoch 94.923) train_loss=241.69760132 time/batch=1.15s
11543/10943 (epoch 94.931) train_loss=80.89649963 time/batch=0.46s
11544/10943 (epoch 94.939) train_loss=98.55370331 time/batch=0.59s
11545/10943 (epoch 94.947) train_loss=138.57102966 time/batch=0.75s
11546/10943 (epoch 94.956) train_loss=105.59631348 time/batch=0.63s
11547/10943 (epoch 94.964) train_loss=188.26637268 time/batch=0.93s
11548/10943 (epoch 94.972) train_loss=66.59818268 time/batch=0.33s
11549/10943 (epoch 94.980) train_loss=466.85131836 time/batch=2.13s
11550/10943 (epoch 94.988) train_loss=157.94897461 time/batch=0.87s
11551/10943 (epoch 94.997) train_loss=471.67980957 time/batch=3.07s
11552/10943 (epoch 95.005) train_loss=277.93127441 time/batch=1.43s
11553/10943 (epoch 95.013) train_loss=164.52600098 time/batch=0.89s
11554/10943 (epoch 95.021) train_loss=260.73962402 time/batch=1.21s
11555/10943 (epoch 95.030) train_loss=221.87792969 time/batch=1.06s
11556/10943 (epoch 95.038) train_loss=292.45831299 time/batch=1.42s
11557/10943 (epoch 95.046) train_loss=118.01368713 time/batch=0.66s
11558/10943 (epoch 95.054) train_loss=243.31611633 time/batch=1.07s
11559/10943 (epoch 95.062) train_loss=103.16979218 time/batch=0.60s
11560/10943 (epoch 95.071) train_loss=217.10656738 time/batch=0.96s
11561/10943 (epoch 95.079) train_loss=82.96174622 time/batch=0.47s
11562/10943 (epoch 95.087) train_loss=241.45390320 time/batch=1.07s
11563/10943 (epoch 95.095) train_loss=219.78042603 time/batch=1.05s
11564/10943 (epoch 95.104) train_loss=105.31645203 time/batch=0.62s
11565/10943 (epoch 95.112) train_loss=130.54208374 time/batch=0.65s
11566/10943 (epoch 95.120) train_loss=134.59843445 time/batch=0.71s
11567/10943 (epoch 95.128) train_loss=66.08574677 time/batch=0.41s
11568/10943 (epoch 95.136) train_loss=58.81293106 time/batch=0.28s
11569/10943 (epoch 95.145) train_loss=159.03593445 time/batch=0.81s
11570/10943 (epoch 95.153) train_loss=152.49247742 time/batch=0.83s
11571/10943 (epoch 95.161) train_loss=151.49076843 time/batch=0.86s
11572/10943 (epoch 95.169) train_loss=271.31335449 time/batch=1.42s
11573/10943 (epoch 95.178) train_loss=133.15502930 time/batch=0.73s
11574/10943 (epoch 95.186) train_loss=61.19509888 time/batch=0.33s
11575/10943 (epoch 95.194) train_loss=116.97439575 time/batch=0.60s
11576/10943 (epoch 95.202) train_loss=234.82124329 time/batch=1.10s
11577/10943 (epoch 95.210) train_loss=68.92650604 time/batch=0.40s
11578/10943 (epoch 95.219) train_loss=161.93060303 time/batch=0.79s
11579/10943 (epoch 95.227) train_loss=102.89032745 time/batch=0.58s
11580/10943 (epoch 95.235) train_loss=91.83200836 time/batch=0.49s
11581/10943 (epoch 95.243) train_loss=86.47201538 time/batch=0.42s
11582/10943 (epoch 95.252) train_loss=108.97645569 time/batch=0.57s
11583/10943 (epoch 95.260) train_loss=186.76457214 time/batch=1.01s
11584/10943 (epoch 95.268) train_loss=201.30158997 time/batch=0.99s
11585/10943 (epoch 95.276) train_loss=127.08245850 time/batch=0.70s
11586/10943 (epoch 95.285) train_loss=65.98498535 time/batch=0.33s
11587/10943 (epoch 95.293) train_loss=70.11452484 time/batch=0.34s
11588/10943 (epoch 95.301) train_loss=176.55813599 time/batch=0.84s
11589/10943 (epoch 95.309) train_loss=180.82064819 time/batch=0.91s
11590/10943 (epoch 95.317) train_loss=143.72789001 time/batch=0.79s
11591/10943 (epoch 95.326) train_loss=177.69284058 time/batch=0.90s
11592/10943 (epoch 95.334) train_loss=104.09308624 time/batch=0.55s
11593/10943 (epoch 95.342) train_loss=76.41368866 time/batch=0.39s
11594/10943 (epoch 95.350) train_loss=86.78238678 time/batch=0.45s
11595/10943 (epoch 95.359) train_loss=198.67358398 time/batch=0.92s
11596/10943 (epoch 95.367) train_loss=156.20559692 time/batch=0.85s
11597/10943 (epoch 95.375) train_loss=169.04238892 time/batch=0.88s
11598/10943 (epoch 95.383) train_loss=122.43990326 time/batch=0.67s
11599/10943 (epoch 95.391) train_loss=196.26255798 time/batch=1.02s
11600/10943 (epoch 95.400) train_loss=146.70715332 time/batch=0.76s
11601/10943 (epoch 95.408) train_loss=69.43765259 time/batch=0.36s
11602/10943 (epoch 95.416) train_loss=131.41247559 time/batch=0.66s
11603/10943 (epoch 95.424) train_loss=85.75177765 time/batch=0.44s
11604/10943 (epoch 95.433) train_loss=103.46887207 time/batch=0.51s
11605/10943 (epoch 95.441) train_loss=112.95610809 time/batch=0.57s
11606/10943 (epoch 95.449) train_loss=107.13693237 time/batch=0.55s
11607/10943 (epoch 95.457) train_loss=139.19531250 time/batch=0.78s
11608/10943 (epoch 95.465) train_loss=84.32722473 time/batch=0.46s
11609/10943 (epoch 95.474) train_loss=84.97055817 time/batch=0.42s
11610/10943 (epoch 95.482) train_loss=137.10348511 time/batch=0.71s
11611/10943 (epoch 95.490) train_loss=146.74894714 time/batch=0.74s
11612/10943 (epoch 95.498) train_loss=148.88815308 time/batch=0.82s
11613/10943 (epoch 95.507) train_loss=116.87567139 time/batch=0.63s
11614/10943 (epoch 95.515) train_loss=116.41557312 time/batch=0.59s
11615/10943 (epoch 95.523) train_loss=118.60936737 time/batch=0.64s
11616/10943 (epoch 95.531) train_loss=149.53099060 time/batch=0.78s
11617/10943 (epoch 95.539) train_loss=86.17529297 time/batch=0.47s
11618/10943 (epoch 95.548) train_loss=158.54470825 time/batch=0.82s
11619/10943 (epoch 95.556) train_loss=149.73777771 time/batch=0.77s
11620/10943 (epoch 95.564) train_loss=161.41345215 time/batch=0.82s
11621/10943 (epoch 95.572) train_loss=99.66435242 time/batch=0.51s
11622/10943 (epoch 95.581) train_loss=159.41802979 time/batch=0.80s
11623/10943 (epoch 95.589) train_loss=119.97575378 time/batch=0.65s
11624/10943 (epoch 95.597) train_loss=114.15687561 time/batch=0.58s
11625/10943 (epoch 95.605) train_loss=144.57736206 time/batch=0.78s
11626/10943 (epoch 95.613) train_loss=133.89846802 time/batch=0.70s
11627/10943 (epoch 95.622) train_loss=89.16033173 time/batch=0.48s
11628/10943 (epoch 95.630) train_loss=79.57930756 time/batch=0.42s
11629/10943 (epoch 95.638) train_loss=110.10168457 time/batch=0.52s
11630/10943 (epoch 95.646) train_loss=93.13980103 time/batch=0.49s
11631/10943 (epoch 95.655) train_loss=112.69409180 time/batch=0.59s
11632/10943 (epoch 95.663) train_loss=141.50869751 time/batch=0.77s
11633/10943 (epoch 95.671) train_loss=138.71882629 time/batch=0.68s
11634/10943 (epoch 95.679) train_loss=144.25561523 time/batch=0.71s
11635/10943 (epoch 95.687) train_loss=97.64633942 time/batch=0.50s
11636/10943 (epoch 95.696) train_loss=123.10736847 time/batch=0.59s
11637/10943 (epoch 95.704) train_loss=131.72631836 time/batch=0.69s
11638/10943 (epoch 95.712) train_loss=150.79681396 time/batch=0.78s
11639/10943 (epoch 95.720) train_loss=146.46759033 time/batch=0.79s
11640/10943 (epoch 95.729) train_loss=101.41052246 time/batch=0.56s
11641/10943 (epoch 95.737) train_loss=143.60726929 time/batch=0.69s
11642/10943 (epoch 95.745) train_loss=101.13291168 time/batch=0.52s
11643/10943 (epoch 95.753) train_loss=68.28256226 time/batch=0.34s
11644/10943 (epoch 95.762) train_loss=114.63404083 time/batch=0.56s
11645/10943 (epoch 95.770) train_loss=135.21081543 time/batch=0.67s
11646/10943 (epoch 95.778) train_loss=141.41229248 time/batch=0.72s
11647/10943 (epoch 95.786) train_loss=82.56023407 time/batch=0.46s
11648/10943 (epoch 95.794) train_loss=127.90095520 time/batch=0.64s
11649/10943 (epoch 95.803) train_loss=129.28305054 time/batch=0.69s
11650/10943 (epoch 95.811) train_loss=136.10281372 time/batch=0.78s
11651/10943 (epoch 95.819) train_loss=105.66972351 time/batch=0.63s
11652/10943 (epoch 95.827) train_loss=121.48677063 time/batch=0.61s
setting learning rate to 0.0011669
  saved to metadata/gru_no_dropout-9_nov_folkwiki-20181207-192453_epoch51.pkl
11653/10943 (epoch 95.836) train_loss=354.67709351 time/batch=1.64s
11654/10943 (epoch 95.844) train_loss=79.41354370 time/batch=0.49s
11655/10943 (epoch 95.852) train_loss=125.42024994 time/batch=0.66s
11656/10943 (epoch 95.860) train_loss=105.57275391 time/batch=0.60s
11657/10943 (epoch 95.868) train_loss=64.28623962 time/batch=0.30s
11658/10943 (epoch 95.877) train_loss=84.10640717 time/batch=0.46s
11659/10943 (epoch 95.885) train_loss=170.26196289 time/batch=0.89s
11660/10943 (epoch 95.893) train_loss=248.47891235 time/batch=1.20s
11661/10943 (epoch 95.901) train_loss=104.06888580 time/batch=0.66s
11662/10943 (epoch 95.910) train_loss=292.91711426 time/batch=1.39s
11663/10943 (epoch 95.918) train_loss=181.32830811 time/batch=1.00s
11664/10943 (epoch 95.926) train_loss=254.14744568 time/batch=1.11s
11665/10943 (epoch 95.934) train_loss=160.80932617 time/batch=0.90s
11666/10943 (epoch 95.942) train_loss=239.81251526 time/batch=1.12s
11667/10943 (epoch 95.951) train_loss=285.61572266 time/batch=1.29s
11668/10943 (epoch 95.959) train_loss=67.32913208 time/batch=0.43s
11669/10943 (epoch 95.967) train_loss=157.65638733 time/batch=0.81s
11670/10943 (epoch 95.975) train_loss=122.25120544 time/batch=0.68s
11671/10943 (epoch 95.984) train_loss=126.76808929 time/batch=0.74s
11672/10943 (epoch 95.992) train_loss=186.50546265 time/batch=0.97s
11673/10943 (epoch 96.000) train_loss=232.08470154 time/batch=1.15s
11674/10943 (epoch 96.008) train_loss=136.16232300 time/batch=0.84s
11675/10943 (epoch 96.016) train_loss=118.61348724 time/batch=0.66s
11676/10943 (epoch 96.025) train_loss=113.86870575 time/batch=0.65s
11677/10943 (epoch 96.033) train_loss=211.41326904 time/batch=1.02s
11678/10943 (epoch 96.041) train_loss=88.99114227 time/batch=0.52s
11679/10943 (epoch 96.049) train_loss=253.39038086 time/batch=1.16s
11680/10943 (epoch 96.058) train_loss=236.89266968 time/batch=1.18s
11681/10943 (epoch 96.066) train_loss=88.79710388 time/batch=0.48s
11682/10943 (epoch 96.074) train_loss=73.89764404 time/batch=0.39s
11683/10943 (epoch 96.082) train_loss=285.12792969 time/batch=1.27s
11684/10943 (epoch 96.090) train_loss=93.10343933 time/batch=0.58s
11685/10943 (epoch 96.099) train_loss=162.54966736 time/batch=0.85s
11686/10943 (epoch 96.107) train_loss=85.69241333 time/batch=0.48s
11687/10943 (epoch 96.115) train_loss=106.14151001 time/batch=0.56s
11688/10943 (epoch 96.123) train_loss=189.55810547 time/batch=0.92s
11689/10943 (epoch 96.132) train_loss=204.97109985 time/batch=1.06s
11690/10943 (epoch 96.140) train_loss=342.94967651 time/batch=1.65s
11691/10943 (epoch 96.148) train_loss=157.65078735 time/batch=0.93s
11692/10943 (epoch 96.156) train_loss=174.06655884 time/batch=0.89s
11693/10943 (epoch 96.164) train_loss=450.14285278 time/batch=2.08s
11694/10943 (epoch 96.173) train_loss=84.58030701 time/batch=0.57s
11695/10943 (epoch 96.181) train_loss=152.62463379 time/batch=0.67s
11696/10943 (epoch 96.189) train_loss=142.41998291 time/batch=0.80s
11697/10943 (epoch 96.197) train_loss=107.16290283 time/batch=0.64s
11698/10943 (epoch 96.206) train_loss=178.09896851 time/batch=0.86s
11699/10943 (epoch 96.214) train_loss=155.72448730 time/batch=0.84s
11700/10943 (epoch 96.222) train_loss=103.47682190 time/batch=0.54s
11701/10943 (epoch 96.230) train_loss=96.47061157 time/batch=0.52s
11702/10943 (epoch 96.238) train_loss=127.76533508 time/batch=0.64s
11703/10943 (epoch 96.247) train_loss=179.60856628 time/batch=0.91s
11704/10943 (epoch 96.255) train_loss=65.21836853 time/batch=0.35s
11705/10943 (epoch 96.263) train_loss=217.38314819 time/batch=0.99s
11706/10943 (epoch 96.271) train_loss=93.08057404 time/batch=0.59s
11707/10943 (epoch 96.280) train_loss=228.76733398 time/batch=1.16s
11708/10943 (epoch 96.288) train_loss=157.67703247 time/batch=0.92s
11709/10943 (epoch 96.296) train_loss=72.76618958 time/batch=0.36s
11710/10943 (epoch 96.304) train_loss=131.48114014 time/batch=0.68s
11711/10943 (epoch 96.313) train_loss=209.09959412 time/batch=0.99s
11712/10943 (epoch 96.321) train_loss=77.67332458 time/batch=0.43s
11713/10943 (epoch 96.329) train_loss=98.49229431 time/batch=0.50s
11714/10943 (epoch 96.337) train_loss=90.92652130 time/batch=0.46s
11715/10943 (epoch 96.345) train_loss=105.87177277 time/batch=0.57s
11716/10943 (epoch 96.354) train_loss=197.91256714 time/batch=0.93s
11717/10943 (epoch 96.362) train_loss=91.29388428 time/batch=0.52s
11718/10943 (epoch 96.370) train_loss=160.83575439 time/batch=0.81s
11719/10943 (epoch 96.378) train_loss=205.07818604 time/batch=0.98s
11720/10943 (epoch 96.387) train_loss=83.95268250 time/batch=0.46s
11721/10943 (epoch 96.395) train_loss=110.95285034 time/batch=0.52s
11722/10943 (epoch 96.403) train_loss=67.67017365 time/batch=0.35s
11723/10943 (epoch 96.411) train_loss=309.62518311 time/batch=2.26s
11724/10943 (epoch 96.419) train_loss=83.40473938 time/batch=0.63s
11725/10943 (epoch 96.428) train_loss=146.82048035 time/batch=0.71s
11726/10943 (epoch 96.436) train_loss=109.62860107 time/batch=0.59s
11727/10943 (epoch 96.444) train_loss=179.44995117 time/batch=0.96s
11728/10943 (epoch 96.452) train_loss=127.84024811 time/batch=0.71s
11729/10943 (epoch 96.461) train_loss=137.85614014 time/batch=0.67s
11730/10943 (epoch 96.469) train_loss=63.39618683 time/batch=0.33s
11731/10943 (epoch 96.477) train_loss=128.28776550 time/batch=0.63s
11732/10943 (epoch 96.485) train_loss=144.68823242 time/batch=0.78s
11733/10943 (epoch 96.493) train_loss=123.76998901 time/batch=0.71s
11734/10943 (epoch 96.502) train_loss=101.21801758 time/batch=0.58s
11735/10943 (epoch 96.510) train_loss=108.24512482 time/batch=0.60s
11736/10943 (epoch 96.518) train_loss=62.18054199 time/batch=0.33s
11737/10943 (epoch 96.526) train_loss=142.13824463 time/batch=0.71s
11738/10943 (epoch 96.535) train_loss=128.71856689 time/batch=0.68s
11739/10943 (epoch 96.543) train_loss=86.75494385 time/batch=0.48s
11740/10943 (epoch 96.551) train_loss=101.46327209 time/batch=0.49s
11741/10943 (epoch 96.559) train_loss=136.39920044 time/batch=0.70s
11742/10943 (epoch 96.567) train_loss=112.03137207 time/batch=0.63s
11743/10943 (epoch 96.576) train_loss=78.43994141 time/batch=0.42s
11744/10943 (epoch 96.584) train_loss=138.70515442 time/batch=0.68s
11745/10943 (epoch 96.592) train_loss=109.17201233 time/batch=0.56s
11746/10943 (epoch 96.600) train_loss=116.29270935 time/batch=0.59s
11747/10943 (epoch 96.609) train_loss=121.95558929 time/batch=0.63s
11748/10943 (epoch 96.617) train_loss=72.95460510 time/batch=0.36s
11749/10943 (epoch 96.625) train_loss=95.26701355 time/batch=0.47s
11750/10943 (epoch 96.633) train_loss=147.36096191 time/batch=0.78s
11751/10943 (epoch 96.641) train_loss=90.47493744 time/batch=0.46s
11752/10943 (epoch 96.650) train_loss=101.24737549 time/batch=0.53s
11753/10943 (epoch 96.658) train_loss=115.94395447 time/batch=0.62s
11754/10943 (epoch 96.666) train_loss=131.32305908 time/batch=0.68s
11755/10943 (epoch 96.674) train_loss=257.66677856 time/batch=3.06s
11756/10943 (epoch 96.683) train_loss=157.52435303 time/batch=0.99s
11757/10943 (epoch 96.691) train_loss=164.24606323 time/batch=0.81s
11758/10943 (epoch 96.699) train_loss=81.78369904 time/batch=0.47s
11759/10943 (epoch 96.707) train_loss=144.74395752 time/batch=0.70s
11760/10943 (epoch 96.715) train_loss=155.62069702 time/batch=0.76s
11761/10943 (epoch 96.724) train_loss=155.85949707 time/batch=0.78s
11762/10943 (epoch 96.732) train_loss=109.76078796 time/batch=0.58s
11763/10943 (epoch 96.740) train_loss=135.18597412 time/batch=0.67s
11764/10943 (epoch 96.748) train_loss=137.39093018 time/batch=0.78s
11765/10943 (epoch 96.757) train_loss=158.61677551 time/batch=0.84s
11766/10943 (epoch 96.765) train_loss=129.12942505 time/batch=0.75s
11767/10943 (epoch 96.773) train_loss=158.39138794 time/batch=0.82s
11768/10943 (epoch 96.781) train_loss=143.84948730 time/batch=0.78s
11769/10943 (epoch 96.790) train_loss=116.28688049 time/batch=0.62s
11770/10943 (epoch 96.798) train_loss=134.70231628 time/batch=0.76s
11771/10943 (epoch 96.806) train_loss=98.94979858 time/batch=0.59s
11772/10943 (epoch 96.814) train_loss=117.20075226 time/batch=0.59s
11773/10943 (epoch 96.822) train_loss=123.06973267 time/batch=0.78s
setting learning rate to 0.0011319
11774/10943 (epoch 96.831) train_loss=83.77509308 time/batch=0.52s
11775/10943 (epoch 96.839) train_loss=346.96655273 time/batch=1.55s
11776/10943 (epoch 96.847) train_loss=551.09558105 time/batch=3.15s
11777/10943 (epoch 96.855) train_loss=69.52714539 time/batch=0.60s
11778/10943 (epoch 96.864) train_loss=71.93635559 time/batch=0.34s
11779/10943 (epoch 96.872) train_loss=184.02508545 time/batch=0.88s
11780/10943 (epoch 96.880) train_loss=316.89791870 time/batch=1.62s
11781/10943 (epoch 96.888) train_loss=180.18983459 time/batch=0.98s
11782/10943 (epoch 96.896) train_loss=124.40618134 time/batch=0.68s
11783/10943 (epoch 96.905) train_loss=192.86140442 time/batch=0.95s
11784/10943 (epoch 96.913) train_loss=95.71483612 time/batch=0.56s
11785/10943 (epoch 96.921) train_loss=65.97290039 time/batch=0.31s
11786/10943 (epoch 96.929) train_loss=196.72721863 time/batch=0.95s
11787/10943 (epoch 96.938) train_loss=274.65374756 time/batch=1.26s
11788/10943 (epoch 96.946) train_loss=172.73777771 time/batch=0.94s
11789/10943 (epoch 96.954) train_loss=282.67608643 time/batch=1.38s
11790/10943 (epoch 96.962) train_loss=112.51403046 time/batch=0.69s
11791/10943 (epoch 96.970) train_loss=96.56748199 time/batch=0.52s
11792/10943 (epoch 96.979) train_loss=122.48106384 time/batch=0.77s
11793/10943 (epoch 96.987) train_loss=224.32891846 time/batch=1.07s
11794/10943 (epoch 96.995) train_loss=142.01232910 time/batch=0.77s
11795/10943 (epoch 97.003) train_loss=101.23594666 time/batch=0.58s
11796/10943 (epoch 97.012) train_loss=54.70488358 time/batch=0.32s
11797/10943 (epoch 97.020) train_loss=77.93089294 time/batch=0.41s
11798/10943 (epoch 97.028) train_loss=136.85571289 time/batch=0.75s
11799/10943 (epoch 97.036) train_loss=83.31703186 time/batch=0.44s
11800/10943 (epoch 97.044) train_loss=280.45373535 time/batch=1.25s
11801/10943 (epoch 97.053) train_loss=139.38525391 time/batch=0.80s
11802/10943 (epoch 97.061) train_loss=70.61208344 time/batch=0.39s
11803/10943 (epoch 97.069) train_loss=144.61570740 time/batch=0.78s
11804/10943 (epoch 97.077) train_loss=219.70486450 time/batch=1.09s
11805/10943 (epoch 97.086) train_loss=278.12661743 time/batch=1.66s
11806/10943 (epoch 97.094) train_loss=167.73158264 time/batch=0.96s
11807/10943 (epoch 97.102) train_loss=122.13548279 time/batch=0.69s
11808/10943 (epoch 97.110) train_loss=164.36001587 time/batch=0.87s
11809/10943 (epoch 97.118) train_loss=129.42976379 time/batch=0.68s
11810/10943 (epoch 97.127) train_loss=67.04975891 time/batch=0.35s
11811/10943 (epoch 97.135) train_loss=148.56774902 time/batch=0.80s
11812/10943 (epoch 97.143) train_loss=122.43015289 time/batch=0.71s
11813/10943 (epoch 97.151) train_loss=247.11004639 time/batch=1.08s
11814/10943 (epoch 97.160) train_loss=77.10765076 time/batch=0.44s
11815/10943 (epoch 97.168) train_loss=233.66767883 time/batch=1.06s
11816/10943 (epoch 97.176) train_loss=149.92788696 time/batch=0.75s
11817/10943 (epoch 97.184) train_loss=81.05337524 time/batch=0.43s
11818/10943 (epoch 97.192) train_loss=85.96066284 time/batch=0.46s
11819/10943 (epoch 97.201) train_loss=204.07083130 time/batch=0.95s
11820/10943 (epoch 97.209) train_loss=99.49792480 time/batch=0.57s
11821/10943 (epoch 97.217) train_loss=106.58544922 time/batch=0.59s
11822/10943 (epoch 97.225) train_loss=82.91868591 time/batch=0.46s
11823/10943 (epoch 97.234) train_loss=236.35745239 time/batch=1.14s
11824/10943 (epoch 97.242) train_loss=266.54522705 time/batch=1.24s
11825/10943 (epoch 97.250) train_loss=106.12735748 time/batch=0.62s
11826/10943 (epoch 97.258) train_loss=143.09825134 time/batch=0.70s
11827/10943 (epoch 97.267) train_loss=106.37737274 time/batch=0.60s
11828/10943 (epoch 97.275) train_loss=125.35580444 time/batch=0.68s
11829/10943 (epoch 97.283) train_loss=219.92062378 time/batch=1.02s
11830/10943 (epoch 97.291) train_loss=123.54663086 time/batch=0.69s
11831/10943 (epoch 97.299) train_loss=86.11381531 time/batch=0.46s
11832/10943 (epoch 97.308) train_loss=57.86504745 time/batch=0.31s
11833/10943 (epoch 97.316) train_loss=105.41654968 time/batch=0.56s
11834/10943 (epoch 97.324) train_loss=192.84063721 time/batch=0.94s
11835/10943 (epoch 97.332) train_loss=271.25683594 time/batch=1.69s
11836/10943 (epoch 97.341) train_loss=98.03762817 time/batch=0.62s
11837/10943 (epoch 97.349) train_loss=98.21147156 time/batch=0.50s
11838/10943 (epoch 97.357) train_loss=130.51541138 time/batch=0.70s
11839/10943 (epoch 97.365) train_loss=65.50756073 time/batch=0.34s
11840/10943 (epoch 97.373) train_loss=161.80883789 time/batch=0.79s
11841/10943 (epoch 97.382) train_loss=92.00352478 time/batch=0.51s
11842/10943 (epoch 97.390) train_loss=133.55413818 time/batch=0.70s
11843/10943 (epoch 97.398) train_loss=75.09814453 time/batch=0.42s
11844/10943 (epoch 97.406) train_loss=73.69427490 time/batch=0.38s
11845/10943 (epoch 97.415) train_loss=205.18585205 time/batch=1.08s
11846/10943 (epoch 97.423) train_loss=164.00796509 time/batch=0.90s
11847/10943 (epoch 97.431) train_loss=89.54312897 time/batch=0.52s
11848/10943 (epoch 97.439) train_loss=137.51110840 time/batch=0.72s
11849/10943 (epoch 97.447) train_loss=112.42270660 time/batch=0.61s
11850/10943 (epoch 97.456) train_loss=175.96302795 time/batch=0.88s
11851/10943 (epoch 97.464) train_loss=130.89849854 time/batch=0.72s
11852/10943 (epoch 97.472) train_loss=176.59416199 time/batch=0.91s
11853/10943 (epoch 97.480) train_loss=89.60639191 time/batch=0.50s
11854/10943 (epoch 97.489) train_loss=68.41789246 time/batch=0.34s
11855/10943 (epoch 97.497) train_loss=124.29374695 time/batch=0.69s
11856/10943 (epoch 97.505) train_loss=144.78283691 time/batch=0.77s
11857/10943 (epoch 97.513) train_loss=164.17947388 time/batch=0.91s
11858/10943 (epoch 97.521) train_loss=76.23546600 time/batch=0.42s
11859/10943 (epoch 97.530) train_loss=83.36439514 time/batch=0.40s
11860/10943 (epoch 97.538) train_loss=205.08166504 time/batch=0.97s
11861/10943 (epoch 97.546) train_loss=163.26196289 time/batch=0.86s
11862/10943 (epoch 97.554) train_loss=102.70179749 time/batch=0.56s
11863/10943 (epoch 97.563) train_loss=131.94587708 time/batch=0.75s
11864/10943 (epoch 97.571) train_loss=107.69035339 time/batch=0.58s
11865/10943 (epoch 97.579) train_loss=136.92713928 time/batch=0.75s
11866/10943 (epoch 97.587) train_loss=88.23091125 time/batch=0.53s
11867/10943 (epoch 97.595) train_loss=111.33747864 time/batch=0.57s
11868/10943 (epoch 97.604) train_loss=190.67922974 time/batch=0.95s
11869/10943 (epoch 97.612) train_loss=114.46752167 time/batch=0.61s
11870/10943 (epoch 97.620) train_loss=145.91998291 time/batch=0.78s
11871/10943 (epoch 97.628) train_loss=132.62686157 time/batch=0.70s
11872/10943 (epoch 97.637) train_loss=185.66828918 time/batch=0.93s
11873/10943 (epoch 97.645) train_loss=99.78018188 time/batch=0.55s
11874/10943 (epoch 97.653) train_loss=102.71118927 time/batch=0.53s
11875/10943 (epoch 97.661) train_loss=123.01095581 time/batch=0.64s
11876/10943 (epoch 97.669) train_loss=139.46641541 time/batch=0.80s
11877/10943 (epoch 97.678) train_loss=116.77925110 time/batch=0.67s
11878/10943 (epoch 97.686) train_loss=120.44001770 time/batch=0.63s
11879/10943 (epoch 97.694) train_loss=129.75556946 time/batch=0.73s
11880/10943 (epoch 97.702) train_loss=145.04037476 time/batch=0.75s
11881/10943 (epoch 97.711) train_loss=106.68931580 time/batch=0.61s
11882/10943 (epoch 97.719) train_loss=114.59210205 time/batch=0.62s
11883/10943 (epoch 97.727) train_loss=116.49878693 time/batch=0.62s
11884/10943 (epoch 97.735) train_loss=117.63983917 time/batch=0.66s
11885/10943 (epoch 97.744) train_loss=147.28057861 time/batch=0.80s
11886/10943 (epoch 97.752) train_loss=119.10012817 time/batch=0.64s
11887/10943 (epoch 97.760) train_loss=118.49211884 time/batch=0.60s
11888/10943 (epoch 97.768) train_loss=154.28192139 time/batch=0.80s
11889/10943 (epoch 97.776) train_loss=101.80664062 time/batch=0.59s
11890/10943 (epoch 97.785) train_loss=144.51641846 time/batch=0.75s
11891/10943 (epoch 97.793) train_loss=116.67868042 time/batch=0.68s
11892/10943 (epoch 97.801) train_loss=157.10424805 time/batch=0.81s
11893/10943 (epoch 97.809) train_loss=141.53228760 time/batch=0.82s
11894/10943 (epoch 97.818) train_loss=123.81291199 time/batch=0.69s
setting learning rate to 0.0010980
  saved to metadata/gru_no_dropout-9_nov_folkwiki-20181207-192453_epoch53.pkl
11895/10943 (epoch 97.826) train_loss=242.14367676 time/batch=1.28s
11896/10943 (epoch 97.834) train_loss=75.50019836 time/batch=0.44s
11897/10943 (epoch 97.842) train_loss=81.91600037 time/batch=0.40s
11898/10943 (epoch 97.850) train_loss=355.81777954 time/batch=1.56s
11899/10943 (epoch 97.859) train_loss=176.94522095 time/batch=1.02s
11900/10943 (epoch 97.867) train_loss=288.28289795 time/batch=1.31s
11901/10943 (epoch 97.875) train_loss=198.30474854 time/batch=1.01s
11902/10943 (epoch 97.883) train_loss=93.26144409 time/batch=0.51s
11903/10943 (epoch 97.892) train_loss=284.84414673 time/batch=1.31s
11904/10943 (epoch 97.900) train_loss=263.32910156 time/batch=1.41s
11905/10943 (epoch 97.908) train_loss=210.50045776 time/batch=1.07s
11906/10943 (epoch 97.916) train_loss=156.22854614 time/batch=0.86s
11907/10943 (epoch 97.924) train_loss=64.42384338 time/batch=0.33s
11908/10943 (epoch 97.933) train_loss=232.53457642 time/batch=1.31s
11909/10943 (epoch 97.941) train_loss=90.63406372 time/batch=0.62s
11910/10943 (epoch 97.949) train_loss=173.86032104 time/batch=0.87s
11911/10943 (epoch 97.957) train_loss=277.44949341 time/batch=1.44s
11912/10943 (epoch 97.966) train_loss=107.75133514 time/batch=0.70s
11913/10943 (epoch 97.974) train_loss=106.42740631 time/batch=0.61s
11914/10943 (epoch 97.982) train_loss=382.55960083 time/batch=1.82s
11915/10943 (epoch 97.990) train_loss=154.15707397 time/batch=0.99s
11916/10943 (epoch 97.998) train_loss=134.24499512 time/batch=0.82s
11917/10943 (epoch 98.007) train_loss=102.44738770 time/batch=0.56s
11918/10943 (epoch 98.015) train_loss=65.12152863 time/batch=0.35s
11919/10943 (epoch 98.023) train_loss=81.88695526 time/batch=0.46s
11920/10943 (epoch 98.031) train_loss=106.70094299 time/batch=0.61s
11921/10943 (epoch 98.040) train_loss=78.78605652 time/batch=0.44s
11922/10943 (epoch 98.048) train_loss=169.79280090 time/batch=0.84s
11923/10943 (epoch 98.056) train_loss=76.16573334 time/batch=0.48s
11924/10943 (epoch 98.064) train_loss=465.98880005 time/batch=3.03s
11925/10943 (epoch 98.072) train_loss=176.95780945 time/batch=1.12s
11926/10943 (epoch 98.081) train_loss=134.52670288 time/batch=0.73s
11927/10943 (epoch 98.089) train_loss=125.27872467 time/batch=0.69s
11928/10943 (epoch 98.097) train_loss=142.13958740 time/batch=0.71s
11929/10943 (epoch 98.105) train_loss=100.29896545 time/batch=0.54s
11930/10943 (epoch 98.114) train_loss=121.70183563 time/batch=0.64s
11931/10943 (epoch 98.122) train_loss=121.86853027 time/batch=0.65s
11932/10943 (epoch 98.130) train_loss=124.83692932 time/batch=0.77s
11933/10943 (epoch 98.138) train_loss=208.83493042 time/batch=1.02s
11934/10943 (epoch 98.146) train_loss=63.60214233 time/batch=0.35s
11935/10943 (epoch 98.155) train_loss=127.67768097 time/batch=0.74s
11936/10943 (epoch 98.163) train_loss=87.45733643 time/batch=0.50s
11937/10943 (epoch 98.171) train_loss=117.57205200 time/batch=0.66s
11938/10943 (epoch 98.179) train_loss=78.23014832 time/batch=0.48s
11939/10943 (epoch 98.188) train_loss=128.46664429 time/batch=0.73s
11940/10943 (epoch 98.196) train_loss=96.82510376 time/batch=0.53s
11941/10943 (epoch 98.204) train_loss=103.58507538 time/batch=0.61s
11942/10943 (epoch 98.212) train_loss=136.41290283 time/batch=0.76s
11943/10943 (epoch 98.221) train_loss=121.40270996 time/batch=0.67s
11944/10943 (epoch 98.229) train_loss=100.13002777 time/batch=0.55s
11945/10943 (epoch 98.237) train_loss=133.04327393 time/batch=0.71s
11946/10943 (epoch 98.245) train_loss=214.47067261 time/batch=1.05s
11947/10943 (epoch 98.253) train_loss=235.37564087 time/batch=1.11s
11948/10943 (epoch 98.262) train_loss=93.62559509 time/batch=0.53s
11949/10943 (epoch 98.270) train_loss=139.32876587 time/batch=0.77s
11950/10943 (epoch 98.278) train_loss=238.46820068 time/batch=1.12s
11951/10943 (epoch 98.286) train_loss=210.98503113 time/batch=1.03s
11952/10943 (epoch 98.295) train_loss=106.73884583 time/batch=0.64s
11953/10943 (epoch 98.303) train_loss=79.08326721 time/batch=0.42s
11954/10943 (epoch 98.311) train_loss=106.48525238 time/batch=0.57s
11955/10943 (epoch 98.319) train_loss=98.61788940 time/batch=0.51s
11956/10943 (epoch 98.327) train_loss=182.74520874 time/batch=0.94s
11957/10943 (epoch 98.336) train_loss=194.66226196 time/batch=0.99s
11958/10943 (epoch 98.344) train_loss=96.58409119 time/batch=0.60s
11959/10943 (epoch 98.352) train_loss=173.78991699 time/batch=0.90s
11960/10943 (epoch 98.360) train_loss=111.36441803 time/batch=0.64s
11961/10943 (epoch 98.369) train_loss=90.32181549 time/batch=0.48s
11962/10943 (epoch 98.377) train_loss=96.37847137 time/batch=0.54s
11963/10943 (epoch 98.385) train_loss=104.39665222 time/batch=0.56s
11964/10943 (epoch 98.393) train_loss=132.87924194 time/batch=0.73s
11965/10943 (epoch 98.401) train_loss=133.91523743 time/batch=0.72s
11966/10943 (epoch 98.410) train_loss=81.61576843 time/batch=0.46s
11967/10943 (epoch 98.418) train_loss=164.16210938 time/batch=0.83s
11968/10943 (epoch 98.426) train_loss=107.05857849 time/batch=0.61s
11969/10943 (epoch 98.434) train_loss=127.98199463 time/batch=0.66s
11970/10943 (epoch 98.443) train_loss=224.86270142 time/batch=1.09s
11971/10943 (epoch 98.451) train_loss=236.89895630 time/batch=1.16s
11972/10943 (epoch 98.459) train_loss=79.02188110 time/batch=0.46s
11973/10943 (epoch 98.467) train_loss=161.48120117 time/batch=0.85s
11974/10943 (epoch 98.475) train_loss=100.69700623 time/batch=0.56s
11975/10943 (epoch 98.484) train_loss=70.61325073 time/batch=0.36s
11976/10943 (epoch 98.492) train_loss=64.94422150 time/batch=0.30s
11977/10943 (epoch 98.500) train_loss=132.01264954 time/batch=0.75s
11978/10943 (epoch 98.508) train_loss=194.37953186 time/batch=0.99s
11979/10943 (epoch 98.517) train_loss=204.66436768 time/batch=1.04s
11980/10943 (epoch 98.525) train_loss=164.82168579 time/batch=0.93s
11981/10943 (epoch 98.533) train_loss=144.44876099 time/batch=0.76s
11982/10943 (epoch 98.541) train_loss=111.81031799 time/batch=0.61s
11983/10943 (epoch 98.549) train_loss=141.64428711 time/batch=0.77s
11984/10943 (epoch 98.558) train_loss=145.90905762 time/batch=0.75s
11985/10943 (epoch 98.566) train_loss=136.95581055 time/batch=0.76s
11986/10943 (epoch 98.574) train_loss=139.54724121 time/batch=0.74s
11987/10943 (epoch 98.582) train_loss=74.96490479 time/batch=0.40s
11988/10943 (epoch 98.591) train_loss=126.05299377 time/batch=0.64s
11989/10943 (epoch 98.599) train_loss=108.50900269 time/batch=0.63s
11990/10943 (epoch 98.607) train_loss=114.96029663 time/batch=0.63s
11991/10943 (epoch 98.615) train_loss=121.02911377 time/batch=0.69s
11992/10943 (epoch 98.623) train_loss=180.29483032 time/batch=1.13s
11993/10943 (epoch 98.632) train_loss=150.60122681 time/batch=0.87s
11994/10943 (epoch 98.640) train_loss=112.63936615 time/batch=0.61s
11995/10943 (epoch 98.648) train_loss=72.47397614 time/batch=0.38s
11996/10943 (epoch 98.656) train_loss=110.45216370 time/batch=0.58s
11997/10943 (epoch 98.665) train_loss=118.80650330 time/batch=0.63s
11998/10943 (epoch 98.673) train_loss=64.11033630 time/batch=0.32s
11999/10943 (epoch 98.681) train_loss=157.46499634 time/batch=0.79s
Validating
    loss:	319.261968

12000/10943 (epoch 98.689) train_loss=134.99861145 time/batch=2.57s
12001/10943 (epoch 98.698) train_loss=109.92282104 time/batch=0.60s
12002/10943 (epoch 98.706) train_loss=163.69764709 time/batch=0.82s
12003/10943 (epoch 98.714) train_loss=153.36907959 time/batch=0.82s
12004/10943 (epoch 98.722) train_loss=143.76324463 time/batch=0.79s
12005/10943 (epoch 98.730) train_loss=161.12776184 time/batch=0.82s
12006/10943 (epoch 98.739) train_loss=127.95106506 time/batch=0.71s
12007/10943 (epoch 98.747) train_loss=179.79833984 time/batch=1.14s
12008/10943 (epoch 98.755) train_loss=124.52738190 time/batch=0.69s
12009/10943 (epoch 98.763) train_loss=72.86506653 time/batch=0.34s
12010/10943 (epoch 98.772) train_loss=88.42266083 time/batch=0.46s
12011/10943 (epoch 98.780) train_loss=93.27542114 time/batch=0.49s
12012/10943 (epoch 98.788) train_loss=63.97354126 time/batch=0.37s
12013/10943 (epoch 98.796) train_loss=81.00080872 time/batch=0.49s
12014/10943 (epoch 98.804) train_loss=85.57757568 time/batch=0.51s
12015/10943 (epoch 98.813) train_loss=125.71293640 time/batch=0.72s
setting learning rate to 0.0010650
12016/10943 (epoch 98.821) train_loss=83.88282776 time/batch=0.49s
12017/10943 (epoch 98.829) train_loss=232.96279907 time/batch=1.12s
12018/10943 (epoch 98.837) train_loss=75.98872375 time/batch=0.49s
12019/10943 (epoch 98.846) train_loss=128.29382324 time/batch=0.72s
12020/10943 (epoch 98.854) train_loss=100.61654663 time/batch=0.61s
12021/10943 (epoch 98.862) train_loss=131.43869019 time/batch=0.73s
12022/10943 (epoch 98.870) train_loss=130.83767700 time/batch=0.74s
12023/10943 (epoch 98.878) train_loss=363.18603516 time/batch=1.64s
12024/10943 (epoch 98.887) train_loss=302.68151855 time/batch=1.46s
12025/10943 (epoch 98.895) train_loss=68.12197113 time/batch=0.38s
12026/10943 (epoch 98.903) train_loss=222.73495483 time/batch=0.95s
12027/10943 (epoch 98.911) train_loss=115.16922760 time/batch=0.69s
12028/10943 (epoch 98.920) train_loss=239.45443726 time/batch=1.08s
12029/10943 (epoch 98.928) train_loss=218.69306946 time/batch=1.10s
12030/10943 (epoch 98.936) train_loss=187.10665894 time/batch=0.99s
12031/10943 (epoch 98.944) train_loss=289.60858154 time/batch=1.38s
12032/10943 (epoch 98.952) train_loss=220.18943787 time/batch=1.17s
12033/10943 (epoch 98.961) train_loss=533.34265137 time/batch=3.10s
12034/10943 (epoch 98.969) train_loss=135.19662476 time/batch=0.93s
12035/10943 (epoch 98.977) train_loss=314.33471680 time/batch=1.64s
12036/10943 (epoch 98.985) train_loss=199.89138794 time/batch=1.14s
12037/10943 (epoch 98.994) train_loss=82.61480713 time/batch=0.49s
12038/10943 (epoch 99.002) train_loss=263.95852661 time/batch=1.21s
12039/10943 (epoch 99.010) train_loss=284.58877563 time/batch=1.72s
12040/10943 (epoch 99.018) train_loss=191.36825562 time/batch=1.07s
12041/10943 (epoch 99.026) train_loss=249.40115356 time/batch=1.21s
12042/10943 (epoch 99.035) train_loss=140.21072388 time/batch=0.82s
12043/10943 (epoch 99.043) train_loss=73.79867554 time/batch=0.42s
12044/10943 (epoch 99.051) train_loss=130.32672119 time/batch=0.68s
12045/10943 (epoch 99.059) train_loss=130.44180298 time/batch=0.80s
12046/10943 (epoch 99.068) train_loss=166.92520142 time/batch=0.90s
12047/10943 (epoch 99.076) train_loss=102.93360901 time/batch=0.60s
12048/10943 (epoch 99.084) train_loss=223.36509705 time/batch=1.14s
12049/10943 (epoch 99.092) train_loss=102.51246643 time/batch=0.69s
12050/10943 (epoch 99.100) train_loss=69.87376404 time/batch=0.40s
12051/10943 (epoch 99.109) train_loss=211.42544556 time/batch=1.11s
12052/10943 (epoch 99.117) train_loss=133.27738953 time/batch=0.78s
12053/10943 (epoch 99.125) train_loss=139.87123108 time/batch=0.83s
12054/10943 (epoch 99.133) train_loss=124.11418915 time/batch=0.76s
12055/10943 (epoch 99.142) train_loss=117.33113098 time/batch=0.71s
12056/10943 (epoch 99.150) train_loss=87.06477356 time/batch=0.49s
12057/10943 (epoch 99.158) train_loss=53.64218903 time/batch=0.29s
12058/10943 (epoch 99.166) train_loss=159.29655457 time/batch=0.83s
12059/10943 (epoch 99.175) train_loss=190.41125488 time/batch=1.01s
12060/10943 (epoch 99.183) train_loss=133.52813721 time/batch=0.82s
12061/10943 (epoch 99.191) train_loss=58.81930923 time/batch=0.35s
12062/10943 (epoch 99.199) train_loss=59.95969009 time/batch=0.30s
12063/10943 (epoch 99.207) train_loss=67.62745667 time/batch=0.35s
12064/10943 (epoch 99.216) train_loss=71.07135010 time/batch=0.34s
12065/10943 (epoch 99.224) train_loss=109.19042969 time/batch=0.61s
12066/10943 (epoch 99.232) train_loss=85.11494446 time/batch=0.48s
12067/10943 (epoch 99.240) train_loss=137.86840820 time/batch=0.67s
12068/10943 (epoch 99.249) train_loss=128.62655640 time/batch=0.70s
12069/10943 (epoch 99.257) train_loss=108.48294067 time/batch=0.62s
12070/10943 (epoch 99.265) train_loss=64.63082886 time/batch=0.35s
12071/10943 (epoch 99.273) train_loss=82.90714264 time/batch=0.47s
12072/10943 (epoch 99.281) train_loss=125.45957184 time/batch=0.71s
12073/10943 (epoch 99.290) train_loss=84.41850281 time/batch=0.43s
12074/10943 (epoch 99.298) train_loss=122.86520386 time/batch=0.63s
12075/10943 (epoch 99.306) train_loss=114.55441284 time/batch=0.62s
12076/10943 (epoch 99.314) train_loss=160.44680786 time/batch=0.85s
12077/10943 (epoch 99.323) train_loss=193.46536255 time/batch=0.95s
12078/10943 (epoch 99.331) train_loss=106.56969452 time/batch=0.59s
12079/10943 (epoch 99.339) train_loss=108.97579956 time/batch=0.60s
12080/10943 (epoch 99.347) train_loss=141.17932129 time/batch=0.79s
12081/10943 (epoch 99.355) train_loss=82.83477783 time/batch=0.49s
12082/10943 (epoch 99.364) train_loss=144.05194092 time/batch=0.82s
12083/10943 (epoch 99.372) train_loss=101.37672424 time/batch=0.55s
12084/10943 (epoch 99.380) train_loss=98.44550323 time/batch=0.50s
12085/10943 (epoch 99.388) train_loss=151.07804871 time/batch=0.81s
12086/10943 (epoch 99.397) train_loss=165.57427979 time/batch=0.85s
12087/10943 (epoch 99.405) train_loss=103.20919800 time/batch=0.61s
12088/10943 (epoch 99.413) train_loss=120.52166748 time/batch=0.65s
12089/10943 (epoch 99.421) train_loss=138.09591675 time/batch=0.75s
12090/10943 (epoch 99.429) train_loss=167.03276062 time/batch=0.89s
12091/10943 (epoch 99.438) train_loss=78.38708496 time/batch=0.47s
12092/10943 (epoch 99.446) train_loss=108.71768951 time/batch=0.52s
12093/10943 (epoch 99.454) train_loss=65.60774231 time/batch=0.32s
12094/10943 (epoch 99.462) train_loss=116.17869568 time/batch=0.66s
12095/10943 (epoch 99.471) train_loss=88.66775513 time/batch=0.51s
12096/10943 (epoch 99.479) train_loss=104.67587280 time/batch=0.60s
12097/10943 (epoch 99.487) train_loss=125.48412323 time/batch=0.75s
12098/10943 (epoch 99.495) train_loss=175.82733154 time/batch=0.91s
12099/10943 (epoch 99.503) train_loss=119.76504517 time/batch=0.66s
12100/10943 (epoch 99.512) train_loss=234.84220886 time/batch=1.18s
12101/10943 (epoch 99.520) train_loss=82.75135803 time/batch=0.51s
12102/10943 (epoch 99.528) train_loss=111.25836182 time/batch=0.57s
12103/10943 (epoch 99.536) train_loss=98.14276123 time/batch=0.51s
12104/10943 (epoch 99.545) train_loss=96.54470825 time/batch=0.51s
12105/10943 (epoch 99.553) train_loss=139.40380859 time/batch=0.77s
12106/10943 (epoch 99.561) train_loss=146.10211182 time/batch=0.82s
12107/10943 (epoch 99.569) train_loss=168.50582886 time/batch=0.91s
12108/10943 (epoch 99.577) train_loss=113.34535217 time/batch=0.62s
12109/10943 (epoch 99.586) train_loss=98.52226257 time/batch=0.55s
12110/10943 (epoch 99.594) train_loss=68.81752014 time/batch=0.35s
12111/10943 (epoch 99.602) train_loss=71.46708679 time/batch=0.34s
12112/10943 (epoch 99.610) train_loss=112.90786743 time/batch=0.61s
12113/10943 (epoch 99.619) train_loss=107.36470032 time/batch=0.59s
12114/10943 (epoch 99.627) train_loss=105.15873718 time/batch=0.55s
12115/10943 (epoch 99.635) train_loss=90.47764587 time/batch=0.48s
12116/10943 (epoch 99.643) train_loss=155.68511963 time/batch=0.88s
12117/10943 (epoch 99.652) train_loss=111.00381470 time/batch=0.62s
12118/10943 (epoch 99.660) train_loss=101.02157593 time/batch=0.54s
12119/10943 (epoch 99.668) train_loss=190.92504883 time/batch=0.92s
12120/10943 (epoch 99.676) train_loss=83.20143127 time/batch=0.53s
12121/10943 (epoch 99.684) train_loss=131.05462646 time/batch=0.66s
12122/10943 (epoch 99.693) train_loss=132.03434753 time/batch=0.66s
12123/10943 (epoch 99.701) train_loss=144.06867981 time/batch=0.81s
12124/10943 (epoch 99.709) train_loss=158.45935059 time/batch=0.83s
12125/10943 (epoch 99.717) train_loss=159.58435059 time/batch=0.79s
12126/10943 (epoch 99.726) train_loss=140.59977722 time/batch=0.79s
12127/10943 (epoch 99.734) train_loss=169.40042114 time/batch=0.92s
12128/10943 (epoch 99.742) train_loss=133.76382446 time/batch=0.71s
12129/10943 (epoch 99.750) train_loss=201.38513184 time/batch=0.96s
12130/10943 (epoch 99.758) train_loss=143.72230530 time/batch=0.85s
12131/10943 (epoch 99.767) train_loss=135.24627686 time/batch=0.82s
12132/10943 (epoch 99.775) train_loss=161.58424377 time/batch=0.92s
12133/10943 (epoch 99.783) train_loss=97.92306519 time/batch=0.53s
12134/10943 (epoch 99.791) train_loss=94.03112793 time/batch=0.51s
12135/10943 (epoch 99.800) train_loss=121.13735962 time/batch=0.64s
12136/10943 (epoch 99.808) train_loss=92.99102020 time/batch=0.56s
setting learning rate to 0.0010331
  saved to metadata/gru_no_dropout-9_nov_folkwiki-20181207-192453_epoch55.pkl
12137/10943 (epoch 99.816) train_loss=131.72744751 time/batch=0.86s
12138/10943 (epoch 99.824) train_loss=126.78225708 time/batch=0.81s
12139/10943 (epoch 99.832) train_loss=149.04006958 time/batch=0.93s
12140/10943 (epoch 99.841) train_loss=134.92018127 time/batch=0.87s
12141/10943 (epoch 99.849) train_loss=210.64837646 time/batch=1.02s
12142/10943 (epoch 99.857) train_loss=469.09484863 time/batch=2.38s
12143/10943 (epoch 99.865) train_loss=97.35383606 time/batch=0.68s
12144/10943 (epoch 99.874) train_loss=102.75688934 time/batch=0.57s
12145/10943 (epoch 99.882) train_loss=182.35446167 time/batch=0.93s
12146/10943 (epoch 99.890) train_loss=141.12243652 time/batch=0.79s
12147/10943 (epoch 99.898) train_loss=109.86251831 time/batch=0.64s
12148/10943 (epoch 99.906) train_loss=107.68046570 time/batch=0.69s
12149/10943 (epoch 99.915) train_loss=200.61584473 time/batch=1.01s
12150/10943 (epoch 99.923) train_loss=191.62574768 time/batch=1.06s
12151/10943 (epoch 99.931) train_loss=167.97964478 time/batch=0.91s
12152/10943 (epoch 99.939) train_loss=151.25296021 time/batch=0.88s
12153/10943 (epoch 99.948) train_loss=276.02459717 time/batch=1.33s
12154/10943 (epoch 99.956) train_loss=229.40782166 time/batch=1.13s
12155/10943 (epoch 99.964) train_loss=287.96032715 time/batch=1.28s
12156/10943 (epoch 99.972) train_loss=109.40617371 time/batch=0.70s
12157/10943 (epoch 99.980) train_loss=53.57733917 time/batch=0.28s
12158/10943 (epoch 99.989) train_loss=229.95492554 time/batch=1.06s
12159/10943 (epoch 99.997) train_loss=148.53552246 time/batch=0.86s
12160/10943 (epoch 100.005) train_loss=178.53585815 time/batch=0.98s
12161/10943 (epoch 100.013) train_loss=103.43946838 time/batch=0.62s
12162/10943 (epoch 100.022) train_loss=296.31796265 time/batch=1.46s
12163/10943 (epoch 100.030) train_loss=143.06326294 time/batch=0.87s
12164/10943 (epoch 100.038) train_loss=121.40768433 time/batch=0.69s
12165/10943 (epoch 100.046) train_loss=99.89075470 time/batch=0.59s
12166/10943 (epoch 100.054) train_loss=140.62463379 time/batch=0.80s
12167/10943 (epoch 100.063) train_loss=237.73738098 time/batch=1.18s
12168/10943 (epoch 100.071) train_loss=83.79399109 time/batch=0.53s
12169/10943 (epoch 100.079) train_loss=61.68132019 time/batch=0.30s
12170/10943 (epoch 100.087) train_loss=64.24034119 time/batch=0.33s
12171/10943 (epoch 100.096) train_loss=75.31450653 time/batch=0.40s
12172/10943 (epoch 100.104) train_loss=95.91033173 time/batch=0.51s
12173/10943 (epoch 100.112) train_loss=147.18322754 time/batch=0.81s
12174/10943 (epoch 100.120) train_loss=70.03129578 time/batch=0.41s
12175/10943 (epoch 100.129) train_loss=96.02009583 time/batch=0.52s
12176/10943 (epoch 100.137) train_loss=63.88888168 time/batch=0.36s
12177/10943 (epoch 100.145) train_loss=71.02835846 time/batch=0.36s
12178/10943 (epoch 100.153) train_loss=198.33389282 time/batch=0.93s
12179/10943 (epoch 100.161) train_loss=121.90792847 time/batch=0.72s
12180/10943 (epoch 100.170) train_loss=232.05462646 time/batch=1.14s
12181/10943 (epoch 100.178) train_loss=171.12895203 time/batch=0.97s
12182/10943 (epoch 100.186) train_loss=198.47909546 time/batch=1.05s
12183/10943 (epoch 100.194) train_loss=194.23425293 time/batch=0.98s
12184/10943 (epoch 100.203) train_loss=140.97967529 time/batch=0.76s
12185/10943 (epoch 100.211) train_loss=89.48149109 time/batch=0.49s
12186/10943 (epoch 100.219) train_loss=81.55059814 time/batch=0.42s
12187/10943 (epoch 100.227) train_loss=60.92863464 time/batch=0.29s
12188/10943 (epoch 100.235) train_loss=107.38882446 time/batch=0.53s
12189/10943 (epoch 100.244) train_loss=113.66189575 time/batch=0.67s
12190/10943 (epoch 100.252) train_loss=276.52276611 time/batch=1.36s
12191/10943 (epoch 100.260) train_loss=87.70443726 time/batch=0.52s
12192/10943 (epoch 100.268) train_loss=119.40959930 time/batch=0.63s
12193/10943 (epoch 100.277) train_loss=441.45516968 time/batch=3.06s
12194/10943 (epoch 100.285) train_loss=106.46451569 time/batch=0.81s
12195/10943 (epoch 100.293) train_loss=144.26199341 time/batch=0.74s
12196/10943 (epoch 100.301) train_loss=79.90896606 time/batch=0.50s
12197/10943 (epoch 100.309) train_loss=177.49153137 time/batch=0.87s
12198/10943 (epoch 100.318) train_loss=75.02001953 time/batch=0.41s
12199/10943 (epoch 100.326) train_loss=139.22760010 time/batch=0.74s
12200/10943 (epoch 100.334) train_loss=254.12831116 time/batch=1.38s
12201/10943 (epoch 100.342) train_loss=72.26216125 time/batch=0.46s
12202/10943 (epoch 100.351) train_loss=257.37792969 time/batch=1.49s
12203/10943 (epoch 100.359) train_loss=251.00250244 time/batch=1.17s
12204/10943 (epoch 100.367) train_loss=110.74639893 time/batch=0.66s
12205/10943 (epoch 100.375) train_loss=127.79129791 time/batch=0.66s
12206/10943 (epoch 100.383) train_loss=107.58802032 time/batch=0.60s
12207/10943 (epoch 100.392) train_loss=106.13494110 time/batch=0.63s
12208/10943 (epoch 100.400) train_loss=74.94110107 time/batch=0.41s
12209/10943 (epoch 100.408) train_loss=101.30276489 time/batch=0.52s
12210/10943 (epoch 100.416) train_loss=220.55264282 time/batch=1.06s
12211/10943 (epoch 100.425) train_loss=98.92996216 time/batch=0.63s
12212/10943 (epoch 100.433) train_loss=86.26022339 time/batch=0.49s
12213/10943 (epoch 100.441) train_loss=154.23686218 time/batch=0.87s
12214/10943 (epoch 100.449) train_loss=122.19946289 time/batch=0.67s
12215/10943 (epoch 100.457) train_loss=95.60975647 time/batch=0.53s
12216/10943 (epoch 100.466) train_loss=131.27287292 time/batch=0.68s
12217/10943 (epoch 100.474) train_loss=138.92097473 time/batch=0.74s
12218/10943 (epoch 100.482) train_loss=61.08952713 time/batch=0.34s
12219/10943 (epoch 100.490) train_loss=122.67149353 time/batch=0.66s
12220/10943 (epoch 100.499) train_loss=72.26524353 time/batch=0.42s
12221/10943 (epoch 100.507) train_loss=125.95048523 time/batch=0.71s
12222/10943 (epoch 100.515) train_loss=171.85240173 time/batch=1.03s
12223/10943 (epoch 100.523) train_loss=169.86669922 time/batch=0.92s
12224/10943 (epoch 100.531) train_loss=142.97253418 time/batch=0.78s
12225/10943 (epoch 100.540) train_loss=100.63765717 time/batch=0.60s
12226/10943 (epoch 100.548) train_loss=123.20908356 time/batch=0.76s
12227/10943 (epoch 100.556) train_loss=94.90454865 time/batch=0.56s
12228/10943 (epoch 100.564) train_loss=64.79718018 time/batch=0.33s
12229/10943 (epoch 100.573) train_loss=142.60882568 time/batch=0.66s
12230/10943 (epoch 100.581) train_loss=144.06697083 time/batch=0.75s
12231/10943 (epoch 100.589) train_loss=110.27137756 time/batch=0.63s
12232/10943 (epoch 100.597) train_loss=107.21822357 time/batch=0.57s
12233/10943 (epoch 100.605) train_loss=125.24081421 time/batch=0.65s
12234/10943 (epoch 100.614) train_loss=88.46761322 time/batch=0.51s
12235/10943 (epoch 100.622) train_loss=129.85855103 time/batch=0.78s
12236/10943 (epoch 100.630) train_loss=88.94699097 time/batch=0.52s
12237/10943 (epoch 100.638) train_loss=89.52326965 time/batch=0.48s
12238/10943 (epoch 100.647) train_loss=124.62695312 time/batch=0.64s
12239/10943 (epoch 100.655) train_loss=136.85052490 time/batch=0.70s
12240/10943 (epoch 100.663) train_loss=86.63167572 time/batch=0.45s
12241/10943 (epoch 100.671) train_loss=135.73207092 time/batch=0.75s
12242/10943 (epoch 100.680) train_loss=98.88673401 time/batch=0.53s
12243/10943 (epoch 100.688) train_loss=120.14424133 time/batch=0.61s
12244/10943 (epoch 100.696) train_loss=136.15470886 time/batch=0.81s
12245/10943 (epoch 100.704) train_loss=155.42794800 time/batch=0.87s
12246/10943 (epoch 100.712) train_loss=114.00099182 time/batch=0.64s
12247/10943 (epoch 100.721) train_loss=139.43679810 time/batch=0.71s
12248/10943 (epoch 100.729) train_loss=110.24158478 time/batch=0.61s
12249/10943 (epoch 100.737) train_loss=103.57236481 time/batch=0.59s
12250/10943 (epoch 100.745) train_loss=157.34722900 time/batch=0.82s
12251/10943 (epoch 100.754) train_loss=73.98094940 time/batch=0.46s
12252/10943 (epoch 100.762) train_loss=155.15983582 time/batch=0.79s
12253/10943 (epoch 100.770) train_loss=94.70965576 time/batch=0.53s
12254/10943 (epoch 100.778) train_loss=138.92611694 time/batch=0.77s
12255/10943 (epoch 100.786) train_loss=100.15911865 time/batch=0.63s
12256/10943 (epoch 100.795) train_loss=111.93225861 time/batch=0.63s
12257/10943 (epoch 100.803) train_loss=125.40580750 time/batch=0.71s
setting learning rate to 0.0010021
12258/10943 (epoch 100.811) train_loss=181.58474731 time/batch=0.95s
12259/10943 (epoch 100.819) train_loss=102.93505859 time/batch=0.63s
12260/10943 (epoch 100.828) train_loss=118.97316742 time/batch=0.65s
12261/10943 (epoch 100.836) train_loss=240.38487244 time/batch=1.19s
12262/10943 (epoch 100.844) train_loss=243.56805420 time/batch=1.14s
12263/10943 (epoch 100.852) train_loss=221.27206421 time/batch=1.13s
12264/10943 (epoch 100.860) train_loss=122.52442932 time/batch=0.70s
12265/10943 (epoch 100.869) train_loss=214.61093140 time/batch=1.05s
12266/10943 (epoch 100.877) train_loss=87.67929840 time/batch=0.52s
12267/10943 (epoch 100.885) train_loss=68.59558105 time/batch=0.41s
12268/10943 (epoch 100.893) train_loss=223.22103882 time/batch=1.13s
12269/10943 (epoch 100.902) train_loss=275.18145752 time/batch=1.39s
12270/10943 (epoch 100.910) train_loss=69.71246338 time/batch=0.46s
12271/10943 (epoch 100.918) train_loss=282.72369385 time/batch=1.42s
12272/10943 (epoch 100.926) train_loss=186.76988220 time/batch=1.05s
12273/10943 (epoch 100.934) train_loss=71.16688538 time/batch=0.41s
12274/10943 (epoch 100.943) train_loss=136.55200195 time/batch=0.70s
12275/10943 (epoch 100.951) train_loss=336.61221313 time/batch=1.58s
12276/10943 (epoch 100.959) train_loss=109.52677155 time/batch=0.72s
12277/10943 (epoch 100.967) train_loss=193.20796204 time/batch=0.96s
12278/10943 (epoch 100.976) train_loss=58.43035889 time/batch=0.36s
12279/10943 (epoch 100.984) train_loss=515.85058594 time/batch=3.01s
12280/10943 (epoch 100.992) train_loss=70.22604370 time/batch=0.58s
12281/10943 (epoch 101.000) train_loss=277.64709473 time/batch=1.17s
12282/10943 (epoch 101.008) train_loss=338.83044434 time/batch=1.71s
12283/10943 (epoch 101.017) train_loss=166.71102905 time/batch=0.98s
12284/10943 (epoch 101.025) train_loss=131.35501099 time/batch=0.81s
12285/10943 (epoch 101.033) train_loss=86.39720154 time/batch=0.50s
12286/10943 (epoch 101.041) train_loss=106.40179443 time/batch=0.56s
12287/10943 (epoch 101.050) train_loss=132.41648865 time/batch=0.72s
12288/10943 (epoch 101.058) train_loss=116.54372406 time/batch=0.67s
12289/10943 (epoch 101.066) train_loss=185.75354004 time/batch=0.99s
12290/10943 (epoch 101.074) train_loss=128.62835693 time/batch=0.75s
12291/10943 (epoch 101.082) train_loss=72.76205444 time/batch=0.40s
12292/10943 (epoch 101.091) train_loss=137.05935669 time/batch=0.74s
12293/10943 (epoch 101.099) train_loss=145.77825928 time/batch=0.85s
12294/10943 (epoch 101.107) train_loss=83.87539673 time/batch=0.53s
12295/10943 (epoch 101.115) train_loss=167.12226868 time/batch=0.85s
12296/10943 (epoch 101.124) train_loss=277.89154053 time/batch=1.29s
12297/10943 (epoch 101.132) train_loss=95.29756165 time/batch=0.64s
12298/10943 (epoch 101.140) train_loss=234.46578979 time/batch=1.25s
12299/10943 (epoch 101.148) train_loss=196.21832275 time/batch=1.13s
12300/10943 (epoch 101.157) train_loss=128.50610352 time/batch=0.78s
12301/10943 (epoch 101.165) train_loss=126.80399323 time/batch=0.75s
12302/10943 (epoch 101.173) train_loss=228.91989136 time/batch=1.10s
12303/10943 (epoch 101.181) train_loss=128.66288757 time/batch=0.83s
12304/10943 (epoch 101.189) train_loss=84.10352325 time/batch=0.48s
12305/10943 (epoch 101.198) train_loss=92.45393372 time/batch=0.50s
12306/10943 (epoch 101.206) train_loss=160.75677490 time/batch=0.87s
12307/10943 (epoch 101.214) train_loss=91.86943054 time/batch=0.55s
12308/10943 (epoch 101.222) train_loss=72.18014526 time/batch=0.39s
12309/10943 (epoch 101.231) train_loss=179.94882202 time/batch=0.91s
12310/10943 (epoch 101.239) train_loss=130.60803223 time/batch=0.78s
12311/10943 (epoch 101.247) train_loss=94.93714142 time/batch=0.63s
12312/10943 (epoch 101.255) train_loss=170.42272949 time/batch=0.92s
12313/10943 (epoch 101.263) train_loss=125.41831207 time/batch=0.73s
12314/10943 (epoch 101.272) train_loss=76.38139343 time/batch=0.45s
12315/10943 (epoch 101.280) train_loss=101.50422668 time/batch=0.60s
12316/10943 (epoch 101.288) train_loss=158.39810181 time/batch=0.90s
12317/10943 (epoch 101.296) train_loss=116.61169434 time/batch=0.68s
12318/10943 (epoch 101.305) train_loss=117.23950195 time/batch=0.66s
12319/10943 (epoch 101.313) train_loss=101.17903137 time/batch=0.61s
12320/10943 (epoch 101.321) train_loss=101.29960632 time/batch=0.54s
12321/10943 (epoch 101.329) train_loss=62.75002670 time/batch=0.32s
12322/10943 (epoch 101.337) train_loss=131.01525879 time/batch=0.67s
12323/10943 (epoch 101.346) train_loss=190.86972046 time/batch=0.98s
12324/10943 (epoch 101.354) train_loss=84.28437805 time/batch=0.50s
12325/10943 (epoch 101.362) train_loss=107.20175171 time/batch=0.61s
12326/10943 (epoch 101.370) train_loss=198.71630859 time/batch=0.99s
12327/10943 (epoch 101.379) train_loss=132.53494263 time/batch=0.75s
12328/10943 (epoch 101.387) train_loss=120.26986694 time/batch=0.67s
12329/10943 (epoch 101.395) train_loss=90.83358765 time/batch=0.53s
12330/10943 (epoch 101.403) train_loss=171.40542603 time/batch=0.98s
12331/10943 (epoch 101.411) train_loss=125.18041992 time/batch=0.73s
12332/10943 (epoch 101.420) train_loss=114.04704285 time/batch=0.62s
12333/10943 (epoch 101.428) train_loss=134.19473267 time/batch=0.76s
12334/10943 (epoch 101.436) train_loss=65.30731964 time/batch=0.36s
12335/10943 (epoch 101.444) train_loss=66.58946228 time/batch=0.32s
12336/10943 (epoch 101.453) train_loss=71.10110474 time/batch=0.37s
12337/10943 (epoch 101.461) train_loss=133.31782532 time/batch=0.73s
12338/10943 (epoch 101.469) train_loss=75.21691895 time/batch=0.42s
12339/10943 (epoch 101.477) train_loss=150.77604675 time/batch=0.80s
12340/10943 (epoch 101.485) train_loss=96.85732269 time/batch=0.57s
12341/10943 (epoch 101.494) train_loss=71.43118286 time/batch=0.35s
12342/10943 (epoch 101.502) train_loss=137.05422974 time/batch=0.73s
12343/10943 (epoch 101.510) train_loss=56.17517853 time/batch=0.35s
12344/10943 (epoch 101.518) train_loss=147.55981445 time/batch=0.77s
12345/10943 (epoch 101.527) train_loss=141.75793457 time/batch=0.83s
12346/10943 (epoch 101.535) train_loss=140.86938477 time/batch=0.79s
12347/10943 (epoch 101.543) train_loss=196.61758423 time/batch=1.01s
12348/10943 (epoch 101.551) train_loss=91.00856018 time/batch=0.52s
12349/10943 (epoch 101.559) train_loss=106.69247437 time/batch=0.57s
12350/10943 (epoch 101.568) train_loss=68.20793915 time/batch=0.42s
12351/10943 (epoch 101.576) train_loss=104.03795624 time/batch=0.56s
12352/10943 (epoch 101.584) train_loss=95.41234589 time/batch=0.56s
12353/10943 (epoch 101.592) train_loss=101.48552704 time/batch=0.55s
12354/10943 (epoch 101.601) train_loss=81.27215576 time/batch=0.44s
12355/10943 (epoch 101.609) train_loss=150.96221924 time/batch=0.79s
12356/10943 (epoch 101.617) train_loss=72.19869995 time/batch=0.47s
12357/10943 (epoch 101.625) train_loss=130.92239380 time/batch=0.77s
12358/10943 (epoch 101.634) train_loss=132.72891235 time/batch=0.80s
12359/10943 (epoch 101.642) train_loss=95.60258484 time/batch=0.57s
12360/10943 (epoch 101.650) train_loss=141.54907227 time/batch=0.83s
12361/10943 (epoch 101.658) train_loss=90.84042358 time/batch=0.52s
12362/10943 (epoch 101.666) train_loss=122.79289246 time/batch=0.66s
12363/10943 (epoch 101.675) train_loss=101.26248169 time/batch=0.58s
12364/10943 (epoch 101.683) train_loss=152.10530090 time/batch=0.82s
12365/10943 (epoch 101.691) train_loss=94.46804047 time/batch=0.55s
12366/10943 (epoch 101.699) train_loss=157.82473755 time/batch=0.83s
12367/10943 (epoch 101.708) train_loss=88.14710999 time/batch=0.52s
12368/10943 (epoch 101.716) train_loss=125.91903687 time/batch=0.65s
12369/10943 (epoch 101.724) train_loss=119.66935730 time/batch=0.69s
12370/10943 (epoch 101.732) train_loss=117.38047791 time/batch=0.67s
12371/10943 (epoch 101.740) train_loss=148.88237000 time/batch=0.82s
12372/10943 (epoch 101.749) train_loss=116.60768127 time/batch=0.80s
12373/10943 (epoch 101.757) train_loss=94.40962219 time/batch=0.59s
12374/10943 (epoch 101.765) train_loss=123.26560974 time/batch=0.65s
12375/10943 (epoch 101.773) train_loss=107.22550964 time/batch=0.61s
12376/10943 (epoch 101.782) train_loss=147.17590332 time/batch=0.84s
12377/10943 (epoch 101.790) train_loss=114.02087402 time/batch=0.63s
12378/10943 (epoch 101.798) train_loss=105.09127045 time/batch=0.59s
setting learning rate to 0.0009720
  saved to metadata/gru_no_dropout-9_nov_folkwiki-20181207-192453_epoch57.pkl
12379/10943 (epoch 101.806) train_loss=65.79020691 time/batch=0.47s
12380/10943 (epoch 101.814) train_loss=187.04290771 time/batch=1.00s
12381/10943 (epoch 101.823) train_loss=127.33226013 time/batch=0.90s
12382/10943 (epoch 101.831) train_loss=61.45996094 time/batch=0.34s
12383/10943 (epoch 101.839) train_loss=171.91616821 time/batch=0.88s
12384/10943 (epoch 101.847) train_loss=272.68502808 time/batch=1.32s
12385/10943 (epoch 101.856) train_loss=110.95226288 time/batch=0.68s
12386/10943 (epoch 101.864) train_loss=112.53244781 time/batch=0.66s
12387/10943 (epoch 101.872) train_loss=224.09257507 time/batch=1.07s
12388/10943 (epoch 101.880) train_loss=98.57392120 time/batch=0.61s
12389/10943 (epoch 101.888) train_loss=87.26522827 time/batch=0.49s
12390/10943 (epoch 101.897) train_loss=128.59614563 time/batch=0.74s
12391/10943 (epoch 101.905) train_loss=498.47082520 time/batch=3.06s
12392/10943 (epoch 101.913) train_loss=249.67654419 time/batch=1.35s
12393/10943 (epoch 101.921) train_loss=120.74777222 time/batch=0.73s
12394/10943 (epoch 101.930) train_loss=138.57566833 time/batch=0.74s
12395/10943 (epoch 101.938) train_loss=80.35626984 time/batch=0.44s
12396/10943 (epoch 101.946) train_loss=58.35332489 time/batch=0.29s
12397/10943 (epoch 101.954) train_loss=112.85213470 time/batch=0.61s
12398/10943 (epoch 101.962) train_loss=363.83978271 time/batch=1.66s
12399/10943 (epoch 101.971) train_loss=57.50116730 time/batch=0.45s
12400/10943 (epoch 101.979) train_loss=269.47030640 time/batch=1.21s
12401/10943 (epoch 101.987) train_loss=97.30119324 time/batch=0.63s
12402/10943 (epoch 101.995) train_loss=125.74738312 time/batch=0.70s
12403/10943 (epoch 102.004) train_loss=232.73039246 time/batch=1.13s
12404/10943 (epoch 102.012) train_loss=139.92819214 time/batch=0.81s
12405/10943 (epoch 102.020) train_loss=98.19110107 time/batch=0.63s
12406/10943 (epoch 102.028) train_loss=71.61170959 time/batch=0.40s
12407/10943 (epoch 102.036) train_loss=306.66461182 time/batch=1.50s
12408/10943 (epoch 102.045) train_loss=265.77795410 time/batch=1.41s
12409/10943 (epoch 102.053) train_loss=237.41275024 time/batch=1.17s
12410/10943 (epoch 102.061) train_loss=77.93656921 time/batch=0.51s
12411/10943 (epoch 102.069) train_loss=125.56265259 time/batch=0.72s
12412/10943 (epoch 102.078) train_loss=82.15838623 time/batch=0.48s
12413/10943 (epoch 102.086) train_loss=237.19934082 time/batch=1.16s
12414/10943 (epoch 102.094) train_loss=237.91625977 time/batch=1.40s
12415/10943 (epoch 102.102) train_loss=128.77871704 time/batch=0.85s
12416/10943 (epoch 102.111) train_loss=179.01678467 time/batch=0.97s
12417/10943 (epoch 102.119) train_loss=83.23390198 time/batch=0.52s
12418/10943 (epoch 102.127) train_loss=90.15945435 time/batch=0.49s
12419/10943 (epoch 102.135) train_loss=61.39324570 time/batch=0.32s
12420/10943 (epoch 102.143) train_loss=138.84417725 time/batch=0.81s
12421/10943 (epoch 102.152) train_loss=186.94592285 time/batch=0.96s
12422/10943 (epoch 102.160) train_loss=91.45088196 time/batch=0.57s
12423/10943 (epoch 102.168) train_loss=126.14418793 time/batch=0.75s
12424/10943 (epoch 102.176) train_loss=188.42472839 time/batch=0.97s
12425/10943 (epoch 102.185) train_loss=152.67706299 time/batch=0.89s
12426/10943 (epoch 102.193) train_loss=264.38916016 time/batch=1.43s
12427/10943 (epoch 102.201) train_loss=76.19876099 time/batch=0.46s
12428/10943 (epoch 102.209) train_loss=100.92185974 time/batch=0.56s
12429/10943 (epoch 102.217) train_loss=124.94468689 time/batch=0.70s
12430/10943 (epoch 102.226) train_loss=209.09745789 time/batch=1.07s
12431/10943 (epoch 102.234) train_loss=79.74023438 time/batch=0.50s
12432/10943 (epoch 102.242) train_loss=136.72334290 time/batch=0.70s
12433/10943 (epoch 102.250) train_loss=142.81246948 time/batch=0.82s
12434/10943 (epoch 102.259) train_loss=81.62564087 time/batch=0.53s
12435/10943 (epoch 102.267) train_loss=137.68623352 time/batch=0.81s
12436/10943 (epoch 102.275) train_loss=115.94046021 time/batch=0.71s
12437/10943 (epoch 102.283) train_loss=195.68978882 time/batch=0.98s
12438/10943 (epoch 102.291) train_loss=108.65970612 time/batch=0.61s
12439/10943 (epoch 102.300) train_loss=164.44123840 time/batch=0.89s
12440/10943 (epoch 102.308) train_loss=139.06323242 time/batch=0.81s
12441/10943 (epoch 102.316) train_loss=170.30004883 time/batch=0.95s
12442/10943 (epoch 102.324) train_loss=229.14440918 time/batch=1.13s
12443/10943 (epoch 102.333) train_loss=76.37124634 time/batch=0.49s
12444/10943 (epoch 102.341) train_loss=88.52784729 time/batch=0.49s
12445/10943 (epoch 102.349) train_loss=129.99291992 time/batch=0.77s
12446/10943 (epoch 102.357) train_loss=57.72060013 time/batch=0.35s
12447/10943 (epoch 102.365) train_loss=105.20887756 time/batch=0.59s
12448/10943 (epoch 102.374) train_loss=75.16218567 time/batch=0.44s
12449/10943 (epoch 102.382) train_loss=118.56875610 time/batch=0.63s
12450/10943 (epoch 102.390) train_loss=169.66824341 time/batch=0.87s
12451/10943 (epoch 102.398) train_loss=121.34223938 time/batch=0.71s
12452/10943 (epoch 102.407) train_loss=130.45761108 time/batch=0.77s
12453/10943 (epoch 102.415) train_loss=86.77667999 time/batch=0.50s
12454/10943 (epoch 102.423) train_loss=130.48565674 time/batch=0.72s
12455/10943 (epoch 102.431) train_loss=95.68046570 time/batch=0.59s
12456/10943 (epoch 102.439) train_loss=186.83485413 time/batch=0.97s
12457/10943 (epoch 102.448) train_loss=69.19708252 time/batch=0.42s
12458/10943 (epoch 102.456) train_loss=170.37008667 time/batch=0.87s
12459/10943 (epoch 102.464) train_loss=102.05410767 time/batch=0.64s
12460/10943 (epoch 102.472) train_loss=137.72988892 time/batch=0.70s
12461/10943 (epoch 102.481) train_loss=117.35700226 time/batch=0.64s
12462/10943 (epoch 102.489) train_loss=102.76229858 time/batch=0.54s
12463/10943 (epoch 102.497) train_loss=150.73348999 time/batch=0.83s
12464/10943 (epoch 102.505) train_loss=88.08541107 time/batch=0.52s
12465/10943 (epoch 102.513) train_loss=179.96099854 time/batch=0.97s
12466/10943 (epoch 102.522) train_loss=121.00579071 time/batch=0.69s
12467/10943 (epoch 102.530) train_loss=150.27035522 time/batch=0.83s
12468/10943 (epoch 102.538) train_loss=118.98649597 time/batch=0.72s
12469/10943 (epoch 102.546) train_loss=99.39717102 time/batch=0.54s
12470/10943 (epoch 102.555) train_loss=64.18928528 time/batch=0.36s
12471/10943 (epoch 102.563) train_loss=104.54966736 time/batch=0.57s
12472/10943 (epoch 102.571) train_loss=140.56039429 time/batch=0.81s
12473/10943 (epoch 102.579) train_loss=133.98492432 time/batch=0.72s
12474/10943 (epoch 102.588) train_loss=102.91580200 time/batch=0.60s
12475/10943 (epoch 102.596) train_loss=81.57405090 time/batch=0.45s
12476/10943 (epoch 102.604) train_loss=91.65045166 time/batch=0.50s
12477/10943 (epoch 102.612) train_loss=82.60171509 time/batch=0.46s
12478/10943 (epoch 102.620) train_loss=103.66790009 time/batch=0.61s
12479/10943 (epoch 102.629) train_loss=102.09865570 time/batch=0.60s
12480/10943 (epoch 102.637) train_loss=121.05747986 time/batch=0.66s
12481/10943 (epoch 102.645) train_loss=114.59597778 time/batch=0.67s
12482/10943 (epoch 102.653) train_loss=71.37509155 time/batch=0.38s
12483/10943 (epoch 102.662) train_loss=159.63197327 time/batch=0.79s
12484/10943 (epoch 102.670) train_loss=114.57923889 time/batch=0.63s
12485/10943 (epoch 102.678) train_loss=74.16910553 time/batch=0.39s
12486/10943 (epoch 102.686) train_loss=162.62164307 time/batch=0.85s
12487/10943 (epoch 102.694) train_loss=97.69489288 time/batch=0.58s
12488/10943 (epoch 102.703) train_loss=128.72216797 time/batch=0.67s
12489/10943 (epoch 102.711) train_loss=132.05969238 time/batch=0.77s
12490/10943 (epoch 102.719) train_loss=135.95516968 time/batch=0.81s
12491/10943 (epoch 102.727) train_loss=114.41721344 time/batch=0.60s
12492/10943 (epoch 102.736) train_loss=147.52755737 time/batch=0.79s
12493/10943 (epoch 102.744) train_loss=128.69876099 time/batch=0.67s
12494/10943 (epoch 102.752) train_loss=105.64753723 time/batch=0.62s
12495/10943 (epoch 102.760) train_loss=100.98478699 time/batch=0.61s
12496/10943 (epoch 102.768) train_loss=144.73338318 time/batch=0.80s
12497/10943 (epoch 102.777) train_loss=124.52476501 time/batch=0.75s
12498/10943 (epoch 102.785) train_loss=64.66349792 time/batch=0.39s
12499/10943 (epoch 102.793) train_loss=87.28102112 time/batch=0.57s
setting learning rate to 0.0009429
12500/10943 (epoch 102.801) train_loss=60.44856644 time/batch=0.31s
12501/10943 (epoch 102.810) train_loss=172.13310242 time/batch=0.89s
12502/10943 (epoch 102.818) train_loss=151.17201233 time/batch=0.89s
12503/10943 (epoch 102.826) train_loss=89.69157410 time/batch=0.61s
12504/10943 (epoch 102.834) train_loss=225.45356750 time/batch=1.12s
12505/10943 (epoch 102.842) train_loss=53.69004822 time/batch=0.34s
12506/10943 (epoch 102.851) train_loss=74.56069946 time/batch=0.37s
12507/10943 (epoch 102.859) train_loss=516.50854492 time/batch=3.04s
12508/10943 (epoch 102.867) train_loss=242.39352417 time/batch=1.38s
12509/10943 (epoch 102.875) train_loss=82.09924316 time/batch=0.48s
12510/10943 (epoch 102.884) train_loss=84.86854553 time/batch=0.46s
12511/10943 (epoch 102.892) train_loss=137.20550537 time/batch=0.74s
12512/10943 (epoch 102.900) train_loss=268.67462158 time/batch=1.38s
12513/10943 (epoch 102.908) train_loss=173.12799072 time/batch=0.98s
12514/10943 (epoch 102.916) train_loss=279.56060791 time/batch=1.32s
12515/10943 (epoch 102.925) train_loss=134.51171875 time/batch=0.81s
12516/10943 (epoch 102.933) train_loss=201.18357849 time/batch=0.99s
12517/10943 (epoch 102.941) train_loss=88.12161255 time/batch=0.66s
12518/10943 (epoch 102.949) train_loss=167.76698303 time/batch=0.97s
12519/10943 (epoch 102.958) train_loss=127.88897705 time/batch=0.81s
12520/10943 (epoch 102.966) train_loss=248.81890869 time/batch=1.22s
12521/10943 (epoch 102.974) train_loss=253.16069031 time/batch=1.16s
12522/10943 (epoch 102.982) train_loss=110.68974304 time/batch=0.66s
12523/10943 (epoch 102.990) train_loss=296.63562012 time/batch=1.49s
12524/10943 (epoch 102.999) train_loss=228.98336792 time/batch=1.26s
12525/10943 (epoch 103.007) train_loss=133.47045898 time/batch=0.82s
12526/10943 (epoch 103.015) train_loss=122.69268799 time/batch=0.79s
12527/10943 (epoch 103.023) train_loss=87.78971863 time/batch=0.53s
12528/10943 (epoch 103.032) train_loss=352.51110840 time/batch=1.60s
12529/10943 (epoch 103.040) train_loss=83.06095886 time/batch=0.60s
12530/10943 (epoch 103.048) train_loss=237.76110840 time/batch=1.16s
12531/10943 (epoch 103.056) train_loss=129.04782104 time/batch=0.77s
12532/10943 (epoch 103.065) train_loss=60.86742020 time/batch=0.39s
12533/10943 (epoch 103.073) train_loss=66.77059937 time/batch=0.33s
12534/10943 (epoch 103.081) train_loss=151.36784363 time/batch=0.85s
12535/10943 (epoch 103.089) train_loss=112.72085571 time/batch=0.68s
12536/10943 (epoch 103.097) train_loss=215.63783264 time/batch=1.22s
12537/10943 (epoch 103.106) train_loss=110.07261658 time/batch=0.65s
12538/10943 (epoch 103.114) train_loss=86.18820190 time/batch=0.49s
12539/10943 (epoch 103.122) train_loss=190.68507385 time/batch=0.98s
12540/10943 (epoch 103.130) train_loss=85.89059448 time/batch=0.53s
12541/10943 (epoch 103.139) train_loss=97.45256042 time/batch=0.58s
12542/10943 (epoch 103.147) train_loss=184.21975708 time/batch=0.94s
12543/10943 (epoch 103.155) train_loss=63.09223938 time/batch=0.36s
12544/10943 (epoch 103.163) train_loss=224.65588379 time/batch=1.19s
12545/10943 (epoch 103.171) train_loss=55.37021255 time/batch=0.40s
12546/10943 (epoch 103.180) train_loss=77.26196289 time/batch=0.40s
12547/10943 (epoch 103.188) train_loss=113.29888916 time/batch=0.65s
12548/10943 (epoch 103.196) train_loss=118.21467590 time/batch=0.67s
12549/10943 (epoch 103.204) train_loss=210.33544922 time/batch=1.25s
12550/10943 (epoch 103.213) train_loss=65.76365662 time/batch=0.44s
12551/10943 (epoch 103.221) train_loss=89.91738892 time/batch=0.49s
12552/10943 (epoch 103.229) train_loss=118.76788330 time/batch=0.66s
12553/10943 (epoch 103.237) train_loss=108.76999664 time/batch=0.70s
12554/10943 (epoch 103.245) train_loss=91.65100098 time/batch=0.53s
12555/10943 (epoch 103.254) train_loss=95.07376862 time/batch=0.57s
12556/10943 (epoch 103.262) train_loss=128.10884094 time/batch=0.76s
12557/10943 (epoch 103.270) train_loss=152.38110352 time/batch=0.87s
12558/10943 (epoch 103.278) train_loss=71.93737793 time/batch=0.42s
12559/10943 (epoch 103.287) train_loss=129.86741638 time/batch=0.77s
12560/10943 (epoch 103.295) train_loss=204.00282288 time/batch=1.01s
12561/10943 (epoch 103.303) train_loss=119.28386688 time/batch=0.73s
12562/10943 (epoch 103.311) train_loss=118.03962708 time/batch=0.66s
12563/10943 (epoch 103.319) train_loss=64.83979797 time/batch=0.34s
12564/10943 (epoch 103.328) train_loss=135.71650696 time/batch=0.80s
12565/10943 (epoch 103.336) train_loss=67.57386780 time/batch=0.39s
12566/10943 (epoch 103.344) train_loss=144.06806946 time/batch=0.81s
12567/10943 (epoch 103.352) train_loss=77.89189148 time/batch=0.48s
12568/10943 (epoch 103.361) train_loss=155.03482056 time/batch=0.84s
12569/10943 (epoch 103.369) train_loss=260.10656738 time/batch=1.68s
12570/10943 (epoch 103.377) train_loss=141.34579468 time/batch=0.85s
12571/10943 (epoch 103.385) train_loss=109.35070801 time/batch=0.63s
12572/10943 (epoch 103.393) train_loss=106.54021454 time/batch=0.63s
12573/10943 (epoch 103.402) train_loss=69.18536377 time/batch=0.43s
12574/10943 (epoch 103.410) train_loss=187.42077637 time/batch=0.95s
12575/10943 (epoch 103.418) train_loss=131.38854980 time/batch=0.76s
12576/10943 (epoch 103.426) train_loss=75.56895447 time/batch=0.45s
12577/10943 (epoch 103.435) train_loss=142.74438477 time/batch=0.78s
12578/10943 (epoch 103.443) train_loss=109.75244141 time/batch=0.65s
12579/10943 (epoch 103.451) train_loss=160.50952148 time/batch=0.91s
12580/10943 (epoch 103.459) train_loss=161.44459534 time/batch=0.93s
12581/10943 (epoch 103.467) train_loss=110.74967957 time/batch=0.66s
12582/10943 (epoch 103.476) train_loss=99.14971924 time/batch=0.59s
12583/10943 (epoch 103.484) train_loss=121.39207458 time/batch=0.69s
12584/10943 (epoch 103.492) train_loss=143.54040527 time/batch=0.80s
12585/10943 (epoch 103.500) train_loss=105.59037781 time/batch=0.62s
12586/10943 (epoch 103.509) train_loss=96.63300323 time/batch=0.57s
12587/10943 (epoch 103.517) train_loss=74.60249329 time/batch=0.43s
12588/10943 (epoch 103.525) train_loss=129.79911804 time/batch=0.72s
12589/10943 (epoch 103.533) train_loss=173.76686096 time/batch=0.95s
12590/10943 (epoch 103.542) train_loss=132.80955505 time/batch=0.76s
12591/10943 (epoch 103.550) train_loss=149.72729492 time/batch=0.91s
12592/10943 (epoch 103.558) train_loss=82.45317078 time/batch=0.49s
12593/10943 (epoch 103.566) train_loss=100.23657990 time/batch=0.56s
12594/10943 (epoch 103.574) train_loss=118.63698578 time/batch=0.66s
12595/10943 (epoch 103.583) train_loss=101.49858856 time/batch=0.54s
12596/10943 (epoch 103.591) train_loss=92.46052551 time/batch=0.54s
12597/10943 (epoch 103.599) train_loss=82.70244598 time/batch=0.46s
12598/10943 (epoch 103.607) train_loss=106.94332123 time/batch=0.62s
12599/10943 (epoch 103.616) train_loss=71.73811340 time/batch=0.44s
12600/10943 (epoch 103.624) train_loss=95.93531036 time/batch=0.52s
12601/10943 (epoch 103.632) train_loss=93.20504761 time/batch=0.55s
12602/10943 (epoch 103.640) train_loss=105.24598694 time/batch=0.60s
12603/10943 (epoch 103.648) train_loss=73.46144104 time/batch=0.46s
12604/10943 (epoch 103.657) train_loss=136.87063599 time/batch=0.68s
12605/10943 (epoch 103.665) train_loss=135.05505371 time/batch=0.79s
12606/10943 (epoch 103.673) train_loss=154.04801941 time/batch=0.84s
12607/10943 (epoch 103.681) train_loss=140.74758911 time/batch=0.81s
12608/10943 (epoch 103.690) train_loss=92.44271851 time/batch=0.53s
12609/10943 (epoch 103.698) train_loss=129.69918823 time/batch=0.71s
12610/10943 (epoch 103.706) train_loss=120.25224304 time/batch=0.66s
12611/10943 (epoch 103.714) train_loss=123.64154053 time/batch=0.70s
12612/10943 (epoch 103.722) train_loss=98.87395477 time/batch=0.54s
12613/10943 (epoch 103.731) train_loss=134.41186523 time/batch=0.78s
12614/10943 (epoch 103.739) train_loss=145.93971252 time/batch=0.82s
12615/10943 (epoch 103.747) train_loss=95.02531433 time/batch=0.53s
12616/10943 (epoch 103.755) train_loss=100.12686157 time/batch=0.59s
12617/10943 (epoch 103.764) train_loss=133.95549011 time/batch=0.73s
12618/10943 (epoch 103.772) train_loss=154.98509216 time/batch=0.84s
12619/10943 (epoch 103.780) train_loss=124.81652832 time/batch=0.67s
12620/10943 (epoch 103.788) train_loss=132.56025696 time/batch=0.81s
setting learning rate to 0.0009146
  saved to metadata/gru_no_dropout-9_nov_folkwiki-20181207-192453_epoch59.pkl
12621/10943 (epoch 103.796) train_loss=255.18188477 time/batch=1.31s
12622/10943 (epoch 103.805) train_loss=78.81002808 time/batch=0.52s
12623/10943 (epoch 103.813) train_loss=508.37652588 time/batch=3.03s
12624/10943 (epoch 103.821) train_loss=76.01066589 time/batch=0.65s
12625/10943 (epoch 103.829) train_loss=133.77227783 time/batch=0.75s
12626/10943 (epoch 103.838) train_loss=198.19216919 time/batch=1.00s
12627/10943 (epoch 103.846) train_loss=142.19021606 time/batch=0.87s
12628/10943 (epoch 103.854) train_loss=237.24490356 time/batch=1.20s
12629/10943 (epoch 103.862) train_loss=191.78454590 time/batch=1.02s
12630/10943 (epoch 103.870) train_loss=53.88089371 time/batch=0.32s
12631/10943 (epoch 103.879) train_loss=61.71657562 time/batch=0.30s
12632/10943 (epoch 103.887) train_loss=233.99208069 time/batch=1.14s
12633/10943 (epoch 103.895) train_loss=89.10137939 time/batch=0.63s
12634/10943 (epoch 103.903) train_loss=257.99261475 time/batch=1.24s
12635/10943 (epoch 103.912) train_loss=239.08180237 time/batch=1.34s
12636/10943 (epoch 103.920) train_loss=184.55969238 time/batch=0.99s
12637/10943 (epoch 103.928) train_loss=104.67639923 time/batch=0.61s
12638/10943 (epoch 103.936) train_loss=203.38699341 time/batch=1.04s
12639/10943 (epoch 103.944) train_loss=272.86737061 time/batch=1.40s
12640/10943 (epoch 103.953) train_loss=161.21629333 time/batch=0.99s
12641/10943 (epoch 103.961) train_loss=59.34021378 time/batch=0.34s
12642/10943 (epoch 103.969) train_loss=281.25018311 time/batch=1.45s
12643/10943 (epoch 103.977) train_loss=145.83465576 time/batch=0.91s
12644/10943 (epoch 103.986) train_loss=73.16058350 time/batch=0.49s
12645/10943 (epoch 103.994) train_loss=72.37770081 time/batch=0.43s
12646/10943 (epoch 104.002) train_loss=74.19421387 time/batch=0.40s
12647/10943 (epoch 104.010) train_loss=216.48345947 time/batch=1.07s
12648/10943 (epoch 104.019) train_loss=121.16120911 time/batch=0.84s
12649/10943 (epoch 104.027) train_loss=149.82867432 time/batch=0.88s
12650/10943 (epoch 104.035) train_loss=62.02464294 time/batch=0.37s
12651/10943 (epoch 104.043) train_loss=119.76540375 time/batch=0.72s
12652/10943 (epoch 104.051) train_loss=116.85927582 time/batch=0.80s
12653/10943 (epoch 104.060) train_loss=69.26081848 time/batch=0.40s
12654/10943 (epoch 104.068) train_loss=350.33248901 time/batch=1.62s
12655/10943 (epoch 104.076) train_loss=131.94812012 time/batch=0.83s
12656/10943 (epoch 104.084) train_loss=81.17597961 time/batch=0.47s
12657/10943 (epoch 104.093) train_loss=87.88806152 time/batch=0.47s
12658/10943 (epoch 104.101) train_loss=128.18707275 time/batch=0.79s
12659/10943 (epoch 104.109) train_loss=100.06503296 time/batch=0.65s
12660/10943 (epoch 104.117) train_loss=79.63749695 time/batch=0.46s
12661/10943 (epoch 104.125) train_loss=191.50006104 time/batch=0.96s
12662/10943 (epoch 104.134) train_loss=62.58559418 time/batch=0.40s
12663/10943 (epoch 104.142) train_loss=274.13641357 time/batch=1.49s
12664/10943 (epoch 104.150) train_loss=61.12635422 time/batch=0.43s
12665/10943 (epoch 104.158) train_loss=102.86166382 time/batch=0.56s
12666/10943 (epoch 104.167) train_loss=91.69255066 time/batch=0.55s
12667/10943 (epoch 104.175) train_loss=156.75080872 time/batch=0.87s
12668/10943 (epoch 104.183) train_loss=142.27745056 time/batch=0.83s
12669/10943 (epoch 104.191) train_loss=155.53562927 time/batch=0.88s
12670/10943 (epoch 104.199) train_loss=108.81611633 time/batch=0.69s
12671/10943 (epoch 104.208) train_loss=148.19459534 time/batch=0.91s
12672/10943 (epoch 104.216) train_loss=180.38706970 time/batch=1.00s
12673/10943 (epoch 104.224) train_loss=189.36808777 time/batch=1.06s
12674/10943 (epoch 104.232) train_loss=203.05621338 time/batch=1.07s
12675/10943 (epoch 104.241) train_loss=76.79183197 time/batch=0.52s
12676/10943 (epoch 104.249) train_loss=93.56973267 time/batch=0.53s
12677/10943 (epoch 104.257) train_loss=132.26736450 time/batch=0.79s
12678/10943 (epoch 104.265) train_loss=110.61864471 time/batch=0.71s
12679/10943 (epoch 104.273) train_loss=177.21343994 time/batch=0.97s
12680/10943 (epoch 104.282) train_loss=76.71534729 time/batch=0.45s
12681/10943 (epoch 104.290) train_loss=236.16683960 time/batch=1.05s
12682/10943 (epoch 104.298) train_loss=94.71337891 time/batch=0.56s
12683/10943 (epoch 104.306) train_loss=117.29341125 time/batch=0.68s
12684/10943 (epoch 104.315) train_loss=103.75382996 time/batch=0.59s
12685/10943 (epoch 104.323) train_loss=217.45620728 time/batch=1.06s
12686/10943 (epoch 104.331) train_loss=85.02864075 time/batch=0.54s
12687/10943 (epoch 104.339) train_loss=66.29358673 time/batch=0.36s
12688/10943 (epoch 104.347) train_loss=164.21508789 time/batch=0.86s
12689/10943 (epoch 104.356) train_loss=122.47192383 time/batch=0.73s
12690/10943 (epoch 104.364) train_loss=107.93717957 time/batch=0.63s
12691/10943 (epoch 104.372) train_loss=133.52236938 time/batch=0.75s
12692/10943 (epoch 104.380) train_loss=141.30273438 time/batch=0.84s
12693/10943 (epoch 104.389) train_loss=178.61172485 time/batch=0.95s
12694/10943 (epoch 104.397) train_loss=149.58586121 time/batch=0.85s
12695/10943 (epoch 104.405) train_loss=135.49255371 time/batch=0.76s
12696/10943 (epoch 104.413) train_loss=138.57250977 time/batch=0.78s
12697/10943 (epoch 104.421) train_loss=135.57919312 time/batch=0.86s
12698/10943 (epoch 104.430) train_loss=129.92996216 time/batch=0.73s
12699/10943 (epoch 104.438) train_loss=78.34544373 time/batch=0.42s
12700/10943 (epoch 104.446) train_loss=101.94029999 time/batch=0.56s
12701/10943 (epoch 104.454) train_loss=97.69662476 time/batch=0.57s
12702/10943 (epoch 104.463) train_loss=117.60159302 time/batch=0.67s
12703/10943 (epoch 104.471) train_loss=112.29612732 time/batch=0.64s
12704/10943 (epoch 104.479) train_loss=130.16571045 time/batch=0.75s
12705/10943 (epoch 104.487) train_loss=102.23767853 time/batch=0.64s
12706/10943 (epoch 104.496) train_loss=150.31372070 time/batch=0.86s
12707/10943 (epoch 104.504) train_loss=141.10771179 time/batch=0.81s
12708/10943 (epoch 104.512) train_loss=73.36726379 time/batch=0.41s
12709/10943 (epoch 104.520) train_loss=99.45352173 time/batch=0.60s
12710/10943 (epoch 104.528) train_loss=106.60857391 time/batch=0.58s
12711/10943 (epoch 104.537) train_loss=64.84269714 time/batch=0.35s
12712/10943 (epoch 104.545) train_loss=89.54386902 time/batch=0.48s
12713/10943 (epoch 104.553) train_loss=123.14836121 time/batch=0.69s
12714/10943 (epoch 104.561) train_loss=113.13547516 time/batch=0.67s
12715/10943 (epoch 104.570) train_loss=128.38941956 time/batch=0.72s
12716/10943 (epoch 104.578) train_loss=70.56074524 time/batch=0.39s
12717/10943 (epoch 104.586) train_loss=115.41846466 time/batch=0.61s
12718/10943 (epoch 104.594) train_loss=112.85964966 time/batch=0.62s
12719/10943 (epoch 104.602) train_loss=92.63549042 time/batch=0.48s
12720/10943 (epoch 104.611) train_loss=91.10090637 time/batch=0.51s
12721/10943 (epoch 104.619) train_loss=93.79595947 time/batch=0.50s
12722/10943 (epoch 104.627) train_loss=81.25034332 time/batch=0.48s
12723/10943 (epoch 104.635) train_loss=145.93914795 time/batch=0.82s
12724/10943 (epoch 104.644) train_loss=105.00686646 time/batch=0.61s
12725/10943 (epoch 104.652) train_loss=96.80735779 time/batch=0.54s
12726/10943 (epoch 104.660) train_loss=122.37265015 time/batch=0.63s
12727/10943 (epoch 104.668) train_loss=134.13037109 time/batch=0.73s
12728/10943 (epoch 104.676) train_loss=128.57698059 time/batch=0.67s
12729/10943 (epoch 104.685) train_loss=134.58618164 time/batch=0.73s
12730/10943 (epoch 104.693) train_loss=137.19245911 time/batch=0.74s
12731/10943 (epoch 104.701) train_loss=105.58847809 time/batch=0.61s
12732/10943 (epoch 104.709) train_loss=131.56410217 time/batch=0.77s
12733/10943 (epoch 104.718) train_loss=99.35450745 time/batch=0.57s
12734/10943 (epoch 104.726) train_loss=92.06819153 time/batch=0.51s
12735/10943 (epoch 104.734) train_loss=133.64584351 time/batch=0.76s
12736/10943 (epoch 104.742) train_loss=95.75129700 time/batch=0.60s
12737/10943 (epoch 104.750) train_loss=129.07408142 time/batch=0.76s
12738/10943 (epoch 104.759) train_loss=121.19512177 time/batch=0.68s
12739/10943 (epoch 104.767) train_loss=125.33882141 time/batch=0.66s
12740/10943 (epoch 104.775) train_loss=105.11274719 time/batch=0.64s
12741/10943 (epoch 104.783) train_loss=80.85314941 time/batch=0.63s
setting learning rate to 0.0008871
12742/10943 (epoch 104.792) train_loss=67.50971222 time/batch=0.50s
12743/10943 (epoch 104.800) train_loss=135.68550110 time/batch=0.79s
12744/10943 (epoch 104.808) train_loss=221.13490295 time/batch=1.10s
12745/10943 (epoch 104.816) train_loss=124.07608795 time/batch=0.80s
12746/10943 (epoch 104.824) train_loss=294.45852661 time/batch=1.48s
12747/10943 (epoch 104.833) train_loss=284.47479248 time/batch=1.32s
12748/10943 (epoch 104.841) train_loss=59.68417358 time/batch=0.36s
12749/10943 (epoch 104.849) train_loss=543.03002930 time/batch=3.02s
12750/10943 (epoch 104.857) train_loss=135.63928223 time/batch=1.02s
12751/10943 (epoch 104.866) train_loss=332.17001343 time/batch=1.59s
12752/10943 (epoch 104.874) train_loss=243.60035706 time/batch=1.26s
12753/10943 (epoch 104.882) train_loss=82.14274597 time/batch=0.50s
12754/10943 (epoch 104.890) train_loss=192.56269836 time/batch=1.00s
12755/10943 (epoch 104.898) train_loss=142.52514648 time/batch=0.87s
12756/10943 (epoch 104.907) train_loss=264.83285522 time/batch=1.32s
12757/10943 (epoch 104.915) train_loss=58.72640228 time/batch=0.38s
12758/10943 (epoch 104.923) train_loss=115.49403381 time/batch=0.62s
12759/10943 (epoch 104.931) train_loss=184.98960876 time/batch=0.95s
12760/10943 (epoch 104.940) train_loss=319.62646484 time/batch=1.69s
12761/10943 (epoch 104.948) train_loss=162.33013916 time/batch=0.99s
12762/10943 (epoch 104.956) train_loss=95.00075531 time/batch=0.61s
12763/10943 (epoch 104.964) train_loss=97.20043945 time/batch=0.62s
12764/10943 (epoch 104.973) train_loss=65.98762512 time/batch=0.37s
12765/10943 (epoch 104.981) train_loss=226.72077942 time/batch=1.12s
12766/10943 (epoch 104.989) train_loss=262.07296753 time/batch=1.39s
12767/10943 (epoch 104.997) train_loss=87.09420776 time/batch=0.55s
12768/10943 (epoch 105.005) train_loss=64.26140594 time/batch=0.35s
12769/10943 (epoch 105.014) train_loss=116.32310486 time/batch=0.67s
12770/10943 (epoch 105.022) train_loss=68.03050995 time/batch=0.38s
12771/10943 (epoch 105.030) train_loss=111.31629944 time/batch=0.65s
12772/10943 (epoch 105.038) train_loss=187.20184326 time/batch=0.98s
12773/10943 (epoch 105.047) train_loss=129.85214233 time/batch=0.85s
12774/10943 (epoch 105.055) train_loss=156.63720703 time/batch=0.91s
12775/10943 (epoch 105.063) train_loss=61.66806412 time/batch=0.36s
12776/10943 (epoch 105.071) train_loss=82.87041473 time/batch=0.52s
12777/10943 (epoch 105.079) train_loss=84.68738556 time/batch=0.50s
12778/10943 (epoch 105.088) train_loss=67.57826233 time/batch=0.38s
12779/10943 (epoch 105.096) train_loss=171.03652954 time/batch=0.89s
12780/10943 (epoch 105.104) train_loss=127.47106934 time/batch=0.75s
12781/10943 (epoch 105.112) train_loss=76.43505859 time/batch=0.46s
12782/10943 (epoch 105.121) train_loss=65.42731476 time/batch=0.37s
12783/10943 (epoch 105.129) train_loss=101.34236908 time/batch=0.58s
12784/10943 (epoch 105.137) train_loss=137.30725098 time/batch=0.82s
12785/10943 (epoch 105.145) train_loss=191.82907104 time/batch=1.02s
12786/10943 (epoch 105.153) train_loss=202.59622192 time/batch=1.06s
12787/10943 (epoch 105.162) train_loss=166.89794922 time/batch=0.95s
12788/10943 (epoch 105.170) train_loss=141.38543701 time/batch=0.79s
12789/10943 (epoch 105.178) train_loss=132.99768066 time/batch=0.72s
12790/10943 (epoch 105.186) train_loss=172.29049683 time/batch=0.97s
12791/10943 (epoch 105.195) train_loss=213.38081360 time/batch=1.12s
12792/10943 (epoch 105.203) train_loss=81.58354950 time/batch=0.54s
12793/10943 (epoch 105.211) train_loss=83.80535889 time/batch=0.49s
12794/10943 (epoch 105.219) train_loss=89.40391541 time/batch=0.50s
12795/10943 (epoch 105.227) train_loss=69.95613098 time/batch=0.40s
12796/10943 (epoch 105.236) train_loss=125.85306549 time/batch=0.70s
12797/10943 (epoch 105.244) train_loss=83.44666290 time/batch=0.48s
12798/10943 (epoch 105.252) train_loss=101.04347229 time/batch=0.59s
12799/10943 (epoch 105.260) train_loss=135.74230957 time/batch=0.83s
12800/10943 (epoch 105.269) train_loss=100.31701660 time/batch=0.60s
12801/10943 (epoch 105.277) train_loss=109.60711670 time/batch=0.68s
12802/10943 (epoch 105.285) train_loss=169.00209045 time/batch=0.94s
12803/10943 (epoch 105.293) train_loss=154.22502136 time/batch=0.90s
12804/10943 (epoch 105.301) train_loss=124.08390808 time/batch=0.74s
12805/10943 (epoch 105.310) train_loss=210.98081970 time/batch=1.06s
12806/10943 (epoch 105.318) train_loss=134.14080811 time/batch=0.77s
12807/10943 (epoch 105.326) train_loss=101.28378296 time/batch=0.62s
12808/10943 (epoch 105.334) train_loss=120.08474731 time/batch=0.72s
12809/10943 (epoch 105.343) train_loss=87.77883911 time/batch=0.50s
12810/10943 (epoch 105.351) train_loss=62.26479340 time/batch=0.32s
12811/10943 (epoch 105.359) train_loss=133.66827393 time/batch=0.71s
12812/10943 (epoch 105.367) train_loss=100.34815216 time/batch=0.65s
12813/10943 (epoch 105.375) train_loss=76.23079681 time/batch=0.47s
12814/10943 (epoch 105.384) train_loss=236.34255981 time/batch=1.16s
12815/10943 (epoch 105.392) train_loss=117.86643219 time/batch=0.71s
12816/10943 (epoch 105.400) train_loss=140.31805420 time/batch=0.80s
12817/10943 (epoch 105.408) train_loss=137.79577637 time/batch=0.85s
12818/10943 (epoch 105.417) train_loss=224.76992798 time/batch=1.12s
12819/10943 (epoch 105.425) train_loss=136.16557312 time/batch=0.79s
12820/10943 (epoch 105.433) train_loss=159.33119202 time/batch=0.88s
12821/10943 (epoch 105.441) train_loss=113.17288971 time/batch=0.69s
12822/10943 (epoch 105.449) train_loss=146.21789551 time/batch=0.82s
12823/10943 (epoch 105.458) train_loss=173.24575806 time/batch=1.00s
12824/10943 (epoch 105.466) train_loss=132.73509216 time/batch=0.81s
12825/10943 (epoch 105.474) train_loss=92.73922729 time/batch=0.59s
12826/10943 (epoch 105.482) train_loss=56.53063965 time/batch=0.32s
12827/10943 (epoch 105.491) train_loss=75.80795288 time/batch=0.41s
12828/10943 (epoch 105.499) train_loss=112.50410461 time/batch=0.74s
12829/10943 (epoch 105.507) train_loss=105.19132233 time/batch=0.58s
12830/10943 (epoch 105.515) train_loss=73.38667297 time/batch=0.44s
12831/10943 (epoch 105.524) train_loss=133.23536682 time/batch=0.75s
12832/10943 (epoch 105.532) train_loss=100.36968994 time/batch=0.60s
12833/10943 (epoch 105.540) train_loss=129.16148376 time/batch=0.82s
12834/10943 (epoch 105.548) train_loss=106.66582489 time/batch=0.64s
12835/10943 (epoch 105.556) train_loss=115.83595276 time/batch=0.64s
12836/10943 (epoch 105.565) train_loss=101.24023438 time/batch=0.58s
12837/10943 (epoch 105.573) train_loss=146.22521973 time/batch=0.85s
12838/10943 (epoch 105.581) train_loss=89.75202942 time/batch=0.54s
12839/10943 (epoch 105.589) train_loss=103.65637970 time/batch=0.62s
12840/10943 (epoch 105.598) train_loss=149.39158630 time/batch=0.88s
12841/10943 (epoch 105.606) train_loss=67.37202454 time/batch=0.43s
12842/10943 (epoch 105.614) train_loss=132.71694946 time/batch=0.80s
12843/10943 (epoch 105.622) train_loss=73.75334167 time/batch=0.43s
12844/10943 (epoch 105.630) train_loss=100.16522980 time/batch=0.56s
12845/10943 (epoch 105.639) train_loss=106.70855713 time/batch=0.63s
12846/10943 (epoch 105.647) train_loss=64.29678345 time/batch=0.35s
12847/10943 (epoch 105.655) train_loss=118.79954529 time/batch=0.63s
12848/10943 (epoch 105.663) train_loss=89.24990845 time/batch=0.54s
12849/10943 (epoch 105.672) train_loss=111.43334961 time/batch=0.63s
12850/10943 (epoch 105.680) train_loss=127.53256226 time/batch=0.78s
12851/10943 (epoch 105.688) train_loss=162.77537537 time/batch=0.91s
12852/10943 (epoch 105.696) train_loss=76.80499268 time/batch=0.49s
12853/10943 (epoch 105.704) train_loss=118.70550537 time/batch=0.64s
12854/10943 (epoch 105.713) train_loss=91.78688049 time/batch=0.53s
12855/10943 (epoch 105.721) train_loss=106.32362366 time/batch=0.65s
12856/10943 (epoch 105.729) train_loss=94.47640991 time/batch=0.55s
12857/10943 (epoch 105.737) train_loss=132.01982117 time/batch=0.77s
12858/10943 (epoch 105.746) train_loss=98.66822052 time/batch=0.60s
12859/10943 (epoch 105.754) train_loss=117.45227051 time/batch=0.77s
12860/10943 (epoch 105.762) train_loss=116.12456512 time/batch=0.70s
12861/10943 (epoch 105.770) train_loss=91.03013611 time/batch=0.54s
12862/10943 (epoch 105.778) train_loss=103.62895203 time/batch=0.58s
setting learning rate to 0.0008605
  saved to metadata/gru_no_dropout-9_nov_folkwiki-20181207-192453_epoch61.pkl
12863/10943 (epoch 105.787) train_loss=129.56581116 time/batch=0.90s
12864/10943 (epoch 105.795) train_loss=183.87727356 time/batch=1.05s
12865/10943 (epoch 105.803) train_loss=89.87419128 time/batch=0.66s
12866/10943 (epoch 105.811) train_loss=89.02987671 time/batch=0.59s
12867/10943 (epoch 105.820) train_loss=59.03589630 time/batch=0.31s
12868/10943 (epoch 105.828) train_loss=120.11140442 time/batch=0.73s
12869/10943 (epoch 105.836) train_loss=150.31498718 time/batch=0.92s
12870/10943 (epoch 105.844) train_loss=211.87084961 time/batch=1.08s
12871/10943 (epoch 105.852) train_loss=406.33154297 time/batch=1.89s
12872/10943 (epoch 105.861) train_loss=218.03788757 time/batch=1.12s
12873/10943 (epoch 105.869) train_loss=149.76818848 time/batch=0.86s
12874/10943 (epoch 105.877) train_loss=283.35290527 time/batch=1.28s
12875/10943 (epoch 105.885) train_loss=121.26376343 time/batch=0.86s
12876/10943 (epoch 105.894) train_loss=94.90860748 time/batch=0.62s
12877/10943 (epoch 105.902) train_loss=268.89202881 time/batch=1.30s
12878/10943 (epoch 105.910) train_loss=85.66059113 time/batch=0.63s
12879/10943 (epoch 105.918) train_loss=102.29826355 time/batch=0.60s
12880/10943 (epoch 105.926) train_loss=127.08325958 time/batch=0.76s
12881/10943 (epoch 105.935) train_loss=113.35355377 time/batch=0.68s
12882/10943 (epoch 105.943) train_loss=79.59661865 time/batch=0.47s
12883/10943 (epoch 105.951) train_loss=80.01228333 time/batch=0.50s
12884/10943 (epoch 105.959) train_loss=78.13642120 time/batch=0.52s
12885/10943 (epoch 105.968) train_loss=52.71084976 time/batch=0.27s
12886/10943 (epoch 105.976) train_loss=209.19635010 time/batch=1.06s
12887/10943 (epoch 105.984) train_loss=302.47222900 time/batch=1.57s
12888/10943 (epoch 105.992) train_loss=238.58880615 time/batch=1.28s
12889/10943 (epoch 106.001) train_loss=62.90823746 time/batch=0.40s
12890/10943 (epoch 106.009) train_loss=56.55186462 time/batch=0.30s
12891/10943 (epoch 106.017) train_loss=229.68928528 time/batch=1.08s
12892/10943 (epoch 106.025) train_loss=136.61853027 time/batch=0.89s
12893/10943 (epoch 106.033) train_loss=128.28921509 time/batch=0.80s
12894/10943 (epoch 106.042) train_loss=221.73397827 time/batch=1.20s
12895/10943 (epoch 106.050) train_loss=240.11326599 time/batch=1.27s
12896/10943 (epoch 106.058) train_loss=108.75456238 time/batch=0.75s
12897/10943 (epoch 106.066) train_loss=57.29399872 time/batch=0.35s
12898/10943 (epoch 106.075) train_loss=108.25546265 time/batch=0.63s
12899/10943 (epoch 106.083) train_loss=83.84069824 time/batch=0.51s
12900/10943 (epoch 106.091) train_loss=64.99578857 time/batch=0.36s
12901/10943 (epoch 106.099) train_loss=412.34948730 time/batch=2.24s
12902/10943 (epoch 106.107) train_loss=126.25995636 time/batch=0.84s
12903/10943 (epoch 106.116) train_loss=131.87692261 time/batch=0.74s
12904/10943 (epoch 106.124) train_loss=141.41912842 time/batch=0.85s
12905/10943 (epoch 106.132) train_loss=58.42716980 time/batch=0.38s
12906/10943 (epoch 106.140) train_loss=84.55921173 time/batch=0.49s
12907/10943 (epoch 106.149) train_loss=118.82241821 time/batch=0.70s
12908/10943 (epoch 106.157) train_loss=334.75292969 time/batch=3.08s
12909/10943 (epoch 106.165) train_loss=257.52392578 time/batch=1.59s
12910/10943 (epoch 106.173) train_loss=57.43949890 time/batch=0.42s
12911/10943 (epoch 106.181) train_loss=207.82090759 time/batch=0.97s
12912/10943 (epoch 106.190) train_loss=95.74394226 time/batch=0.59s
12913/10943 (epoch 106.198) train_loss=84.53962708 time/batch=0.49s
12914/10943 (epoch 106.206) train_loss=122.52238464 time/batch=0.71s
12915/10943 (epoch 106.214) train_loss=121.55537415 time/batch=0.75s
12916/10943 (epoch 106.223) train_loss=109.65220642 time/batch=0.65s
12917/10943 (epoch 106.231) train_loss=192.79293823 time/batch=1.03s
12918/10943 (epoch 106.239) train_loss=101.37957001 time/batch=0.66s
12919/10943 (epoch 106.247) train_loss=128.98770142 time/batch=0.80s
12920/10943 (epoch 106.255) train_loss=93.55870056 time/batch=0.56s
12921/10943 (epoch 106.264) train_loss=98.31979370 time/batch=0.58s
12922/10943 (epoch 106.272) train_loss=121.96252441 time/batch=0.71s
12923/10943 (epoch 106.280) train_loss=147.79534912 time/batch=0.86s
12924/10943 (epoch 106.288) train_loss=69.47985077 time/batch=0.39s
12925/10943 (epoch 106.297) train_loss=114.35575104 time/batch=0.65s
12926/10943 (epoch 106.305) train_loss=183.59246826 time/batch=0.97s
12927/10943 (epoch 106.313) train_loss=127.65534210 time/batch=0.78s
12928/10943 (epoch 106.321) train_loss=68.85508728 time/batch=0.39s
12929/10943 (epoch 106.329) train_loss=148.18447876 time/batch=0.79s
12930/10943 (epoch 106.338) train_loss=196.44523621 time/batch=1.08s
12931/10943 (epoch 106.346) train_loss=75.43161774 time/batch=0.48s
12932/10943 (epoch 106.354) train_loss=164.82546997 time/batch=0.84s
12933/10943 (epoch 106.362) train_loss=90.94848633 time/batch=0.54s
12934/10943 (epoch 106.371) train_loss=155.59078979 time/batch=0.90s
12935/10943 (epoch 106.379) train_loss=112.67887878 time/batch=0.69s
12936/10943 (epoch 106.387) train_loss=105.10430908 time/batch=0.60s
12937/10943 (epoch 106.395) train_loss=94.74389648 time/batch=0.56s
12938/10943 (epoch 106.403) train_loss=133.78958130 time/batch=0.77s
12939/10943 (epoch 106.412) train_loss=100.08776855 time/batch=0.63s
12940/10943 (epoch 106.420) train_loss=78.34397888 time/batch=0.45s
12941/10943 (epoch 106.428) train_loss=89.67845917 time/batch=0.53s
12942/10943 (epoch 106.436) train_loss=146.70140076 time/batch=0.86s
12943/10943 (epoch 106.445) train_loss=67.65664673 time/batch=0.42s
12944/10943 (epoch 106.453) train_loss=115.79129028 time/batch=0.63s
12945/10943 (epoch 106.461) train_loss=120.03379822 time/batch=0.68s
12946/10943 (epoch 106.469) train_loss=188.22824097 time/batch=0.95s
12947/10943 (epoch 106.478) train_loss=89.81172943 time/batch=0.54s
12948/10943 (epoch 106.486) train_loss=73.75623322 time/batch=0.37s
12949/10943 (epoch 106.494) train_loss=168.67367554 time/batch=0.85s
12950/10943 (epoch 106.502) train_loss=125.83235168 time/batch=0.80s
12951/10943 (epoch 106.510) train_loss=134.97436523 time/batch=0.79s
12952/10943 (epoch 106.519) train_loss=150.36964417 time/batch=0.82s
12953/10943 (epoch 106.527) train_loss=185.52285767 time/batch=0.95s
12954/10943 (epoch 106.535) train_loss=179.90301514 time/batch=0.97s
12955/10943 (epoch 106.543) train_loss=122.87084961 time/batch=0.73s
12956/10943 (epoch 106.552) train_loss=156.94219971 time/batch=0.81s
12957/10943 (epoch 106.560) train_loss=102.58694458 time/batch=0.62s
12958/10943 (epoch 106.568) train_loss=167.48117065 time/batch=0.94s
12959/10943 (epoch 106.576) train_loss=108.77761841 time/batch=0.66s
12960/10943 (epoch 106.584) train_loss=102.17227173 time/batch=0.62s
12961/10943 (epoch 106.593) train_loss=75.77565765 time/batch=0.41s
12962/10943 (epoch 106.601) train_loss=144.05360413 time/batch=0.84s
12963/10943 (epoch 106.609) train_loss=123.86303711 time/batch=0.83s
12964/10943 (epoch 106.617) train_loss=127.84582520 time/batch=0.76s
12965/10943 (epoch 106.626) train_loss=77.91336060 time/batch=0.45s
12966/10943 (epoch 106.634) train_loss=67.15713501 time/batch=0.39s
12967/10943 (epoch 106.642) train_loss=129.99943542 time/batch=0.75s
12968/10943 (epoch 106.650) train_loss=135.60119629 time/batch=0.72s
12969/10943 (epoch 106.658) train_loss=98.54144287 time/batch=0.59s
12970/10943 (epoch 106.667) train_loss=98.80290222 time/batch=0.58s
12971/10943 (epoch 106.675) train_loss=116.73698425 time/batch=0.68s
12972/10943 (epoch 106.683) train_loss=105.61347198 time/batch=0.63s
12973/10943 (epoch 106.691) train_loss=129.46228027 time/batch=0.80s
12974/10943 (epoch 106.700) train_loss=78.70088196 time/batch=0.45s
12975/10943 (epoch 106.708) train_loss=92.08543396 time/batch=0.53s
12976/10943 (epoch 106.716) train_loss=121.11983490 time/batch=0.69s
12977/10943 (epoch 106.724) train_loss=108.57108307 time/batch=0.68s
12978/10943 (epoch 106.732) train_loss=85.31484222 time/batch=0.57s
12979/10943 (epoch 106.741) train_loss=111.02110291 time/batch=0.65s
12980/10943 (epoch 106.749) train_loss=87.77641296 time/batch=0.48s
12981/10943 (epoch 106.757) train_loss=78.81153870 time/batch=0.46s
12982/10943 (epoch 106.765) train_loss=100.77840424 time/batch=0.55s
12983/10943 (epoch 106.774) train_loss=80.00933838 time/batch=0.45s
setting learning rate to 0.0008347
12984/10943 (epoch 106.782) train_loss=495.02041626 time/batch=3.04s
12985/10943 (epoch 106.790) train_loss=57.30387878 time/batch=0.55s
12986/10943 (epoch 106.798) train_loss=123.34150696 time/batch=0.75s
12987/10943 (epoch 106.806) train_loss=191.17227173 time/batch=1.06s
12988/10943 (epoch 106.815) train_loss=185.53131104 time/batch=0.99s
12989/10943 (epoch 106.823) train_loss=86.16677094 time/batch=0.60s
12990/10943 (epoch 106.831) train_loss=124.79974365 time/batch=0.80s
12991/10943 (epoch 106.839) train_loss=219.08020020 time/batch=1.09s
12992/10943 (epoch 106.848) train_loss=214.46192932 time/batch=1.15s
12993/10943 (epoch 106.856) train_loss=76.96862793 time/batch=0.49s
12994/10943 (epoch 106.864) train_loss=266.56555176 time/batch=1.32s
12995/10943 (epoch 106.872) train_loss=152.89955139 time/batch=0.94s
12996/10943 (epoch 106.880) train_loss=357.78713989 time/batch=1.68s
12997/10943 (epoch 106.889) train_loss=226.39474487 time/batch=1.26s
12998/10943 (epoch 106.897) train_loss=268.29803467 time/batch=1.42s
12999/10943 (epoch 106.905) train_loss=64.77097321 time/batch=0.40s
Validating
    loss:	337.655027

13000/10943 (epoch 106.913) train_loss=259.46182251 time/batch=3.00s
13001/10943 (epoch 106.922) train_loss=201.93280029 time/batch=1.07s
13002/10943 (epoch 106.930) train_loss=137.41748047 time/batch=0.81s
13003/10943 (epoch 106.938) train_loss=234.51123047 time/batch=1.18s
13004/10943 (epoch 106.946) train_loss=296.58477783 time/batch=1.57s
13005/10943 (epoch 106.955) train_loss=129.45242310 time/batch=0.81s
13006/10943 (epoch 106.963) train_loss=70.91632843 time/batch=0.42s
13007/10943 (epoch 106.971) train_loss=67.57995605 time/batch=0.36s
13008/10943 (epoch 106.979) train_loss=117.66572571 time/batch=0.74s
13009/10943 (epoch 106.987) train_loss=91.84674835 time/batch=0.58s
13010/10943 (epoch 106.996) train_loss=82.09725952 time/batch=0.48s
13011/10943 (epoch 107.004) train_loss=72.57375336 time/batch=0.44s
13012/10943 (epoch 107.012) train_loss=98.15597534 time/batch=0.58s
13013/10943 (epoch 107.020) train_loss=184.49929810 time/batch=1.00s
13014/10943 (epoch 107.029) train_loss=70.87101746 time/batch=0.46s
13015/10943 (epoch 107.037) train_loss=109.84703064 time/batch=0.63s
13016/10943 (epoch 107.045) train_loss=133.08763123 time/batch=0.83s
13017/10943 (epoch 107.053) train_loss=149.52459717 time/batch=0.92s
13018/10943 (epoch 107.061) train_loss=253.13539124 time/batch=1.44s
13019/10943 (epoch 107.070) train_loss=142.90759277 time/batch=0.94s
13020/10943 (epoch 107.078) train_loss=92.10858917 time/batch=0.60s
13021/10943 (epoch 107.086) train_loss=81.19904327 time/batch=0.46s
13022/10943 (epoch 107.094) train_loss=118.47528839 time/batch=0.76s
13023/10943 (epoch 107.103) train_loss=94.01121521 time/batch=0.60s
13024/10943 (epoch 107.111) train_loss=104.03031158 time/batch=0.60s
13025/10943 (epoch 107.119) train_loss=200.62039185 time/batch=1.04s
13026/10943 (epoch 107.127) train_loss=170.91104126 time/batch=1.00s
13027/10943 (epoch 107.135) train_loss=120.83845520 time/batch=0.70s
13028/10943 (epoch 107.144) train_loss=156.75765991 time/batch=0.92s
13029/10943 (epoch 107.152) train_loss=58.68088913 time/batch=0.37s
13030/10943 (epoch 107.160) train_loss=72.62579346 time/batch=0.41s
13031/10943 (epoch 107.168) train_loss=168.79600525 time/batch=0.93s
13032/10943 (epoch 107.177) train_loss=95.30580139 time/batch=0.60s
13033/10943 (epoch 107.185) train_loss=134.26608276 time/batch=0.84s
13034/10943 (epoch 107.193) train_loss=89.15882874 time/batch=0.54s
13035/10943 (epoch 107.201) train_loss=93.48727417 time/batch=0.59s
13036/10943 (epoch 107.209) train_loss=127.49909973 time/batch=0.74s
13037/10943 (epoch 107.218) train_loss=60.64334488 time/batch=0.37s
13038/10943 (epoch 107.226) train_loss=87.44914246 time/batch=0.49s
13039/10943 (epoch 107.234) train_loss=109.72416687 time/batch=0.66s
13040/10943 (epoch 107.242) train_loss=124.75204468 time/batch=0.74s
13041/10943 (epoch 107.251) train_loss=122.22572327 time/batch=0.72s
13042/10943 (epoch 107.259) train_loss=231.18043518 time/batch=1.20s
13043/10943 (epoch 107.267) train_loss=175.21980286 time/batch=1.03s
13044/10943 (epoch 107.275) train_loss=76.33337402 time/batch=0.48s
13045/10943 (epoch 107.283) train_loss=112.63762665 time/batch=0.67s
13046/10943 (epoch 107.292) train_loss=195.80386353 time/batch=0.98s
13047/10943 (epoch 107.300) train_loss=199.32803345 time/batch=1.09s
13048/10943 (epoch 107.308) train_loss=146.80583191 time/batch=0.85s
13049/10943 (epoch 107.316) train_loss=125.97359467 time/batch=0.74s
13050/10943 (epoch 107.325) train_loss=145.82403564 time/batch=0.84s
13051/10943 (epoch 107.333) train_loss=59.41811371 time/batch=0.36s
13052/10943 (epoch 107.341) train_loss=98.14567566 time/batch=0.60s
13053/10943 (epoch 107.349) train_loss=110.71696472 time/batch=0.68s
13054/10943 (epoch 107.357) train_loss=130.55014038 time/batch=0.80s
13055/10943 (epoch 107.366) train_loss=60.33053589 time/batch=0.36s
13056/10943 (epoch 107.374) train_loss=81.97261047 time/batch=0.47s
13057/10943 (epoch 107.382) train_loss=61.98444366 time/batch=0.34s
13058/10943 (epoch 107.390) train_loss=116.42710114 time/batch=0.65s
13059/10943 (epoch 107.399) train_loss=134.88279724 time/batch=0.80s
13060/10943 (epoch 107.407) train_loss=159.11395264 time/batch=0.88s
13061/10943 (epoch 107.415) train_loss=130.14889526 time/batch=0.81s
13062/10943 (epoch 107.423) train_loss=162.72668457 time/batch=0.92s
13063/10943 (epoch 107.432) train_loss=185.29512024 time/batch=1.12s
13064/10943 (epoch 107.440) train_loss=72.39366913 time/batch=0.42s
13065/10943 (epoch 107.448) train_loss=84.97250366 time/batch=0.48s
13066/10943 (epoch 107.456) train_loss=97.29760742 time/batch=0.53s
13067/10943 (epoch 107.464) train_loss=112.67079163 time/batch=0.63s
13068/10943 (epoch 107.473) train_loss=103.58238220 time/batch=0.63s
13069/10943 (epoch 107.481) train_loss=156.86230469 time/batch=1.08s
13070/10943 (epoch 107.489) train_loss=141.20208740 time/batch=0.79s
13071/10943 (epoch 107.497) train_loss=130.60192871 time/batch=0.79s
13072/10943 (epoch 107.506) train_loss=145.23515320 time/batch=0.84s
13073/10943 (epoch 107.514) train_loss=119.95587921 time/batch=0.67s
13074/10943 (epoch 107.522) train_loss=90.07388306 time/batch=0.58s
13075/10943 (epoch 107.530) train_loss=119.23382568 time/batch=0.70s
13076/10943 (epoch 107.538) train_loss=97.08732605 time/batch=0.62s
13077/10943 (epoch 107.547) train_loss=70.98825073 time/batch=0.45s
13078/10943 (epoch 107.555) train_loss=125.90722656 time/batch=0.70s
13079/10943 (epoch 107.563) train_loss=122.09568024 time/batch=0.79s
13080/10943 (epoch 107.571) train_loss=116.33122253 time/batch=0.68s
13081/10943 (epoch 107.580) train_loss=92.18309784 time/batch=0.53s
13082/10943 (epoch 107.588) train_loss=150.27644348 time/batch=0.81s
13083/10943 (epoch 107.596) train_loss=71.20056915 time/batch=0.40s
13084/10943 (epoch 107.604) train_loss=67.74751282 time/batch=0.43s
13085/10943 (epoch 107.612) train_loss=133.60409546 time/batch=0.81s
13086/10943 (epoch 107.621) train_loss=103.26409912 time/batch=0.64s
13087/10943 (epoch 107.629) train_loss=64.88163757 time/batch=0.38s
13088/10943 (epoch 107.637) train_loss=73.44319153 time/batch=0.44s
13089/10943 (epoch 107.645) train_loss=118.24989319 time/batch=0.81s
13090/10943 (epoch 107.654) train_loss=110.97993469 time/batch=0.72s
13091/10943 (epoch 107.662) train_loss=115.88556671 time/batch=0.68s
13092/10943 (epoch 107.670) train_loss=106.95498657 time/batch=0.64s
13093/10943 (epoch 107.678) train_loss=104.88191223 time/batch=0.63s
13094/10943 (epoch 107.686) train_loss=82.05955505 time/batch=0.48s
13095/10943 (epoch 107.695) train_loss=82.09245300 time/batch=0.48s
13096/10943 (epoch 107.703) train_loss=87.69151306 time/batch=0.51s
13097/10943 (epoch 107.711) train_loss=107.49850464 time/batch=0.63s
13098/10943 (epoch 107.719) train_loss=128.00679016 time/batch=0.73s
13099/10943 (epoch 107.728) train_loss=101.80001831 time/batch=0.60s
13100/10943 (epoch 107.736) train_loss=116.23640442 time/batch=0.73s
13101/10943 (epoch 107.744) train_loss=104.16796875 time/batch=0.60s
13102/10943 (epoch 107.752) train_loss=78.42861176 time/batch=0.52s
13103/10943 (epoch 107.760) train_loss=95.04274750 time/batch=0.56s
13104/10943 (epoch 107.769) train_loss=95.31366730 time/batch=0.58s
setting learning rate to 0.0008097
  saved to metadata/gru_no_dropout-9_nov_folkwiki-20181207-192453_epoch63.pkl
13105/10943 (epoch 107.777) train_loss=268.48635864 time/batch=1.33s
13106/10943 (epoch 107.785) train_loss=179.13665771 time/batch=1.00s
13107/10943 (epoch 107.793) train_loss=64.55651093 time/batch=0.42s
13108/10943 (epoch 107.802) train_loss=453.81231689 time/batch=2.33s
13109/10943 (epoch 107.810) train_loss=244.88183594 time/batch=1.37s
13110/10943 (epoch 107.818) train_loss=78.23593140 time/batch=0.50s
13111/10943 (epoch 107.826) train_loss=261.73959351 time/batch=1.26s
13112/10943 (epoch 107.834) train_loss=201.27885437 time/batch=1.08s
13113/10943 (epoch 107.843) train_loss=92.74499512 time/batch=0.56s
13114/10943 (epoch 107.851) train_loss=65.56353760 time/batch=0.36s
13115/10943 (epoch 107.859) train_loss=50.65164948 time/batch=0.25s
13116/10943 (epoch 107.867) train_loss=193.96994019 time/batch=1.01s
13117/10943 (epoch 107.876) train_loss=136.93212891 time/batch=0.87s
13118/10943 (epoch 107.884) train_loss=401.11264038 time/batch=3.07s
13119/10943 (epoch 107.892) train_loss=64.54092407 time/batch=0.60s
13120/10943 (epoch 107.900) train_loss=82.87400818 time/batch=0.50s
13121/10943 (epoch 107.909) train_loss=263.82611084 time/batch=1.34s
13122/10943 (epoch 107.917) train_loss=222.02758789 time/batch=1.17s
13123/10943 (epoch 107.925) train_loss=120.50634766 time/batch=0.76s
13124/10943 (epoch 107.933) train_loss=207.24438477 time/batch=1.11s
13125/10943 (epoch 107.941) train_loss=120.53633118 time/batch=0.76s
13126/10943 (epoch 107.950) train_loss=246.24539185 time/batch=1.38s
13127/10943 (epoch 107.958) train_loss=88.32767487 time/batch=0.60s
13128/10943 (epoch 107.966) train_loss=85.25608826 time/batch=0.53s
13129/10943 (epoch 107.974) train_loss=139.09600830 time/batch=0.84s
13130/10943 (epoch 107.983) train_loss=82.37049103 time/batch=0.54s
13131/10943 (epoch 107.991) train_loss=71.45762634 time/batch=0.40s
13132/10943 (epoch 107.999) train_loss=113.19638824 time/batch=0.71s
13133/10943 (epoch 108.007) train_loss=166.84609985 time/batch=0.96s
13134/10943 (epoch 108.015) train_loss=98.66432953 time/batch=0.65s
13135/10943 (epoch 108.024) train_loss=86.56191254 time/batch=0.57s
13136/10943 (epoch 108.032) train_loss=117.32479858 time/batch=0.74s
13137/10943 (epoch 108.040) train_loss=232.16879272 time/batch=1.18s
13138/10943 (epoch 108.048) train_loss=152.27352905 time/batch=0.92s
13139/10943 (epoch 108.057) train_loss=111.01466370 time/batch=0.67s
13140/10943 (epoch 108.065) train_loss=73.04455566 time/batch=0.48s
13141/10943 (epoch 108.073) train_loss=94.40678406 time/batch=0.58s
13142/10943 (epoch 108.081) train_loss=89.46296692 time/batch=0.55s
13143/10943 (epoch 108.089) train_loss=103.25053406 time/batch=0.63s
13144/10943 (epoch 108.098) train_loss=119.42864990 time/batch=0.75s
13145/10943 (epoch 108.106) train_loss=264.75143433 time/batch=1.49s
13146/10943 (epoch 108.114) train_loss=118.79674530 time/batch=0.76s
13147/10943 (epoch 108.122) train_loss=93.92849731 time/batch=0.59s
13148/10943 (epoch 108.131) train_loss=103.15318298 time/batch=0.61s
13149/10943 (epoch 108.139) train_loss=125.39779663 time/batch=0.74s
13150/10943 (epoch 108.147) train_loss=153.73248291 time/batch=0.91s
13151/10943 (epoch 108.155) train_loss=97.59920502 time/batch=0.62s
13152/10943 (epoch 108.163) train_loss=188.69039917 time/batch=1.05s
13153/10943 (epoch 108.172) train_loss=198.15637207 time/batch=1.02s
13154/10943 (epoch 108.180) train_loss=77.40702820 time/batch=0.55s
13155/10943 (epoch 108.188) train_loss=271.95559692 time/batch=1.50s
13156/10943 (epoch 108.196) train_loss=84.32669067 time/batch=0.64s
13157/10943 (epoch 108.205) train_loss=186.21380615 time/batch=0.98s
13158/10943 (epoch 108.213) train_loss=126.92663574 time/batch=0.75s
13159/10943 (epoch 108.221) train_loss=120.37268066 time/batch=0.65s
13160/10943 (epoch 108.229) train_loss=83.70761108 time/batch=0.49s
13161/10943 (epoch 108.237) train_loss=65.21910095 time/batch=0.36s
13162/10943 (epoch 108.246) train_loss=59.69242477 time/batch=0.33s
13163/10943 (epoch 108.254) train_loss=129.37748718 time/batch=0.73s
13164/10943 (epoch 108.262) train_loss=126.03404236 time/batch=0.79s
13165/10943 (epoch 108.270) train_loss=139.33528137 time/batch=0.83s
13166/10943 (epoch 108.279) train_loss=91.39470673 time/batch=0.62s
13167/10943 (epoch 108.287) train_loss=86.34190369 time/batch=0.53s
13168/10943 (epoch 108.295) train_loss=63.84827042 time/batch=0.33s
13169/10943 (epoch 108.303) train_loss=170.77488708 time/batch=0.92s
13170/10943 (epoch 108.311) train_loss=153.10925293 time/batch=0.94s
13171/10943 (epoch 108.320) train_loss=124.70186615 time/batch=0.84s
13172/10943 (epoch 108.328) train_loss=136.54940796 time/batch=0.81s
13173/10943 (epoch 108.336) train_loss=63.44905090 time/batch=0.33s
13174/10943 (epoch 108.344) train_loss=74.45076752 time/batch=0.43s
13175/10943 (epoch 108.353) train_loss=208.98400879 time/batch=1.05s
13176/10943 (epoch 108.361) train_loss=77.96358490 time/batch=0.51s
13177/10943 (epoch 108.369) train_loss=178.07589722 time/batch=0.92s
13178/10943 (epoch 108.377) train_loss=127.14682007 time/batch=0.70s
13179/10943 (epoch 108.386) train_loss=55.17532349 time/batch=0.33s
13180/10943 (epoch 108.394) train_loss=95.35490417 time/batch=0.56s
13181/10943 (epoch 108.402) train_loss=140.25161743 time/batch=0.83s
13182/10943 (epoch 108.410) train_loss=108.27644348 time/batch=0.72s
13183/10943 (epoch 108.418) train_loss=127.52576447 time/batch=0.77s
13184/10943 (epoch 108.427) train_loss=148.14459229 time/batch=0.87s
13185/10943 (epoch 108.435) train_loss=128.24230957 time/batch=0.75s
13186/10943 (epoch 108.443) train_loss=171.64097595 time/batch=0.97s
13187/10943 (epoch 108.451) train_loss=134.36665344 time/batch=0.80s
13188/10943 (epoch 108.460) train_loss=133.96414185 time/batch=0.81s
13189/10943 (epoch 108.468) train_loss=89.75529480 time/batch=0.57s
13190/10943 (epoch 108.476) train_loss=61.91014862 time/batch=0.36s
13191/10943 (epoch 108.484) train_loss=128.50421143 time/batch=0.67s
13192/10943 (epoch 108.492) train_loss=119.11146545 time/batch=0.68s
13193/10943 (epoch 108.501) train_loss=112.06924438 time/batch=0.71s
13194/10943 (epoch 108.509) train_loss=112.56774902 time/batch=0.67s
13195/10943 (epoch 108.517) train_loss=99.11616516 time/batch=0.61s
13196/10943 (epoch 108.525) train_loss=93.73387146 time/batch=0.56s
13197/10943 (epoch 108.534) train_loss=167.21606445 time/batch=0.99s
13198/10943 (epoch 108.542) train_loss=155.25628662 time/batch=0.92s
13199/10943 (epoch 108.550) train_loss=134.20005798 time/batch=0.75s
13200/10943 (epoch 108.558) train_loss=100.75404358 time/batch=0.58s
13201/10943 (epoch 108.566) train_loss=148.06166077 time/batch=0.83s
13202/10943 (epoch 108.575) train_loss=95.19117737 time/batch=0.65s
13203/10943 (epoch 108.583) train_loss=124.07997894 time/batch=0.78s
13204/10943 (epoch 108.591) train_loss=116.10171509 time/batch=0.75s
13205/10943 (epoch 108.599) train_loss=102.79586029 time/batch=0.64s
13206/10943 (epoch 108.608) train_loss=90.65159607 time/batch=0.57s
13207/10943 (epoch 108.616) train_loss=137.55468750 time/batch=0.80s
13208/10943 (epoch 108.624) train_loss=77.26647949 time/batch=0.47s
13209/10943 (epoch 108.632) train_loss=102.57706451 time/batch=0.61s
13210/10943 (epoch 108.640) train_loss=144.51812744 time/batch=0.87s
13211/10943 (epoch 108.649) train_loss=124.40251160 time/batch=0.79s
13212/10943 (epoch 108.657) train_loss=85.09435272 time/batch=0.48s
13213/10943 (epoch 108.665) train_loss=75.48047638 time/batch=0.43s
13214/10943 (epoch 108.673) train_loss=75.57108307 time/batch=0.42s
13215/10943 (epoch 108.682) train_loss=102.13081360 time/batch=0.61s
13216/10943 (epoch 108.690) train_loss=138.40646362 time/batch=0.81s
13217/10943 (epoch 108.698) train_loss=86.88331604 time/batch=0.59s
13218/10943 (epoch 108.706) train_loss=104.15981293 time/batch=0.62s
13219/10943 (epoch 108.714) train_loss=116.09152985 time/batch=0.77s
13220/10943 (epoch 108.723) train_loss=110.23231506 time/batch=0.68s
13221/10943 (epoch 108.731) train_loss=62.68232727 time/batch=0.35s
13222/10943 (epoch 108.739) train_loss=108.38340759 time/batch=0.63s
13223/10943 (epoch 108.747) train_loss=124.54679108 time/batch=0.82s
13224/10943 (epoch 108.756) train_loss=73.88628387 time/batch=0.42s
13225/10943 (epoch 108.764) train_loss=96.72732544 time/batch=0.54s
setting learning rate to 0.0007854
13226/10943 (epoch 108.772) train_loss=108.25511932 time/batch=0.78s
13227/10943 (epoch 108.780) train_loss=148.29385376 time/batch=0.91s
13228/10943 (epoch 108.788) train_loss=349.73931885 time/batch=1.68s
13229/10943 (epoch 108.797) train_loss=139.03488159 time/batch=0.96s
13230/10943 (epoch 108.805) train_loss=236.93339539 time/batch=1.22s
13231/10943 (epoch 108.813) train_loss=319.46148682 time/batch=1.76s
13232/10943 (epoch 108.821) train_loss=192.74180603 time/batch=1.08s
13233/10943 (epoch 108.830) train_loss=89.04412842 time/batch=0.58s
13234/10943 (epoch 108.838) train_loss=89.21244812 time/batch=0.51s
13235/10943 (epoch 108.846) train_loss=50.51440048 time/batch=0.27s
13236/10943 (epoch 108.854) train_loss=112.70742035 time/batch=0.66s
13237/10943 (epoch 108.863) train_loss=140.93399048 time/batch=0.86s
13238/10943 (epoch 108.871) train_loss=257.35757446 time/batch=1.37s
13239/10943 (epoch 108.879) train_loss=111.28056335 time/batch=0.76s
13240/10943 (epoch 108.887) train_loss=251.14361572 time/batch=1.37s
13241/10943 (epoch 108.895) train_loss=74.67903900 time/batch=0.57s
13242/10943 (epoch 108.904) train_loss=121.39855194 time/batch=0.72s
13243/10943 (epoch 108.912) train_loss=70.20344543 time/batch=0.43s
13244/10943 (epoch 108.920) train_loss=54.87447739 time/batch=0.33s
13245/10943 (epoch 108.928) train_loss=134.96539307 time/batch=0.78s
13246/10943 (epoch 108.937) train_loss=139.49539185 time/batch=0.84s
13247/10943 (epoch 108.945) train_loss=244.91406250 time/batch=1.23s
13248/10943 (epoch 108.953) train_loss=88.86652374 time/batch=0.64s
13249/10943 (epoch 108.961) train_loss=480.72711182 time/batch=3.05s
13250/10943 (epoch 108.969) train_loss=93.38644409 time/batch=0.84s
13251/10943 (epoch 108.978) train_loss=54.32585907 time/batch=0.29s
13252/10943 (epoch 108.986) train_loss=73.48767090 time/batch=0.43s
13253/10943 (epoch 108.994) train_loss=180.53842163 time/batch=0.95s
13254/10943 (epoch 109.002) train_loss=78.82546234 time/batch=0.54s
13255/10943 (epoch 109.011) train_loss=198.86132812 time/batch=1.02s
13256/10943 (epoch 109.019) train_loss=104.71571350 time/batch=0.73s
13257/10943 (epoch 109.027) train_loss=252.66441345 time/batch=1.25s
13258/10943 (epoch 109.035) train_loss=160.75418091 time/batch=1.00s
13259/10943 (epoch 109.043) train_loss=124.98503876 time/batch=0.83s
13260/10943 (epoch 109.052) train_loss=71.44708252 time/batch=0.43s
13261/10943 (epoch 109.060) train_loss=73.47010803 time/batch=0.41s
13262/10943 (epoch 109.068) train_loss=93.73617554 time/batch=0.60s
13263/10943 (epoch 109.076) train_loss=209.46282959 time/batch=1.09s
13264/10943 (epoch 109.085) train_loss=134.27505493 time/batch=0.82s
13265/10943 (epoch 109.093) train_loss=63.22750092 time/batch=0.40s
13266/10943 (epoch 109.101) train_loss=67.56079865 time/batch=0.39s
13267/10943 (epoch 109.109) train_loss=115.03372192 time/batch=0.75s
13268/10943 (epoch 109.117) train_loss=103.30904388 time/batch=0.65s
13269/10943 (epoch 109.126) train_loss=116.90892792 time/batch=0.71s
13270/10943 (epoch 109.134) train_loss=114.59385681 time/batch=0.66s
13271/10943 (epoch 109.142) train_loss=107.03570557 time/batch=0.65s
13272/10943 (epoch 109.150) train_loss=228.37461853 time/batch=1.26s
13273/10943 (epoch 109.159) train_loss=85.83161926 time/batch=0.55s
13274/10943 (epoch 109.167) train_loss=131.46780396 time/batch=0.79s
13275/10943 (epoch 109.175) train_loss=87.92898560 time/batch=0.64s
13276/10943 (epoch 109.183) train_loss=215.46432495 time/batch=1.11s
13277/10943 (epoch 109.191) train_loss=111.76026917 time/batch=0.69s
13278/10943 (epoch 109.200) train_loss=177.88937378 time/batch=0.98s
13279/10943 (epoch 109.208) train_loss=67.62133789 time/batch=0.44s
13280/10943 (epoch 109.216) train_loss=190.74835205 time/batch=0.97s
13281/10943 (epoch 109.224) train_loss=186.27465820 time/batch=1.08s
13282/10943 (epoch 109.233) train_loss=215.19206238 time/batch=1.10s
13283/10943 (epoch 109.241) train_loss=70.41316223 time/batch=0.43s
13284/10943 (epoch 109.249) train_loss=130.11012268 time/batch=0.70s
13285/10943 (epoch 109.257) train_loss=113.20619202 time/batch=0.67s
13286/10943 (epoch 109.265) train_loss=59.61800766 time/batch=0.33s
13287/10943 (epoch 109.274) train_loss=77.20736694 time/batch=0.45s
13288/10943 (epoch 109.282) train_loss=237.48226929 time/batch=1.39s
13289/10943 (epoch 109.290) train_loss=112.76487732 time/batch=0.78s
13290/10943 (epoch 109.298) train_loss=94.31468201 time/batch=0.57s
13291/10943 (epoch 109.307) train_loss=100.24272156 time/batch=0.59s
13292/10943 (epoch 109.315) train_loss=121.83749390 time/batch=0.75s
13293/10943 (epoch 109.323) train_loss=52.99701309 time/batch=0.35s
13294/10943 (epoch 109.331) train_loss=100.51119995 time/batch=0.55s
13295/10943 (epoch 109.340) train_loss=125.97268677 time/batch=0.71s
13296/10943 (epoch 109.348) train_loss=65.84937286 time/batch=0.39s
13297/10943 (epoch 109.356) train_loss=82.33937836 time/batch=0.46s
13298/10943 (epoch 109.364) train_loss=109.84284973 time/batch=0.67s
13299/10943 (epoch 109.372) train_loss=82.58433533 time/batch=0.50s
13300/10943 (epoch 109.381) train_loss=127.99481201 time/batch=0.77s
13301/10943 (epoch 109.389) train_loss=135.13908386 time/batch=0.86s
13302/10943 (epoch 109.397) train_loss=93.25064087 time/batch=0.57s
13303/10943 (epoch 109.405) train_loss=95.75673676 time/batch=0.58s
13304/10943 (epoch 109.414) train_loss=136.27769470 time/batch=0.82s
13305/10943 (epoch 109.422) train_loss=92.58773041 time/batch=0.55s
13306/10943 (epoch 109.430) train_loss=123.45129395 time/batch=0.70s
13307/10943 (epoch 109.438) train_loss=91.99055481 time/batch=0.53s
13308/10943 (epoch 109.446) train_loss=152.69754028 time/batch=0.84s
13309/10943 (epoch 109.455) train_loss=78.41421509 time/batch=0.48s
13310/10943 (epoch 109.463) train_loss=89.72715759 time/batch=0.50s
13311/10943 (epoch 109.471) train_loss=136.96438599 time/batch=0.72s
13312/10943 (epoch 109.479) train_loss=73.76591492 time/batch=0.46s
13313/10943 (epoch 109.488) train_loss=151.89628601 time/batch=0.89s
13314/10943 (epoch 109.496) train_loss=187.51818848 time/batch=0.97s
13315/10943 (epoch 109.504) train_loss=106.06654358 time/batch=0.65s
13316/10943 (epoch 109.512) train_loss=169.90747070 time/batch=0.98s
13317/10943 (epoch 109.520) train_loss=134.18890381 time/batch=0.83s
13318/10943 (epoch 109.529) train_loss=175.68521118 time/batch=0.95s
13319/10943 (epoch 109.537) train_loss=64.40847778 time/batch=0.37s
13320/10943 (epoch 109.545) train_loss=173.09162903 time/batch=0.95s
13321/10943 (epoch 109.553) train_loss=109.56054688 time/batch=0.70s
13322/10943 (epoch 109.562) train_loss=81.81838989 time/batch=0.55s
13323/10943 (epoch 109.570) train_loss=63.55071259 time/batch=0.34s
13324/10943 (epoch 109.578) train_loss=114.54093170 time/batch=0.67s
13325/10943 (epoch 109.586) train_loss=122.27276611 time/batch=0.76s
13326/10943 (epoch 109.594) train_loss=104.66610718 time/batch=0.66s
13327/10943 (epoch 109.603) train_loss=123.11621094 time/batch=0.73s
13328/10943 (epoch 109.611) train_loss=82.79200745 time/batch=0.56s
13329/10943 (epoch 109.619) train_loss=136.90286255 time/batch=0.79s
13330/10943 (epoch 109.627) train_loss=110.05700684 time/batch=0.63s
13331/10943 (epoch 109.636) train_loss=131.39877319 time/batch=0.75s
13332/10943 (epoch 109.644) train_loss=128.15670776 time/batch=0.84s
13333/10943 (epoch 109.652) train_loss=101.18341064 time/batch=0.60s
13334/10943 (epoch 109.660) train_loss=99.48558807 time/batch=0.60s
13335/10943 (epoch 109.668) train_loss=92.10918427 time/batch=0.55s
13336/10943 (epoch 109.677) train_loss=116.46464539 time/batch=0.65s
13337/10943 (epoch 109.685) train_loss=178.58953857 time/batch=1.00s
13338/10943 (epoch 109.693) train_loss=108.09391785 time/batch=0.65s
13339/10943 (epoch 109.701) train_loss=91.21212769 time/batch=0.56s
13340/10943 (epoch 109.710) train_loss=131.14877319 time/batch=0.82s
13341/10943 (epoch 109.718) train_loss=155.62385559 time/batch=0.89s
13342/10943 (epoch 109.726) train_loss=83.50395203 time/batch=0.62s
13343/10943 (epoch 109.734) train_loss=113.84671021 time/batch=0.65s
13344/10943 (epoch 109.742) train_loss=125.11492920 time/batch=0.77s
13345/10943 (epoch 109.751) train_loss=109.39231873 time/batch=0.84s
13346/10943 (epoch 109.759) train_loss=99.63096619 time/batch=0.61s
setting learning rate to 0.0007618
  saved to metadata/gru_no_dropout-9_nov_folkwiki-20181207-192453_epoch65.pkl
13347/10943 (epoch 109.767) train_loss=213.64202881 time/batch=1.14s
13348/10943 (epoch 109.775) train_loss=226.77449036 time/batch=1.18s
13349/10943 (epoch 109.784) train_loss=80.37022400 time/batch=0.52s
13350/10943 (epoch 109.792) train_loss=249.62258911 time/batch=1.22s
13351/10943 (epoch 109.800) train_loss=186.51589966 time/batch=1.09s
13352/10943 (epoch 109.808) train_loss=122.58599854 time/batch=0.84s
13353/10943 (epoch 109.816) train_loss=255.61930847 time/batch=1.43s
13354/10943 (epoch 109.825) train_loss=95.93566895 time/batch=0.70s
13355/10943 (epoch 109.833) train_loss=140.42924500 time/batch=0.86s
13356/10943 (epoch 109.841) train_loss=362.12646484 time/batch=1.77s
13357/10943 (epoch 109.849) train_loss=168.86331177 time/batch=1.09s
13358/10943 (epoch 109.858) train_loss=135.31149292 time/batch=0.88s
13359/10943 (epoch 109.866) train_loss=184.77760315 time/batch=1.03s
13360/10943 (epoch 109.874) train_loss=52.60987091 time/batch=0.37s
13361/10943 (epoch 109.882) train_loss=50.92352676 time/batch=0.25s
13362/10943 (epoch 109.891) train_loss=82.63549805 time/batch=0.49s
13363/10943 (epoch 109.899) train_loss=58.53789902 time/batch=0.30s
13364/10943 (epoch 109.907) train_loss=174.77528381 time/batch=0.96s
13365/10943 (epoch 109.915) train_loss=255.94958496 time/batch=1.35s
13366/10943 (epoch 109.923) train_loss=121.84931946 time/batch=0.74s
13367/10943 (epoch 109.932) train_loss=67.13319397 time/batch=0.38s
13368/10943 (epoch 109.940) train_loss=124.76933289 time/batch=0.79s
13369/10943 (epoch 109.948) train_loss=126.93743896 time/batch=0.83s
13370/10943 (epoch 109.956) train_loss=148.93069458 time/batch=0.90s
13371/10943 (epoch 109.965) train_loss=222.15570068 time/batch=1.18s
13372/10943 (epoch 109.973) train_loss=61.85379028 time/batch=0.41s
13373/10943 (epoch 109.981) train_loss=108.58365631 time/batch=0.66s
13374/10943 (epoch 109.989) train_loss=170.51184082 time/batch=0.94s
13375/10943 (epoch 109.997) train_loss=94.13610077 time/batch=0.59s
13376/10943 (epoch 110.006) train_loss=231.06204224 time/batch=1.17s
13377/10943 (epoch 110.014) train_loss=320.08721924 time/batch=1.82s
13378/10943 (epoch 110.022) train_loss=171.64236450 time/batch=1.06s
13379/10943 (epoch 110.030) train_loss=132.75784302 time/batch=0.82s
13380/10943 (epoch 110.039) train_loss=125.28288269 time/batch=0.74s
13381/10943 (epoch 110.047) train_loss=88.21115112 time/batch=0.64s
13382/10943 (epoch 110.055) train_loss=87.32363129 time/batch=0.53s
13383/10943 (epoch 110.063) train_loss=120.64433289 time/batch=0.75s
13384/10943 (epoch 110.071) train_loss=171.49264526 time/batch=0.97s
13385/10943 (epoch 110.080) train_loss=122.25209045 time/batch=0.76s
13386/10943 (epoch 110.088) train_loss=70.01190186 time/batch=0.44s
13387/10943 (epoch 110.096) train_loss=98.05133057 time/batch=0.58s
13388/10943 (epoch 110.104) train_loss=56.64096832 time/batch=0.33s
13389/10943 (epoch 110.113) train_loss=450.09173584 time/batch=3.03s
13390/10943 (epoch 110.121) train_loss=132.04605103 time/batch=1.12s
13391/10943 (epoch 110.129) train_loss=83.13713074 time/batch=0.53s
13392/10943 (epoch 110.137) train_loss=204.28182983 time/batch=1.05s
13393/10943 (epoch 110.145) train_loss=259.47015381 time/batch=1.39s
13394/10943 (epoch 110.154) train_loss=72.17964172 time/batch=0.48s
13395/10943 (epoch 110.162) train_loss=73.23450470 time/batch=0.39s
13396/10943 (epoch 110.170) train_loss=94.85139465 time/batch=0.57s
13397/10943 (epoch 110.178) train_loss=93.80992126 time/batch=0.58s
13398/10943 (epoch 110.187) train_loss=117.57263184 time/batch=0.78s
13399/10943 (epoch 110.195) train_loss=141.82966614 time/batch=0.86s
13400/10943 (epoch 110.203) train_loss=116.52327728 time/batch=0.68s
13401/10943 (epoch 110.211) train_loss=122.57093048 time/batch=0.71s
13402/10943 (epoch 110.219) train_loss=187.89820862 time/batch=0.99s
13403/10943 (epoch 110.228) train_loss=119.93058777 time/batch=0.71s
13404/10943 (epoch 110.236) train_loss=68.91227722 time/batch=0.41s
13405/10943 (epoch 110.244) train_loss=125.21820831 time/batch=0.70s
13406/10943 (epoch 110.252) train_loss=97.36080170 time/batch=0.63s
13407/10943 (epoch 110.261) train_loss=89.74494934 time/batch=0.50s
13408/10943 (epoch 110.269) train_loss=122.83355713 time/batch=0.73s
13409/10943 (epoch 110.277) train_loss=127.44834137 time/batch=0.81s
13410/10943 (epoch 110.285) train_loss=138.49090576 time/batch=0.85s
13411/10943 (epoch 110.293) train_loss=61.77662277 time/batch=0.35s
13412/10943 (epoch 110.302) train_loss=151.25924683 time/batch=0.84s
13413/10943 (epoch 110.310) train_loss=209.03271484 time/batch=1.11s
13414/10943 (epoch 110.318) train_loss=157.78109741 time/batch=0.90s
13415/10943 (epoch 110.326) train_loss=121.86095428 time/batch=0.81s
13416/10943 (epoch 110.335) train_loss=129.66612244 time/batch=0.80s
13417/10943 (epoch 110.343) train_loss=141.52563477 time/batch=0.84s
13418/10943 (epoch 110.351) train_loss=116.06512451 time/batch=0.67s
13419/10943 (epoch 110.359) train_loss=76.59104919 time/batch=0.46s
13420/10943 (epoch 110.368) train_loss=98.50620270 time/batch=0.60s
13421/10943 (epoch 110.376) train_loss=113.34996796 time/batch=0.77s
13422/10943 (epoch 110.384) train_loss=96.23065186 time/batch=0.63s
13423/10943 (epoch 110.392) train_loss=216.96594238 time/batch=1.14s
13424/10943 (epoch 110.400) train_loss=129.82635498 time/batch=0.85s
13425/10943 (epoch 110.409) train_loss=173.52474976 time/batch=1.01s
13426/10943 (epoch 110.417) train_loss=85.82939148 time/batch=0.53s
13427/10943 (epoch 110.425) train_loss=68.48994446 time/batch=0.42s
13428/10943 (epoch 110.433) train_loss=105.78919220 time/batch=0.60s
13429/10943 (epoch 110.442) train_loss=139.17094421 time/batch=0.85s
13430/10943 (epoch 110.450) train_loss=122.93124390 time/batch=0.73s
13431/10943 (epoch 110.458) train_loss=84.73634338 time/batch=0.49s
13432/10943 (epoch 110.466) train_loss=151.26087952 time/batch=0.88s
13433/10943 (epoch 110.474) train_loss=127.04682922 time/batch=0.76s
13434/10943 (epoch 110.483) train_loss=88.16848755 time/batch=0.57s
13435/10943 (epoch 110.491) train_loss=83.31298065 time/batch=0.48s
13436/10943 (epoch 110.499) train_loss=126.63281250 time/batch=0.69s
13437/10943 (epoch 110.507) train_loss=146.12313843 time/batch=0.91s
13438/10943 (epoch 110.516) train_loss=96.02954102 time/batch=0.58s
13439/10943 (epoch 110.524) train_loss=109.87799072 time/batch=0.63s
13440/10943 (epoch 110.532) train_loss=116.30743408 time/batch=0.66s
13441/10943 (epoch 110.540) train_loss=98.04736328 time/batch=0.59s
13442/10943 (epoch 110.548) train_loss=108.98456573 time/batch=0.67s
13443/10943 (epoch 110.557) train_loss=116.35914612 time/batch=0.75s
13444/10943 (epoch 110.565) train_loss=111.16714478 time/batch=0.68s
13445/10943 (epoch 110.573) train_loss=74.82937622 time/batch=0.44s
13446/10943 (epoch 110.581) train_loss=108.82772827 time/batch=0.65s
13447/10943 (epoch 110.590) train_loss=99.91705322 time/batch=0.64s
13448/10943 (epoch 110.598) train_loss=137.97186279 time/batch=0.78s
13449/10943 (epoch 110.606) train_loss=73.12519836 time/batch=0.46s
13450/10943 (epoch 110.614) train_loss=94.99665833 time/batch=0.56s
13451/10943 (epoch 110.622) train_loss=99.34932709 time/batch=0.59s
13452/10943 (epoch 110.631) train_loss=110.47908020 time/batch=0.69s
13453/10943 (epoch 110.639) train_loss=90.51152039 time/batch=0.56s
13454/10943 (epoch 110.647) train_loss=64.70027924 time/batch=0.37s
13455/10943 (epoch 110.655) train_loss=121.88699341 time/batch=0.70s
13456/10943 (epoch 110.664) train_loss=92.66197968 time/batch=0.59s
13457/10943 (epoch 110.672) train_loss=111.54311371 time/batch=0.72s
13458/10943 (epoch 110.680) train_loss=62.34295654 time/batch=0.37s
13459/10943 (epoch 110.688) train_loss=65.32869720 time/batch=0.33s
13460/10943 (epoch 110.696) train_loss=102.04724121 time/batch=0.54s
13461/10943 (epoch 110.705) train_loss=75.54986572 time/batch=0.46s
13462/10943 (epoch 110.713) train_loss=94.51797485 time/batch=0.49s
13463/10943 (epoch 110.721) train_loss=81.21931458 time/batch=0.46s
13464/10943 (epoch 110.729) train_loss=94.87705231 time/batch=0.56s
13465/10943 (epoch 110.738) train_loss=82.51553345 time/batch=0.50s
13466/10943 (epoch 110.746) train_loss=111.45410156 time/batch=0.73s
13467/10943 (epoch 110.754) train_loss=87.81964874 time/batch=0.59s
setting learning rate to 0.0007390
13468/10943 (epoch 110.762) train_loss=55.92696381 time/batch=0.31s
13469/10943 (epoch 110.770) train_loss=67.71775818 time/batch=0.40s
13470/10943 (epoch 110.779) train_loss=174.72979736 time/batch=0.94s
13471/10943 (epoch 110.787) train_loss=217.65110779 time/batch=1.15s
13472/10943 (epoch 110.795) train_loss=55.83409882 time/batch=0.37s
13473/10943 (epoch 110.803) train_loss=100.96746826 time/batch=0.65s
13474/10943 (epoch 110.812) train_loss=405.77566528 time/batch=2.05s
13475/10943 (epoch 110.820) train_loss=65.19148254 time/batch=0.49s
13476/10943 (epoch 110.828) train_loss=474.30041504 time/batch=3.00s
13477/10943 (epoch 110.836) train_loss=131.92678833 time/batch=0.94s
13478/10943 (epoch 110.845) train_loss=187.19451904 time/batch=0.98s
13479/10943 (epoch 110.853) train_loss=207.55206299 time/batch=1.14s
13480/10943 (epoch 110.861) train_loss=115.17798615 time/batch=0.76s
13481/10943 (epoch 110.869) train_loss=263.11676025 time/batch=1.47s
13482/10943 (epoch 110.877) train_loss=286.91616821 time/batch=1.61s
13483/10943 (epoch 110.886) train_loss=60.70802689 time/batch=0.45s
13484/10943 (epoch 110.894) train_loss=169.01022339 time/batch=0.89s
13485/10943 (epoch 110.902) train_loss=145.49783325 time/batch=0.95s
13486/10943 (epoch 110.910) train_loss=95.67802429 time/batch=0.65s
13487/10943 (epoch 110.919) train_loss=144.33206177 time/batch=0.87s
13488/10943 (epoch 110.927) train_loss=82.86560059 time/batch=0.60s
13489/10943 (epoch 110.935) train_loss=83.50968933 time/batch=0.52s
13490/10943 (epoch 110.943) train_loss=132.12864685 time/batch=0.81s
13491/10943 (epoch 110.951) train_loss=264.65264893 time/batch=1.29s
13492/10943 (epoch 110.960) train_loss=49.55820084 time/batch=0.36s
13493/10943 (epoch 110.968) train_loss=112.12310028 time/batch=0.62s
13494/10943 (epoch 110.976) train_loss=55.18779373 time/batch=0.36s
13495/10943 (epoch 110.984) train_loss=69.31059265 time/batch=0.42s
13496/10943 (epoch 110.993) train_loss=214.29553223 time/batch=1.05s
13497/10943 (epoch 111.001) train_loss=119.18370819 time/batch=0.82s
13498/10943 (epoch 111.009) train_loss=65.20892334 time/batch=0.42s
13499/10943 (epoch 111.017) train_loss=162.76647949 time/batch=0.90s
13500/10943 (epoch 111.025) train_loss=101.36115265 time/batch=0.72s
13501/10943 (epoch 111.034) train_loss=107.33687592 time/batch=0.67s
13502/10943 (epoch 111.042) train_loss=243.20631409 time/batch=1.28s
13503/10943 (epoch 111.050) train_loss=60.96562958 time/batch=0.41s
13504/10943 (epoch 111.058) train_loss=87.67640686 time/batch=0.48s
13505/10943 (epoch 111.067) train_loss=244.86720276 time/batch=1.32s
13506/10943 (epoch 111.075) train_loss=113.15296936 time/batch=0.73s
13507/10943 (epoch 111.083) train_loss=120.69475555 time/batch=0.73s
13508/10943 (epoch 111.091) train_loss=218.03598022 time/batch=1.17s
13509/10943 (epoch 111.099) train_loss=136.20999146 time/batch=0.90s
13510/10943 (epoch 111.108) train_loss=207.32736206 time/batch=1.14s
13511/10943 (epoch 111.116) train_loss=200.42224121 time/batch=1.06s
13512/10943 (epoch 111.124) train_loss=71.28781128 time/batch=0.48s
13513/10943 (epoch 111.132) train_loss=85.60734558 time/batch=0.54s
13514/10943 (epoch 111.141) train_loss=115.25598145 time/batch=0.69s
13515/10943 (epoch 111.149) train_loss=160.99690247 time/batch=1.01s
13516/10943 (epoch 111.157) train_loss=153.66046143 time/batch=0.93s
13517/10943 (epoch 111.165) train_loss=97.36251831 time/batch=0.67s
13518/10943 (epoch 111.173) train_loss=133.65457153 time/batch=0.84s
13519/10943 (epoch 111.182) train_loss=214.39477539 time/batch=1.18s
13520/10943 (epoch 111.190) train_loss=202.09753418 time/batch=1.07s
13521/10943 (epoch 111.198) train_loss=84.88052368 time/batch=0.53s
13522/10943 (epoch 111.206) train_loss=68.20825958 time/batch=0.37s
13523/10943 (epoch 111.215) train_loss=140.70770264 time/batch=0.80s
13524/10943 (epoch 111.223) train_loss=67.60951233 time/batch=0.40s
13525/10943 (epoch 111.231) train_loss=146.77978516 time/batch=0.83s
13526/10943 (epoch 111.239) train_loss=81.20066833 time/batch=0.53s
13527/10943 (epoch 111.247) train_loss=97.45413971 time/batch=0.61s
13528/10943 (epoch 111.256) train_loss=120.68766785 time/batch=0.74s
13529/10943 (epoch 111.264) train_loss=119.92480469 time/batch=0.80s
13530/10943 (epoch 111.272) train_loss=103.97872925 time/batch=0.70s
13531/10943 (epoch 111.280) train_loss=101.23823547 time/batch=0.69s
13532/10943 (epoch 111.289) train_loss=157.00378418 time/batch=0.95s
13533/10943 (epoch 111.297) train_loss=106.44858551 time/batch=0.73s
13534/10943 (epoch 111.305) train_loss=116.84004211 time/batch=0.78s
13535/10943 (epoch 111.313) train_loss=120.49111938 time/batch=0.72s
13536/10943 (epoch 111.322) train_loss=165.09378052 time/batch=0.96s
13537/10943 (epoch 111.330) train_loss=101.26275635 time/batch=0.63s
13538/10943 (epoch 111.338) train_loss=192.06927490 time/batch=1.17s
13539/10943 (epoch 111.346) train_loss=81.96260071 time/batch=0.57s
13540/10943 (epoch 111.354) train_loss=147.62289429 time/batch=0.86s
13541/10943 (epoch 111.363) train_loss=105.58119202 time/batch=0.66s
13542/10943 (epoch 111.371) train_loss=104.48937988 time/batch=0.64s
13543/10943 (epoch 111.379) train_loss=119.40295410 time/batch=0.80s
13544/10943 (epoch 111.387) train_loss=66.16372681 time/batch=0.42s
13545/10943 (epoch 111.396) train_loss=192.40107727 time/batch=1.16s
13546/10943 (epoch 111.404) train_loss=98.47924805 time/batch=0.60s
13547/10943 (epoch 111.412) train_loss=70.52064514 time/batch=0.46s
13548/10943 (epoch 111.420) train_loss=62.15173721 time/batch=0.36s
13549/10943 (epoch 111.428) train_loss=78.01752472 time/batch=0.44s
13550/10943 (epoch 111.437) train_loss=70.25204468 time/batch=0.39s
13551/10943 (epoch 111.445) train_loss=129.48731995 time/batch=0.78s
13552/10943 (epoch 111.453) train_loss=142.95603943 time/batch=0.87s
13553/10943 (epoch 111.461) train_loss=69.51477051 time/batch=0.44s
13554/10943 (epoch 111.470) train_loss=95.23448181 time/batch=0.52s
13555/10943 (epoch 111.478) train_loss=133.19367981 time/batch=0.79s
13556/10943 (epoch 111.486) train_loss=83.46006775 time/batch=0.53s
13557/10943 (epoch 111.494) train_loss=87.73017883 time/batch=0.49s
13558/10943 (epoch 111.502) train_loss=70.08167267 time/batch=0.43s
13559/10943 (epoch 111.511) train_loss=91.50531006 time/batch=0.60s
13560/10943 (epoch 111.519) train_loss=93.79519653 time/batch=0.57s
13561/10943 (epoch 111.527) train_loss=134.79637146 time/batch=0.80s
13562/10943 (epoch 111.535) train_loss=147.77111816 time/batch=0.85s
13563/10943 (epoch 111.544) train_loss=126.06077576 time/batch=0.79s
13564/10943 (epoch 111.552) train_loss=137.25964355 time/batch=0.77s
13565/10943 (epoch 111.560) train_loss=80.70964050 time/batch=0.47s
13566/10943 (epoch 111.568) train_loss=84.19374084 time/batch=0.50s
13567/10943 (epoch 111.576) train_loss=117.30435944 time/batch=0.65s
13568/10943 (epoch 111.585) train_loss=87.20993805 time/batch=0.58s
13569/10943 (epoch 111.593) train_loss=130.15859985 time/batch=0.72s
13570/10943 (epoch 111.601) train_loss=90.93872070 time/batch=0.54s
13571/10943 (epoch 111.609) train_loss=86.37705994 time/batch=0.53s
13572/10943 (epoch 111.618) train_loss=95.74282074 time/batch=0.57s
13573/10943 (epoch 111.626) train_loss=130.33706665 time/batch=0.76s
13574/10943 (epoch 111.634) train_loss=78.90417480 time/batch=0.56s
13575/10943 (epoch 111.642) train_loss=98.35781860 time/batch=0.59s
13576/10943 (epoch 111.650) train_loss=102.99759674 time/batch=0.60s
13577/10943 (epoch 111.659) train_loss=119.35743713 time/batch=0.74s
13578/10943 (epoch 111.667) train_loss=111.25454712 time/batch=0.67s
13579/10943 (epoch 111.675) train_loss=138.89891052 time/batch=0.80s
13580/10943 (epoch 111.683) train_loss=139.01237488 time/batch=0.74s
13581/10943 (epoch 111.692) train_loss=100.64210510 time/batch=0.60s
13582/10943 (epoch 111.700) train_loss=125.19164276 time/batch=0.76s
13583/10943 (epoch 111.708) train_loss=130.66125488 time/batch=0.82s
13584/10943 (epoch 111.716) train_loss=102.60871887 time/batch=0.61s
13585/10943 (epoch 111.724) train_loss=99.86984253 time/batch=0.58s
13586/10943 (epoch 111.733) train_loss=103.86563110 time/batch=0.63s
13587/10943 (epoch 111.741) train_loss=94.80677032 time/batch=0.63s
13588/10943 (epoch 111.749) train_loss=112.59581757 time/batch=0.73s
setting learning rate to 0.0007168
  saved to metadata/gru_no_dropout-9_nov_folkwiki-20181207-192453_epoch67.pkl
13589/10943 (epoch 111.757) train_loss=111.85028839 time/batch=0.83s
13590/10943 (epoch 111.766) train_loss=66.68869781 time/batch=0.48s
13591/10943 (epoch 111.774) train_loss=216.05426025 time/batch=1.16s
13592/10943 (epoch 111.782) train_loss=168.34117126 time/batch=1.00s
13593/10943 (epoch 111.790) train_loss=103.04064941 time/batch=0.68s
13594/10943 (epoch 111.799) train_loss=483.39935303 time/batch=3.07s
13595/10943 (epoch 111.807) train_loss=231.54814148 time/batch=1.38s
13596/10943 (epoch 111.815) train_loss=131.00204468 time/batch=0.85s
13597/10943 (epoch 111.823) train_loss=269.55432129 time/batch=1.28s
13598/10943 (epoch 111.831) train_loss=159.82109070 time/batch=0.95s
13599/10943 (epoch 111.840) train_loss=53.59270859 time/batch=0.31s
13600/10943 (epoch 111.848) train_loss=258.98510742 time/batch=1.34s
13601/10943 (epoch 111.856) train_loss=170.45892334 time/batch=1.04s
13602/10943 (epoch 111.864) train_loss=221.73013306 time/batch=1.17s
13603/10943 (epoch 111.873) train_loss=315.24774170 time/batch=1.63s
13604/10943 (epoch 111.881) train_loss=346.94488525 time/batch=1.75s
13605/10943 (epoch 111.889) train_loss=70.53994751 time/batch=0.51s
13606/10943 (epoch 111.897) train_loss=125.36008453 time/batch=0.75s
13607/10943 (epoch 111.905) train_loss=208.90869141 time/batch=1.11s
13608/10943 (epoch 111.914) train_loss=179.12835693 time/batch=1.03s
13609/10943 (epoch 111.922) train_loss=196.37051392 time/batch=1.07s
13610/10943 (epoch 111.930) train_loss=63.12474060 time/batch=0.39s
13611/10943 (epoch 111.938) train_loss=217.58651733 time/batch=1.15s
13612/10943 (epoch 111.947) train_loss=119.29384613 time/batch=0.83s
13613/10943 (epoch 111.955) train_loss=107.43088531 time/batch=0.69s
13614/10943 (epoch 111.963) train_loss=81.40458679 time/batch=0.53s
13615/10943 (epoch 111.971) train_loss=143.88583374 time/batch=0.86s
13616/10943 (epoch 111.979) train_loss=69.15565491 time/batch=0.48s
13617/10943 (epoch 111.988) train_loss=88.32338715 time/batch=0.52s
13618/10943 (epoch 111.996) train_loss=62.45306396 time/batch=0.36s
13619/10943 (epoch 112.004) train_loss=231.60896301 time/batch=1.19s
13620/10943 (epoch 112.012) train_loss=165.97268677 time/batch=1.02s
13621/10943 (epoch 112.021) train_loss=180.13717651 time/batch=1.01s
13622/10943 (epoch 112.029) train_loss=255.89140320 time/batch=1.44s
13623/10943 (epoch 112.037) train_loss=91.24681091 time/batch=0.72s
13624/10943 (epoch 112.045) train_loss=92.15145874 time/batch=0.62s
13625/10943 (epoch 112.053) train_loss=117.47766113 time/batch=0.77s
13626/10943 (epoch 112.062) train_loss=86.77880859 time/batch=0.63s
13627/10943 (epoch 112.070) train_loss=171.44041443 time/batch=0.99s
13628/10943 (epoch 112.078) train_loss=115.21974945 time/batch=0.76s
13629/10943 (epoch 112.086) train_loss=58.83394241 time/batch=0.33s
13630/10943 (epoch 112.095) train_loss=104.55686951 time/batch=0.63s
13631/10943 (epoch 112.103) train_loss=124.02895355 time/batch=0.84s
13632/10943 (epoch 112.111) train_loss=81.57888794 time/batch=0.59s
13633/10943 (epoch 112.119) train_loss=134.13995361 time/batch=0.84s
13634/10943 (epoch 112.127) train_loss=121.56430817 time/batch=0.75s
13635/10943 (epoch 112.136) train_loss=75.56221771 time/batch=0.52s
13636/10943 (epoch 112.144) train_loss=58.11495972 time/batch=0.29s
13637/10943 (epoch 112.152) train_loss=141.45243835 time/batch=0.87s
13638/10943 (epoch 112.160) train_loss=78.33958435 time/batch=0.51s
13639/10943 (epoch 112.169) train_loss=50.11272049 time/batch=0.31s
13640/10943 (epoch 112.177) train_loss=65.86519623 time/batch=0.38s
13641/10943 (epoch 112.185) train_loss=132.50935364 time/batch=0.83s
13642/10943 (epoch 112.193) train_loss=137.34819031 time/batch=0.85s
13643/10943 (epoch 112.201) train_loss=121.52648926 time/batch=0.77s
13644/10943 (epoch 112.210) train_loss=125.26799774 time/batch=0.81s
13645/10943 (epoch 112.218) train_loss=199.11531067 time/batch=1.28s
13646/10943 (epoch 112.226) train_loss=73.20611572 time/batch=0.51s
13647/10943 (epoch 112.234) train_loss=88.32865143 time/batch=0.57s
13648/10943 (epoch 112.243) train_loss=149.43652344 time/batch=0.90s
13649/10943 (epoch 112.251) train_loss=122.20202637 time/batch=0.83s
13650/10943 (epoch 112.259) train_loss=95.55269623 time/batch=0.62s
13651/10943 (epoch 112.267) train_loss=122.87002563 time/batch=0.70s
13652/10943 (epoch 112.276) train_loss=129.16400146 time/batch=0.81s
13653/10943 (epoch 112.284) train_loss=112.89366150 time/batch=0.70s
13654/10943 (epoch 112.292) train_loss=137.94677734 time/batch=0.82s
13655/10943 (epoch 112.300) train_loss=108.68060303 time/batch=0.71s
13656/10943 (epoch 112.308) train_loss=100.03449249 time/batch=0.63s
13657/10943 (epoch 112.317) train_loss=87.39754486 time/batch=0.57s
13658/10943 (epoch 112.325) train_loss=97.91181946 time/batch=0.60s
13659/10943 (epoch 112.333) train_loss=102.58486938 time/batch=0.62s
13660/10943 (epoch 112.341) train_loss=88.89057159 time/batch=0.54s
13661/10943 (epoch 112.350) train_loss=86.45463562 time/batch=0.52s
13662/10943 (epoch 112.358) train_loss=102.86160278 time/batch=0.67s
13663/10943 (epoch 112.366) train_loss=125.21218872 time/batch=0.75s
13664/10943 (epoch 112.374) train_loss=77.67817688 time/batch=0.50s
13665/10943 (epoch 112.382) train_loss=87.20587158 time/batch=0.49s
13666/10943 (epoch 112.391) train_loss=137.31106567 time/batch=0.80s
13667/10943 (epoch 112.399) train_loss=173.55752563 time/batch=1.02s
13668/10943 (epoch 112.407) train_loss=90.06390381 time/batch=0.56s
13669/10943 (epoch 112.415) train_loss=146.68853760 time/batch=0.83s
13670/10943 (epoch 112.424) train_loss=93.95420074 time/batch=0.60s
13671/10943 (epoch 112.432) train_loss=100.21427917 time/batch=0.62s
13672/10943 (epoch 112.440) train_loss=60.83026505 time/batch=0.35s
13673/10943 (epoch 112.448) train_loss=103.96971130 time/batch=0.64s
13674/10943 (epoch 112.456) train_loss=200.06051636 time/batch=1.01s
13675/10943 (epoch 112.465) train_loss=133.15017700 time/batch=0.80s
13676/10943 (epoch 112.473) train_loss=76.95957947 time/batch=0.46s
13677/10943 (epoch 112.481) train_loss=111.37046814 time/batch=0.62s
13678/10943 (epoch 112.489) train_loss=133.91151428 time/batch=0.81s
13679/10943 (epoch 112.498) train_loss=114.50837708 time/batch=0.66s
13680/10943 (epoch 112.506) train_loss=187.12582397 time/batch=1.05s
13681/10943 (epoch 112.514) train_loss=67.63964844 time/batch=0.43s
13682/10943 (epoch 112.522) train_loss=129.60272217 time/batch=0.71s
13683/10943 (epoch 112.530) train_loss=74.56984711 time/batch=0.43s
13684/10943 (epoch 112.539) train_loss=115.11923218 time/batch=0.73s
13685/10943 (epoch 112.547) train_loss=69.09204865 time/batch=0.42s
13686/10943 (epoch 112.555) train_loss=93.30758667 time/batch=0.51s
13687/10943 (epoch 112.563) train_loss=153.69769287 time/batch=0.98s
13688/10943 (epoch 112.572) train_loss=139.12188721 time/batch=0.90s
13689/10943 (epoch 112.580) train_loss=97.90563202 time/batch=0.62s
13690/10943 (epoch 112.588) train_loss=74.77020264 time/batch=0.44s
13691/10943 (epoch 112.596) train_loss=99.55509949 time/batch=0.62s
13692/10943 (epoch 112.604) train_loss=74.80627441 time/batch=0.48s
13693/10943 (epoch 112.613) train_loss=79.20639801 time/batch=0.46s
13694/10943 (epoch 112.621) train_loss=115.55860901 time/batch=0.68s
13695/10943 (epoch 112.629) train_loss=95.89662170 time/batch=0.59s
13696/10943 (epoch 112.637) train_loss=84.16931152 time/batch=0.53s
13697/10943 (epoch 112.646) train_loss=94.11225891 time/batch=0.57s
13698/10943 (epoch 112.654) train_loss=120.04386139 time/batch=0.69s
13699/10943 (epoch 112.662) train_loss=114.31831360 time/batch=0.67s
13700/10943 (epoch 112.670) train_loss=67.82174683 time/batch=0.41s
13701/10943 (epoch 112.678) train_loss=121.09523010 time/batch=0.64s
13702/10943 (epoch 112.687) train_loss=113.30430603 time/batch=0.68s
13703/10943 (epoch 112.695) train_loss=91.12649536 time/batch=0.55s
13704/10943 (epoch 112.703) train_loss=61.04344559 time/batch=0.35s
13705/10943 (epoch 112.711) train_loss=69.71146393 time/batch=0.46s
13706/10943 (epoch 112.720) train_loss=109.31644440 time/batch=0.68s
13707/10943 (epoch 112.728) train_loss=100.07159424 time/batch=0.59s
13708/10943 (epoch 112.736) train_loss=133.47961426 time/batch=0.77s
13709/10943 (epoch 112.744) train_loss=135.56805420 time/batch=0.82s
setting learning rate to 0.0006953
13710/10943 (epoch 112.753) train_loss=445.03308105 time/batch=2.37s
13711/10943 (epoch 112.761) train_loss=150.52392578 time/batch=1.06s
13712/10943 (epoch 112.769) train_loss=229.66561890 time/batch=1.21s
13713/10943 (epoch 112.777) train_loss=57.29232407 time/batch=0.39s
13714/10943 (epoch 112.785) train_loss=49.28581238 time/batch=0.32s
13715/10943 (epoch 112.794) train_loss=275.03976440 time/batch=1.44s
13716/10943 (epoch 112.802) train_loss=126.17362976 time/batch=0.90s
13717/10943 (epoch 112.810) train_loss=249.14916992 time/batch=1.25s
13718/10943 (epoch 112.818) train_loss=90.38583374 time/batch=0.59s
13719/10943 (epoch 112.827) train_loss=75.07835388 time/batch=0.48s
13720/10943 (epoch 112.835) train_loss=155.72033691 time/batch=0.87s
13721/10943 (epoch 112.843) train_loss=121.85899353 time/batch=0.79s
13722/10943 (epoch 112.851) train_loss=117.30769348 time/batch=0.74s
13723/10943 (epoch 112.859) train_loss=135.50732422 time/batch=0.86s
13724/10943 (epoch 112.868) train_loss=149.95780945 time/batch=0.89s
13725/10943 (epoch 112.876) train_loss=109.31407166 time/batch=0.73s
13726/10943 (epoch 112.884) train_loss=109.57118225 time/batch=0.78s
13727/10943 (epoch 112.892) train_loss=100.81115723 time/batch=0.67s
13728/10943 (epoch 112.901) train_loss=120.93737793 time/batch=0.77s
13729/10943 (epoch 112.909) train_loss=60.80756378 time/batch=0.39s
13730/10943 (epoch 112.917) train_loss=255.10809326 time/batch=1.31s
13731/10943 (epoch 112.925) train_loss=218.59411621 time/batch=1.22s
13732/10943 (epoch 112.933) train_loss=192.50000000 time/batch=1.10s
13733/10943 (epoch 112.942) train_loss=73.80787659 time/batch=0.48s
13734/10943 (epoch 112.950) train_loss=231.21347046 time/batch=1.21s
13735/10943 (epoch 112.958) train_loss=122.79373169 time/batch=0.87s
13736/10943 (epoch 112.966) train_loss=128.74597168 time/batch=0.86s
13737/10943 (epoch 112.975) train_loss=97.11537170 time/batch=0.66s
13738/10943 (epoch 112.983) train_loss=92.75746155 time/batch=0.55s
13739/10943 (epoch 112.991) train_loss=53.47472382 time/batch=0.30s
13740/10943 (epoch 112.999) train_loss=105.67503357 time/batch=0.70s
13741/10943 (epoch 113.007) train_loss=254.72808838 time/batch=1.50s
13742/10943 (epoch 113.016) train_loss=122.90702820 time/batch=0.82s
13743/10943 (epoch 113.024) train_loss=177.04464722 time/batch=0.99s
13744/10943 (epoch 113.032) train_loss=134.71609497 time/batch=0.84s
13745/10943 (epoch 113.040) train_loss=66.95384216 time/batch=0.40s
13746/10943 (epoch 113.049) train_loss=87.34215546 time/batch=0.51s
13747/10943 (epoch 113.057) train_loss=201.58895874 time/batch=1.08s
13748/10943 (epoch 113.065) train_loss=423.04107666 time/batch=3.10s
13749/10943 (epoch 113.073) train_loss=91.54353333 time/batch=0.78s
13750/10943 (epoch 113.081) train_loss=111.13671875 time/batch=0.63s
13751/10943 (epoch 113.090) train_loss=200.73022461 time/batch=1.07s
13752/10943 (epoch 113.098) train_loss=69.73348999 time/batch=0.48s
13753/10943 (epoch 113.106) train_loss=50.53861237 time/batch=0.28s
13754/10943 (epoch 113.114) train_loss=89.95947266 time/batch=0.56s
13755/10943 (epoch 113.123) train_loss=59.67040253 time/batch=0.32s
13756/10943 (epoch 113.131) train_loss=87.72537994 time/batch=0.58s
13757/10943 (epoch 113.139) train_loss=218.62948608 time/batch=1.26s
13758/10943 (epoch 113.147) train_loss=131.90267944 time/batch=0.81s
13759/10943 (epoch 113.155) train_loss=66.60572052 time/batch=0.45s
13760/10943 (epoch 113.164) train_loss=61.83271790 time/batch=0.36s
13761/10943 (epoch 113.172) train_loss=54.29114532 time/batch=0.31s
13762/10943 (epoch 113.180) train_loss=90.47043610 time/batch=0.54s
13763/10943 (epoch 113.188) train_loss=187.65721130 time/batch=0.99s
13764/10943 (epoch 113.197) train_loss=247.89501953 time/batch=1.55s
13765/10943 (epoch 113.205) train_loss=78.86129761 time/batch=0.60s
13766/10943 (epoch 113.213) train_loss=88.19975281 time/batch=0.54s
13767/10943 (epoch 113.221) train_loss=146.13858032 time/batch=0.81s
13768/10943 (epoch 113.230) train_loss=124.32421112 time/batch=0.80s
13769/10943 (epoch 113.238) train_loss=151.85113525 time/batch=0.94s
13770/10943 (epoch 113.246) train_loss=150.86758423 time/batch=0.90s
13771/10943 (epoch 113.254) train_loss=181.03598022 time/batch=0.98s
13772/10943 (epoch 113.262) train_loss=86.28171539 time/batch=0.55s
13773/10943 (epoch 113.271) train_loss=71.37928772 time/batch=0.42s
13774/10943 (epoch 113.279) train_loss=101.33778381 time/batch=0.58s
13775/10943 (epoch 113.287) train_loss=187.96362305 time/batch=0.99s
13776/10943 (epoch 113.295) train_loss=103.83172607 time/batch=0.66s
13777/10943 (epoch 113.304) train_loss=125.21868896 time/batch=0.70s
13778/10943 (epoch 113.312) train_loss=124.92787170 time/batch=0.81s
13779/10943 (epoch 113.320) train_loss=92.74906921 time/batch=0.62s
13780/10943 (epoch 113.328) train_loss=190.61373901 time/batch=1.04s
13781/10943 (epoch 113.336) train_loss=188.42907715 time/batch=1.00s
13782/10943 (epoch 113.345) train_loss=81.79145050 time/batch=0.54s
13783/10943 (epoch 113.353) train_loss=91.65669250 time/batch=0.58s
13784/10943 (epoch 113.361) train_loss=56.98689270 time/batch=0.36s
13785/10943 (epoch 113.369) train_loss=126.47704315 time/batch=0.71s
13786/10943 (epoch 113.378) train_loss=74.58525085 time/batch=0.53s
13787/10943 (epoch 113.386) train_loss=104.89048767 time/batch=0.66s
13788/10943 (epoch 113.394) train_loss=101.84927368 time/batch=0.70s
13789/10943 (epoch 113.402) train_loss=107.90776062 time/batch=0.68s
13790/10943 (epoch 113.410) train_loss=117.18586731 time/batch=0.72s
13791/10943 (epoch 113.419) train_loss=145.23316956 time/batch=0.91s
13792/10943 (epoch 113.427) train_loss=69.40994263 time/batch=0.43s
13793/10943 (epoch 113.435) train_loss=113.62812805 time/batch=0.76s
13794/10943 (epoch 113.443) train_loss=117.26347351 time/batch=0.69s
13795/10943 (epoch 113.452) train_loss=71.79232788 time/batch=0.45s
13796/10943 (epoch 113.460) train_loss=122.99414062 time/batch=0.77s
13797/10943 (epoch 113.468) train_loss=86.13250732 time/batch=0.58s
13798/10943 (epoch 113.476) train_loss=159.22680664 time/batch=0.91s
13799/10943 (epoch 113.484) train_loss=94.83346558 time/batch=0.61s
13800/10943 (epoch 113.493) train_loss=123.03380585 time/batch=0.74s
13801/10943 (epoch 113.501) train_loss=139.07019043 time/batch=0.84s
13802/10943 (epoch 113.509) train_loss=113.30565643 time/batch=0.69s
13803/10943 (epoch 113.517) train_loss=168.68682861 time/batch=0.96s
13804/10943 (epoch 113.526) train_loss=120.02106476 time/batch=0.71s
13805/10943 (epoch 113.534) train_loss=77.72612000 time/batch=0.48s
13806/10943 (epoch 113.542) train_loss=88.00813293 time/batch=0.55s
13807/10943 (epoch 113.550) train_loss=109.68997192 time/batch=0.64s
13808/10943 (epoch 113.558) train_loss=102.26832581 time/batch=0.60s
13809/10943 (epoch 113.567) train_loss=84.58381653 time/batch=0.52s
13810/10943 (epoch 113.575) train_loss=110.12050629 time/batch=0.65s
13811/10943 (epoch 113.583) train_loss=143.97503662 time/batch=0.89s
13812/10943 (epoch 113.591) train_loss=115.49000549 time/batch=0.71s
13813/10943 (epoch 113.600) train_loss=101.22573090 time/batch=0.60s
13814/10943 (epoch 113.608) train_loss=74.43692017 time/batch=0.44s
13815/10943 (epoch 113.616) train_loss=100.03344727 time/batch=0.61s
13816/10943 (epoch 113.624) train_loss=118.06719208 time/batch=0.70s
13817/10943 (epoch 113.632) train_loss=91.40562439 time/batch=0.60s
13818/10943 (epoch 113.641) train_loss=81.42567444 time/batch=0.46s
13819/10943 (epoch 113.649) train_loss=69.52111816 time/batch=0.44s
13820/10943 (epoch 113.657) train_loss=97.22471619 time/batch=0.60s
13821/10943 (epoch 113.665) train_loss=170.01657104 time/batch=0.92s
13822/10943 (epoch 113.674) train_loss=72.26736450 time/batch=0.50s
13823/10943 (epoch 113.682) train_loss=125.47059631 time/batch=0.72s
13824/10943 (epoch 113.690) train_loss=77.21224976 time/batch=0.49s
13825/10943 (epoch 113.698) train_loss=97.12652588 time/batch=0.59s
13826/10943 (epoch 113.707) train_loss=133.04615784 time/batch=0.80s
13827/10943 (epoch 113.715) train_loss=126.70809937 time/batch=0.81s
13828/10943 (epoch 113.723) train_loss=89.54412842 time/batch=0.55s
13829/10943 (epoch 113.731) train_loss=98.99594116 time/batch=0.58s
13830/10943 (epoch 113.739) train_loss=136.91635132 time/batch=0.83s
setting learning rate to 0.0006744
  saved to metadata/gru_no_dropout-9_nov_folkwiki-20181207-192453_epoch69.pkl
13831/10943 (epoch 113.748) train_loss=132.44839478 time/batch=0.87s
13832/10943 (epoch 113.756) train_loss=364.18832397 time/batch=1.74s
13833/10943 (epoch 113.764) train_loss=80.27352905 time/batch=0.57s
13834/10943 (epoch 113.772) train_loss=62.54294205 time/batch=0.36s
13835/10943 (epoch 113.781) train_loss=146.97003174 time/batch=0.84s
13836/10943 (epoch 113.789) train_loss=105.74938202 time/batch=0.71s
13837/10943 (epoch 113.797) train_loss=165.93856812 time/batch=0.93s
13838/10943 (epoch 113.805) train_loss=135.98614502 time/batch=0.87s
13839/10943 (epoch 113.813) train_loss=116.74128723 time/batch=0.76s
13840/10943 (epoch 113.822) train_loss=248.58503723 time/batch=1.24s
13841/10943 (epoch 113.830) train_loss=56.50137329 time/batch=0.37s
13842/10943 (epoch 113.838) train_loss=60.61731720 time/batch=0.35s
13843/10943 (epoch 113.846) train_loss=87.32183075 time/batch=0.49s
13844/10943 (epoch 113.855) train_loss=249.79624939 time/batch=1.30s
13845/10943 (epoch 113.863) train_loss=494.58099365 time/batch=3.14s
13846/10943 (epoch 113.871) train_loss=282.94891357 time/batch=1.63s
13847/10943 (epoch 113.879) train_loss=175.16842651 time/batch=1.04s
13848/10943 (epoch 113.887) train_loss=92.31372070 time/batch=0.58s
13849/10943 (epoch 113.896) train_loss=86.50227356 time/batch=0.57s
13850/10943 (epoch 113.904) train_loss=211.04891968 time/batch=1.08s
13851/10943 (epoch 113.912) train_loss=92.64524841 time/batch=0.61s
13852/10943 (epoch 113.920) train_loss=120.75588989 time/batch=0.71s
13853/10943 (epoch 113.929) train_loss=181.29908752 time/batch=1.01s
13854/10943 (epoch 113.937) train_loss=181.34071350 time/batch=1.02s
13855/10943 (epoch 113.945) train_loss=79.19444275 time/batch=0.57s
13856/10943 (epoch 113.953) train_loss=92.15207672 time/batch=0.62s
13857/10943 (epoch 113.961) train_loss=208.54504395 time/batch=1.10s
13858/10943 (epoch 113.970) train_loss=225.28446960 time/batch=1.24s
13859/10943 (epoch 113.978) train_loss=227.57278442 time/batch=1.20s
13860/10943 (epoch 113.986) train_loss=294.13964844 time/batch=1.58s
13861/10943 (epoch 113.994) train_loss=216.06576538 time/batch=1.29s
13862/10943 (epoch 114.003) train_loss=77.19689941 time/batch=0.50s
13863/10943 (epoch 114.011) train_loss=194.89660645 time/batch=1.07s
13864/10943 (epoch 114.019) train_loss=199.27590942 time/batch=1.10s
13865/10943 (epoch 114.027) train_loss=240.92639160 time/batch=1.46s
13866/10943 (epoch 114.035) train_loss=53.74486542 time/batch=0.40s
13867/10943 (epoch 114.044) train_loss=73.84820557 time/batch=0.45s
13868/10943 (epoch 114.052) train_loss=116.09414673 time/batch=0.77s
13869/10943 (epoch 114.060) train_loss=64.21510315 time/batch=0.40s
13870/10943 (epoch 114.068) train_loss=121.29406738 time/batch=0.76s
13871/10943 (epoch 114.077) train_loss=69.68997192 time/batch=0.48s
13872/10943 (epoch 114.085) train_loss=116.26485443 time/batch=0.77s
13873/10943 (epoch 114.093) train_loss=63.53888702 time/batch=0.42s
13874/10943 (epoch 114.101) train_loss=91.73735809 time/batch=0.57s
13875/10943 (epoch 114.109) train_loss=127.70349884 time/batch=0.82s
13876/10943 (epoch 114.118) train_loss=72.16496277 time/batch=0.49s
13877/10943 (epoch 114.126) train_loss=161.62730408 time/batch=0.96s
13878/10943 (epoch 114.134) train_loss=65.39385986 time/batch=0.47s
13879/10943 (epoch 114.142) train_loss=122.43779755 time/batch=0.78s
13880/10943 (epoch 114.151) train_loss=125.47715759 time/batch=0.86s
13881/10943 (epoch 114.159) train_loss=131.61837769 time/batch=0.84s
13882/10943 (epoch 114.167) train_loss=140.10159302 time/batch=0.87s
13883/10943 (epoch 114.175) train_loss=103.76181030 time/batch=0.70s
13884/10943 (epoch 114.184) train_loss=169.21508789 time/batch=1.03s
13885/10943 (epoch 114.192) train_loss=106.45150757 time/batch=0.71s
13886/10943 (epoch 114.200) train_loss=84.31942749 time/batch=0.51s
13887/10943 (epoch 114.208) train_loss=111.33895874 time/batch=0.69s
13888/10943 (epoch 114.216) train_loss=57.13973999 time/batch=0.36s
13889/10943 (epoch 114.225) train_loss=86.42748260 time/batch=0.53s
13890/10943 (epoch 114.233) train_loss=146.99987793 time/batch=0.85s
13891/10943 (epoch 114.241) train_loss=95.26556396 time/batch=0.63s
13892/10943 (epoch 114.249) train_loss=183.13626099 time/batch=1.00s
13893/10943 (epoch 114.258) train_loss=76.72979736 time/batch=0.52s
13894/10943 (epoch 114.266) train_loss=84.42362976 time/batch=0.55s
13895/10943 (epoch 114.274) train_loss=82.07267761 time/batch=0.49s
13896/10943 (epoch 114.282) train_loss=90.75648499 time/batch=0.56s
13897/10943 (epoch 114.290) train_loss=124.21578979 time/batch=0.72s
13898/10943 (epoch 114.299) train_loss=64.90949249 time/batch=0.42s
13899/10943 (epoch 114.307) train_loss=109.57843781 time/batch=0.66s
13900/10943 (epoch 114.315) train_loss=68.24138641 time/batch=0.42s
13901/10943 (epoch 114.323) train_loss=130.82220459 time/batch=0.74s
13902/10943 (epoch 114.332) train_loss=96.88261414 time/batch=0.63s
13903/10943 (epoch 114.340) train_loss=131.03041077 time/batch=0.81s
13904/10943 (epoch 114.348) train_loss=106.87460327 time/batch=0.71s
13905/10943 (epoch 114.356) train_loss=121.72321320 time/batch=0.78s
13906/10943 (epoch 114.364) train_loss=82.68159485 time/batch=0.51s
13907/10943 (epoch 114.373) train_loss=117.12145996 time/batch=0.72s
13908/10943 (epoch 114.381) train_loss=93.81539154 time/batch=0.61s
13909/10943 (epoch 114.389) train_loss=101.42587280 time/batch=0.67s
13910/10943 (epoch 114.397) train_loss=89.61802673 time/batch=0.62s
13911/10943 (epoch 114.406) train_loss=91.24678802 time/batch=0.57s
13912/10943 (epoch 114.414) train_loss=120.09916687 time/batch=0.80s
13913/10943 (epoch 114.422) train_loss=68.80165863 time/batch=0.43s
13914/10943 (epoch 114.430) train_loss=111.13789368 time/batch=0.71s
13915/10943 (epoch 114.438) train_loss=177.67686462 time/batch=1.01s
13916/10943 (epoch 114.447) train_loss=81.18982697 time/batch=0.52s
13917/10943 (epoch 114.455) train_loss=58.84465790 time/batch=0.31s
13918/10943 (epoch 114.463) train_loss=79.37129211 time/batch=0.46s
13919/10943 (epoch 114.471) train_loss=115.84860229 time/batch=0.66s
13920/10943 (epoch 114.480) train_loss=101.28613281 time/batch=0.63s
13921/10943 (epoch 114.488) train_loss=152.40937805 time/batch=0.90s
13922/10943 (epoch 114.496) train_loss=96.32974243 time/batch=0.58s
13923/10943 (epoch 114.504) train_loss=105.93096161 time/batch=0.60s
13924/10943 (epoch 114.512) train_loss=61.56604004 time/batch=0.33s
13925/10943 (epoch 114.521) train_loss=63.62953186 time/batch=0.31s
13926/10943 (epoch 114.529) train_loss=73.46329498 time/batch=0.41s
13927/10943 (epoch 114.537) train_loss=58.11980057 time/batch=0.31s
13928/10943 (epoch 114.545) train_loss=89.68038177 time/batch=0.56s
13929/10943 (epoch 114.554) train_loss=87.29508972 time/batch=0.59s
13930/10943 (epoch 114.562) train_loss=95.89758301 time/batch=0.51s
13931/10943 (epoch 114.570) train_loss=140.23284912 time/batch=0.83s
13932/10943 (epoch 114.578) train_loss=174.87658691 time/batch=0.96s
13933/10943 (epoch 114.586) train_loss=106.26107788 time/batch=0.64s
13934/10943 (epoch 114.595) train_loss=156.62820435 time/batch=0.90s
13935/10943 (epoch 114.603) train_loss=79.83791351 time/batch=0.56s
13936/10943 (epoch 114.611) train_loss=127.03150940 time/batch=0.72s
13937/10943 (epoch 114.619) train_loss=158.78094482 time/batch=0.92s
13938/10943 (epoch 114.628) train_loss=121.02774048 time/batch=0.69s
13939/10943 (epoch 114.636) train_loss=99.16209412 time/batch=0.61s
13940/10943 (epoch 114.644) train_loss=100.43324280 time/batch=0.62s
13941/10943 (epoch 114.652) train_loss=144.58044434 time/batch=0.89s
13942/10943 (epoch 114.660) train_loss=125.42161560 time/batch=0.73s
13943/10943 (epoch 114.669) train_loss=120.99807739 time/batch=0.78s
13944/10943 (epoch 114.677) train_loss=129.78717041 time/batch=0.72s
13945/10943 (epoch 114.685) train_loss=122.92990112 time/batch=0.78s
13946/10943 (epoch 114.693) train_loss=134.47297668 time/batch=0.83s
13947/10943 (epoch 114.702) train_loss=112.73410034 time/batch=0.72s
13948/10943 (epoch 114.710) train_loss=109.70855713 time/batch=0.65s
13949/10943 (epoch 114.718) train_loss=125.62917328 time/batch=0.81s
13950/10943 (epoch 114.726) train_loss=116.85624695 time/batch=0.67s
13951/10943 (epoch 114.735) train_loss=101.64358521 time/batch=0.66s
setting learning rate to 0.0006542
13952/10943 (epoch 114.743) train_loss=68.12654114 time/batch=0.45s
13953/10943 (epoch 114.751) train_loss=257.93203735 time/batch=1.24s
13954/10943 (epoch 114.759) train_loss=88.83973694 time/batch=0.62s
13955/10943 (epoch 114.767) train_loss=55.39439392 time/batch=0.31s
13956/10943 (epoch 114.776) train_loss=219.37698364 time/batch=1.10s
13957/10943 (epoch 114.784) train_loss=135.28297424 time/batch=0.86s
13958/10943 (epoch 114.792) train_loss=134.50494385 time/batch=0.84s
13959/10943 (epoch 114.800) train_loss=259.46865845 time/batch=1.34s
13960/10943 (epoch 114.809) train_loss=144.86544800 time/batch=0.86s
13961/10943 (epoch 114.817) train_loss=65.70884705 time/batch=0.39s
13962/10943 (epoch 114.825) train_loss=99.98654175 time/batch=0.67s
13963/10943 (epoch 114.833) train_loss=103.94276428 time/batch=0.67s
13964/10943 (epoch 114.841) train_loss=97.41271973 time/batch=0.66s
13965/10943 (epoch 114.850) train_loss=94.00329590 time/batch=0.64s
13966/10943 (epoch 114.858) train_loss=73.53203583 time/batch=0.46s
13967/10943 (epoch 114.866) train_loss=253.80641174 time/batch=1.37s
13968/10943 (epoch 114.874) train_loss=187.71913147 time/batch=1.12s
13969/10943 (epoch 114.883) train_loss=83.98344421 time/batch=0.60s
13970/10943 (epoch 114.891) train_loss=484.75231934 time/batch=3.02s
13971/10943 (epoch 114.899) train_loss=74.53020477 time/batch=0.66s
13972/10943 (epoch 114.907) train_loss=91.07986450 time/batch=0.55s
13973/10943 (epoch 114.915) train_loss=198.66421509 time/batch=1.05s
13974/10943 (epoch 114.924) train_loss=123.45496368 time/batch=0.81s
13975/10943 (epoch 114.932) train_loss=122.49737549 time/batch=0.74s
13976/10943 (epoch 114.940) train_loss=224.10675049 time/batch=1.18s
13977/10943 (epoch 114.948) train_loss=221.85038757 time/batch=1.13s
13978/10943 (epoch 114.957) train_loss=93.86183167 time/batch=0.65s
13979/10943 (epoch 114.965) train_loss=83.92565918 time/batch=0.56s
13980/10943 (epoch 114.973) train_loss=104.76327515 time/batch=0.68s
13981/10943 (epoch 114.981) train_loss=143.59364319 time/batch=0.88s
13982/10943 (epoch 114.989) train_loss=70.53662109 time/batch=0.44s
13983/10943 (epoch 114.998) train_loss=55.82281113 time/batch=0.29s
13984/10943 (epoch 115.006) train_loss=88.77607727 time/batch=0.53s
13985/10943 (epoch 115.014) train_loss=99.40319061 time/batch=0.64s
13986/10943 (epoch 115.022) train_loss=89.69519043 time/batch=0.61s
13987/10943 (epoch 115.031) train_loss=209.23585510 time/batch=1.10s
13988/10943 (epoch 115.039) train_loss=143.28823853 time/batch=0.96s
13989/10943 (epoch 115.047) train_loss=114.74990845 time/batch=0.75s
13990/10943 (epoch 115.055) train_loss=284.30361938 time/batch=1.53s
13991/10943 (epoch 115.063) train_loss=224.64723206 time/batch=1.27s
13992/10943 (epoch 115.072) train_loss=90.42681885 time/batch=0.61s
13993/10943 (epoch 115.080) train_loss=86.90774536 time/batch=0.49s
13994/10943 (epoch 115.088) train_loss=119.39663696 time/batch=0.76s
13995/10943 (epoch 115.096) train_loss=115.34955597 time/batch=0.81s
13996/10943 (epoch 115.105) train_loss=103.46417236 time/batch=0.69s
13997/10943 (epoch 115.113) train_loss=344.75350952 time/batch=1.66s
13998/10943 (epoch 115.121) train_loss=166.03433228 time/batch=1.04s
13999/10943 (epoch 115.129) train_loss=75.76113892 time/batch=0.49s
Validating
    loss:	350.169670

14000/10943 (epoch 115.137) train_loss=165.93592834 time/batch=2.76s
14001/10943 (epoch 115.146) train_loss=187.06188965 time/batch=1.09s
14002/10943 (epoch 115.154) train_loss=150.23800659 time/batch=0.91s
14003/10943 (epoch 115.162) train_loss=123.66979218 time/batch=0.83s
14004/10943 (epoch 115.170) train_loss=51.61454773 time/batch=0.29s
14005/10943 (epoch 115.179) train_loss=137.91371155 time/batch=0.78s
14006/10943 (epoch 115.187) train_loss=97.27227783 time/batch=0.64s
14007/10943 (epoch 115.195) train_loss=57.94155884 time/batch=0.33s
14008/10943 (epoch 115.203) train_loss=171.32098389 time/batch=0.95s
14009/10943 (epoch 115.212) train_loss=146.90039062 time/batch=0.91s
14010/10943 (epoch 115.220) train_loss=58.02444458 time/batch=0.39s
14011/10943 (epoch 115.228) train_loss=125.75344849 time/batch=0.76s
14012/10943 (epoch 115.236) train_loss=73.97515869 time/batch=0.44s
14013/10943 (epoch 115.244) train_loss=118.55201721 time/batch=0.70s
14014/10943 (epoch 115.253) train_loss=169.48257446 time/batch=0.96s
14015/10943 (epoch 115.261) train_loss=57.74640274 time/batch=0.39s
14016/10943 (epoch 115.269) train_loss=91.38147736 time/batch=0.54s
14017/10943 (epoch 115.277) train_loss=129.29504395 time/batch=0.83s
14018/10943 (epoch 115.286) train_loss=234.42294312 time/batch=1.42s
14019/10943 (epoch 115.294) train_loss=96.45062256 time/batch=0.68s
14020/10943 (epoch 115.302) train_loss=165.95788574 time/batch=0.94s
14021/10943 (epoch 115.310) train_loss=193.98284912 time/batch=1.02s
14022/10943 (epoch 115.318) train_loss=131.02030945 time/batch=0.84s
14023/10943 (epoch 115.327) train_loss=100.94559479 time/batch=0.61s
14024/10943 (epoch 115.335) train_loss=112.27721405 time/batch=0.77s
14025/10943 (epoch 115.343) train_loss=70.49377441 time/batch=0.41s
14026/10943 (epoch 115.351) train_loss=91.08406830 time/batch=0.51s
14027/10943 (epoch 115.360) train_loss=131.39588928 time/batch=0.82s
14028/10943 (epoch 115.368) train_loss=67.46659851 time/batch=0.44s
14029/10943 (epoch 115.376) train_loss=133.48414612 time/batch=0.74s
14030/10943 (epoch 115.384) train_loss=121.64031982 time/batch=0.75s
14031/10943 (epoch 115.392) train_loss=79.41919708 time/batch=0.53s
14032/10943 (epoch 115.401) train_loss=98.08528137 time/batch=0.61s
14033/10943 (epoch 115.409) train_loss=71.24377441 time/batch=0.46s
14034/10943 (epoch 115.417) train_loss=65.32826233 time/batch=0.37s
14035/10943 (epoch 115.425) train_loss=201.28256226 time/batch=1.15s
14036/10943 (epoch 115.434) train_loss=138.02548218 time/batch=0.90s
14037/10943 (epoch 115.442) train_loss=116.39492035 time/batch=0.70s
14038/10943 (epoch 115.450) train_loss=93.72981262 time/batch=0.53s
14039/10943 (epoch 115.458) train_loss=138.36189270 time/batch=0.84s
14040/10943 (epoch 115.466) train_loss=175.96902466 time/batch=1.02s
14041/10943 (epoch 115.475) train_loss=120.64846802 time/batch=0.74s
14042/10943 (epoch 115.483) train_loss=79.29450989 time/batch=0.51s
14043/10943 (epoch 115.491) train_loss=115.20494843 time/batch=0.69s
14044/10943 (epoch 115.499) train_loss=57.97232819 time/batch=0.33s
14045/10943 (epoch 115.508) train_loss=100.64107513 time/batch=0.56s
14046/10943 (epoch 115.516) train_loss=63.89025879 time/batch=0.39s
14047/10943 (epoch 115.524) train_loss=83.72962952 time/batch=0.51s
14048/10943 (epoch 115.532) train_loss=113.50016022 time/batch=0.74s
14049/10943 (epoch 115.540) train_loss=81.63160706 time/batch=0.49s
14050/10943 (epoch 115.549) train_loss=154.10145569 time/batch=0.86s
14051/10943 (epoch 115.557) train_loss=122.00600433 time/batch=0.81s
14052/10943 (epoch 115.565) train_loss=59.73296356 time/batch=0.45s
14053/10943 (epoch 115.573) train_loss=79.18645477 time/batch=0.45s
14054/10943 (epoch 115.582) train_loss=128.99142456 time/batch=0.83s
14055/10943 (epoch 115.590) train_loss=122.82413483 time/batch=0.72s
14056/10943 (epoch 115.598) train_loss=81.46398163 time/batch=0.49s
14057/10943 (epoch 115.606) train_loss=96.67489624 time/batch=0.55s
14058/10943 (epoch 115.614) train_loss=128.57165527 time/batch=0.72s
14059/10943 (epoch 115.623) train_loss=81.52161407 time/batch=0.50s
14060/10943 (epoch 115.631) train_loss=108.34681702 time/batch=0.71s
14061/10943 (epoch 115.639) train_loss=118.94540405 time/batch=0.67s
14062/10943 (epoch 115.647) train_loss=110.06932068 time/batch=0.66s
14063/10943 (epoch 115.656) train_loss=81.30129242 time/batch=0.54s
14064/10943 (epoch 115.664) train_loss=98.45277405 time/batch=0.60s
14065/10943 (epoch 115.672) train_loss=87.89849854 time/batch=0.58s
14066/10943 (epoch 115.680) train_loss=140.75778198 time/batch=0.98s
14067/10943 (epoch 115.689) train_loss=92.95039368 time/batch=0.66s
14068/10943 (epoch 115.697) train_loss=115.30046082 time/batch=0.70s
14069/10943 (epoch 115.705) train_loss=90.45806122 time/batch=0.61s
14070/10943 (epoch 115.713) train_loss=108.13574219 time/batch=0.63s
14071/10943 (epoch 115.721) train_loss=121.93010712 time/batch=0.74s
14072/10943 (epoch 115.730) train_loss=101.84487915 time/batch=0.65s
setting learning rate to 0.0006346
  saved to metadata/gru_no_dropout-9_nov_folkwiki-20181207-192453_epoch71.pkl
14073/10943 (epoch 115.738) train_loss=49.00469208 time/batch=0.37s
14074/10943 (epoch 115.746) train_loss=221.42166138 time/batch=1.13s
14075/10943 (epoch 115.754) train_loss=165.91856384 time/batch=0.99s
14076/10943 (epoch 115.763) train_loss=271.63009644 time/batch=1.29s
14077/10943 (epoch 115.771) train_loss=346.22116089 time/batch=1.65s
14078/10943 (epoch 115.779) train_loss=166.48089600 time/batch=0.98s
14079/10943 (epoch 115.787) train_loss=97.64073181 time/batch=0.63s
14080/10943 (epoch 115.795) train_loss=273.06604004 time/batch=1.59s
14081/10943 (epoch 115.804) train_loss=202.53259277 time/batch=1.16s
14082/10943 (epoch 115.812) train_loss=497.29260254 time/batch=3.09s
14083/10943 (epoch 115.820) train_loss=199.02629089 time/batch=1.29s
14084/10943 (epoch 115.828) train_loss=140.97817993 time/batch=0.89s
14085/10943 (epoch 115.837) train_loss=96.25633240 time/batch=0.57s
14086/10943 (epoch 115.845) train_loss=126.01779175 time/batch=0.75s
14087/10943 (epoch 115.853) train_loss=57.77963257 time/batch=0.34s
14088/10943 (epoch 115.861) train_loss=145.14532471 time/batch=0.87s
14089/10943 (epoch 115.869) train_loss=58.22118378 time/batch=0.39s
14090/10943 (epoch 115.878) train_loss=84.78887939 time/batch=0.57s
14091/10943 (epoch 115.886) train_loss=68.95420074 time/batch=0.45s
14092/10943 (epoch 115.894) train_loss=84.78396606 time/batch=0.55s
14093/10943 (epoch 115.902) train_loss=177.21966553 time/batch=0.98s
14094/10943 (epoch 115.911) train_loss=108.80344391 time/batch=0.71s
14095/10943 (epoch 115.919) train_loss=108.11443329 time/batch=0.69s
14096/10943 (epoch 115.927) train_loss=83.97656250 time/batch=0.55s
14097/10943 (epoch 115.935) train_loss=117.63825989 time/batch=0.79s
14098/10943 (epoch 115.943) train_loss=218.29071045 time/batch=1.09s
14099/10943 (epoch 115.952) train_loss=217.51394653 time/batch=1.17s
14100/10943 (epoch 115.960) train_loss=122.96063232 time/batch=0.84s
14101/10943 (epoch 115.968) train_loss=128.56387329 time/batch=0.85s
14102/10943 (epoch 115.976) train_loss=74.05612183 time/batch=0.53s
14103/10943 (epoch 115.985) train_loss=61.95478439 time/batch=0.35s
14104/10943 (epoch 115.993) train_loss=116.84371948 time/batch=0.69s
14105/10943 (epoch 116.001) train_loss=222.21127319 time/batch=1.21s
14106/10943 (epoch 116.009) train_loss=108.45135498 time/batch=0.71s
14107/10943 (epoch 116.017) train_loss=193.42549133 time/batch=1.03s
14108/10943 (epoch 116.026) train_loss=64.53774261 time/batch=0.42s
14109/10943 (epoch 116.034) train_loss=160.94462585 time/batch=0.89s
14110/10943 (epoch 116.042) train_loss=64.77434540 time/batch=0.43s
14111/10943 (epoch 116.050) train_loss=185.96670532 time/batch=1.06s
14112/10943 (epoch 116.059) train_loss=93.39359283 time/batch=0.68s
14113/10943 (epoch 116.067) train_loss=76.40435791 time/batch=0.48s
14114/10943 (epoch 116.075) train_loss=213.49284363 time/batch=1.12s
14115/10943 (epoch 116.083) train_loss=91.48361969 time/batch=0.62s
14116/10943 (epoch 116.091) train_loss=201.68130493 time/batch=1.20s
14117/10943 (epoch 116.100) train_loss=89.93544006 time/batch=0.60s
14118/10943 (epoch 116.108) train_loss=165.82206726 time/batch=0.93s
14119/10943 (epoch 116.116) train_loss=54.55437851 time/batch=0.37s
14120/10943 (epoch 116.124) train_loss=70.54988861 time/batch=0.41s
14121/10943 (epoch 116.133) train_loss=142.65716553 time/batch=0.84s
14122/10943 (epoch 116.141) train_loss=127.97113037 time/batch=0.84s
14123/10943 (epoch 116.149) train_loss=154.66175842 time/batch=0.97s
14124/10943 (epoch 116.157) train_loss=64.74372864 time/batch=0.44s
14125/10943 (epoch 116.166) train_loss=282.67849731 time/batch=1.62s
14126/10943 (epoch 116.174) train_loss=241.87269592 time/batch=1.41s
14127/10943 (epoch 116.182) train_loss=111.49555969 time/batch=0.69s
14128/10943 (epoch 116.190) train_loss=165.79061890 time/batch=0.96s
14129/10943 (epoch 116.198) train_loss=116.86325836 time/batch=0.75s
14130/10943 (epoch 116.207) train_loss=73.69572449 time/batch=0.49s
14131/10943 (epoch 116.215) train_loss=95.75069427 time/batch=0.60s
14132/10943 (epoch 116.223) train_loss=90.93447876 time/batch=0.56s
14133/10943 (epoch 116.231) train_loss=135.91387939 time/batch=0.80s
14134/10943 (epoch 116.240) train_loss=68.03329468 time/batch=0.47s
14135/10943 (epoch 116.248) train_loss=133.67068481 time/batch=0.80s
14136/10943 (epoch 116.256) train_loss=120.43812561 time/batch=0.74s
14137/10943 (epoch 116.264) train_loss=87.00585938 time/batch=0.63s
14138/10943 (epoch 116.272) train_loss=118.36804199 time/batch=0.73s
14139/10943 (epoch 116.281) train_loss=94.17668152 time/batch=0.60s
14140/10943 (epoch 116.289) train_loss=175.61593628 time/batch=0.97s
14141/10943 (epoch 116.297) train_loss=76.84126282 time/batch=0.51s
14142/10943 (epoch 116.305) train_loss=186.95404053 time/batch=1.31s
14143/10943 (epoch 116.314) train_loss=117.83222961 time/batch=0.83s
14144/10943 (epoch 116.322) train_loss=86.05577087 time/batch=0.56s
14145/10943 (epoch 116.330) train_loss=99.43901062 time/batch=0.62s
14146/10943 (epoch 116.338) train_loss=97.16072083 time/batch=0.61s
14147/10943 (epoch 116.346) train_loss=74.38662720 time/batch=0.46s
14148/10943 (epoch 116.355) train_loss=116.96606445 time/batch=0.73s
14149/10943 (epoch 116.363) train_loss=70.07302856 time/batch=0.45s
14150/10943 (epoch 116.371) train_loss=102.03122711 time/batch=0.62s
14151/10943 (epoch 116.379) train_loss=76.84695435 time/batch=0.50s
14152/10943 (epoch 116.388) train_loss=72.33204651 time/batch=0.40s
14153/10943 (epoch 116.396) train_loss=116.47096252 time/batch=0.67s
14154/10943 (epoch 116.404) train_loss=112.62648773 time/batch=0.69s
14155/10943 (epoch 116.412) train_loss=78.20336914 time/batch=0.48s
14156/10943 (epoch 116.420) train_loss=73.72683716 time/batch=0.47s
14157/10943 (epoch 116.429) train_loss=134.19377136 time/batch=0.83s
14158/10943 (epoch 116.437) train_loss=123.02731323 time/batch=0.79s
14159/10943 (epoch 116.445) train_loss=120.94053650 time/batch=0.79s
14160/10943 (epoch 116.453) train_loss=64.35752869 time/batch=0.41s
14161/10943 (epoch 116.462) train_loss=100.27080536 time/batch=0.65s
14162/10943 (epoch 116.470) train_loss=104.69731140 time/batch=0.65s
14163/10943 (epoch 116.478) train_loss=131.16925049 time/batch=0.81s
14164/10943 (epoch 116.486) train_loss=95.18872070 time/batch=0.61s
14165/10943 (epoch 116.494) train_loss=96.99386597 time/batch=0.61s
14166/10943 (epoch 116.503) train_loss=116.86293030 time/batch=0.68s
14167/10943 (epoch 116.511) train_loss=91.35931396 time/batch=0.63s
14168/10943 (epoch 116.519) train_loss=52.98738098 time/batch=0.33s
14169/10943 (epoch 116.527) train_loss=153.05432129 time/batch=0.84s
14170/10943 (epoch 116.536) train_loss=60.92977524 time/batch=0.39s
14171/10943 (epoch 116.544) train_loss=63.96379089 time/batch=0.34s
14172/10943 (epoch 116.552) train_loss=122.24354553 time/batch=0.75s
14173/10943 (epoch 116.560) train_loss=123.57571411 time/batch=0.84s
14174/10943 (epoch 116.568) train_loss=130.69496155 time/batch=0.74s
14175/10943 (epoch 116.577) train_loss=86.82243347 time/batch=0.56s
14176/10943 (epoch 116.585) train_loss=96.64344788 time/batch=0.56s
14177/10943 (epoch 116.593) train_loss=121.42276001 time/batch=0.76s
14178/10943 (epoch 116.601) train_loss=80.92599487 time/batch=0.51s
14179/10943 (epoch 116.610) train_loss=133.99468994 time/batch=0.80s
14180/10943 (epoch 116.618) train_loss=133.60951233 time/batch=0.81s
14181/10943 (epoch 116.626) train_loss=68.15065002 time/batch=0.41s
14182/10943 (epoch 116.634) train_loss=88.92810059 time/batch=0.53s
14183/10943 (epoch 116.643) train_loss=133.04745483 time/batch=0.87s
14184/10943 (epoch 116.651) train_loss=110.60942078 time/batch=0.72s
14185/10943 (epoch 116.659) train_loss=127.51265717 time/batch=0.84s
14186/10943 (epoch 116.667) train_loss=130.17379761 time/batch=0.86s
14187/10943 (epoch 116.675) train_loss=119.24033356 time/batch=0.71s
14188/10943 (epoch 116.684) train_loss=94.37028503 time/batch=0.52s
14189/10943 (epoch 116.692) train_loss=87.09428406 time/batch=0.57s
14190/10943 (epoch 116.700) train_loss=120.03546143 time/batch=0.73s
14191/10943 (epoch 116.708) train_loss=112.77935791 time/batch=0.70s
14192/10943 (epoch 116.717) train_loss=99.77135468 time/batch=0.60s
14193/10943 (epoch 116.725) train_loss=113.25399017 time/batch=0.65s
setting learning rate to 0.0006155
14194/10943 (epoch 116.733) train_loss=266.87200928 time/batch=1.49s
14195/10943 (epoch 116.741) train_loss=223.26486206 time/batch=1.24s
14196/10943 (epoch 116.749) train_loss=363.47976685 time/batch=1.67s
14197/10943 (epoch 116.758) train_loss=54.43830872 time/batch=0.39s
14198/10943 (epoch 116.766) train_loss=187.18756104 time/batch=0.94s
14199/10943 (epoch 116.774) train_loss=225.14892578 time/batch=1.22s
14200/10943 (epoch 116.782) train_loss=76.56359863 time/batch=0.56s
14201/10943 (epoch 116.791) train_loss=93.23307800 time/batch=0.60s
14202/10943 (epoch 116.799) train_loss=112.80408478 time/batch=0.73s
14203/10943 (epoch 116.807) train_loss=499.62719727 time/batch=3.06s
14204/10943 (epoch 116.815) train_loss=288.48367310 time/batch=1.63s
14205/10943 (epoch 116.823) train_loss=191.31860352 time/batch=1.07s
14206/10943 (epoch 116.832) train_loss=217.38275146 time/batch=1.20s
14207/10943 (epoch 116.840) train_loss=160.93515015 time/batch=1.01s
14208/10943 (epoch 116.848) train_loss=118.95710754 time/batch=0.88s
14209/10943 (epoch 116.856) train_loss=102.08023071 time/batch=0.76s
14210/10943 (epoch 116.865) train_loss=199.91189575 time/batch=1.10s
14211/10943 (epoch 116.873) train_loss=78.52180481 time/batch=0.57s
14212/10943 (epoch 116.881) train_loss=113.87866211 time/batch=0.69s
14213/10943 (epoch 116.889) train_loss=266.75061035 time/batch=1.67s
14214/10943 (epoch 116.897) train_loss=265.44412231 time/batch=1.38s
14215/10943 (epoch 116.906) train_loss=191.21585083 time/batch=1.08s
14216/10943 (epoch 116.914) train_loss=66.39136505 time/batch=0.42s
14217/10943 (epoch 116.922) train_loss=57.46944046 time/batch=0.30s
14218/10943 (epoch 116.930) train_loss=144.73291016 time/batch=0.86s
14219/10943 (epoch 116.939) train_loss=110.36195374 time/batch=0.70s
14220/10943 (epoch 116.947) train_loss=161.05484009 time/batch=0.93s
14221/10943 (epoch 116.955) train_loss=122.25457001 time/batch=0.84s
14222/10943 (epoch 116.963) train_loss=100.24983215 time/batch=0.72s
14223/10943 (epoch 116.971) train_loss=118.27227783 time/batch=0.78s
14224/10943 (epoch 116.980) train_loss=75.87661743 time/batch=0.50s
14225/10943 (epoch 116.988) train_loss=80.51739502 time/batch=0.54s
14226/10943 (epoch 116.996) train_loss=63.43096161 time/batch=0.40s
14227/10943 (epoch 117.004) train_loss=122.52940369 time/batch=0.78s
14228/10943 (epoch 117.013) train_loss=116.29521179 time/batch=0.78s
14229/10943 (epoch 117.021) train_loss=67.27758789 time/batch=0.40s
14230/10943 (epoch 117.029) train_loss=70.95291901 time/batch=0.43s
14231/10943 (epoch 117.037) train_loss=212.59986877 time/batch=1.17s
14232/10943 (epoch 117.045) train_loss=138.70652771 time/batch=0.89s
14233/10943 (epoch 117.054) train_loss=130.38619995 time/batch=0.85s
14234/10943 (epoch 117.062) train_loss=114.75659943 time/batch=0.73s
14235/10943 (epoch 117.070) train_loss=67.27024841 time/batch=0.46s
14236/10943 (epoch 117.078) train_loss=226.02685547 time/batch=1.19s
14237/10943 (epoch 117.087) train_loss=97.60936737 time/batch=0.62s
14238/10943 (epoch 117.095) train_loss=81.81994629 time/batch=0.55s
14239/10943 (epoch 117.103) train_loss=53.06391144 time/batch=0.32s
14240/10943 (epoch 117.111) train_loss=102.90681458 time/batch=0.61s
14241/10943 (epoch 117.120) train_loss=104.04316711 time/batch=0.66s
14242/10943 (epoch 117.128) train_loss=124.47890472 time/batch=0.73s
14243/10943 (epoch 117.136) train_loss=124.04167175 time/batch=0.73s
14244/10943 (epoch 117.144) train_loss=95.07785034 time/batch=0.61s
14245/10943 (epoch 117.152) train_loss=99.30390930 time/batch=0.62s
14246/10943 (epoch 117.161) train_loss=125.53276825 time/batch=0.76s
14247/10943 (epoch 117.169) train_loss=91.72124481 time/batch=0.65s
14248/10943 (epoch 117.177) train_loss=84.00666046 time/batch=0.58s
14249/10943 (epoch 117.185) train_loss=116.23806763 time/batch=0.70s
14250/10943 (epoch 117.194) train_loss=135.95242310 time/batch=0.83s
14251/10943 (epoch 117.202) train_loss=96.98847198 time/batch=0.62s
14252/10943 (epoch 117.210) train_loss=88.27651978 time/batch=0.57s
14253/10943 (epoch 117.218) train_loss=110.54025269 time/batch=0.77s
14254/10943 (epoch 117.226) train_loss=60.60728455 time/batch=0.40s
14255/10943 (epoch 117.235) train_loss=83.98955536 time/batch=0.52s
14256/10943 (epoch 117.243) train_loss=82.99050903 time/batch=0.52s
14257/10943 (epoch 117.251) train_loss=194.23068237 time/batch=1.04s
14258/10943 (epoch 117.259) train_loss=74.55763245 time/batch=0.53s
14259/10943 (epoch 117.268) train_loss=93.03013611 time/batch=0.56s
14260/10943 (epoch 117.276) train_loss=101.23673248 time/batch=0.63s
14261/10943 (epoch 117.284) train_loss=148.82421875 time/batch=0.91s
14262/10943 (epoch 117.292) train_loss=115.01663208 time/batch=0.73s
14263/10943 (epoch 117.300) train_loss=77.78929138 time/batch=0.50s
14264/10943 (epoch 117.309) train_loss=69.42491913 time/batch=0.40s
14265/10943 (epoch 117.317) train_loss=193.25799561 time/batch=1.03s
14266/10943 (epoch 117.325) train_loss=110.64653778 time/batch=0.70s
14267/10943 (epoch 117.333) train_loss=198.02784729 time/batch=1.06s
14268/10943 (epoch 117.342) train_loss=152.64302063 time/batch=0.95s
14269/10943 (epoch 117.350) train_loss=64.89060974 time/batch=0.43s
14270/10943 (epoch 117.358) train_loss=175.51841736 time/batch=0.92s
14271/10943 (epoch 117.366) train_loss=159.19845581 time/batch=0.97s
14272/10943 (epoch 117.374) train_loss=97.23240662 time/batch=0.63s
14273/10943 (epoch 117.383) train_loss=105.95469666 time/batch=0.67s
14274/10943 (epoch 117.391) train_loss=131.29638672 time/batch=0.84s
14275/10943 (epoch 117.399) train_loss=101.00770569 time/batch=0.67s
14276/10943 (epoch 117.407) train_loss=90.92662048 time/batch=0.65s
14277/10943 (epoch 117.416) train_loss=66.15655518 time/batch=0.38s
14278/10943 (epoch 117.424) train_loss=91.08947754 time/batch=0.54s
14279/10943 (epoch 117.432) train_loss=115.42942810 time/batch=0.66s
14280/10943 (epoch 117.440) train_loss=86.90924072 time/batch=0.55s
14281/10943 (epoch 117.448) train_loss=58.78566742 time/batch=0.30s
14282/10943 (epoch 117.457) train_loss=56.22647476 time/batch=0.31s
14283/10943 (epoch 117.465) train_loss=119.69665527 time/batch=0.71s
14284/10943 (epoch 117.473) train_loss=84.63137817 time/batch=0.53s
14285/10943 (epoch 117.481) train_loss=141.38507080 time/batch=0.83s
14286/10943 (epoch 117.490) train_loss=169.84408569 time/batch=0.96s
14287/10943 (epoch 117.498) train_loss=101.35569000 time/batch=0.64s
14288/10943 (epoch 117.506) train_loss=87.22871399 time/batch=0.51s
14289/10943 (epoch 117.514) train_loss=113.02741241 time/batch=0.74s
14290/10943 (epoch 117.522) train_loss=76.18130493 time/batch=0.48s
14291/10943 (epoch 117.531) train_loss=56.07150269 time/batch=0.32s
14292/10943 (epoch 117.539) train_loss=156.11242676 time/batch=0.84s
14293/10943 (epoch 117.547) train_loss=62.75226212 time/batch=0.38s
14294/10943 (epoch 117.555) train_loss=73.80662537 time/batch=0.42s
14295/10943 (epoch 117.564) train_loss=137.48484802 time/batch=0.83s
14296/10943 (epoch 117.572) train_loss=132.16125488 time/batch=0.82s
14297/10943 (epoch 117.580) train_loss=64.52072144 time/batch=0.44s
14298/10943 (epoch 117.588) train_loss=131.11212158 time/batch=0.82s
14299/10943 (epoch 117.597) train_loss=120.75028992 time/batch=0.81s
14300/10943 (epoch 117.605) train_loss=132.38749695 time/batch=0.96s
14301/10943 (epoch 117.613) train_loss=79.29528046 time/batch=0.54s
14302/10943 (epoch 117.621) train_loss=95.97599030 time/batch=0.57s
14303/10943 (epoch 117.629) train_loss=110.05458069 time/batch=0.68s
14304/10943 (epoch 117.638) train_loss=147.35968018 time/batch=1.00s
14305/10943 (epoch 117.646) train_loss=123.94911957 time/batch=0.82s
14306/10943 (epoch 117.654) train_loss=108.34298706 time/batch=0.63s
14307/10943 (epoch 117.662) train_loss=93.46575928 time/batch=0.60s
14308/10943 (epoch 117.671) train_loss=69.44088745 time/batch=0.43s
14309/10943 (epoch 117.679) train_loss=125.32685852 time/batch=0.75s
14310/10943 (epoch 117.687) train_loss=77.14841461 time/batch=0.52s
14311/10943 (epoch 117.695) train_loss=85.00670624 time/batch=0.50s
14312/10943 (epoch 117.703) train_loss=94.10791779 time/batch=0.60s
14313/10943 (epoch 117.712) train_loss=112.39349365 time/batch=0.74s
14314/10943 (epoch 117.720) train_loss=109.31190491 time/batch=0.70s
setting learning rate to 0.0005971
  saved to metadata/gru_no_dropout-9_nov_folkwiki-20181207-192453_epoch73.pkl
14315/10943 (epoch 117.728) train_loss=78.96133423 time/batch=0.62s
14316/10943 (epoch 117.736) train_loss=216.17901611 time/batch=1.14s
14317/10943 (epoch 117.745) train_loss=272.75119019 time/batch=1.48s
14318/10943 (epoch 117.753) train_loss=108.38139343 time/batch=0.77s
14319/10943 (epoch 117.761) train_loss=55.18680954 time/batch=0.32s
14320/10943 (epoch 117.769) train_loss=76.54623413 time/batch=0.47s
14321/10943 (epoch 117.777) train_loss=72.31788635 time/batch=0.46s
14322/10943 (epoch 117.786) train_loss=104.09389496 time/batch=0.75s
14323/10943 (epoch 117.794) train_loss=65.93301392 time/batch=0.43s
14324/10943 (epoch 117.802) train_loss=329.98233032 time/batch=1.56s
14325/10943 (epoch 117.810) train_loss=72.77813721 time/batch=0.49s
14326/10943 (epoch 117.819) train_loss=431.00930786 time/batch=2.13s
14327/10943 (epoch 117.827) train_loss=136.67770386 time/batch=0.88s
14328/10943 (epoch 117.835) train_loss=144.24435425 time/batch=0.83s
14329/10943 (epoch 117.843) train_loss=272.23876953 time/batch=1.29s
14330/10943 (epoch 117.851) train_loss=63.08745956 time/batch=0.50s
14331/10943 (epoch 117.860) train_loss=251.51531982 time/batch=1.31s
14332/10943 (epoch 117.868) train_loss=121.43827820 time/batch=0.84s
14333/10943 (epoch 117.876) train_loss=119.02140808 time/batch=0.76s
14334/10943 (epoch 117.884) train_loss=126.68023682 time/batch=0.86s
14335/10943 (epoch 117.893) train_loss=192.18325806 time/batch=1.02s
14336/10943 (epoch 117.901) train_loss=55.11767197 time/batch=0.38s
14337/10943 (epoch 117.909) train_loss=211.63705444 time/batch=1.04s
14338/10943 (epoch 117.917) train_loss=175.23654175 time/batch=1.06s
14339/10943 (epoch 117.925) train_loss=161.15765381 time/batch=1.00s
14340/10943 (epoch 117.934) train_loss=51.17566681 time/batch=0.33s
14341/10943 (epoch 117.942) train_loss=99.26622009 time/batch=0.59s
14342/10943 (epoch 117.950) train_loss=139.00053406 time/batch=0.88s
14343/10943 (epoch 117.958) train_loss=54.55747604 time/batch=0.36s
14344/10943 (epoch 117.967) train_loss=93.03655243 time/batch=0.59s
14345/10943 (epoch 117.975) train_loss=74.68687439 time/batch=0.47s
14346/10943 (epoch 117.983) train_loss=203.12435913 time/batch=1.06s
14347/10943 (epoch 117.991) train_loss=155.65617371 time/batch=0.94s
14348/10943 (epoch 117.999) train_loss=65.52938843 time/batch=0.48s
14349/10943 (epoch 118.008) train_loss=228.00622559 time/batch=1.20s
14350/10943 (epoch 118.016) train_loss=141.28109741 time/batch=0.91s
14351/10943 (epoch 118.024) train_loss=90.68685913 time/batch=0.59s
14352/10943 (epoch 118.032) train_loss=90.82203674 time/batch=0.53s
14353/10943 (epoch 118.041) train_loss=184.47033691 time/batch=1.03s
14354/10943 (epoch 118.049) train_loss=109.31642151 time/batch=0.74s
14355/10943 (epoch 118.057) train_loss=75.23206329 time/batch=0.49s
14356/10943 (epoch 118.065) train_loss=360.77520752 time/batch=3.02s
14357/10943 (epoch 118.074) train_loss=56.45222473 time/batch=0.61s
14358/10943 (epoch 118.082) train_loss=114.67859650 time/batch=0.75s
14359/10943 (epoch 118.090) train_loss=191.36270142 time/batch=1.07s
14360/10943 (epoch 118.098) train_loss=116.68788910 time/batch=0.71s
14361/10943 (epoch 118.106) train_loss=221.27597046 time/batch=1.19s
14362/10943 (epoch 118.115) train_loss=138.01341248 time/batch=0.88s
14363/10943 (epoch 118.123) train_loss=211.73774719 time/batch=1.17s
14364/10943 (epoch 118.131) train_loss=91.05088043 time/batch=0.61s
14365/10943 (epoch 118.139) train_loss=142.49572754 time/batch=0.89s
14366/10943 (epoch 118.148) train_loss=66.13536072 time/batch=0.41s
14367/10943 (epoch 118.156) train_loss=173.59979248 time/batch=1.02s
14368/10943 (epoch 118.164) train_loss=87.96365356 time/batch=0.57s
14369/10943 (epoch 118.172) train_loss=129.26824951 time/batch=0.81s
14370/10943 (epoch 118.180) train_loss=160.79040527 time/batch=0.95s
14371/10943 (epoch 118.189) train_loss=68.48914337 time/batch=0.45s
14372/10943 (epoch 118.197) train_loss=57.48949814 time/batch=0.36s
14373/10943 (epoch 118.205) train_loss=198.58316040 time/batch=1.07s
14374/10943 (epoch 118.213) train_loss=165.07479858 time/batch=0.98s
14375/10943 (epoch 118.222) train_loss=97.05886841 time/batch=0.67s
14376/10943 (epoch 118.230) train_loss=115.72132874 time/batch=0.74s
14377/10943 (epoch 118.238) train_loss=87.81379700 time/batch=0.58s
14378/10943 (epoch 118.246) train_loss=64.93429565 time/batch=0.39s
14379/10943 (epoch 118.254) train_loss=119.45267487 time/batch=0.68s
14380/10943 (epoch 118.263) train_loss=54.42787552 time/batch=0.36s
14381/10943 (epoch 118.271) train_loss=58.75706863 time/batch=0.33s
14382/10943 (epoch 118.279) train_loss=91.95349121 time/batch=0.58s
14383/10943 (epoch 118.287) train_loss=121.72718048 time/batch=0.75s
14384/10943 (epoch 118.296) train_loss=93.91699219 time/batch=0.61s
14385/10943 (epoch 118.304) train_loss=121.55946350 time/batch=0.78s
14386/10943 (epoch 118.312) train_loss=103.59347534 time/batch=0.72s
14387/10943 (epoch 118.320) train_loss=106.88468170 time/batch=0.70s
14388/10943 (epoch 118.328) train_loss=70.29994202 time/batch=0.44s
14389/10943 (epoch 118.337) train_loss=105.76174927 time/batch=0.62s
14390/10943 (epoch 118.345) train_loss=91.01355743 time/batch=0.58s
14391/10943 (epoch 118.353) train_loss=124.92266846 time/batch=0.72s
14392/10943 (epoch 118.361) train_loss=110.85511780 time/batch=0.76s
14393/10943 (epoch 118.370) train_loss=173.15966797 time/batch=1.11s
14394/10943 (epoch 118.378) train_loss=117.91715240 time/batch=0.77s
14395/10943 (epoch 118.386) train_loss=85.94620514 time/batch=0.55s
14396/10943 (epoch 118.394) train_loss=89.64070129 time/batch=0.57s
14397/10943 (epoch 118.402) train_loss=73.79957581 time/batch=0.50s
14398/10943 (epoch 118.411) train_loss=88.92424774 time/batch=0.56s
14399/10943 (epoch 118.419) train_loss=149.18272400 time/batch=0.88s
14400/10943 (epoch 118.427) train_loss=68.09288025 time/batch=0.42s
14401/10943 (epoch 118.435) train_loss=128.67382812 time/batch=0.82s
14402/10943 (epoch 118.444) train_loss=94.87815857 time/batch=0.64s
14403/10943 (epoch 118.452) train_loss=67.35829163 time/batch=0.42s
14404/10943 (epoch 118.460) train_loss=65.00577545 time/batch=0.42s
14405/10943 (epoch 118.468) train_loss=83.67425537 time/batch=0.49s
14406/10943 (epoch 118.476) train_loss=107.86344910 time/batch=0.67s
14407/10943 (epoch 118.485) train_loss=117.45515442 time/batch=0.79s
14408/10943 (epoch 118.493) train_loss=98.13360596 time/batch=0.63s
14409/10943 (epoch 118.501) train_loss=164.68360901 time/batch=0.92s
14410/10943 (epoch 118.509) train_loss=138.91729736 time/batch=0.85s
14411/10943 (epoch 118.518) train_loss=161.53146362 time/batch=0.96s
14412/10943 (epoch 118.526) train_loss=138.93894958 time/batch=0.85s
14413/10943 (epoch 118.534) train_loss=141.95045471 time/batch=0.87s
14414/10943 (epoch 118.542) train_loss=111.49074554 time/batch=0.67s
14415/10943 (epoch 118.551) train_loss=81.70997620 time/batch=0.51s
14416/10943 (epoch 118.559) train_loss=77.13372803 time/batch=0.47s
14417/10943 (epoch 118.567) train_loss=121.41120911 time/batch=0.78s
14418/10943 (epoch 118.575) train_loss=123.76647949 time/batch=0.81s
14419/10943 (epoch 118.583) train_loss=119.27674103 time/batch=0.73s
14420/10943 (epoch 118.592) train_loss=90.88836670 time/batch=0.59s
14421/10943 (epoch 118.600) train_loss=79.49730682 time/batch=0.49s
14422/10943 (epoch 118.608) train_loss=122.37035370 time/batch=0.84s
14423/10943 (epoch 118.616) train_loss=95.08502960 time/batch=0.58s
14424/10943 (epoch 118.625) train_loss=88.90286255 time/batch=0.58s
14425/10943 (epoch 118.633) train_loss=113.20008850 time/batch=0.72s
14426/10943 (epoch 118.641) train_loss=84.77581787 time/batch=0.57s
14427/10943 (epoch 118.649) train_loss=103.17510223 time/batch=0.59s
14428/10943 (epoch 118.657) train_loss=113.39836121 time/batch=0.65s
14429/10943 (epoch 118.666) train_loss=107.65016937 time/batch=0.64s
14430/10943 (epoch 118.674) train_loss=115.39561462 time/batch=0.67s
14431/10943 (epoch 118.682) train_loss=127.76303864 time/batch=0.76s
14432/10943 (epoch 118.690) train_loss=93.65556335 time/batch=0.64s
14433/10943 (epoch 118.699) train_loss=113.97612000 time/batch=0.67s
14434/10943 (epoch 118.707) train_loss=97.92667389 time/batch=0.68s
14435/10943 (epoch 118.715) train_loss=122.90012360 time/batch=0.76s
setting learning rate to 0.0005792
14436/10943 (epoch 118.723) train_loss=91.59589386 time/batch=0.62s
14437/10943 (epoch 118.731) train_loss=321.21331787 time/batch=1.57s
14438/10943 (epoch 118.740) train_loss=205.73480225 time/batch=1.11s
14439/10943 (epoch 118.748) train_loss=186.00732422 time/batch=1.07s
14440/10943 (epoch 118.756) train_loss=130.67950439 time/batch=0.82s
14441/10943 (epoch 118.764) train_loss=213.07601929 time/batch=1.13s
14442/10943 (epoch 118.773) train_loss=253.23907471 time/batch=1.35s
14443/10943 (epoch 118.781) train_loss=270.52081299 time/batch=1.41s
14444/10943 (epoch 118.789) train_loss=118.32101440 time/batch=0.79s
14445/10943 (epoch 118.797) train_loss=201.24429321 time/batch=1.13s
14446/10943 (epoch 118.805) train_loss=222.56286621 time/batch=1.22s
14447/10943 (epoch 118.814) train_loss=87.20422363 time/batch=0.63s
14448/10943 (epoch 118.822) train_loss=240.56124878 time/batch=1.37s
14449/10943 (epoch 118.830) train_loss=155.44515991 time/batch=1.03s
14450/10943 (epoch 118.838) train_loss=204.07681274 time/batch=1.22s
14451/10943 (epoch 118.847) train_loss=117.07437134 time/batch=0.82s
14452/10943 (epoch 118.855) train_loss=485.04071045 time/batch=3.08s
14453/10943 (epoch 118.863) train_loss=251.36343384 time/batch=1.69s
14454/10943 (epoch 118.871) train_loss=97.59218597 time/batch=0.69s
14455/10943 (epoch 118.879) train_loss=78.50356293 time/batch=0.45s
14456/10943 (epoch 118.888) train_loss=255.96737671 time/batch=1.57s
14457/10943 (epoch 118.896) train_loss=57.76964951 time/batch=0.45s
14458/10943 (epoch 118.904) train_loss=90.45947266 time/batch=0.57s
14459/10943 (epoch 118.912) train_loss=223.53952026 time/batch=1.60s
14460/10943 (epoch 118.921) train_loss=68.84948730 time/batch=0.57s
14461/10943 (epoch 118.929) train_loss=66.83805847 time/batch=0.41s
14462/10943 (epoch 118.937) train_loss=222.47912598 time/batch=1.61s
14463/10943 (epoch 118.945) train_loss=55.98122025 time/batch=0.42s
14464/10943 (epoch 118.953) train_loss=162.18847656 time/batch=0.92s
14465/10943 (epoch 118.962) train_loss=113.68202972 time/batch=0.82s
14466/10943 (epoch 118.970) train_loss=144.88009644 time/batch=0.89s
14467/10943 (epoch 118.978) train_loss=74.55014801 time/batch=0.53s
14468/10943 (epoch 118.986) train_loss=113.06056976 time/batch=0.77s
14469/10943 (epoch 118.995) train_loss=62.85562515 time/batch=0.43s
14470/10943 (epoch 119.003) train_loss=109.13199615 time/batch=0.73s
14471/10943 (epoch 119.011) train_loss=140.79199219 time/batch=0.93s
14472/10943 (epoch 119.019) train_loss=95.29293823 time/batch=0.80s
14473/10943 (epoch 119.027) train_loss=56.66565704 time/batch=0.34s
14474/10943 (epoch 119.036) train_loss=150.64320374 time/batch=0.88s
14475/10943 (epoch 119.044) train_loss=102.92198181 time/batch=0.71s
14476/10943 (epoch 119.052) train_loss=53.26609421 time/batch=0.36s
14477/10943 (epoch 119.060) train_loss=82.10871887 time/batch=0.52s
14478/10943 (epoch 119.069) train_loss=56.27476501 time/batch=0.34s
14479/10943 (epoch 119.077) train_loss=115.70960999 time/batch=0.69s
14480/10943 (epoch 119.085) train_loss=132.24041748 time/batch=0.83s
14481/10943 (epoch 119.093) train_loss=117.43943787 time/batch=0.75s
14482/10943 (epoch 119.102) train_loss=66.97010803 time/batch=0.38s
14483/10943 (epoch 119.110) train_loss=174.21031189 time/batch=0.94s
14484/10943 (epoch 119.118) train_loss=99.79879761 time/batch=0.68s
14485/10943 (epoch 119.126) train_loss=184.73826599 time/batch=0.99s
14486/10943 (epoch 119.134) train_loss=136.85005188 time/batch=0.85s
14487/10943 (epoch 119.143) train_loss=86.04624176 time/batch=0.55s
14488/10943 (epoch 119.151) train_loss=83.22326660 time/batch=0.50s
14489/10943 (epoch 119.159) train_loss=66.41934204 time/batch=0.40s
14490/10943 (epoch 119.167) train_loss=109.75999451 time/batch=0.76s
14491/10943 (epoch 119.176) train_loss=108.48236084 time/batch=0.67s
14492/10943 (epoch 119.184) train_loss=64.66075897 time/batch=0.38s
14493/10943 (epoch 119.192) train_loss=98.13043213 time/batch=0.67s
14494/10943 (epoch 119.200) train_loss=64.19885254 time/batch=0.41s
14495/10943 (epoch 119.208) train_loss=113.78813934 time/batch=0.78s
14496/10943 (epoch 119.217) train_loss=124.00901794 time/batch=0.87s
14497/10943 (epoch 119.225) train_loss=70.44848633 time/batch=0.47s
14498/10943 (epoch 119.233) train_loss=75.52055359 time/batch=0.47s
14499/10943 (epoch 119.241) train_loss=94.44242859 time/batch=0.58s
14500/10943 (epoch 119.250) train_loss=144.40089417 time/batch=0.89s
14501/10943 (epoch 119.258) train_loss=154.73490906 time/batch=0.92s
14502/10943 (epoch 119.266) train_loss=111.06236267 time/batch=0.71s
14503/10943 (epoch 119.274) train_loss=134.82751465 time/batch=0.86s
14504/10943 (epoch 119.282) train_loss=89.88967896 time/batch=0.59s
14505/10943 (epoch 119.291) train_loss=68.95504761 time/batch=0.45s
14506/10943 (epoch 119.299) train_loss=96.80270386 time/batch=0.53s
14507/10943 (epoch 119.307) train_loss=176.08551025 time/batch=1.03s
14508/10943 (epoch 119.315) train_loss=95.09577942 time/batch=0.66s
14509/10943 (epoch 119.324) train_loss=55.91332245 time/batch=0.37s
14510/10943 (epoch 119.332) train_loss=154.87246704 time/batch=0.90s
14511/10943 (epoch 119.340) train_loss=102.76633453 time/batch=0.67s
14512/10943 (epoch 119.348) train_loss=107.58157349 time/batch=0.66s
14513/10943 (epoch 119.356) train_loss=54.87136078 time/batch=0.34s
14514/10943 (epoch 119.365) train_loss=70.60540771 time/batch=0.44s
14515/10943 (epoch 119.373) train_loss=131.87243652 time/batch=0.75s
14516/10943 (epoch 119.381) train_loss=78.49686432 time/batch=0.50s
14517/10943 (epoch 119.389) train_loss=121.98393250 time/batch=0.72s
14518/10943 (epoch 119.398) train_loss=171.59725952 time/batch=0.99s
14519/10943 (epoch 119.406) train_loss=75.45135498 time/batch=0.54s
14520/10943 (epoch 119.414) train_loss=104.09312439 time/batch=0.76s
14521/10943 (epoch 119.422) train_loss=81.32952118 time/batch=0.57s
14522/10943 (epoch 119.430) train_loss=85.25621033 time/batch=0.55s
14523/10943 (epoch 119.439) train_loss=135.88082886 time/batch=0.81s
14524/10943 (epoch 119.447) train_loss=109.24435425 time/batch=0.64s
14525/10943 (epoch 119.455) train_loss=93.70738983 time/batch=0.59s
14526/10943 (epoch 119.463) train_loss=92.13247681 time/batch=0.61s
14527/10943 (epoch 119.472) train_loss=116.83775330 time/batch=0.69s
14528/10943 (epoch 119.480) train_loss=73.58738708 time/batch=0.43s
14529/10943 (epoch 119.488) train_loss=74.25427246 time/batch=0.45s
14530/10943 (epoch 119.496) train_loss=106.68164062 time/batch=0.65s
14531/10943 (epoch 119.504) train_loss=133.98657227 time/batch=0.86s
14532/10943 (epoch 119.513) train_loss=129.54870605 time/batch=0.73s
14533/10943 (epoch 119.521) train_loss=142.97848511 time/batch=0.99s
14534/10943 (epoch 119.529) train_loss=139.73504639 time/batch=0.87s
14535/10943 (epoch 119.537) train_loss=90.76054382 time/batch=0.55s
14536/10943 (epoch 119.546) train_loss=87.02206421 time/batch=0.60s
14537/10943 (epoch 119.554) train_loss=136.80470276 time/batch=0.85s
14538/10943 (epoch 119.562) train_loss=115.90904236 time/batch=0.70s
14539/10943 (epoch 119.570) train_loss=92.12109375 time/batch=0.59s
14540/10943 (epoch 119.579) train_loss=123.84755707 time/batch=0.79s
14541/10943 (epoch 119.587) train_loss=97.69557953 time/batch=0.65s
14542/10943 (epoch 119.595) train_loss=113.24536133 time/batch=0.69s
14543/10943 (epoch 119.603) train_loss=93.08125305 time/batch=0.59s
14544/10943 (epoch 119.611) train_loss=121.10816956 time/batch=0.71s
14545/10943 (epoch 119.620) train_loss=138.95285034 time/batch=0.87s
14546/10943 (epoch 119.628) train_loss=130.61880493 time/batch=0.83s
14547/10943 (epoch 119.636) train_loss=110.55416107 time/batch=0.71s
14548/10943 (epoch 119.644) train_loss=50.53493500 time/batch=0.34s
14549/10943 (epoch 119.653) train_loss=107.73054504 time/batch=0.61s
14550/10943 (epoch 119.661) train_loss=102.60253906 time/batch=0.64s
14551/10943 (epoch 119.669) train_loss=119.35566711 time/batch=0.77s
14552/10943 (epoch 119.677) train_loss=94.72601318 time/batch=0.64s
14553/10943 (epoch 119.685) train_loss=81.74161530 time/batch=0.57s
14554/10943 (epoch 119.694) train_loss=64.00478363 time/batch=0.37s
14555/10943 (epoch 119.702) train_loss=100.58238220 time/batch=0.68s
14556/10943 (epoch 119.710) train_loss=90.29684448 time/batch=0.71s
setting learning rate to 0.0005618
  saved to metadata/gru_no_dropout-9_nov_folkwiki-20181207-192453_epoch75.pkl
14557/10943 (epoch 119.718) train_loss=347.73297119 time/batch=1.89s
14558/10943 (epoch 119.727) train_loss=51.45483017 time/batch=0.42s
14559/10943 (epoch 119.735) train_loss=217.54473877 time/batch=1.07s
14560/10943 (epoch 119.743) train_loss=225.76293945 time/batch=1.21s
14561/10943 (epoch 119.751) train_loss=121.27877808 time/batch=0.78s
14562/10943 (epoch 119.759) train_loss=368.33489990 time/batch=2.01s
14563/10943 (epoch 119.768) train_loss=106.19612885 time/batch=0.80s
14564/10943 (epoch 119.776) train_loss=65.16809845 time/batch=0.41s
14565/10943 (epoch 119.784) train_loss=75.45716858 time/batch=0.46s
14566/10943 (epoch 119.792) train_loss=68.52967834 time/batch=0.44s
14567/10943 (epoch 119.801) train_loss=248.35601807 time/batch=1.27s
14568/10943 (epoch 119.809) train_loss=165.93350220 time/batch=1.02s
14569/10943 (epoch 119.817) train_loss=262.70602417 time/batch=1.34s
14570/10943 (epoch 119.825) train_loss=169.62875366 time/batch=1.01s
14571/10943 (epoch 119.833) train_loss=149.08172607 time/batch=0.93s
14572/10943 (epoch 119.842) train_loss=183.45635986 time/batch=1.05s
14573/10943 (epoch 119.850) train_loss=85.91955566 time/batch=0.62s
14574/10943 (epoch 119.858) train_loss=248.50756836 time/batch=1.37s
14575/10943 (epoch 119.866) train_loss=137.77632141 time/batch=0.94s
14576/10943 (epoch 119.875) train_loss=224.92723083 time/batch=1.20s
14577/10943 (epoch 119.883) train_loss=210.27578735 time/batch=1.18s
14578/10943 (epoch 119.891) train_loss=124.96961975 time/batch=0.76s
14579/10943 (epoch 119.899) train_loss=251.16220093 time/batch=1.47s
14580/10943 (epoch 119.907) train_loss=227.09350586 time/batch=1.27s
14581/10943 (epoch 119.916) train_loss=114.86167908 time/batch=0.72s
14582/10943 (epoch 119.924) train_loss=77.82992554 time/batch=0.50s
14583/10943 (epoch 119.932) train_loss=87.61978149 time/batch=0.53s
14584/10943 (epoch 119.940) train_loss=186.07415771 time/batch=1.04s
14585/10943 (epoch 119.949) train_loss=139.87344360 time/batch=0.93s
14586/10943 (epoch 119.957) train_loss=57.68611908 time/batch=0.38s
14587/10943 (epoch 119.965) train_loss=165.91394043 time/batch=0.95s
14588/10943 (epoch 119.973) train_loss=363.12399292 time/batch=3.10s
14589/10943 (epoch 119.981) train_loss=87.97274780 time/batch=0.79s
14590/10943 (epoch 119.990) train_loss=71.64743805 time/batch=0.46s
14591/10943 (epoch 119.998) train_loss=125.10279846 time/batch=0.79s
14592/10943 (epoch 120.006) train_loss=98.32321167 time/batch=0.69s
14593/10943 (epoch 120.014) train_loss=69.57910156 time/batch=0.42s
14594/10943 (epoch 120.023) train_loss=112.80905914 time/batch=0.67s
14595/10943 (epoch 120.031) train_loss=63.94755173 time/batch=0.36s
14596/10943 (epoch 120.039) train_loss=156.68827820 time/batch=0.92s
14597/10943 (epoch 120.047) train_loss=55.46177673 time/batch=0.35s
14598/10943 (epoch 120.056) train_loss=112.69743347 time/batch=0.74s
14599/10943 (epoch 120.064) train_loss=110.29197693 time/batch=0.76s
14600/10943 (epoch 120.072) train_loss=128.94929504 time/batch=0.87s
14601/10943 (epoch 120.080) train_loss=81.83441925 time/batch=0.50s
14602/10943 (epoch 120.088) train_loss=61.55593109 time/batch=0.37s
14603/10943 (epoch 120.097) train_loss=92.70912170 time/batch=0.59s
14604/10943 (epoch 120.105) train_loss=92.32582092 time/batch=0.63s
14605/10943 (epoch 120.113) train_loss=125.83720398 time/batch=0.83s
14606/10943 (epoch 120.121) train_loss=197.03651428 time/batch=1.09s
14607/10943 (epoch 120.130) train_loss=127.08854675 time/batch=0.85s
14608/10943 (epoch 120.138) train_loss=87.04450226 time/batch=0.58s
14609/10943 (epoch 120.146) train_loss=190.99172974 time/batch=0.99s
14610/10943 (epoch 120.154) train_loss=117.65084839 time/batch=0.80s
14611/10943 (epoch 120.162) train_loss=126.36450195 time/batch=0.83s
14612/10943 (epoch 120.171) train_loss=76.52104187 time/batch=0.51s
14613/10943 (epoch 120.179) train_loss=117.13322449 time/batch=0.74s
14614/10943 (epoch 120.187) train_loss=53.34473419 time/batch=0.34s
14615/10943 (epoch 120.195) train_loss=68.26348114 time/batch=0.42s
14616/10943 (epoch 120.204) train_loss=95.55177307 time/batch=0.62s
14617/10943 (epoch 120.212) train_loss=87.23667908 time/batch=0.58s
14618/10943 (epoch 120.220) train_loss=95.43414307 time/batch=0.63s
14619/10943 (epoch 120.228) train_loss=85.56097412 time/batch=0.59s
14620/10943 (epoch 120.236) train_loss=109.15774536 time/batch=0.64s
14621/10943 (epoch 120.245) train_loss=131.12130737 time/batch=0.83s
14622/10943 (epoch 120.253) train_loss=115.87864685 time/batch=0.80s
14623/10943 (epoch 120.261) train_loss=152.07598877 time/batch=0.93s
14624/10943 (epoch 120.269) train_loss=118.02595520 time/batch=0.76s
14625/10943 (epoch 120.278) train_loss=107.76908875 time/batch=0.70s
14626/10943 (epoch 120.286) train_loss=96.86315918 time/batch=0.61s
14627/10943 (epoch 120.294) train_loss=89.89382935 time/batch=0.54s
14628/10943 (epoch 120.302) train_loss=81.40238953 time/batch=0.54s
14629/10943 (epoch 120.310) train_loss=74.90805054 time/batch=0.50s
14630/10943 (epoch 120.319) train_loss=57.51042175 time/batch=0.36s
14631/10943 (epoch 120.327) train_loss=49.98177338 time/batch=0.30s
14632/10943 (epoch 120.335) train_loss=112.34286499 time/batch=0.75s
14633/10943 (epoch 120.343) train_loss=120.28313446 time/batch=0.78s
14634/10943 (epoch 120.352) train_loss=143.53475952 time/batch=0.92s
14635/10943 (epoch 120.360) train_loss=109.57896423 time/batch=0.73s
14636/10943 (epoch 120.368) train_loss=189.02603149 time/batch=1.03s
14637/10943 (epoch 120.376) train_loss=94.43431091 time/batch=0.66s
14638/10943 (epoch 120.384) train_loss=99.77807617 time/batch=0.60s
14639/10943 (epoch 120.393) train_loss=165.28105164 time/batch=0.94s
14640/10943 (epoch 120.401) train_loss=90.89978790 time/batch=0.61s
14641/10943 (epoch 120.409) train_loss=152.69725037 time/batch=0.88s
14642/10943 (epoch 120.417) train_loss=69.17787170 time/batch=0.47s
14643/10943 (epoch 120.426) train_loss=100.35041809 time/batch=0.66s
14644/10943 (epoch 120.434) train_loss=93.50337219 time/batch=0.62s
14645/10943 (epoch 120.442) train_loss=79.06077576 time/batch=0.57s
14646/10943 (epoch 120.450) train_loss=97.31166077 time/batch=0.60s
14647/10943 (epoch 120.458) train_loss=113.80314636 time/batch=0.77s
14648/10943 (epoch 120.467) train_loss=109.90539551 time/batch=0.68s
14649/10943 (epoch 120.475) train_loss=117.15561676 time/batch=0.80s
14650/10943 (epoch 120.483) train_loss=107.74624634 time/batch=0.69s
14651/10943 (epoch 120.491) train_loss=59.26553345 time/batch=0.37s
14652/10943 (epoch 120.500) train_loss=120.38407135 time/batch=0.75s
14653/10943 (epoch 120.508) train_loss=134.57398987 time/batch=0.92s
14654/10943 (epoch 120.516) train_loss=82.37738037 time/batch=0.49s
14655/10943 (epoch 120.524) train_loss=57.03505325 time/batch=0.33s
14656/10943 (epoch 120.533) train_loss=124.62486267 time/batch=0.77s
14657/10943 (epoch 120.541) train_loss=70.99720764 time/batch=0.45s
14658/10943 (epoch 120.549) train_loss=68.94665527 time/batch=0.44s
14659/10943 (epoch 120.557) train_loss=127.21655273 time/batch=0.79s
14660/10943 (epoch 120.565) train_loss=146.63273621 time/batch=0.99s
14661/10943 (epoch 120.574) train_loss=108.29481506 time/batch=0.72s
14662/10943 (epoch 120.582) train_loss=116.05227661 time/batch=0.68s
14663/10943 (epoch 120.590) train_loss=76.60769653 time/batch=0.52s
14664/10943 (epoch 120.598) train_loss=123.02555847 time/batch=0.79s
14665/10943 (epoch 120.607) train_loss=122.39396667 time/batch=0.75s
14666/10943 (epoch 120.615) train_loss=89.95456696 time/batch=0.61s
14667/10943 (epoch 120.623) train_loss=62.78746796 time/batch=0.38s
14668/10943 (epoch 120.631) train_loss=91.94010162 time/batch=0.58s
14669/10943 (epoch 120.639) train_loss=119.37900543 time/batch=0.72s
14670/10943 (epoch 120.648) train_loss=82.51523590 time/batch=0.53s
14671/10943 (epoch 120.656) train_loss=65.31037903 time/batch=0.37s
14672/10943 (epoch 120.664) train_loss=94.94540405 time/batch=0.60s
14673/10943 (epoch 120.672) train_loss=139.09684753 time/batch=0.83s
14674/10943 (epoch 120.681) train_loss=85.60782623 time/batch=0.56s
14675/10943 (epoch 120.689) train_loss=107.18161011 time/batch=0.70s
14676/10943 (epoch 120.697) train_loss=70.23287964 time/batch=0.54s
14677/10943 (epoch 120.705) train_loss=96.37512207 time/batch=0.71s
setting learning rate to 0.0005449
14678/10943 (epoch 120.713) train_loss=356.62158203 time/batch=1.85s
14679/10943 (epoch 120.722) train_loss=385.77334595 time/batch=2.14s
14680/10943 (epoch 120.730) train_loss=297.95834351 time/batch=1.50s
14681/10943 (epoch 120.738) train_loss=371.16204834 time/batch=2.43s
14682/10943 (epoch 120.746) train_loss=60.10028458 time/batch=0.51s
14683/10943 (epoch 120.755) train_loss=90.57504272 time/batch=0.53s
14684/10943 (epoch 120.763) train_loss=218.40457153 time/batch=1.13s
14685/10943 (epoch 120.771) train_loss=66.60931396 time/batch=0.43s
14686/10943 (epoch 120.779) train_loss=54.34144592 time/batch=0.30s
14687/10943 (epoch 120.787) train_loss=174.23577881 time/batch=1.00s
14688/10943 (epoch 120.796) train_loss=47.20686722 time/batch=0.33s
14689/10943 (epoch 120.804) train_loss=168.60662842 time/batch=0.94s
14690/10943 (epoch 120.812) train_loss=67.85291290 time/batch=0.51s
14691/10943 (epoch 120.820) train_loss=76.68630981 time/batch=0.54s
14692/10943 (epoch 120.829) train_loss=100.27671814 time/batch=0.64s
14693/10943 (epoch 120.837) train_loss=53.63024139 time/batch=0.37s
14694/10943 (epoch 120.845) train_loss=177.34725952 time/batch=0.97s
14695/10943 (epoch 120.853) train_loss=256.14175415 time/batch=1.30s
14696/10943 (epoch 120.861) train_loss=125.67810822 time/batch=0.78s
14697/10943 (epoch 120.870) train_loss=190.71025085 time/batch=1.05s
14698/10943 (epoch 120.878) train_loss=83.91397095 time/batch=0.64s
14699/10943 (epoch 120.886) train_loss=57.95811462 time/batch=0.38s
14700/10943 (epoch 120.894) train_loss=63.03553772 time/batch=0.41s
14701/10943 (epoch 120.903) train_loss=82.08795929 time/batch=0.57s
14702/10943 (epoch 120.911) train_loss=179.85403442 time/batch=1.05s
14703/10943 (epoch 120.919) train_loss=142.09289551 time/batch=0.96s
14704/10943 (epoch 120.927) train_loss=92.96899414 time/batch=0.60s
14705/10943 (epoch 120.935) train_loss=66.87182617 time/batch=0.41s
14706/10943 (epoch 120.944) train_loss=144.01025391 time/batch=0.85s
14707/10943 (epoch 120.952) train_loss=161.80278015 time/batch=0.97s
14708/10943 (epoch 120.960) train_loss=53.51441193 time/batch=0.37s
14709/10943 (epoch 120.968) train_loss=139.48599243 time/batch=0.84s
14710/10943 (epoch 120.977) train_loss=115.16800690 time/batch=0.76s
14711/10943 (epoch 120.985) train_loss=88.70276642 time/batch=0.64s
14712/10943 (epoch 120.993) train_loss=81.36705017 time/batch=0.55s
14713/10943 (epoch 121.001) train_loss=53.61855698 time/batch=0.32s
14714/10943 (epoch 121.010) train_loss=210.99990845 time/batch=1.13s
14715/10943 (epoch 121.018) train_loss=88.13880920 time/batch=0.64s
14716/10943 (epoch 121.026) train_loss=298.59429932 time/batch=3.04s
14717/10943 (epoch 121.034) train_loss=76.70780945 time/batch=0.71s
14718/10943 (epoch 121.042) train_loss=221.67776489 time/batch=1.15s
14719/10943 (epoch 121.051) train_loss=210.25813293 time/batch=1.24s
14720/10943 (epoch 121.059) train_loss=73.96048737 time/batch=0.51s
14721/10943 (epoch 121.067) train_loss=245.95478821 time/batch=1.23s
14722/10943 (epoch 121.075) train_loss=114.03793335 time/batch=0.85s
14723/10943 (epoch 121.084) train_loss=183.73526001 time/batch=0.99s
14724/10943 (epoch 121.092) train_loss=115.30052185 time/batch=0.75s
14725/10943 (epoch 121.100) train_loss=68.07585144 time/batch=0.41s
14726/10943 (epoch 121.108) train_loss=93.68026733 time/batch=0.59s
14727/10943 (epoch 121.116) train_loss=123.67588043 time/batch=0.81s
14728/10943 (epoch 121.125) train_loss=101.04657745 time/batch=0.67s
14729/10943 (epoch 121.133) train_loss=69.09204102 time/batch=0.46s
14730/10943 (epoch 121.141) train_loss=98.66914368 time/batch=0.66s
14731/10943 (epoch 121.149) train_loss=110.40481567 time/batch=0.77s
14732/10943 (epoch 121.158) train_loss=91.60142517 time/batch=0.63s
14733/10943 (epoch 121.166) train_loss=112.18627930 time/batch=0.70s
14734/10943 (epoch 121.174) train_loss=168.94750977 time/batch=1.01s
14735/10943 (epoch 121.182) train_loss=135.97209167 time/batch=0.89s
14736/10943 (epoch 121.190) train_loss=122.65711212 time/batch=0.74s
14737/10943 (epoch 121.199) train_loss=88.31576538 time/batch=0.60s
14738/10943 (epoch 121.207) train_loss=77.86790466 time/batch=0.48s
14739/10943 (epoch 121.215) train_loss=100.20117188 time/batch=0.66s
14740/10943 (epoch 121.223) train_loss=109.64523315 time/batch=0.80s
14741/10943 (epoch 121.232) train_loss=159.11611938 time/batch=0.95s
14742/10943 (epoch 121.240) train_loss=83.49387360 time/batch=0.57s
14743/10943 (epoch 121.248) train_loss=78.86917114 time/batch=0.52s
14744/10943 (epoch 121.256) train_loss=213.15504456 time/batch=1.18s
14745/10943 (epoch 121.264) train_loss=114.98527527 time/batch=0.78s
14746/10943 (epoch 121.273) train_loss=162.48382568 time/batch=0.96s
14747/10943 (epoch 121.281) train_loss=69.65090942 time/batch=0.46s
14748/10943 (epoch 121.289) train_loss=104.09652710 time/batch=0.66s
14749/10943 (epoch 121.297) train_loss=106.39826965 time/batch=0.66s
14750/10943 (epoch 121.306) train_loss=90.25730133 time/batch=0.54s
14751/10943 (epoch 121.314) train_loss=81.24391174 time/batch=0.46s
14752/10943 (epoch 121.322) train_loss=57.48327637 time/batch=0.32s
14753/10943 (epoch 121.330) train_loss=81.01448059 time/batch=0.50s
14754/10943 (epoch 121.338) train_loss=62.96096420 time/batch=0.46s
14755/10943 (epoch 121.347) train_loss=85.53234863 time/batch=0.48s
14756/10943 (epoch 121.355) train_loss=107.09380341 time/batch=0.65s
14757/10943 (epoch 121.363) train_loss=116.18670654 time/batch=0.77s
14758/10943 (epoch 121.371) train_loss=74.09854889 time/batch=0.51s
14759/10943 (epoch 121.380) train_loss=117.22616577 time/batch=0.73s
14760/10943 (epoch 121.388) train_loss=96.27715302 time/batch=0.64s
14761/10943 (epoch 121.396) train_loss=126.23902893 time/batch=0.82s
14762/10943 (epoch 121.404) train_loss=125.54440308 time/batch=0.86s
14763/10943 (epoch 121.412) train_loss=109.83646393 time/batch=0.69s
14764/10943 (epoch 121.421) train_loss=122.71526337 time/batch=0.73s
14765/10943 (epoch 121.429) train_loss=119.92294312 time/batch=0.81s
14766/10943 (epoch 121.437) train_loss=61.45939636 time/batch=0.40s
14767/10943 (epoch 121.445) train_loss=120.87881470 time/batch=0.78s
14768/10943 (epoch 121.454) train_loss=139.48356628 time/batch=0.85s
14769/10943 (epoch 121.462) train_loss=126.84727478 time/batch=0.82s
14770/10943 (epoch 121.470) train_loss=102.84870911 time/batch=0.66s
14771/10943 (epoch 121.478) train_loss=84.65209961 time/batch=0.58s
14772/10943 (epoch 121.487) train_loss=82.45834351 time/batch=0.58s
14773/10943 (epoch 121.495) train_loss=112.53507233 time/batch=0.73s
14774/10943 (epoch 121.503) train_loss=141.80863953 time/batch=0.96s
14775/10943 (epoch 121.511) train_loss=78.87818909 time/batch=0.54s
14776/10943 (epoch 121.519) train_loss=56.70124054 time/batch=0.37s
14777/10943 (epoch 121.528) train_loss=62.25033569 time/batch=0.44s
14778/10943 (epoch 121.536) train_loss=103.15029907 time/batch=0.65s
14779/10943 (epoch 121.544) train_loss=140.51155090 time/batch=0.87s
14780/10943 (epoch 121.552) train_loss=127.04006958 time/batch=0.86s
14781/10943 (epoch 121.561) train_loss=125.25335693 time/batch=0.80s
14782/10943 (epoch 121.569) train_loss=147.59973145 time/batch=0.87s
14783/10943 (epoch 121.577) train_loss=89.62641907 time/batch=0.62s
14784/10943 (epoch 121.585) train_loss=100.55516052 time/batch=0.68s
14785/10943 (epoch 121.593) train_loss=129.61309814 time/batch=0.81s
14786/10943 (epoch 121.602) train_loss=123.01209259 time/batch=0.78s
14787/10943 (epoch 121.610) train_loss=171.77243042 time/batch=0.97s
14788/10943 (epoch 121.618) train_loss=106.56679535 time/batch=0.67s
14789/10943 (epoch 121.626) train_loss=74.98336029 time/batch=0.49s
14790/10943 (epoch 121.635) train_loss=93.91348267 time/batch=0.59s
14791/10943 (epoch 121.643) train_loss=85.64854431 time/batch=0.62s
14792/10943 (epoch 121.651) train_loss=110.74887848 time/batch=0.67s
14793/10943 (epoch 121.659) train_loss=120.90211487 time/batch=0.78s
14794/10943 (epoch 121.667) train_loss=99.50080872 time/batch=0.61s
14795/10943 (epoch 121.676) train_loss=94.52098846 time/batch=0.59s
14796/10943 (epoch 121.684) train_loss=117.02059174 time/batch=0.76s
14797/10943 (epoch 121.692) train_loss=95.58348083 time/batch=0.68s
14798/10943 (epoch 121.700) train_loss=121.81437683 time/batch=0.95s
setting learning rate to 0.0005286
  saved to metadata/gru_no_dropout-9_nov_folkwiki-20181207-192453_epoch77.pkl
14799/10943 (epoch 121.709) train_loss=198.35797119 time/batch=1.19s
14800/10943 (epoch 121.717) train_loss=299.64996338 time/batch=1.56s
14801/10943 (epoch 121.725) train_loss=118.83847809 time/batch=0.77s
14802/10943 (epoch 121.733) train_loss=108.66299438 time/batch=0.83s
14803/10943 (epoch 121.741) train_loss=211.67311096 time/batch=1.17s
14804/10943 (epoch 121.750) train_loss=111.99462891 time/batch=0.81s
14805/10943 (epoch 121.758) train_loss=176.48350525 time/batch=1.05s
14806/10943 (epoch 121.766) train_loss=264.48016357 time/batch=1.30s
14807/10943 (epoch 121.774) train_loss=133.53913879 time/batch=0.90s
14808/10943 (epoch 121.783) train_loss=70.11662292 time/batch=0.53s
14809/10943 (epoch 121.791) train_loss=231.38076782 time/batch=1.27s
14810/10943 (epoch 121.799) train_loss=130.11940002 time/batch=0.92s
14811/10943 (epoch 121.807) train_loss=142.19911194 time/batch=0.89s
14812/10943 (epoch 121.815) train_loss=105.88056946 time/batch=0.73s
14813/10943 (epoch 121.824) train_loss=199.64636230 time/batch=1.07s
14814/10943 (epoch 121.832) train_loss=101.65868378 time/batch=0.72s
14815/10943 (epoch 121.840) train_loss=123.83888245 time/batch=0.87s
14816/10943 (epoch 121.848) train_loss=61.85144424 time/batch=0.41s
14817/10943 (epoch 121.857) train_loss=69.63077545 time/batch=0.44s
14818/10943 (epoch 121.865) train_loss=483.01547241 time/batch=3.03s
14819/10943 (epoch 121.873) train_loss=174.79116821 time/batch=1.20s
14820/10943 (epoch 121.881) train_loss=90.78924561 time/batch=0.63s
14821/10943 (epoch 121.889) train_loss=56.74440765 time/batch=0.38s
14822/10943 (epoch 121.898) train_loss=252.61033630 time/batch=1.34s
14823/10943 (epoch 121.906) train_loss=133.38771057 time/batch=0.92s
14824/10943 (epoch 121.914) train_loss=163.82312012 time/batch=0.97s
14825/10943 (epoch 121.922) train_loss=56.70597076 time/batch=0.33s
14826/10943 (epoch 121.931) train_loss=92.17803955 time/batch=0.66s
14827/10943 (epoch 121.939) train_loss=122.98562622 time/batch=0.71s
14828/10943 (epoch 121.947) train_loss=277.34368896 time/batch=1.57s
14829/10943 (epoch 121.955) train_loss=143.78256226 time/batch=1.02s
14830/10943 (epoch 121.964) train_loss=50.37949753 time/batch=0.34s
14831/10943 (epoch 121.972) train_loss=118.63005066 time/batch=0.68s
14832/10943 (epoch 121.980) train_loss=104.42802429 time/batch=0.67s
14833/10943 (epoch 121.988) train_loss=266.76995850 time/batch=1.64s
14834/10943 (epoch 121.996) train_loss=161.78344727 time/batch=1.05s
14835/10943 (epoch 122.005) train_loss=71.05914307 time/batch=0.47s
14836/10943 (epoch 122.013) train_loss=232.70635986 time/batch=1.63s
14837/10943 (epoch 122.021) train_loss=87.04441071 time/batch=0.70s
14838/10943 (epoch 122.029) train_loss=71.00994110 time/batch=0.45s
14839/10943 (epoch 122.038) train_loss=90.17105865 time/batch=0.58s
14840/10943 (epoch 122.046) train_loss=201.16392517 time/batch=1.10s
14841/10943 (epoch 122.054) train_loss=156.10095215 time/batch=1.01s
14842/10943 (epoch 122.062) train_loss=112.54432678 time/batch=0.78s
14843/10943 (epoch 122.070) train_loss=72.35301208 time/batch=0.52s
14844/10943 (epoch 122.079) train_loss=99.60136414 time/batch=0.63s
14845/10943 (epoch 122.087) train_loss=135.54652405 time/batch=0.88s
14846/10943 (epoch 122.095) train_loss=57.13718414 time/batch=0.36s
14847/10943 (epoch 122.103) train_loss=112.39958191 time/batch=0.67s
14848/10943 (epoch 122.112) train_loss=177.97485352 time/batch=1.04s
14849/10943 (epoch 122.120) train_loss=115.78382874 time/batch=0.81s
14850/10943 (epoch 122.128) train_loss=53.62879181 time/batch=0.35s
14851/10943 (epoch 122.136) train_loss=60.75864410 time/batch=0.40s
14852/10943 (epoch 122.144) train_loss=164.48817444 time/batch=0.95s
14853/10943 (epoch 122.153) train_loss=199.31304932 time/batch=1.18s
14854/10943 (epoch 122.161) train_loss=114.88006592 time/batch=0.85s
14855/10943 (epoch 122.169) train_loss=114.73201752 time/batch=0.73s
14856/10943 (epoch 122.177) train_loss=130.39486694 time/batch=0.83s
14857/10943 (epoch 122.186) train_loss=113.26332092 time/batch=0.74s
14858/10943 (epoch 122.194) train_loss=104.36235809 time/batch=0.69s
14859/10943 (epoch 122.202) train_loss=72.06214905 time/batch=0.46s
14860/10943 (epoch 122.210) train_loss=133.94984436 time/batch=0.82s
14861/10943 (epoch 122.218) train_loss=115.83036041 time/batch=0.82s
14862/10943 (epoch 122.227) train_loss=89.59286499 time/batch=0.59s
14863/10943 (epoch 122.235) train_loss=108.96987915 time/batch=0.64s
14864/10943 (epoch 122.243) train_loss=88.56181335 time/batch=0.59s
14865/10943 (epoch 122.251) train_loss=103.85990143 time/batch=0.77s
14866/10943 (epoch 122.260) train_loss=83.71198273 time/batch=0.59s
14867/10943 (epoch 122.268) train_loss=88.24541473 time/batch=0.54s
14868/10943 (epoch 122.276) train_loss=120.91094971 time/batch=0.79s
14869/10943 (epoch 122.284) train_loss=95.35836792 time/batch=0.65s
14870/10943 (epoch 122.292) train_loss=163.95214844 time/batch=0.97s
14871/10943 (epoch 122.301) train_loss=135.98010254 time/batch=0.92s
14872/10943 (epoch 122.309) train_loss=107.81221771 time/batch=0.81s
14873/10943 (epoch 122.317) train_loss=75.31570435 time/batch=0.49s
14874/10943 (epoch 122.325) train_loss=67.16717529 time/batch=0.41s
14875/10943 (epoch 122.334) train_loss=81.84657288 time/batch=0.60s
14876/10943 (epoch 122.342) train_loss=96.65419769 time/batch=0.67s
14877/10943 (epoch 122.350) train_loss=76.11128235 time/batch=0.49s
14878/10943 (epoch 122.358) train_loss=110.63520813 time/batch=0.73s
14879/10943 (epoch 122.366) train_loss=61.20601654 time/batch=0.40s
14880/10943 (epoch 122.375) train_loss=106.18954468 time/batch=0.69s
14881/10943 (epoch 122.383) train_loss=55.48342896 time/batch=0.36s
14882/10943 (epoch 122.391) train_loss=176.26898193 time/batch=0.95s
14883/10943 (epoch 122.399) train_loss=69.14128113 time/batch=0.44s
14884/10943 (epoch 122.408) train_loss=99.13565063 time/batch=0.59s
14885/10943 (epoch 122.416) train_loss=112.98300171 time/batch=0.72s
14886/10943 (epoch 122.424) train_loss=87.92639160 time/batch=0.64s
14887/10943 (epoch 122.432) train_loss=93.41397095 time/batch=0.59s
14888/10943 (epoch 122.441) train_loss=75.10889435 time/batch=0.48s
14889/10943 (epoch 122.449) train_loss=141.34167480 time/batch=0.86s
14890/10943 (epoch 122.457) train_loss=122.71392822 time/batch=0.82s
14891/10943 (epoch 122.465) train_loss=106.05226135 time/batch=0.67s
14892/10943 (epoch 122.473) train_loss=181.76884460 time/batch=1.00s
14893/10943 (epoch 122.482) train_loss=119.73199463 time/batch=0.82s
14894/10943 (epoch 122.490) train_loss=61.51499176 time/batch=0.37s
14895/10943 (epoch 122.498) train_loss=100.50369263 time/batch=0.58s
14896/10943 (epoch 122.506) train_loss=83.15782928 time/batch=0.52s
14897/10943 (epoch 122.515) train_loss=120.15161133 time/batch=0.77s
14898/10943 (epoch 122.523) train_loss=58.67082977 time/batch=0.35s
14899/10943 (epoch 122.531) train_loss=66.02979279 time/batch=0.38s
14900/10943 (epoch 122.539) train_loss=72.71167755 time/batch=0.46s
14901/10943 (epoch 122.547) train_loss=102.44118500 time/batch=0.64s
14902/10943 (epoch 122.556) train_loss=105.37167358 time/batch=0.65s
14903/10943 (epoch 122.564) train_loss=91.83686066 time/batch=0.61s
14904/10943 (epoch 122.572) train_loss=96.98599243 time/batch=0.68s
14905/10943 (epoch 122.580) train_loss=111.74737549 time/batch=0.73s
14906/10943 (epoch 122.589) train_loss=117.79055023 time/batch=0.79s
14907/10943 (epoch 122.597) train_loss=65.56122589 time/batch=0.38s
14908/10943 (epoch 122.605) train_loss=153.58093262 time/batch=0.97s
14909/10943 (epoch 122.613) train_loss=84.97542572 time/batch=0.59s
14910/10943 (epoch 122.621) train_loss=89.71900940 time/batch=0.57s
14911/10943 (epoch 122.630) train_loss=76.67845154 time/batch=0.48s
14912/10943 (epoch 122.638) train_loss=85.59707642 time/batch=0.53s
14913/10943 (epoch 122.646) train_loss=114.73323822 time/batch=0.77s
14914/10943 (epoch 122.654) train_loss=86.38320923 time/batch=0.53s
14915/10943 (epoch 122.663) train_loss=85.66091919 time/batch=0.50s
14916/10943 (epoch 122.671) train_loss=134.21980286 time/batch=0.99s
14917/10943 (epoch 122.679) train_loss=94.33185577 time/batch=0.61s
14918/10943 (epoch 122.687) train_loss=90.10946655 time/batch=0.55s
14919/10943 (epoch 122.695) train_loss=88.88746643 time/batch=0.51s
setting learning rate to 0.0005127
14920/10943 (epoch 122.704) train_loss=48.65930176 time/batch=0.28s
14921/10943 (epoch 122.712) train_loss=118.33009338 time/batch=0.76s
14922/10943 (epoch 122.720) train_loss=290.02453613 time/batch=1.57s
14923/10943 (epoch 122.728) train_loss=132.45997620 time/batch=0.91s
14924/10943 (epoch 122.737) train_loss=83.87971497 time/batch=0.59s
14925/10943 (epoch 122.745) train_loss=70.25825500 time/batch=0.51s
14926/10943 (epoch 122.753) train_loss=113.78583527 time/batch=0.64s
14927/10943 (epoch 122.761) train_loss=247.57546997 time/batch=1.36s
14928/10943 (epoch 122.769) train_loss=507.78302002 time/batch=3.12s
14929/10943 (epoch 122.778) train_loss=126.43487549 time/batch=1.00s
14930/10943 (epoch 122.786) train_loss=88.21257019 time/batch=0.57s
14931/10943 (epoch 122.794) train_loss=313.90679932 time/batch=1.59s
14932/10943 (epoch 122.802) train_loss=228.93621826 time/batch=1.31s
14933/10943 (epoch 122.811) train_loss=149.80302429 time/batch=0.95s
14934/10943 (epoch 122.819) train_loss=171.94529724 time/batch=1.01s
14935/10943 (epoch 122.827) train_loss=221.96763611 time/batch=1.18s
14936/10943 (epoch 122.835) train_loss=120.34326172 time/batch=0.82s
14937/10943 (epoch 122.843) train_loss=99.42908478 time/batch=0.67s
14938/10943 (epoch 122.852) train_loss=200.61518860 time/batch=1.11s
14939/10943 (epoch 122.860) train_loss=89.61116791 time/batch=0.64s
14940/10943 (epoch 122.868) train_loss=239.19444275 time/batch=1.23s
14941/10943 (epoch 122.876) train_loss=65.44023132 time/batch=0.46s
14942/10943 (epoch 122.885) train_loss=91.49674225 time/batch=0.60s
14943/10943 (epoch 122.893) train_loss=80.99485779 time/batch=0.61s
14944/10943 (epoch 122.901) train_loss=121.92356873 time/batch=0.81s
14945/10943 (epoch 122.909) train_loss=128.70574951 time/batch=0.86s
14946/10943 (epoch 122.918) train_loss=70.48458862 time/batch=0.49s
14947/10943 (epoch 122.926) train_loss=124.70985413 time/batch=0.83s
14948/10943 (epoch 122.934) train_loss=53.65575409 time/batch=0.36s
14949/10943 (epoch 122.942) train_loss=157.80526733 time/batch=0.89s
14950/10943 (epoch 122.950) train_loss=82.30200195 time/batch=0.66s
14951/10943 (epoch 122.959) train_loss=233.60836792 time/batch=1.27s
14952/10943 (epoch 122.967) train_loss=140.61056519 time/batch=0.97s
14953/10943 (epoch 122.975) train_loss=53.54478455 time/batch=0.36s
14954/10943 (epoch 122.983) train_loss=104.38911438 time/batch=0.73s
14955/10943 (epoch 122.992) train_loss=61.97949982 time/batch=0.42s
14956/10943 (epoch 123.000) train_loss=74.21746826 time/batch=0.50s
14957/10943 (epoch 123.008) train_loss=88.07726288 time/batch=0.61s
14958/10943 (epoch 123.016) train_loss=104.54028320 time/batch=0.65s
14959/10943 (epoch 123.024) train_loss=262.84851074 time/batch=1.66s
14960/10943 (epoch 123.033) train_loss=58.02080917 time/batch=0.45s
14961/10943 (epoch 123.041) train_loss=179.09306335 time/batch=0.99s
14962/10943 (epoch 123.049) train_loss=70.88484192 time/batch=0.47s
14963/10943 (epoch 123.057) train_loss=54.91070557 time/batch=0.33s
14964/10943 (epoch 123.066) train_loss=111.01109314 time/batch=0.77s
14965/10943 (epoch 123.074) train_loss=162.58255005 time/batch=0.97s
14966/10943 (epoch 123.082) train_loss=121.65591431 time/batch=0.83s
14967/10943 (epoch 123.090) train_loss=59.49871826 time/batch=0.42s
14968/10943 (epoch 123.098) train_loss=85.13641357 time/batch=0.56s
14969/10943 (epoch 123.107) train_loss=113.77892303 time/batch=0.72s
14970/10943 (epoch 123.115) train_loss=68.35853577 time/batch=0.48s
14971/10943 (epoch 123.123) train_loss=144.74392700 time/batch=0.90s
14972/10943 (epoch 123.131) train_loss=74.79755402 time/batch=0.54s
14973/10943 (epoch 123.140) train_loss=122.56538391 time/batch=0.82s
14974/10943 (epoch 123.148) train_loss=50.03727722 time/batch=0.37s
14975/10943 (epoch 123.156) train_loss=153.21600342 time/batch=0.90s
14976/10943 (epoch 123.164) train_loss=62.47964859 time/batch=0.43s
14977/10943 (epoch 123.172) train_loss=127.39724731 time/batch=0.66s
14978/10943 (epoch 123.181) train_loss=176.80215454 time/batch=1.01s
14979/10943 (epoch 123.189) train_loss=90.21484375 time/batch=0.55s
14980/10943 (epoch 123.197) train_loss=215.57241821 time/batch=1.06s
14981/10943 (epoch 123.205) train_loss=193.70413208 time/batch=1.10s
14982/10943 (epoch 123.214) train_loss=85.01068115 time/batch=0.55s
14983/10943 (epoch 123.222) train_loss=187.91921997 time/batch=0.97s
14984/10943 (epoch 123.230) train_loss=108.10818481 time/batch=0.71s
14985/10943 (epoch 123.238) train_loss=120.59583282 time/batch=0.73s
14986/10943 (epoch 123.246) train_loss=68.59647369 time/batch=0.46s
14987/10943 (epoch 123.255) train_loss=110.27030182 time/batch=0.67s
14988/10943 (epoch 123.263) train_loss=102.56183624 time/batch=0.71s
14989/10943 (epoch 123.271) train_loss=91.42189026 time/batch=0.60s
14990/10943 (epoch 123.279) train_loss=112.58502197 time/batch=0.77s
14991/10943 (epoch 123.288) train_loss=66.61915588 time/batch=0.45s
14992/10943 (epoch 123.296) train_loss=115.99352264 time/batch=0.69s
14993/10943 (epoch 123.304) train_loss=86.31218719 time/batch=0.59s
14994/10943 (epoch 123.312) train_loss=96.50302124 time/batch=0.62s
14995/10943 (epoch 123.320) train_loss=115.80235291 time/batch=0.74s
14996/10943 (epoch 123.329) train_loss=206.92407227 time/batch=1.16s
14997/10943 (epoch 123.337) train_loss=80.29896545 time/batch=0.54s
14998/10943 (epoch 123.345) train_loss=114.20893860 time/batch=0.79s
14999/10943 (epoch 123.353) train_loss=159.09481812 time/batch=0.96s
Validating
    loss:	362.918391

15000/10943 (epoch 123.362) train_loss=87.29164124 time/batch=2.35s
15001/10943 (epoch 123.370) train_loss=200.53874207 time/batch=1.14s
15002/10943 (epoch 123.378) train_loss=65.89859009 time/batch=0.50s
15003/10943 (epoch 123.386) train_loss=119.17654419 time/batch=0.72s
15004/10943 (epoch 123.395) train_loss=108.24893188 time/batch=0.69s
15005/10943 (epoch 123.403) train_loss=103.37181854 time/batch=0.67s
15006/10943 (epoch 123.411) train_loss=138.39682007 time/batch=0.86s
15007/10943 (epoch 123.419) train_loss=79.70313263 time/batch=0.52s
15008/10943 (epoch 123.427) train_loss=99.50131226 time/batch=0.60s
15009/10943 (epoch 123.436) train_loss=107.17230225 time/batch=0.66s
15010/10943 (epoch 123.444) train_loss=93.86654663 time/batch=0.61s
15011/10943 (epoch 123.452) train_loss=141.07107544 time/batch=0.82s
15012/10943 (epoch 123.460) train_loss=132.55590820 time/batch=0.88s
15013/10943 (epoch 123.469) train_loss=161.99697876 time/batch=0.90s
15014/10943 (epoch 123.477) train_loss=85.62564087 time/batch=0.58s
15015/10943 (epoch 123.485) train_loss=91.66485596 time/batch=0.58s
15016/10943 (epoch 123.493) train_loss=106.88185120 time/batch=0.73s
15017/10943 (epoch 123.501) train_loss=125.17832947 time/batch=0.77s
15018/10943 (epoch 123.510) train_loss=160.34120178 time/batch=0.97s
15019/10943 (epoch 123.518) train_loss=97.87344360 time/batch=0.67s
15020/10943 (epoch 123.526) train_loss=103.67497253 time/batch=0.64s
15021/10943 (epoch 123.534) train_loss=118.08168030 time/batch=0.77s
15022/10943 (epoch 123.543) train_loss=159.93530273 time/batch=1.02s
15023/10943 (epoch 123.551) train_loss=74.22454834 time/batch=0.49s
15024/10943 (epoch 123.559) train_loss=54.94944763 time/batch=0.32s
15025/10943 (epoch 123.567) train_loss=113.22935486 time/batch=0.75s
15026/10943 (epoch 123.575) train_loss=105.08779144 time/batch=0.70s
15027/10943 (epoch 123.584) train_loss=81.42309570 time/batch=0.50s
15028/10943 (epoch 123.592) train_loss=92.36195374 time/batch=0.56s
15029/10943 (epoch 123.600) train_loss=68.32990265 time/batch=0.36s
15030/10943 (epoch 123.608) train_loss=74.36337280 time/batch=0.43s
15031/10943 (epoch 123.617) train_loss=92.02856445 time/batch=0.56s
15032/10943 (epoch 123.625) train_loss=75.16012573 time/batch=0.48s
15033/10943 (epoch 123.633) train_loss=97.87143707 time/batch=0.66s
15034/10943 (epoch 123.641) train_loss=133.45053101 time/batch=0.83s
15035/10943 (epoch 123.649) train_loss=122.94409180 time/batch=0.76s
15036/10943 (epoch 123.658) train_loss=121.14795685 time/batch=0.80s
15037/10943 (epoch 123.666) train_loss=61.11082840 time/batch=0.39s
15038/10943 (epoch 123.674) train_loss=86.83087158 time/batch=0.55s
15039/10943 (epoch 123.682) train_loss=94.61538696 time/batch=0.58s
15040/10943 (epoch 123.691) train_loss=101.86491394 time/batch=0.66s
setting learning rate to 0.0004973
  saved to metadata/gru_no_dropout-9_nov_folkwiki-20181207-192453_epoch79.pkl
15041/10943 (epoch 123.699) train_loss=255.28048706 time/batch=1.33s
15042/10943 (epoch 123.707) train_loss=222.13183594 time/batch=1.18s
15043/10943 (epoch 123.715) train_loss=140.38781738 time/batch=0.91s
15044/10943 (epoch 123.723) train_loss=84.55690002 time/batch=0.54s
15045/10943 (epoch 123.732) train_loss=76.40668488 time/batch=0.50s
15046/10943 (epoch 123.740) train_loss=106.99923706 time/batch=0.75s
15047/10943 (epoch 123.748) train_loss=52.11371994 time/batch=0.32s
15048/10943 (epoch 123.756) train_loss=284.83447266 time/batch=1.50s
15049/10943 (epoch 123.765) train_loss=114.36682129 time/batch=0.82s
15050/10943 (epoch 123.773) train_loss=180.28512573 time/batch=1.02s
15051/10943 (epoch 123.781) train_loss=205.27316284 time/batch=1.17s
15052/10943 (epoch 123.789) train_loss=243.94494629 time/batch=1.33s
15053/10943 (epoch 123.797) train_loss=107.05871582 time/batch=0.72s
15054/10943 (epoch 123.806) train_loss=64.30406189 time/batch=0.46s
15055/10943 (epoch 123.814) train_loss=483.97357178 time/batch=3.03s
15056/10943 (epoch 123.822) train_loss=169.54283142 time/batch=1.16s
15057/10943 (epoch 123.830) train_loss=305.99832153 time/batch=1.61s
15058/10943 (epoch 123.839) train_loss=190.44616699 time/batch=1.15s
15059/10943 (epoch 123.847) train_loss=217.62353516 time/batch=1.11s
15060/10943 (epoch 123.855) train_loss=220.48678589 time/batch=1.23s
15061/10943 (epoch 123.863) train_loss=86.55384827 time/batch=0.58s
15062/10943 (epoch 123.871) train_loss=100.90552521 time/batch=0.67s
15063/10943 (epoch 123.880) train_loss=117.93594360 time/batch=0.84s
15064/10943 (epoch 123.888) train_loss=174.12310791 time/batch=1.00s
15065/10943 (epoch 123.896) train_loss=63.57032776 time/batch=0.45s
15066/10943 (epoch 123.904) train_loss=52.97793579 time/batch=0.32s
15067/10943 (epoch 123.913) train_loss=108.44885254 time/batch=0.70s
15068/10943 (epoch 123.921) train_loss=186.75280762 time/batch=1.14s
15069/10943 (epoch 123.929) train_loss=159.59819031 time/batch=1.00s
15070/10943 (epoch 123.937) train_loss=63.89440155 time/batch=0.42s
15071/10943 (epoch 123.946) train_loss=155.89930725 time/batch=0.90s
15072/10943 (epoch 123.954) train_loss=82.07646179 time/batch=0.58s
15073/10943 (epoch 123.962) train_loss=104.03504944 time/batch=0.66s
15074/10943 (epoch 123.970) train_loss=113.93973541 time/batch=0.79s
15075/10943 (epoch 123.978) train_loss=100.52151489 time/batch=0.68s
15076/10943 (epoch 123.987) train_loss=273.78155518 time/batch=1.66s
15077/10943 (epoch 123.995) train_loss=126.47599792 time/batch=0.93s
15078/10943 (epoch 124.003) train_loss=146.17663574 time/batch=0.94s
15079/10943 (epoch 124.011) train_loss=141.57563782 time/batch=0.93s
15080/10943 (epoch 124.020) train_loss=211.59408569 time/batch=1.31s
15081/10943 (epoch 124.028) train_loss=110.33601379 time/batch=0.85s
15082/10943 (epoch 124.036) train_loss=154.38302612 time/batch=0.97s
15083/10943 (epoch 124.044) train_loss=74.99292755 time/batch=0.54s
15084/10943 (epoch 124.052) train_loss=157.35397339 time/batch=0.96s
15085/10943 (epoch 124.061) train_loss=189.35104370 time/batch=1.31s
15086/10943 (epoch 124.069) train_loss=130.46604919 time/batch=0.93s
15087/10943 (epoch 124.077) train_loss=141.13360596 time/batch=0.91s
15088/10943 (epoch 124.085) train_loss=67.94452667 time/batch=0.45s
15089/10943 (epoch 124.094) train_loss=103.85221100 time/batch=0.64s
15090/10943 (epoch 124.102) train_loss=91.13229370 time/batch=0.63s
15091/10943 (epoch 124.110) train_loss=142.72070312 time/batch=0.87s
15092/10943 (epoch 124.118) train_loss=219.27983093 time/batch=1.36s
15093/10943 (epoch 124.126) train_loss=132.98214722 time/batch=0.90s
15094/10943 (epoch 124.135) train_loss=92.45768738 time/batch=0.65s
15095/10943 (epoch 124.143) train_loss=72.34265137 time/batch=0.47s
15096/10943 (epoch 124.151) train_loss=112.47688293 time/batch=0.73s
15097/10943 (epoch 124.159) train_loss=84.42050934 time/batch=0.57s
15098/10943 (epoch 124.168) train_loss=99.73327637 time/batch=0.73s
15099/10943 (epoch 124.176) train_loss=93.27742767 time/batch=0.64s
15100/10943 (epoch 124.184) train_loss=49.30705261 time/batch=0.31s
15101/10943 (epoch 124.192) train_loss=57.98991394 time/batch=0.33s
15102/10943 (epoch 124.200) train_loss=82.08569336 time/batch=0.50s
15103/10943 (epoch 124.209) train_loss=56.14905548 time/batch=0.32s
15104/10943 (epoch 124.217) train_loss=65.44107056 time/batch=0.42s
15105/10943 (epoch 124.225) train_loss=79.10211182 time/batch=0.56s
15106/10943 (epoch 124.233) train_loss=123.66285706 time/batch=0.89s
15107/10943 (epoch 124.242) train_loss=90.24821472 time/batch=0.63s
15108/10943 (epoch 124.250) train_loss=94.76898956 time/batch=0.68s
15109/10943 (epoch 124.258) train_loss=83.80490875 time/batch=0.58s
15110/10943 (epoch 124.266) train_loss=70.12643433 time/batch=0.45s
15111/10943 (epoch 124.274) train_loss=72.46635437 time/batch=0.48s
15112/10943 (epoch 124.283) train_loss=95.38621521 time/batch=0.60s
15113/10943 (epoch 124.291) train_loss=63.89964294 time/batch=0.42s
15114/10943 (epoch 124.299) train_loss=91.52106476 time/batch=0.60s
15115/10943 (epoch 124.307) train_loss=118.86911011 time/batch=0.77s
15116/10943 (epoch 124.316) train_loss=65.85898590 time/batch=0.45s
15117/10943 (epoch 124.324) train_loss=111.47926331 time/batch=0.75s
15118/10943 (epoch 124.332) train_loss=119.56291199 time/batch=0.74s
15119/10943 (epoch 124.340) train_loss=57.75759506 time/batch=0.33s
15120/10943 (epoch 124.348) train_loss=127.76959229 time/batch=0.79s
15121/10943 (epoch 124.357) train_loss=130.84774780 time/batch=0.84s
15122/10943 (epoch 124.365) train_loss=108.42398071 time/batch=0.66s
15123/10943 (epoch 124.373) train_loss=107.71261597 time/batch=0.68s
15124/10943 (epoch 124.381) train_loss=84.41458893 time/batch=0.55s
15125/10943 (epoch 124.390) train_loss=100.07847595 time/batch=0.67s
15126/10943 (epoch 124.398) train_loss=89.72806549 time/batch=0.57s
15127/10943 (epoch 124.406) train_loss=86.09603882 time/batch=0.56s
15128/10943 (epoch 124.414) train_loss=114.18899536 time/batch=0.77s
15129/10943 (epoch 124.423) train_loss=126.22742462 time/batch=0.82s
15130/10943 (epoch 124.431) train_loss=95.51444244 time/batch=0.60s
15131/10943 (epoch 124.439) train_loss=75.62583923 time/batch=0.48s
15132/10943 (epoch 124.447) train_loss=117.04360962 time/batch=0.78s
15133/10943 (epoch 124.455) train_loss=86.80850983 time/batch=0.64s
15134/10943 (epoch 124.464) train_loss=89.94535065 time/batch=0.58s
15135/10943 (epoch 124.472) train_loss=143.63729858 time/batch=0.83s
15136/10943 (epoch 124.480) train_loss=65.05614471 time/batch=0.41s
15137/10943 (epoch 124.488) train_loss=118.73875427 time/batch=0.69s
15138/10943 (epoch 124.497) train_loss=125.40687561 time/batch=0.75s
15139/10943 (epoch 124.505) train_loss=116.13934326 time/batch=0.70s
15140/10943 (epoch 124.513) train_loss=120.66857147 time/batch=0.75s
15141/10943 (epoch 124.521) train_loss=131.28825378 time/batch=0.92s
15142/10943 (epoch 124.529) train_loss=118.65084076 time/batch=0.70s
15143/10943 (epoch 124.538) train_loss=182.57052612 time/batch=1.00s
15144/10943 (epoch 124.546) train_loss=100.51805115 time/batch=0.65s
15145/10943 (epoch 124.554) train_loss=117.82989502 time/batch=0.75s
15146/10943 (epoch 124.562) train_loss=94.59483337 time/batch=0.60s
15147/10943 (epoch 124.571) train_loss=91.49615479 time/batch=0.58s
15148/10943 (epoch 124.579) train_loss=74.66760254 time/batch=0.45s
15149/10943 (epoch 124.587) train_loss=93.61193848 time/batch=0.62s
15150/10943 (epoch 124.595) train_loss=75.75521851 time/batch=0.47s
15151/10943 (epoch 124.603) train_loss=77.02490997 time/batch=0.46s
15152/10943 (epoch 124.612) train_loss=141.57690430 time/batch=0.91s
15153/10943 (epoch 124.620) train_loss=63.47235870 time/batch=0.41s
15154/10943 (epoch 124.628) train_loss=70.72454834 time/batch=0.45s
15155/10943 (epoch 124.636) train_loss=51.81679153 time/batch=0.33s
15156/10943 (epoch 124.645) train_loss=84.55378723 time/batch=0.55s
15157/10943 (epoch 124.653) train_loss=56.18928146 time/batch=0.38s
15158/10943 (epoch 124.661) train_loss=106.49429321 time/batch=0.67s
15159/10943 (epoch 124.669) train_loss=128.31689453 time/batch=0.72s
15160/10943 (epoch 124.677) train_loss=90.94879150 time/batch=0.60s
15161/10943 (epoch 124.686) train_loss=84.17077637 time/batch=0.69s
setting learning rate to 0.0004824
15162/10943 (epoch 124.694) train_loss=102.19824219 time/batch=0.71s
15163/10943 (epoch 124.702) train_loss=83.70150757 time/batch=0.61s
15164/10943 (epoch 124.710) train_loss=249.83221436 time/batch=1.40s
15165/10943 (epoch 124.719) train_loss=232.65869141 time/batch=1.23s
15166/10943 (epoch 124.727) train_loss=206.47048950 time/batch=1.07s
15167/10943 (epoch 124.735) train_loss=451.77612305 time/batch=2.39s
15168/10943 (epoch 124.743) train_loss=54.34687805 time/batch=0.54s
15169/10943 (epoch 124.751) train_loss=95.99472046 time/batch=0.58s
15170/10943 (epoch 124.760) train_loss=347.21154785 time/batch=1.60s
15171/10943 (epoch 124.768) train_loss=247.71781921 time/batch=1.31s
15172/10943 (epoch 124.776) train_loss=268.88940430 time/batch=1.53s
15173/10943 (epoch 124.784) train_loss=73.23122406 time/batch=0.52s
15174/10943 (epoch 124.793) train_loss=200.62245178 time/batch=1.04s
15175/10943 (epoch 124.801) train_loss=60.38814163 time/batch=0.41s
15176/10943 (epoch 124.809) train_loss=101.99838257 time/batch=0.71s
15177/10943 (epoch 124.817) train_loss=51.15241241 time/batch=0.39s
15178/10943 (epoch 124.825) train_loss=124.47525787 time/batch=0.81s
15179/10943 (epoch 124.834) train_loss=99.16865540 time/batch=0.71s
15180/10943 (epoch 124.842) train_loss=119.45998383 time/batch=0.85s
15181/10943 (epoch 124.850) train_loss=114.78356934 time/batch=0.83s
15182/10943 (epoch 124.858) train_loss=203.74102783 time/batch=1.14s
15183/10943 (epoch 124.867) train_loss=55.91831207 time/batch=0.36s
15184/10943 (epoch 124.875) train_loss=66.39949036 time/batch=0.42s
15185/10943 (epoch 124.883) train_loss=106.47361755 time/batch=0.72s
15186/10943 (epoch 124.891) train_loss=50.36859131 time/batch=0.33s
15187/10943 (epoch 124.900) train_loss=78.03086853 time/batch=0.59s
15188/10943 (epoch 124.908) train_loss=61.30695343 time/batch=0.46s
15189/10943 (epoch 124.916) train_loss=197.17242432 time/batch=1.05s
15190/10943 (epoch 124.924) train_loss=214.80786133 time/batch=1.22s
15191/10943 (epoch 124.932) train_loss=178.58465576 time/batch=1.03s
15192/10943 (epoch 124.941) train_loss=118.56641388 time/batch=0.79s
15193/10943 (epoch 124.949) train_loss=103.47923279 time/batch=0.79s
15194/10943 (epoch 124.957) train_loss=331.99093628 time/batch=3.09s
15195/10943 (epoch 124.965) train_loss=122.02484131 time/batch=1.05s
15196/10943 (epoch 124.974) train_loss=123.96170044 time/batch=0.81s
15197/10943 (epoch 124.982) train_loss=56.49923325 time/batch=0.36s
15198/10943 (epoch 124.990) train_loss=181.45071411 time/batch=0.98s
15199/10943 (epoch 124.998) train_loss=47.76488876 time/batch=0.36s
15200/10943 (epoch 125.006) train_loss=109.78036499 time/batch=0.71s
15201/10943 (epoch 125.015) train_loss=120.79343414 time/batch=0.76s
15202/10943 (epoch 125.023) train_loss=207.81701660 time/batch=1.22s
15203/10943 (epoch 125.031) train_loss=251.45880127 time/batch=1.32s
15204/10943 (epoch 125.039) train_loss=75.05291748 time/batch=0.62s
15205/10943 (epoch 125.048) train_loss=100.93923187 time/batch=0.63s
15206/10943 (epoch 125.056) train_loss=64.94179535 time/batch=0.44s
15207/10943 (epoch 125.064) train_loss=113.73107910 time/batch=0.68s
15208/10943 (epoch 125.072) train_loss=145.79364014 time/batch=0.92s
15209/10943 (epoch 125.080) train_loss=95.00954437 time/batch=0.66s
15210/10943 (epoch 125.089) train_loss=160.33316040 time/batch=0.95s
15211/10943 (epoch 125.097) train_loss=118.48883057 time/batch=0.81s
15212/10943 (epoch 125.105) train_loss=131.35511780 time/batch=0.87s
15213/10943 (epoch 125.113) train_loss=67.46332550 time/batch=0.44s
15214/10943 (epoch 125.122) train_loss=100.75273132 time/batch=0.64s
15215/10943 (epoch 125.130) train_loss=208.40603638 time/batch=1.27s
15216/10943 (epoch 125.138) train_loss=128.91345215 time/batch=0.91s
15217/10943 (epoch 125.146) train_loss=66.36985779 time/batch=0.46s
15218/10943 (epoch 125.154) train_loss=86.15153503 time/batch=0.56s
15219/10943 (epoch 125.163) train_loss=162.10527039 time/batch=0.93s
15220/10943 (epoch 125.171) train_loss=57.80842590 time/batch=0.39s
15221/10943 (epoch 125.179) train_loss=131.79180908 time/batch=0.83s
15222/10943 (epoch 125.187) train_loss=142.12197876 time/batch=0.89s
15223/10943 (epoch 125.196) train_loss=63.32798004 time/batch=0.40s
15224/10943 (epoch 125.204) train_loss=171.54197693 time/batch=0.99s
15225/10943 (epoch 125.212) train_loss=92.57136536 time/batch=0.65s
15226/10943 (epoch 125.220) train_loss=105.56907654 time/batch=0.66s
15227/10943 (epoch 125.228) train_loss=110.90489197 time/batch=0.79s
15228/10943 (epoch 125.237) train_loss=88.34024811 time/batch=0.56s
15229/10943 (epoch 125.245) train_loss=78.34443665 time/batch=0.52s
15230/10943 (epoch 125.253) train_loss=156.92678833 time/batch=0.93s
15231/10943 (epoch 125.261) train_loss=108.37123108 time/batch=0.71s
15232/10943 (epoch 125.270) train_loss=87.95475769 time/batch=0.58s
15233/10943 (epoch 125.278) train_loss=94.10974121 time/batch=0.61s
15234/10943 (epoch 125.286) train_loss=111.03218079 time/batch=0.78s
15235/10943 (epoch 125.294) train_loss=54.99594116 time/batch=0.38s
15236/10943 (epoch 125.302) train_loss=83.50933075 time/batch=0.55s
15237/10943 (epoch 125.311) train_loss=99.56877899 time/batch=0.69s
15238/10943 (epoch 125.319) train_loss=75.55048370 time/batch=0.50s
15239/10943 (epoch 125.327) train_loss=135.64552307 time/batch=0.80s
15240/10943 (epoch 125.335) train_loss=117.53764343 time/batch=0.74s
15241/10943 (epoch 125.344) train_loss=126.47113037 time/batch=0.82s
15242/10943 (epoch 125.352) train_loss=89.11645508 time/batch=0.60s
15243/10943 (epoch 125.360) train_loss=116.32347107 time/batch=0.77s
15244/10943 (epoch 125.368) train_loss=104.18065643 time/batch=0.67s
15245/10943 (epoch 125.377) train_loss=107.08921814 time/batch=0.68s
15246/10943 (epoch 125.385) train_loss=160.05413818 time/batch=0.88s
15247/10943 (epoch 125.393) train_loss=64.08326721 time/batch=0.44s
15248/10943 (epoch 125.401) train_loss=131.17364502 time/batch=0.79s
15249/10943 (epoch 125.409) train_loss=71.77888489 time/batch=0.53s
15250/10943 (epoch 125.418) train_loss=68.00366974 time/batch=0.37s
15251/10943 (epoch 125.426) train_loss=88.47529602 time/batch=0.52s
15252/10943 (epoch 125.434) train_loss=141.78633118 time/batch=0.89s
15253/10943 (epoch 125.442) train_loss=133.49681091 time/batch=0.88s
15254/10943 (epoch 125.451) train_loss=165.39376831 time/batch=0.97s
15255/10943 (epoch 125.459) train_loss=94.73519897 time/batch=0.60s
15256/10943 (epoch 125.467) train_loss=80.66939545 time/batch=0.46s
15257/10943 (epoch 125.475) train_loss=62.08154678 time/batch=0.43s
15258/10943 (epoch 125.483) train_loss=76.24011993 time/batch=0.45s
15259/10943 (epoch 125.492) train_loss=82.64697266 time/batch=0.54s
15260/10943 (epoch 125.500) train_loss=136.23083496 time/batch=0.87s
15261/10943 (epoch 125.508) train_loss=119.74665833 time/batch=0.80s
15262/10943 (epoch 125.516) train_loss=78.70438385 time/batch=0.52s
15263/10943 (epoch 125.525) train_loss=162.26683044 time/batch=0.95s
15264/10943 (epoch 125.533) train_loss=114.58289337 time/batch=0.70s
15265/10943 (epoch 125.541) train_loss=83.14982605 time/batch=0.52s
15266/10943 (epoch 125.549) train_loss=93.63279724 time/batch=0.61s
15267/10943 (epoch 125.557) train_loss=71.95019531 time/batch=0.47s
15268/10943 (epoch 125.566) train_loss=87.89733887 time/batch=0.53s
15269/10943 (epoch 125.574) train_loss=117.41539001 time/batch=0.78s
15270/10943 (epoch 125.582) train_loss=97.97280884 time/batch=0.66s
15271/10943 (epoch 125.590) train_loss=123.53210449 time/batch=0.80s
15272/10943 (epoch 125.599) train_loss=115.44331360 time/batch=0.80s
15273/10943 (epoch 125.607) train_loss=89.62592316 time/batch=0.54s
15274/10943 (epoch 125.615) train_loss=92.16296387 time/batch=0.58s
15275/10943 (epoch 125.623) train_loss=89.10261536 time/batch=0.58s
15276/10943 (epoch 125.631) train_loss=107.11703491 time/batch=0.69s
15277/10943 (epoch 125.640) train_loss=99.23509979 time/batch=0.64s
15278/10943 (epoch 125.648) train_loss=93.27288055 time/batch=0.59s
15279/10943 (epoch 125.656) train_loss=80.13890076 time/batch=0.49s
15280/10943 (epoch 125.664) train_loss=93.04811859 time/batch=0.59s
15281/10943 (epoch 125.673) train_loss=80.67561340 time/batch=0.63s
15282/10943 (epoch 125.681) train_loss=111.58811951 time/batch=0.69s
setting learning rate to 0.0004679
  saved to metadata/gru_no_dropout-9_nov_folkwiki-20181207-192453_epoch81.pkl
15283/10943 (epoch 125.689) train_loss=123.42205811 time/batch=0.88s
15284/10943 (epoch 125.697) train_loss=240.66906738 time/batch=1.34s
15285/10943 (epoch 125.705) train_loss=529.20343018 time/batch=3.13s
15286/10943 (epoch 125.714) train_loss=262.37927246 time/batch=1.44s
15287/10943 (epoch 125.722) train_loss=322.21533203 time/batch=1.63s
15288/10943 (epoch 125.730) train_loss=240.68377686 time/batch=1.31s
15289/10943 (epoch 125.738) train_loss=139.62417603 time/batch=0.96s
15290/10943 (epoch 125.747) train_loss=114.83403015 time/batch=0.78s
15291/10943 (epoch 125.755) train_loss=205.59855652 time/batch=1.13s
15292/10943 (epoch 125.763) train_loss=170.72723389 time/batch=1.01s
15293/10943 (epoch 125.771) train_loss=77.40623474 time/batch=0.60s
15294/10943 (epoch 125.779) train_loss=56.43921280 time/batch=0.35s
15295/10943 (epoch 125.788) train_loss=79.83146667 time/batch=0.52s
15296/10943 (epoch 125.796) train_loss=61.60591507 time/batch=0.43s
15297/10943 (epoch 125.804) train_loss=304.28863525 time/batch=1.63s
15298/10943 (epoch 125.812) train_loss=120.70182037 time/batch=0.87s
15299/10943 (epoch 125.821) train_loss=84.69103241 time/batch=0.61s
15300/10943 (epoch 125.829) train_loss=197.51461792 time/batch=1.10s
15301/10943 (epoch 125.837) train_loss=165.98648071 time/batch=1.04s
15302/10943 (epoch 125.845) train_loss=112.94264221 time/batch=0.79s
15303/10943 (epoch 125.854) train_loss=242.93710327 time/batch=1.26s
15304/10943 (epoch 125.862) train_loss=110.33247375 time/batch=0.79s
15305/10943 (epoch 125.870) train_loss=69.99140930 time/batch=0.48s
15306/10943 (epoch 125.878) train_loss=247.13848877 time/batch=1.38s
15307/10943 (epoch 125.886) train_loss=107.93269348 time/batch=0.81s
15308/10943 (epoch 125.895) train_loss=52.97327042 time/batch=0.34s
15309/10943 (epoch 125.903) train_loss=59.37539673 time/batch=0.40s
15310/10943 (epoch 125.911) train_loss=136.20970154 time/batch=0.84s
15311/10943 (epoch 125.919) train_loss=72.54340363 time/batch=0.51s
15312/10943 (epoch 125.928) train_loss=92.10818481 time/batch=0.62s
15313/10943 (epoch 125.936) train_loss=138.52145386 time/batch=0.92s
15314/10943 (epoch 125.944) train_loss=145.70202637 time/batch=0.92s
15315/10943 (epoch 125.952) train_loss=116.83261108 time/batch=0.76s
15316/10943 (epoch 125.960) train_loss=156.32574463 time/batch=0.96s
15317/10943 (epoch 125.969) train_loss=191.79586792 time/batch=1.09s
15318/10943 (epoch 125.977) train_loss=71.72636414 time/batch=0.52s
15319/10943 (epoch 125.985) train_loss=61.59662628 time/batch=0.37s
15320/10943 (epoch 125.993) train_loss=89.71228027 time/batch=0.58s
15321/10943 (epoch 126.002) train_loss=98.13679504 time/batch=0.66s
15322/10943 (epoch 126.010) train_loss=78.68502808 time/batch=0.55s
15323/10943 (epoch 126.018) train_loss=67.76312256 time/batch=0.43s
15324/10943 (epoch 126.026) train_loss=86.29811859 time/batch=0.61s
15325/10943 (epoch 126.034) train_loss=185.24609375 time/batch=0.99s
15326/10943 (epoch 126.043) train_loss=159.69210815 time/batch=0.99s
15327/10943 (epoch 126.051) train_loss=113.76716614 time/batch=0.79s
15328/10943 (epoch 126.059) train_loss=88.86080933 time/batch=0.59s
15329/10943 (epoch 126.067) train_loss=83.97902679 time/batch=0.62s
15330/10943 (epoch 126.076) train_loss=205.69783020 time/batch=1.13s
15331/10943 (epoch 126.084) train_loss=87.54933167 time/batch=0.65s
15332/10943 (epoch 126.092) train_loss=53.99110413 time/batch=0.32s
15333/10943 (epoch 126.100) train_loss=52.65488815 time/batch=0.33s
15334/10943 (epoch 126.108) train_loss=160.94503784 time/batch=0.93s
15335/10943 (epoch 126.117) train_loss=106.98371887 time/batch=0.71s
15336/10943 (epoch 126.125) train_loss=76.30003357 time/batch=0.54s
15337/10943 (epoch 126.133) train_loss=89.42449951 time/batch=0.60s
15338/10943 (epoch 126.141) train_loss=61.62495422 time/batch=0.36s
15339/10943 (epoch 126.150) train_loss=71.57635498 time/batch=0.46s
15340/10943 (epoch 126.158) train_loss=61.88016510 time/batch=0.38s
15341/10943 (epoch 126.166) train_loss=111.68231201 time/batch=0.77s
15342/10943 (epoch 126.174) train_loss=85.14782715 time/batch=0.62s
15343/10943 (epoch 126.182) train_loss=212.31480408 time/batch=1.13s
15344/10943 (epoch 126.191) train_loss=137.56137085 time/batch=0.90s
15345/10943 (epoch 126.199) train_loss=224.85339355 time/batch=1.43s
15346/10943 (epoch 126.207) train_loss=147.77883911 time/batch=0.90s
15347/10943 (epoch 126.215) train_loss=76.58569336 time/batch=0.47s
15348/10943 (epoch 126.224) train_loss=113.33232117 time/batch=0.76s
15349/10943 (epoch 126.232) train_loss=55.61791611 time/batch=0.32s
15350/10943 (epoch 126.240) train_loss=85.58358002 time/batch=0.53s
15351/10943 (epoch 126.248) train_loss=104.65971375 time/batch=0.76s
15352/10943 (epoch 126.256) train_loss=160.57974243 time/batch=0.94s
15353/10943 (epoch 126.265) train_loss=116.65425110 time/batch=0.79s
15354/10943 (epoch 126.273) train_loss=121.78008270 time/batch=0.74s
15355/10943 (epoch 126.281) train_loss=111.51171875 time/batch=0.71s
15356/10943 (epoch 126.289) train_loss=134.28538513 time/batch=0.87s
15357/10943 (epoch 126.298) train_loss=180.21781921 time/batch=1.04s
15358/10943 (epoch 126.306) train_loss=92.62466431 time/batch=0.62s
15359/10943 (epoch 126.314) train_loss=58.10760117 time/batch=0.36s
15360/10943 (epoch 126.322) train_loss=79.88591003 time/batch=0.50s
15361/10943 (epoch 126.331) train_loss=146.33468628 time/batch=1.00s
15362/10943 (epoch 126.339) train_loss=93.45976257 time/batch=0.60s
15363/10943 (epoch 126.347) train_loss=120.60338593 time/batch=0.74s
15364/10943 (epoch 126.355) train_loss=48.53259659 time/batch=0.32s
15365/10943 (epoch 126.363) train_loss=144.20188904 time/batch=0.84s
15366/10943 (epoch 126.372) train_loss=132.69049072 time/batch=0.86s
15367/10943 (epoch 126.380) train_loss=88.70393372 time/batch=0.60s
15368/10943 (epoch 126.388) train_loss=95.69232178 time/batch=0.63s
15369/10943 (epoch 126.396) train_loss=115.18412018 time/batch=0.77s
15370/10943 (epoch 126.405) train_loss=70.23287964 time/batch=0.47s
15371/10943 (epoch 126.413) train_loss=85.68387604 time/batch=0.56s
15372/10943 (epoch 126.421) train_loss=126.34422302 time/batch=0.82s
15373/10943 (epoch 126.429) train_loss=106.81756592 time/batch=0.69s
15374/10943 (epoch 126.437) train_loss=57.93265152 time/batch=0.37s
15375/10943 (epoch 126.446) train_loss=74.35864258 time/batch=0.46s
15376/10943 (epoch 126.454) train_loss=124.53929138 time/batch=0.79s
15377/10943 (epoch 126.462) train_loss=132.34396362 time/batch=0.87s
15378/10943 (epoch 126.470) train_loss=121.77128601 time/batch=0.81s
15379/10943 (epoch 126.479) train_loss=85.33064270 time/batch=0.52s
15380/10943 (epoch 126.487) train_loss=97.52468872 time/batch=0.60s
15381/10943 (epoch 126.495) train_loss=99.08924103 time/batch=0.68s
15382/10943 (epoch 126.503) train_loss=68.61330414 time/batch=0.42s
15383/10943 (epoch 126.511) train_loss=90.78840637 time/batch=0.56s
15384/10943 (epoch 126.520) train_loss=126.06917572 time/batch=0.85s
15385/10943 (epoch 126.528) train_loss=117.95629883 time/batch=0.83s
15386/10943 (epoch 126.536) train_loss=121.84422302 time/batch=0.72s
15387/10943 (epoch 126.544) train_loss=122.90275574 time/batch=0.77s
15388/10943 (epoch 126.553) train_loss=115.08831787 time/batch=0.66s
15389/10943 (epoch 126.561) train_loss=104.76470947 time/batch=0.67s
15390/10943 (epoch 126.569) train_loss=75.95782471 time/batch=0.47s
15391/10943 (epoch 126.577) train_loss=102.55812073 time/batch=0.61s
15392/10943 (epoch 126.585) train_loss=107.23212433 time/batch=0.64s
15393/10943 (epoch 126.594) train_loss=81.77892303 time/batch=0.51s
15394/10943 (epoch 126.602) train_loss=62.95085526 time/batch=0.36s
15395/10943 (epoch 126.610) train_loss=67.03117371 time/batch=0.44s
15396/10943 (epoch 126.618) train_loss=124.51138306 time/batch=0.77s
15397/10943 (epoch 126.627) train_loss=131.14578247 time/batch=0.83s
15398/10943 (epoch 126.635) train_loss=77.63418579 time/batch=0.52s
15399/10943 (epoch 126.643) train_loss=76.11704254 time/batch=0.56s
15400/10943 (epoch 126.651) train_loss=111.39411163 time/batch=0.68s
15401/10943 (epoch 126.659) train_loss=114.73593140 time/batch=0.68s
15402/10943 (epoch 126.668) train_loss=86.58674622 time/batch=0.62s
15403/10943 (epoch 126.676) train_loss=99.73797607 time/batch=0.66s
setting learning rate to 0.0004539
15404/10943 (epoch 126.684) train_loss=139.54202271 time/batch=0.90s
15405/10943 (epoch 126.692) train_loss=242.83361816 time/batch=1.39s
15406/10943 (epoch 126.701) train_loss=260.78787231 time/batch=1.46s
15407/10943 (epoch 126.709) train_loss=163.47531128 time/batch=0.95s
15408/10943 (epoch 126.717) train_loss=100.92050171 time/batch=0.72s
15409/10943 (epoch 126.725) train_loss=85.78330994 time/batch=0.56s
15410/10943 (epoch 126.733) train_loss=97.64674377 time/batch=0.65s
15411/10943 (epoch 126.742) train_loss=111.87600708 time/batch=0.81s
15412/10943 (epoch 126.750) train_loss=72.36851501 time/batch=0.49s
15413/10943 (epoch 126.758) train_loss=57.87710571 time/batch=0.34s
15414/10943 (epoch 126.766) train_loss=330.28897095 time/batch=1.60s
15415/10943 (epoch 126.775) train_loss=462.58386230 time/batch=2.47s
15416/10943 (epoch 126.783) train_loss=99.52644348 time/batch=0.81s
15417/10943 (epoch 126.791) train_loss=197.93069458 time/batch=1.05s
15418/10943 (epoch 126.799) train_loss=158.67468262 time/batch=0.93s
15419/10943 (epoch 126.808) train_loss=338.13928223 time/batch=3.09s
15420/10943 (epoch 126.816) train_loss=188.77865601 time/batch=1.25s
15421/10943 (epoch 126.824) train_loss=66.63774109 time/batch=0.47s
15422/10943 (epoch 126.832) train_loss=213.92602539 time/batch=1.05s
15423/10943 (epoch 126.840) train_loss=166.73173523 time/batch=0.99s
15424/10943 (epoch 126.849) train_loss=131.95152283 time/batch=0.92s
15425/10943 (epoch 126.857) train_loss=97.05993652 time/batch=0.69s
15426/10943 (epoch 126.865) train_loss=114.54045105 time/batch=0.84s
15427/10943 (epoch 126.873) train_loss=162.34503174 time/batch=0.98s
15428/10943 (epoch 126.882) train_loss=203.35986328 time/batch=1.14s
15429/10943 (epoch 126.890) train_loss=108.57675171 time/batch=0.84s
15430/10943 (epoch 126.898) train_loss=180.45089722 time/batch=1.04s
15431/10943 (epoch 126.906) train_loss=221.25183105 time/batch=1.21s
15432/10943 (epoch 126.914) train_loss=112.62214661 time/batch=0.86s
15433/10943 (epoch 126.923) train_loss=86.38007355 time/batch=0.63s
15434/10943 (epoch 126.931) train_loss=51.04322815 time/batch=0.33s
15435/10943 (epoch 126.939) train_loss=56.37500000 time/batch=0.33s
15436/10943 (epoch 126.947) train_loss=246.51873779 time/batch=1.37s
15437/10943 (epoch 126.956) train_loss=125.00899506 time/batch=0.91s
15438/10943 (epoch 126.964) train_loss=234.46640015 time/batch=1.22s
15439/10943 (epoch 126.972) train_loss=118.01914978 time/batch=0.80s
15440/10943 (epoch 126.980) train_loss=85.22816467 time/batch=0.56s
15441/10943 (epoch 126.988) train_loss=209.39079285 time/batch=1.20s
15442/10943 (epoch 126.997) train_loss=206.93168640 time/batch=1.48s
15443/10943 (epoch 127.005) train_loss=80.65559387 time/batch=0.61s
15444/10943 (epoch 127.013) train_loss=76.36727905 time/batch=0.51s
15445/10943 (epoch 127.021) train_loss=93.51298523 time/batch=0.66s
15446/10943 (epoch 127.030) train_loss=181.83436584 time/batch=1.10s
15447/10943 (epoch 127.038) train_loss=66.25205994 time/batch=0.45s
15448/10943 (epoch 127.046) train_loss=54.03126526 time/batch=0.30s
15449/10943 (epoch 127.054) train_loss=117.21149445 time/batch=0.74s
15450/10943 (epoch 127.062) train_loss=95.34664917 time/batch=0.67s
15451/10943 (epoch 127.071) train_loss=106.20762634 time/batch=0.70s
15452/10943 (epoch 127.079) train_loss=152.54656982 time/batch=0.94s
15453/10943 (epoch 127.087) train_loss=129.40174866 time/batch=0.88s
15454/10943 (epoch 127.095) train_loss=118.94721985 time/batch=0.74s
15455/10943 (epoch 127.104) train_loss=99.76130676 time/batch=0.66s
15456/10943 (epoch 127.112) train_loss=108.06700134 time/batch=0.70s
15457/10943 (epoch 127.120) train_loss=70.33621979 time/batch=0.49s
15458/10943 (epoch 127.128) train_loss=45.90400696 time/batch=0.26s
15459/10943 (epoch 127.136) train_loss=97.08399200 time/batch=0.62s
15460/10943 (epoch 127.145) train_loss=57.29485321 time/batch=0.38s
15461/10943 (epoch 127.153) train_loss=66.22468567 time/batch=0.45s
15462/10943 (epoch 127.161) train_loss=59.23566437 time/batch=0.37s
15463/10943 (epoch 127.169) train_loss=117.16601562 time/batch=0.76s
15464/10943 (epoch 127.178) train_loss=53.00016022 time/batch=0.32s
15465/10943 (epoch 127.186) train_loss=184.83837891 time/batch=0.97s
15466/10943 (epoch 127.194) train_loss=144.60607910 time/batch=0.87s
15467/10943 (epoch 127.202) train_loss=128.96157837 time/batch=0.76s
15468/10943 (epoch 127.210) train_loss=104.83741760 time/batch=0.71s
15469/10943 (epoch 127.219) train_loss=76.94464111 time/batch=0.49s
15470/10943 (epoch 127.227) train_loss=78.25667572 time/batch=0.48s
15471/10943 (epoch 127.235) train_loss=66.96691132 time/batch=0.42s
15472/10943 (epoch 127.243) train_loss=59.99507904 time/batch=0.37s
15473/10943 (epoch 127.252) train_loss=77.98323822 time/batch=0.50s
15474/10943 (epoch 127.260) train_loss=98.79060364 time/batch=0.65s
15475/10943 (epoch 127.268) train_loss=163.80210876 time/batch=1.03s
15476/10943 (epoch 127.276) train_loss=101.04241943 time/batch=0.66s
15477/10943 (epoch 127.285) train_loss=77.83630371 time/batch=0.49s
15478/10943 (epoch 127.293) train_loss=141.38543701 time/batch=0.90s
15479/10943 (epoch 127.301) train_loss=114.89281464 time/batch=0.81s
15480/10943 (epoch 127.309) train_loss=71.14947510 time/batch=0.46s
15481/10943 (epoch 127.317) train_loss=85.45246887 time/batch=0.54s
15482/10943 (epoch 127.326) train_loss=127.50368500 time/batch=0.84s
15483/10943 (epoch 127.334) train_loss=69.61954498 time/batch=0.44s
15484/10943 (epoch 127.342) train_loss=87.41587830 time/batch=0.56s
15485/10943 (epoch 127.350) train_loss=120.39318848 time/batch=0.70s
15486/10943 (epoch 127.359) train_loss=102.76782227 time/batch=0.69s
15487/10943 (epoch 127.367) train_loss=101.50883484 time/batch=0.62s
15488/10943 (epoch 127.375) train_loss=70.72131348 time/batch=0.49s
15489/10943 (epoch 127.383) train_loss=71.64012146 time/batch=0.48s
15490/10943 (epoch 127.391) train_loss=58.18515778 time/batch=0.32s
15491/10943 (epoch 127.400) train_loss=129.00292969 time/batch=0.82s
15492/10943 (epoch 127.408) train_loss=85.01217651 time/batch=0.57s
15493/10943 (epoch 127.416) train_loss=80.07214355 time/batch=0.52s
15494/10943 (epoch 127.424) train_loss=70.53103638 time/batch=0.48s
15495/10943 (epoch 127.433) train_loss=87.57958984 time/batch=0.55s
15496/10943 (epoch 127.441) train_loss=123.36763000 time/batch=0.81s
15497/10943 (epoch 127.449) train_loss=83.60473633 time/batch=0.59s
15498/10943 (epoch 127.457) train_loss=158.14785767 time/batch=0.94s
15499/10943 (epoch 127.465) train_loss=96.58971405 time/batch=0.67s
15500/10943 (epoch 127.474) train_loss=66.56817627 time/batch=0.49s
15501/10943 (epoch 127.482) train_loss=94.61761475 time/batch=0.60s
15502/10943 (epoch 127.490) train_loss=91.73430634 time/batch=0.58s
15503/10943 (epoch 127.498) train_loss=125.99792480 time/batch=0.80s
15504/10943 (epoch 127.507) train_loss=126.39786530 time/batch=0.78s
15505/10943 (epoch 127.515) train_loss=119.22418213 time/batch=0.73s
15506/10943 (epoch 127.523) train_loss=109.99542236 time/batch=0.76s
15507/10943 (epoch 127.531) train_loss=119.09900665 time/batch=0.73s
15508/10943 (epoch 127.539) train_loss=91.22698212 time/batch=0.60s
15509/10943 (epoch 127.548) train_loss=94.14962769 time/batch=0.59s
15510/10943 (epoch 127.556) train_loss=150.02619934 time/batch=0.95s
15511/10943 (epoch 127.564) train_loss=157.02972412 time/batch=1.01s
15512/10943 (epoch 127.572) train_loss=61.58506775 time/batch=0.41s
15513/10943 (epoch 127.581) train_loss=121.28722382 time/batch=0.74s
15514/10943 (epoch 127.589) train_loss=124.34873962 time/batch=0.77s
15515/10943 (epoch 127.597) train_loss=94.74461365 time/batch=0.59s
15516/10943 (epoch 127.605) train_loss=92.70789337 time/batch=0.59s
15517/10943 (epoch 127.613) train_loss=74.30168152 time/batch=0.50s
15518/10943 (epoch 127.622) train_loss=120.90211487 time/batch=0.70s
15519/10943 (epoch 127.630) train_loss=90.51366425 time/batch=0.62s
15520/10943 (epoch 127.638) train_loss=86.95498657 time/batch=0.61s
15521/10943 (epoch 127.646) train_loss=114.68780518 time/batch=0.78s
15522/10943 (epoch 127.655) train_loss=101.24153137 time/batch=0.66s
15523/10943 (epoch 127.663) train_loss=84.53495789 time/batch=0.76s
15524/10943 (epoch 127.671) train_loss=101.13655090 time/batch=0.79s
setting learning rate to 0.0004403
  saved to metadata/gru_no_dropout-9_nov_folkwiki-20181207-192453_epoch83.pkl
15525/10943 (epoch 127.679) train_loss=64.17484283 time/batch=0.51s
15526/10943 (epoch 127.687) train_loss=206.93121338 time/batch=1.14s
15527/10943 (epoch 127.696) train_loss=104.60806274 time/batch=0.74s
15528/10943 (epoch 127.704) train_loss=53.61993790 time/batch=0.35s
15529/10943 (epoch 127.712) train_loss=81.66324615 time/batch=0.56s
15530/10943 (epoch 127.720) train_loss=247.95523071 time/batch=1.32s
15531/10943 (epoch 127.729) train_loss=308.73706055 time/batch=1.51s
15532/10943 (epoch 127.737) train_loss=191.52085876 time/batch=1.07s
15533/10943 (epoch 127.745) train_loss=501.84063721 time/batch=3.10s
15534/10943 (epoch 127.753) train_loss=121.42883301 time/batch=0.95s
15535/10943 (epoch 127.762) train_loss=274.93478394 time/batch=1.50s
15536/10943 (epoch 127.770) train_loss=112.82633972 time/batch=0.76s
15537/10943 (epoch 127.778) train_loss=105.66237640 time/batch=0.69s
15538/10943 (epoch 127.786) train_loss=182.83737183 time/batch=1.00s
15539/10943 (epoch 127.794) train_loss=213.88652039 time/batch=1.21s
15540/10943 (epoch 127.803) train_loss=74.87409973 time/batch=0.68s
15541/10943 (epoch 127.811) train_loss=245.64477539 time/batch=1.31s
15542/10943 (epoch 127.819) train_loss=110.37734985 time/batch=0.80s
15543/10943 (epoch 127.827) train_loss=146.37042236 time/batch=0.89s
15544/10943 (epoch 127.836) train_loss=204.70001221 time/batch=1.12s
15545/10943 (epoch 127.844) train_loss=200.74511719 time/batch=1.17s
15546/10943 (epoch 127.852) train_loss=114.34124756 time/batch=0.77s
15547/10943 (epoch 127.860) train_loss=74.55374146 time/batch=0.52s
15548/10943 (epoch 127.868) train_loss=176.68029785 time/batch=0.98s
15549/10943 (epoch 127.877) train_loss=113.20872498 time/batch=0.83s
15550/10943 (epoch 127.885) train_loss=164.07064819 time/batch=0.96s
15551/10943 (epoch 127.893) train_loss=55.94537735 time/batch=0.36s
15552/10943 (epoch 127.901) train_loss=45.61640167 time/batch=0.25s
15553/10943 (epoch 127.910) train_loss=121.64603424 time/batch=0.77s
15554/10943 (epoch 127.918) train_loss=99.67356873 time/batch=0.69s
15555/10943 (epoch 127.926) train_loss=72.69482422 time/batch=0.49s
15556/10943 (epoch 127.934) train_loss=112.85031128 time/batch=0.72s
15557/10943 (epoch 127.942) train_loss=132.78250122 time/batch=0.91s
15558/10943 (epoch 127.951) train_loss=125.23506165 time/batch=0.85s
15559/10943 (epoch 127.959) train_loss=52.64747620 time/batch=0.35s
15560/10943 (epoch 127.967) train_loss=326.26635742 time/batch=1.62s
15561/10943 (epoch 127.975) train_loss=123.14215088 time/batch=0.88s
15562/10943 (epoch 127.984) train_loss=210.48080444 time/batch=1.19s
15563/10943 (epoch 127.992) train_loss=93.34295654 time/batch=0.68s
15564/10943 (epoch 128.000) train_loss=80.58181763 time/batch=0.57s
15565/10943 (epoch 128.008) train_loss=141.30473328 time/batch=0.86s
15566/10943 (epoch 128.016) train_loss=168.25518799 time/batch=1.06s
15567/10943 (epoch 128.025) train_loss=65.91236115 time/batch=0.44s
15568/10943 (epoch 128.033) train_loss=93.98675537 time/batch=0.64s
15569/10943 (epoch 128.041) train_loss=236.08888245 time/batch=1.52s
15570/10943 (epoch 128.049) train_loss=51.01888275 time/batch=0.43s
15571/10943 (epoch 128.058) train_loss=107.87519836 time/batch=0.70s
15572/10943 (epoch 128.066) train_loss=67.64668274 time/batch=0.46s
15573/10943 (epoch 128.074) train_loss=151.57817078 time/batch=0.90s
15574/10943 (epoch 128.082) train_loss=58.38658142 time/batch=0.38s
15575/10943 (epoch 128.090) train_loss=70.57520294 time/batch=0.45s
15576/10943 (epoch 128.099) train_loss=151.56587219 time/batch=0.94s
15577/10943 (epoch 128.107) train_loss=148.93263245 time/batch=0.96s
15578/10943 (epoch 128.115) train_loss=129.71147156 time/batch=0.86s
15579/10943 (epoch 128.123) train_loss=113.09651947 time/batch=0.79s
15580/10943 (epoch 128.132) train_loss=118.57707214 time/batch=0.82s
15581/10943 (epoch 128.140) train_loss=69.23327637 time/batch=0.47s
15582/10943 (epoch 128.148) train_loss=108.48771667 time/batch=0.62s
15583/10943 (epoch 128.156) train_loss=65.51031494 time/batch=0.46s
15584/10943 (epoch 128.164) train_loss=79.81677246 time/batch=0.49s
15585/10943 (epoch 128.173) train_loss=88.77708435 time/batch=0.61s
15586/10943 (epoch 128.181) train_loss=58.79344177 time/batch=0.39s
15587/10943 (epoch 128.189) train_loss=77.98543549 time/batch=0.49s
15588/10943 (epoch 128.197) train_loss=66.02182770 time/batch=0.45s
15589/10943 (epoch 128.206) train_loss=129.37194824 time/batch=0.83s
15590/10943 (epoch 128.214) train_loss=198.00283813 time/batch=1.55s
15591/10943 (epoch 128.222) train_loss=65.67803955 time/batch=0.48s
15592/10943 (epoch 128.230) train_loss=56.13790894 time/batch=0.31s
15593/10943 (epoch 128.238) train_loss=117.14196777 time/batch=0.69s
15594/10943 (epoch 128.247) train_loss=108.24440765 time/batch=0.71s
15595/10943 (epoch 128.255) train_loss=70.34668732 time/batch=0.43s
15596/10943 (epoch 128.263) train_loss=110.18479919 time/batch=0.68s
15597/10943 (epoch 128.271) train_loss=88.64714050 time/batch=0.60s
15598/10943 (epoch 128.280) train_loss=77.10023499 time/batch=0.46s
15599/10943 (epoch 128.288) train_loss=86.50210571 time/batch=0.55s
15600/10943 (epoch 128.296) train_loss=57.89769745 time/batch=0.36s
15601/10943 (epoch 128.304) train_loss=107.41755676 time/batch=0.75s
15602/10943 (epoch 128.313) train_loss=132.54013062 time/batch=0.85s
15603/10943 (epoch 128.321) train_loss=133.22836304 time/batch=0.88s
15604/10943 (epoch 128.329) train_loss=103.72737122 time/batch=0.71s
15605/10943 (epoch 128.337) train_loss=118.60504913 time/batch=0.76s
15606/10943 (epoch 128.345) train_loss=158.95135498 time/batch=0.96s
15607/10943 (epoch 128.354) train_loss=115.11106873 time/batch=0.82s
15608/10943 (epoch 128.362) train_loss=85.22756958 time/batch=0.59s
15609/10943 (epoch 128.370) train_loss=113.44139099 time/batch=0.74s
15610/10943 (epoch 128.378) train_loss=125.10491180 time/batch=0.85s
15611/10943 (epoch 128.387) train_loss=79.99288177 time/batch=0.57s
15612/10943 (epoch 128.395) train_loss=88.01316071 time/batch=0.58s
15613/10943 (epoch 128.403) train_loss=90.72163391 time/batch=0.57s
15614/10943 (epoch 128.411) train_loss=118.68018341 time/batch=0.83s
15615/10943 (epoch 128.419) train_loss=157.14955139 time/batch=0.98s
15616/10943 (epoch 128.428) train_loss=95.89928436 time/batch=0.58s
15617/10943 (epoch 128.436) train_loss=122.51483154 time/batch=0.79s
15618/10943 (epoch 128.444) train_loss=94.41365051 time/batch=0.62s
15619/10943 (epoch 128.452) train_loss=64.61975861 time/batch=0.38s
15620/10943 (epoch 128.461) train_loss=87.81298828 time/batch=0.54s
15621/10943 (epoch 128.469) train_loss=187.12695312 time/batch=1.03s
15622/10943 (epoch 128.477) train_loss=66.61840820 time/batch=0.45s
15623/10943 (epoch 128.485) train_loss=96.72379303 time/batch=0.60s
15624/10943 (epoch 128.493) train_loss=88.91615295 time/batch=0.60s
15625/10943 (epoch 128.502) train_loss=98.82969666 time/batch=0.64s
15626/10943 (epoch 128.510) train_loss=98.27627563 time/batch=0.61s
15627/10943 (epoch 128.518) train_loss=128.89822388 time/batch=0.83s
15628/10943 (epoch 128.526) train_loss=96.44686127 time/batch=0.64s
15629/10943 (epoch 128.535) train_loss=120.64150238 time/batch=0.70s
15630/10943 (epoch 128.543) train_loss=164.28886414 time/batch=0.98s
15631/10943 (epoch 128.551) train_loss=127.00621033 time/batch=0.88s
15632/10943 (epoch 128.559) train_loss=76.43412781 time/batch=0.55s
15633/10943 (epoch 128.567) train_loss=66.06209564 time/batch=0.44s
15634/10943 (epoch 128.576) train_loss=74.73938751 time/batch=0.46s
15635/10943 (epoch 128.584) train_loss=90.08754730 time/batch=0.61s
15636/10943 (epoch 128.592) train_loss=84.93499756 time/batch=0.53s
15637/10943 (epoch 128.600) train_loss=113.53301239 time/batch=0.76s
15638/10943 (epoch 128.609) train_loss=124.38447571 time/batch=0.77s
15639/10943 (epoch 128.617) train_loss=108.44291687 time/batch=0.66s
15640/10943 (epoch 128.625) train_loss=104.90893555 time/batch=0.78s
15641/10943 (epoch 128.633) train_loss=77.01593018 time/batch=0.51s
15642/10943 (epoch 128.641) train_loss=101.69154358 time/batch=0.62s
15643/10943 (epoch 128.650) train_loss=74.33677673 time/batch=0.53s
15644/10943 (epoch 128.658) train_loss=80.34786987 time/batch=0.58s
15645/10943 (epoch 128.666) train_loss=102.01672363 time/batch=0.68s
setting learning rate to 0.0004271
15646/10943 (epoch 128.674) train_loss=420.38024902 time/batch=2.34s
15647/10943 (epoch 128.683) train_loss=221.36856079 time/batch=1.26s
15648/10943 (epoch 128.691) train_loss=126.25086975 time/batch=0.89s
15649/10943 (epoch 128.699) train_loss=120.34693909 time/batch=0.83s
15650/10943 (epoch 128.707) train_loss=104.61734009 time/batch=0.68s
15651/10943 (epoch 128.715) train_loss=239.39833069 time/batch=1.25s
15652/10943 (epoch 128.724) train_loss=288.82595825 time/batch=1.60s
15653/10943 (epoch 128.732) train_loss=223.02574158 time/batch=1.28s
15654/10943 (epoch 128.740) train_loss=112.15991211 time/batch=0.81s
15655/10943 (epoch 128.748) train_loss=139.88769531 time/batch=0.89s
15656/10943 (epoch 128.757) train_loss=113.37916565 time/batch=0.83s
15657/10943 (epoch 128.765) train_loss=298.02960205 time/batch=1.61s
15658/10943 (epoch 128.773) train_loss=89.11240387 time/batch=0.72s
15659/10943 (epoch 128.781) train_loss=84.12965393 time/batch=0.59s
15660/10943 (epoch 128.790) train_loss=51.29845810 time/batch=0.30s
15661/10943 (epoch 128.798) train_loss=199.80793762 time/batch=1.05s
15662/10943 (epoch 128.806) train_loss=221.50961304 time/batch=1.26s
15663/10943 (epoch 128.814) train_loss=193.00839233 time/batch=1.13s
15664/10943 (epoch 128.822) train_loss=112.08235168 time/batch=0.75s
15665/10943 (epoch 128.831) train_loss=331.59783936 time/batch=3.07s
15666/10943 (epoch 128.839) train_loss=110.43419647 time/batch=0.95s
15667/10943 (epoch 128.847) train_loss=61.16876602 time/batch=0.36s
15668/10943 (epoch 128.855) train_loss=169.70568848 time/batch=0.99s
15669/10943 (epoch 128.864) train_loss=60.42524719 time/batch=0.42s
15670/10943 (epoch 128.872) train_loss=117.49057007 time/batch=0.78s
15671/10943 (epoch 128.880) train_loss=122.75611877 time/batch=0.87s
15672/10943 (epoch 128.888) train_loss=51.98318481 time/batch=0.40s
15673/10943 (epoch 128.896) train_loss=93.69772339 time/batch=0.62s
15674/10943 (epoch 128.905) train_loss=84.01953125 time/batch=0.61s
15675/10943 (epoch 128.913) train_loss=51.20402145 time/batch=0.32s
15676/10943 (epoch 128.921) train_loss=152.40414429 time/batch=0.93s
15677/10943 (epoch 128.929) train_loss=46.89289856 time/batch=0.35s
15678/10943 (epoch 128.938) train_loss=108.44948578 time/batch=0.72s
15679/10943 (epoch 128.946) train_loss=74.18673706 time/batch=0.54s
15680/10943 (epoch 128.954) train_loss=68.94879150 time/batch=0.44s
15681/10943 (epoch 128.962) train_loss=159.20330811 time/batch=0.90s
15682/10943 (epoch 128.970) train_loss=175.30574036 time/batch=1.03s
15683/10943 (epoch 128.979) train_loss=248.08724976 time/batch=1.34s
15684/10943 (epoch 128.987) train_loss=193.41024780 time/batch=1.06s
15685/10943 (epoch 128.995) train_loss=167.13838196 time/batch=0.96s
15686/10943 (epoch 129.003) train_loss=61.85221100 time/batch=0.45s
15687/10943 (epoch 129.012) train_loss=134.56970215 time/batch=0.79s
15688/10943 (epoch 129.020) train_loss=144.08905029 time/batch=0.89s
15689/10943 (epoch 129.028) train_loss=75.58721161 time/batch=0.51s
15690/10943 (epoch 129.036) train_loss=82.37347412 time/batch=0.56s
15691/10943 (epoch 129.044) train_loss=60.88092041 time/batch=0.39s
15692/10943 (epoch 129.053) train_loss=186.35339355 time/batch=1.04s
15693/10943 (epoch 129.061) train_loss=92.45915985 time/batch=0.65s
15694/10943 (epoch 129.069) train_loss=209.22303772 time/batch=1.12s
15695/10943 (epoch 129.077) train_loss=69.42740631 time/batch=0.49s
15696/10943 (epoch 129.086) train_loss=220.14352417 time/batch=1.30s
15697/10943 (epoch 129.094) train_loss=151.55285645 time/batch=1.00s
15698/10943 (epoch 129.102) train_loss=87.32058716 time/batch=0.61s
15699/10943 (epoch 129.110) train_loss=77.83934021 time/batch=0.56s
15700/10943 (epoch 129.118) train_loss=138.22828674 time/batch=0.88s
15701/10943 (epoch 129.127) train_loss=80.36802673 time/batch=0.65s
15702/10943 (epoch 129.135) train_loss=65.43473816 time/batch=0.41s
15703/10943 (epoch 129.143) train_loss=62.37347412 time/batch=0.47s
15704/10943 (epoch 129.151) train_loss=139.44400024 time/batch=0.89s
15705/10943 (epoch 129.160) train_loss=60.73007965 time/batch=0.41s
15706/10943 (epoch 129.168) train_loss=204.96395874 time/batch=1.06s
15707/10943 (epoch 129.176) train_loss=109.74122620 time/batch=0.83s
15708/10943 (epoch 129.184) train_loss=62.66093445 time/batch=0.46s
15709/10943 (epoch 129.192) train_loss=66.35423279 time/batch=0.44s
15710/10943 (epoch 129.201) train_loss=86.11124420 time/batch=0.52s
15711/10943 (epoch 129.209) train_loss=77.74140167 time/batch=0.50s
15712/10943 (epoch 129.217) train_loss=122.79052734 time/batch=0.75s
15713/10943 (epoch 129.225) train_loss=77.80621338 time/batch=0.55s
15714/10943 (epoch 129.234) train_loss=52.83980942 time/batch=0.32s
15715/10943 (epoch 129.242) train_loss=85.84152222 time/batch=0.54s
15716/10943 (epoch 129.250) train_loss=57.19795227 time/batch=0.33s
15717/10943 (epoch 129.258) train_loss=73.68403625 time/batch=0.44s
15718/10943 (epoch 129.267) train_loss=104.35561371 time/batch=0.66s
15719/10943 (epoch 129.275) train_loss=78.02183533 time/batch=0.51s
15720/10943 (epoch 129.283) train_loss=111.43449402 time/batch=0.76s
15721/10943 (epoch 129.291) train_loss=95.85781860 time/batch=0.64s
15722/10943 (epoch 129.299) train_loss=77.26278687 time/batch=0.49s
15723/10943 (epoch 129.308) train_loss=54.71427536 time/batch=0.36s
15724/10943 (epoch 129.316) train_loss=111.03237915 time/batch=0.63s
15725/10943 (epoch 129.324) train_loss=88.71904755 time/batch=0.63s
15726/10943 (epoch 129.332) train_loss=111.14154053 time/batch=0.71s
15727/10943 (epoch 129.341) train_loss=88.72312164 time/batch=0.61s
15728/10943 (epoch 129.349) train_loss=96.98922729 time/batch=0.63s
15729/10943 (epoch 129.357) train_loss=88.36866760 time/batch=0.56s
15730/10943 (epoch 129.365) train_loss=112.05067444 time/batch=0.68s
15731/10943 (epoch 129.373) train_loss=79.13846588 time/batch=0.56s
15732/10943 (epoch 129.382) train_loss=100.22563171 time/batch=0.66s
15733/10943 (epoch 129.390) train_loss=91.17230225 time/batch=0.62s
15734/10943 (epoch 129.398) train_loss=114.13366699 time/batch=0.70s
15735/10943 (epoch 129.406) train_loss=85.23421478 time/batch=0.53s
15736/10943 (epoch 129.415) train_loss=126.45906067 time/batch=0.81s
15737/10943 (epoch 129.423) train_loss=70.04598999 time/batch=0.47s
15738/10943 (epoch 129.431) train_loss=124.12906647 time/batch=0.71s
15739/10943 (epoch 129.439) train_loss=105.90238953 time/batch=0.65s
15740/10943 (epoch 129.447) train_loss=107.02949524 time/batch=0.63s
15741/10943 (epoch 129.456) train_loss=73.84916687 time/batch=0.45s
15742/10943 (epoch 129.464) train_loss=142.16464233 time/batch=0.86s
15743/10943 (epoch 129.472) train_loss=107.38417816 time/batch=0.72s
15744/10943 (epoch 129.480) train_loss=133.55955505 time/batch=0.92s
15745/10943 (epoch 129.489) train_loss=92.94408417 time/batch=0.62s
15746/10943 (epoch 129.497) train_loss=84.31571960 time/batch=0.51s
15747/10943 (epoch 129.505) train_loss=101.31214142 time/batch=0.60s
15748/10943 (epoch 129.513) train_loss=110.08865356 time/batch=0.75s
15749/10943 (epoch 129.521) train_loss=86.87471008 time/batch=0.65s
15750/10943 (epoch 129.530) train_loss=127.62662506 time/batch=0.73s
15751/10943 (epoch 129.538) train_loss=114.48851013 time/batch=0.79s
15752/10943 (epoch 129.546) train_loss=119.45776367 time/batch=0.74s
15753/10943 (epoch 129.554) train_loss=109.80204773 time/batch=0.71s
15754/10943 (epoch 129.563) train_loss=82.29397583 time/batch=0.54s
15755/10943 (epoch 129.571) train_loss=102.74157715 time/batch=0.67s
15756/10943 (epoch 129.579) train_loss=129.80198669 time/batch=0.85s
15757/10943 (epoch 129.587) train_loss=64.01284790 time/batch=0.44s
15758/10943 (epoch 129.595) train_loss=117.19951630 time/batch=0.69s
15759/10943 (epoch 129.604) train_loss=124.28102112 time/batch=0.81s
15760/10943 (epoch 129.612) train_loss=116.34870148 time/batch=0.81s
15761/10943 (epoch 129.620) train_loss=119.23489380 time/batch=0.79s
15762/10943 (epoch 129.628) train_loss=172.90548706 time/batch=0.96s
15763/10943 (epoch 129.637) train_loss=133.29003906 time/batch=0.82s
15764/10943 (epoch 129.645) train_loss=147.21533203 time/batch=0.99s
15765/10943 (epoch 129.653) train_loss=75.50140381 time/batch=0.58s
15766/10943 (epoch 129.661) train_loss=119.50963593 time/batch=0.77s
setting learning rate to 0.0004143
  saved to metadata/gru_no_dropout-9_nov_folkwiki-20181207-192453_epoch85.pkl
15767/10943 (epoch 129.669) train_loss=64.92662048 time/batch=0.54s
15768/10943 (epoch 129.678) train_loss=109.14794159 time/batch=0.73s
15769/10943 (epoch 129.686) train_loss=157.56317139 time/batch=0.94s
15770/10943 (epoch 129.694) train_loss=232.64596558 time/batch=1.24s
15771/10943 (epoch 129.702) train_loss=255.60598755 time/batch=1.42s
15772/10943 (epoch 129.711) train_loss=216.61976624 time/batch=1.24s
15773/10943 (epoch 129.719) train_loss=358.29241943 time/batch=1.82s
15774/10943 (epoch 129.727) train_loss=208.31277466 time/batch=1.19s
15775/10943 (epoch 129.735) train_loss=102.02590179 time/batch=0.81s
15776/10943 (epoch 129.744) train_loss=98.02499390 time/batch=0.65s
15777/10943 (epoch 129.752) train_loss=82.71865082 time/batch=0.59s
15778/10943 (epoch 129.760) train_loss=80.59281158 time/batch=0.58s
15779/10943 (epoch 129.768) train_loss=176.42202759 time/batch=1.00s
15780/10943 (epoch 129.776) train_loss=285.80871582 time/batch=1.57s
15781/10943 (epoch 129.785) train_loss=89.44628906 time/batch=0.72s
15782/10943 (epoch 129.793) train_loss=124.57378387 time/batch=0.84s
15783/10943 (epoch 129.801) train_loss=463.13897705 time/batch=3.06s
15784/10943 (epoch 129.809) train_loss=97.24449158 time/batch=0.86s
15785/10943 (epoch 129.818) train_loss=110.27568054 time/batch=0.65s
15786/10943 (epoch 129.826) train_loss=88.03130341 time/batch=0.59s
15787/10943 (epoch 129.834) train_loss=93.80982971 time/batch=0.63s
15788/10943 (epoch 129.842) train_loss=62.62801361 time/batch=0.42s
15789/10943 (epoch 129.850) train_loss=234.41076660 time/batch=1.27s
15790/10943 (epoch 129.859) train_loss=103.15861511 time/batch=0.74s
15791/10943 (epoch 129.867) train_loss=144.32341003 time/batch=0.88s
15792/10943 (epoch 129.875) train_loss=151.89288330 time/batch=0.96s
15793/10943 (epoch 129.883) train_loss=72.90180206 time/batch=0.52s
15794/10943 (epoch 129.892) train_loss=126.24285889 time/batch=0.80s
15795/10943 (epoch 129.900) train_loss=73.86624146 time/batch=0.58s
15796/10943 (epoch 129.908) train_loss=78.77944946 time/batch=0.50s
15797/10943 (epoch 129.916) train_loss=96.86189270 time/batch=0.72s
15798/10943 (epoch 129.924) train_loss=77.48823547 time/batch=0.59s
15799/10943 (epoch 129.933) train_loss=64.52250671 time/batch=0.41s
15800/10943 (epoch 129.941) train_loss=77.42008972 time/batch=0.53s
15801/10943 (epoch 129.949) train_loss=108.66677094 time/batch=0.79s
15802/10943 (epoch 129.957) train_loss=130.53404236 time/batch=0.93s
15803/10943 (epoch 129.966) train_loss=179.21849060 time/batch=1.00s
15804/10943 (epoch 129.974) train_loss=120.57478333 time/batch=0.84s
15805/10943 (epoch 129.982) train_loss=115.74604034 time/batch=0.86s
15806/10943 (epoch 129.990) train_loss=86.71903992 time/batch=0.61s
15807/10943 (epoch 129.998) train_loss=245.51809692 time/batch=1.40s
15808/10943 (epoch 130.007) train_loss=216.65176392 time/batch=1.16s
15809/10943 (epoch 130.015) train_loss=110.69799805 time/batch=0.83s
15810/10943 (epoch 130.023) train_loss=79.25244141 time/batch=0.54s
15811/10943 (epoch 130.031) train_loss=63.01292038 time/batch=0.41s
15812/10943 (epoch 130.040) train_loss=102.00569153 time/batch=0.68s
15813/10943 (epoch 130.048) train_loss=98.56159973 time/batch=0.80s
15814/10943 (epoch 130.056) train_loss=178.72398376 time/batch=1.03s
15815/10943 (epoch 130.064) train_loss=61.15192413 time/batch=0.42s
15816/10943 (epoch 130.072) train_loss=198.23834229 time/batch=1.06s
15817/10943 (epoch 130.081) train_loss=108.97105408 time/batch=0.71s
15818/10943 (epoch 130.089) train_loss=125.40773010 time/batch=0.86s
15819/10943 (epoch 130.097) train_loss=75.23898315 time/batch=0.54s
15820/10943 (epoch 130.105) train_loss=132.86845398 time/batch=0.86s
15821/10943 (epoch 130.114) train_loss=125.66307831 time/batch=0.85s
15822/10943 (epoch 130.122) train_loss=211.12844849 time/batch=1.18s
15823/10943 (epoch 130.130) train_loss=122.14029694 time/batch=0.84s
15824/10943 (epoch 130.138) train_loss=88.76635742 time/batch=0.65s
15825/10943 (epoch 130.146) train_loss=72.90137482 time/batch=0.50s
15826/10943 (epoch 130.155) train_loss=122.38368225 time/batch=0.83s
15827/10943 (epoch 130.163) train_loss=208.65588379 time/batch=1.19s
15828/10943 (epoch 130.171) train_loss=149.46466064 time/batch=0.95s
15829/10943 (epoch 130.179) train_loss=76.82038879 time/batch=0.51s
15830/10943 (epoch 130.188) train_loss=53.37676239 time/batch=0.28s
15831/10943 (epoch 130.196) train_loss=65.44485474 time/batch=0.41s
15832/10943 (epoch 130.204) train_loss=148.37539673 time/batch=0.86s
15833/10943 (epoch 130.212) train_loss=55.00092316 time/batch=0.36s
15834/10943 (epoch 130.221) train_loss=108.74187469 time/batch=0.67s
15835/10943 (epoch 130.229) train_loss=123.07257843 time/batch=0.82s
15836/10943 (epoch 130.237) train_loss=83.42081451 time/batch=0.59s
15837/10943 (epoch 130.245) train_loss=47.97371292 time/batch=0.30s
15838/10943 (epoch 130.253) train_loss=98.79492950 time/batch=0.61s
15839/10943 (epoch 130.262) train_loss=86.45144653 time/batch=0.60s
15840/10943 (epoch 130.270) train_loss=156.29629517 time/batch=0.95s
15841/10943 (epoch 130.278) train_loss=121.62802124 time/batch=0.78s
15842/10943 (epoch 130.286) train_loss=141.35482788 time/batch=0.90s
15843/10943 (epoch 130.295) train_loss=151.15628052 time/batch=0.97s
15844/10943 (epoch 130.303) train_loss=186.93243408 time/batch=1.06s
15845/10943 (epoch 130.311) train_loss=208.12367249 time/batch=1.26s
15846/10943 (epoch 130.319) train_loss=111.44011688 time/batch=0.74s
15847/10943 (epoch 130.327) train_loss=157.44854736 time/batch=0.99s
15848/10943 (epoch 130.336) train_loss=86.60095215 time/batch=0.61s
15849/10943 (epoch 130.344) train_loss=62.48356628 time/batch=0.35s
15850/10943 (epoch 130.352) train_loss=90.15721893 time/batch=0.51s
15851/10943 (epoch 130.360) train_loss=98.20640564 time/batch=0.64s
15852/10943 (epoch 130.369) train_loss=103.53141785 time/batch=0.68s
15853/10943 (epoch 130.377) train_loss=92.96315765 time/batch=0.61s
15854/10943 (epoch 130.385) train_loss=113.77017212 time/batch=0.75s
15855/10943 (epoch 130.393) train_loss=89.26502991 time/batch=0.68s
15856/10943 (epoch 130.401) train_loss=96.60438538 time/batch=0.70s
15857/10943 (epoch 130.410) train_loss=62.23737335 time/batch=0.39s
15858/10943 (epoch 130.418) train_loss=122.29396057 time/batch=0.77s
15859/10943 (epoch 130.426) train_loss=117.91151428 time/batch=0.80s
15860/10943 (epoch 130.434) train_loss=70.49896240 time/batch=0.55s
15861/10943 (epoch 130.443) train_loss=70.85147095 time/batch=0.45s
15862/10943 (epoch 130.451) train_loss=61.56056976 time/batch=0.37s
15863/10943 (epoch 130.459) train_loss=57.53789520 time/batch=0.32s
15864/10943 (epoch 130.467) train_loss=123.92445374 time/batch=0.68s
15865/10943 (epoch 130.475) train_loss=116.18255615 time/batch=0.73s
15866/10943 (epoch 130.484) train_loss=64.16911316 time/batch=0.44s
15867/10943 (epoch 130.492) train_loss=82.21743011 time/batch=0.50s
15868/10943 (epoch 130.500) train_loss=64.23017883 time/batch=0.38s
15869/10943 (epoch 130.508) train_loss=91.92152405 time/batch=0.58s
15870/10943 (epoch 130.517) train_loss=52.62072372 time/batch=0.35s
15871/10943 (epoch 130.525) train_loss=95.41543579 time/batch=0.58s
15872/10943 (epoch 130.533) train_loss=85.01989746 time/batch=0.61s
15873/10943 (epoch 130.541) train_loss=55.69904327 time/batch=0.32s
15874/10943 (epoch 130.549) train_loss=111.53603363 time/batch=0.64s
15875/10943 (epoch 130.558) train_loss=108.30157471 time/batch=0.70s
15876/10943 (epoch 130.566) train_loss=127.68057251 time/batch=0.78s
15877/10943 (epoch 130.574) train_loss=92.37419128 time/batch=0.63s
15878/10943 (epoch 130.582) train_loss=72.64421844 time/batch=0.46s
15879/10943 (epoch 130.591) train_loss=75.37627411 time/batch=0.48s
15880/10943 (epoch 130.599) train_loss=63.01145935 time/batch=0.42s
15881/10943 (epoch 130.607) train_loss=58.68297195 time/batch=0.44s
15882/10943 (epoch 130.615) train_loss=89.35012817 time/batch=0.60s
15883/10943 (epoch 130.623) train_loss=89.34223938 time/batch=0.68s
15884/10943 (epoch 130.632) train_loss=122.16767883 time/batch=0.74s
15885/10943 (epoch 130.640) train_loss=117.24678040 time/batch=0.71s
15886/10943 (epoch 130.648) train_loss=121.13518524 time/batch=0.73s
15887/10943 (epoch 130.656) train_loss=126.83225250 time/batch=0.81s
setting learning rate to 0.0004018
15888/10943 (epoch 130.665) train_loss=352.05938721 time/batch=1.73s
15889/10943 (epoch 130.673) train_loss=325.58938599 time/batch=1.86s
15890/10943 (epoch 130.681) train_loss=103.15969086 time/batch=0.73s
15891/10943 (epoch 130.689) train_loss=51.63179398 time/batch=0.34s
15892/10943 (epoch 130.698) train_loss=52.23103714 time/batch=0.29s
15893/10943 (epoch 130.706) train_loss=173.48724365 time/batch=0.94s
15894/10943 (epoch 130.714) train_loss=94.32470703 time/batch=0.65s
15895/10943 (epoch 130.722) train_loss=202.02615356 time/batch=1.09s
15896/10943 (epoch 130.730) train_loss=76.39254761 time/batch=0.54s
15897/10943 (epoch 130.739) train_loss=88.35987091 time/batch=0.58s
15898/10943 (epoch 130.747) train_loss=193.99822998 time/batch=1.11s
15899/10943 (epoch 130.755) train_loss=60.53990936 time/batch=0.45s
15900/10943 (epoch 130.763) train_loss=141.24548340 time/batch=0.86s
15901/10943 (epoch 130.772) train_loss=97.20610809 time/batch=0.72s
15902/10943 (epoch 130.780) train_loss=59.10769272 time/batch=0.45s
15903/10943 (epoch 130.788) train_loss=167.13067627 time/batch=1.01s
15904/10943 (epoch 130.796) train_loss=136.58776855 time/batch=0.95s
15905/10943 (epoch 130.804) train_loss=253.12446594 time/batch=1.31s
15906/10943 (epoch 130.813) train_loss=218.23115540 time/batch=1.18s
15907/10943 (epoch 130.821) train_loss=63.51430893 time/batch=0.46s
15908/10943 (epoch 130.829) train_loss=96.07607269 time/batch=0.66s
15909/10943 (epoch 130.837) train_loss=222.65287781 time/batch=1.22s
15910/10943 (epoch 130.846) train_loss=76.55102539 time/batch=0.61s
15911/10943 (epoch 130.854) train_loss=125.52346802 time/batch=0.83s
15912/10943 (epoch 130.862) train_loss=201.42224121 time/batch=1.17s
15913/10943 (epoch 130.870) train_loss=86.74181366 time/batch=0.59s
15914/10943 (epoch 130.878) train_loss=459.45388794 time/batch=3.04s
15915/10943 (epoch 130.887) train_loss=141.70291138 time/batch=1.09s
15916/10943 (epoch 130.895) train_loss=171.79765320 time/batch=0.99s
15917/10943 (epoch 130.903) train_loss=131.32177734 time/batch=0.90s
15918/10943 (epoch 130.911) train_loss=62.24757004 time/batch=0.40s
15919/10943 (epoch 130.920) train_loss=159.65692139 time/batch=0.91s
15920/10943 (epoch 130.928) train_loss=148.42637634 time/batch=0.89s
15921/10943 (epoch 130.936) train_loss=90.69944000 time/batch=0.61s
15922/10943 (epoch 130.944) train_loss=135.73327637 time/batch=0.86s
15923/10943 (epoch 130.952) train_loss=82.87506104 time/batch=0.59s
15924/10943 (epoch 130.961) train_loss=248.05801392 time/batch=1.40s
15925/10943 (epoch 130.969) train_loss=75.03723145 time/batch=0.58s
15926/10943 (epoch 130.977) train_loss=60.15657806 time/batch=0.36s
15927/10943 (epoch 130.985) train_loss=127.38538361 time/batch=0.84s
15928/10943 (epoch 130.994) train_loss=248.64646912 time/batch=1.34s
15929/10943 (epoch 131.002) train_loss=93.41777039 time/batch=0.69s
15930/10943 (epoch 131.010) train_loss=104.56557465 time/batch=0.70s
15931/10943 (epoch 131.018) train_loss=113.27922058 time/batch=0.71s
15932/10943 (epoch 131.026) train_loss=78.87528229 time/batch=0.52s
15933/10943 (epoch 131.035) train_loss=53.15053558 time/batch=0.35s
15934/10943 (epoch 131.043) train_loss=111.27923584 time/batch=0.75s
15935/10943 (epoch 131.051) train_loss=111.68499756 time/batch=0.82s
15936/10943 (epoch 131.059) train_loss=93.46089935 time/batch=0.72s
15937/10943 (epoch 131.068) train_loss=99.11430359 time/batch=0.66s
15938/10943 (epoch 131.076) train_loss=151.37374878 time/batch=0.96s
15939/10943 (epoch 131.084) train_loss=224.24841309 time/batch=1.36s
15940/10943 (epoch 131.092) train_loss=79.43328094 time/batch=0.63s
15941/10943 (epoch 131.100) train_loss=87.41931915 time/batch=0.59s
15942/10943 (epoch 131.109) train_loss=127.47872925 time/batch=0.88s
15943/10943 (epoch 131.117) train_loss=71.56960297 time/batch=0.50s
15944/10943 (epoch 131.125) train_loss=112.23399353 time/batch=0.70s
15945/10943 (epoch 131.133) train_loss=88.82631683 time/batch=0.58s
15946/10943 (epoch 131.142) train_loss=153.55706787 time/batch=0.92s
15947/10943 (epoch 131.150) train_loss=108.59582520 time/batch=0.82s
15948/10943 (epoch 131.158) train_loss=67.98535156 time/batch=0.50s
15949/10943 (epoch 131.166) train_loss=61.19066620 time/batch=0.39s
15950/10943 (epoch 131.175) train_loss=71.67427826 time/batch=0.47s
15951/10943 (epoch 131.183) train_loss=80.61573792 time/batch=0.56s
15952/10943 (epoch 131.191) train_loss=46.44719696 time/batch=0.29s
15953/10943 (epoch 131.199) train_loss=47.38157272 time/batch=0.29s
15954/10943 (epoch 131.207) train_loss=180.89921570 time/batch=1.01s
15955/10943 (epoch 131.216) train_loss=203.27169800 time/batch=1.17s
15956/10943 (epoch 131.224) train_loss=119.42417908 time/batch=0.84s
15957/10943 (epoch 131.232) train_loss=93.15433502 time/batch=0.63s
15958/10943 (epoch 131.240) train_loss=104.41727448 time/batch=0.65s
15959/10943 (epoch 131.249) train_loss=110.58374023 time/batch=0.76s
15960/10943 (epoch 131.257) train_loss=173.44873047 time/batch=0.99s
15961/10943 (epoch 131.265) train_loss=125.09863281 time/batch=0.84s
15962/10943 (epoch 131.273) train_loss=109.18425751 time/batch=0.73s
15963/10943 (epoch 131.281) train_loss=106.22125244 time/batch=0.67s
15964/10943 (epoch 131.290) train_loss=95.27738190 time/batch=0.63s
15965/10943 (epoch 131.298) train_loss=75.92222595 time/batch=0.48s
15966/10943 (epoch 131.306) train_loss=67.00954437 time/batch=0.40s
15967/10943 (epoch 131.314) train_loss=134.89962769 time/batch=0.88s
15968/10943 (epoch 131.323) train_loss=75.13898468 time/batch=0.53s
15969/10943 (epoch 131.331) train_loss=62.72178650 time/batch=0.42s
15970/10943 (epoch 131.339) train_loss=66.47514343 time/batch=0.42s
15971/10943 (epoch 131.347) train_loss=111.93402863 time/batch=0.72s
15972/10943 (epoch 131.355) train_loss=136.62179565 time/batch=0.84s
15973/10943 (epoch 131.364) train_loss=58.84464264 time/batch=0.44s
15974/10943 (epoch 131.372) train_loss=81.34039307 time/batch=0.49s
15975/10943 (epoch 131.380) train_loss=53.07923889 time/batch=0.32s
15976/10943 (epoch 131.388) train_loss=108.74987793 time/batch=0.69s
15977/10943 (epoch 131.397) train_loss=85.55624390 time/batch=0.52s
15978/10943 (epoch 131.405) train_loss=103.38983154 time/batch=0.64s
15979/10943 (epoch 131.413) train_loss=85.59513855 time/batch=0.62s
15980/10943 (epoch 131.421) train_loss=55.17831421 time/batch=0.34s
15981/10943 (epoch 131.429) train_loss=67.74026489 time/batch=0.47s
15982/10943 (epoch 131.438) train_loss=83.57347870 time/batch=0.54s
15983/10943 (epoch 131.446) train_loss=79.36643982 time/batch=0.56s
15984/10943 (epoch 131.454) train_loss=192.98489380 time/batch=1.04s
15985/10943 (epoch 131.462) train_loss=62.67209244 time/batch=0.48s
15986/10943 (epoch 131.471) train_loss=88.84216309 time/batch=0.56s
15987/10943 (epoch 131.479) train_loss=114.36222839 time/batch=0.73s
15988/10943 (epoch 131.487) train_loss=98.92727661 time/batch=0.65s
15989/10943 (epoch 131.495) train_loss=64.30854797 time/batch=0.45s
15990/10943 (epoch 131.503) train_loss=136.06941223 time/batch=0.80s
15991/10943 (epoch 131.512) train_loss=111.72728729 time/batch=0.77s
15992/10943 (epoch 131.520) train_loss=162.70135498 time/batch=1.01s
15993/10943 (epoch 131.528) train_loss=95.40505981 time/batch=0.63s
15994/10943 (epoch 131.536) train_loss=116.26826477 time/batch=0.65s
15995/10943 (epoch 131.545) train_loss=116.97943115 time/batch=0.71s
15996/10943 (epoch 131.553) train_loss=118.05970001 time/batch=0.78s
15997/10943 (epoch 131.561) train_loss=107.09400177 time/batch=0.68s
15998/10943 (epoch 131.569) train_loss=98.13549805 time/batch=0.63s
15999/10943 (epoch 131.577) train_loss=119.83941650 time/batch=0.77s
Validating
    loss:	369.499766

16000/10943 (epoch 131.586) train_loss=89.56375122 time/batch=2.51s
16001/10943 (epoch 131.594) train_loss=96.23224640 time/batch=0.65s
16002/10943 (epoch 131.602) train_loss=103.30007935 time/batch=0.69s
16003/10943 (epoch 131.610) train_loss=125.10120392 time/batch=0.79s
16004/10943 (epoch 131.619) train_loss=132.34841919 time/batch=0.82s
16005/10943 (epoch 131.627) train_loss=127.40964508 time/batch=0.81s
16006/10943 (epoch 131.635) train_loss=109.71896362 time/batch=0.69s
16007/10943 (epoch 131.643) train_loss=115.56071472 time/batch=0.73s
16008/10943 (epoch 131.652) train_loss=131.29525757 time/batch=0.82s
setting learning rate to 0.0003898
  saved to metadata/gru_no_dropout-9_nov_folkwiki-20181207-192453_epoch87.pkl
16009/10943 (epoch 131.660) train_loss=98.17270660 time/batch=0.83s
16010/10943 (epoch 131.668) train_loss=84.40241241 time/batch=0.64s
16011/10943 (epoch 131.676) train_loss=133.98416138 time/batch=0.90s
16012/10943 (epoch 131.684) train_loss=266.32550049 time/batch=1.52s
16013/10943 (epoch 131.693) train_loss=126.99485016 time/batch=0.90s
16014/10943 (epoch 131.701) train_loss=250.22834778 time/batch=1.25s
16015/10943 (epoch 131.709) train_loss=192.91804504 time/batch=1.05s
16016/10943 (epoch 131.717) train_loss=49.42348480 time/batch=0.33s
16017/10943 (epoch 131.726) train_loss=49.16550827 time/batch=0.28s
16018/10943 (epoch 131.734) train_loss=184.22344971 time/batch=1.01s
16019/10943 (epoch 131.742) train_loss=111.34275818 time/batch=0.76s
16020/10943 (epoch 131.750) train_loss=68.42822266 time/batch=0.48s
16021/10943 (epoch 131.758) train_loss=403.87570190 time/batch=2.14s
16022/10943 (epoch 131.767) train_loss=112.35469055 time/batch=0.87s
16023/10943 (epoch 131.775) train_loss=73.15147400 time/batch=0.50s
16024/10943 (epoch 131.783) train_loss=220.63748169 time/batch=1.16s
16025/10943 (epoch 131.791) train_loss=249.11108398 time/batch=1.40s
16026/10943 (epoch 131.800) train_loss=108.31124878 time/batch=0.74s
16027/10943 (epoch 131.808) train_loss=79.09838104 time/batch=0.63s
16028/10943 (epoch 131.816) train_loss=113.73544312 time/batch=0.70s
16029/10943 (epoch 131.824) train_loss=102.70841217 time/batch=0.78s
16030/10943 (epoch 131.832) train_loss=157.00064087 time/batch=0.99s
16031/10943 (epoch 131.841) train_loss=296.00177002 time/batch=1.62s
16032/10943 (epoch 131.849) train_loss=91.22782898 time/batch=0.73s
16033/10943 (epoch 131.857) train_loss=71.81979370 time/batch=0.46s
16034/10943 (epoch 131.865) train_loss=57.80782318 time/batch=0.35s
16035/10943 (epoch 131.874) train_loss=203.40106201 time/batch=1.11s
16036/10943 (epoch 131.882) train_loss=53.07223511 time/batch=0.39s
16037/10943 (epoch 131.890) train_loss=62.76205826 time/batch=0.35s
16038/10943 (epoch 131.898) train_loss=231.71694946 time/batch=1.23s
16039/10943 (epoch 131.906) train_loss=206.28750610 time/batch=1.18s
16040/10943 (epoch 131.915) train_loss=165.52029419 time/batch=1.01s
16041/10943 (epoch 131.923) train_loss=161.87124634 time/batch=1.00s
16042/10943 (epoch 131.931) train_loss=174.27668762 time/batch=1.09s
16043/10943 (epoch 131.939) train_loss=127.71591187 time/batch=0.88s
16044/10943 (epoch 131.948) train_loss=70.10889435 time/batch=0.50s
16045/10943 (epoch 131.956) train_loss=102.12133026 time/batch=0.76s
16046/10943 (epoch 131.964) train_loss=203.11734009 time/batch=1.27s
16047/10943 (epoch 131.972) train_loss=89.16441345 time/batch=0.65s
16048/10943 (epoch 131.980) train_loss=94.45797729 time/batch=0.63s
16049/10943 (epoch 131.989) train_loss=109.69319916 time/batch=0.78s
16050/10943 (epoch 131.997) train_loss=111.09004974 time/batch=0.79s
16051/10943 (epoch 132.005) train_loss=98.23213959 time/batch=0.72s
16052/10943 (epoch 132.013) train_loss=179.56408691 time/batch=1.01s
16053/10943 (epoch 132.022) train_loss=102.83130646 time/batch=0.72s
16054/10943 (epoch 132.030) train_loss=67.62551880 time/batch=0.48s
16055/10943 (epoch 132.038) train_loss=165.17282104 time/batch=1.03s
16056/10943 (epoch 132.046) train_loss=387.12805176 time/batch=3.11s
16057/10943 (epoch 132.054) train_loss=160.30017090 time/batch=1.15s
16058/10943 (epoch 132.063) train_loss=146.09649658 time/batch=0.93s
16059/10943 (epoch 132.071) train_loss=113.97843933 time/batch=0.82s
16060/10943 (epoch 132.079) train_loss=111.18533325 time/batch=0.74s
16061/10943 (epoch 132.087) train_loss=118.79867554 time/batch=0.82s
16062/10943 (epoch 132.096) train_loss=102.22909546 time/batch=0.70s
16063/10943 (epoch 132.104) train_loss=75.14776611 time/batch=0.50s
16064/10943 (epoch 132.112) train_loss=69.24377441 time/batch=0.48s
16065/10943 (epoch 132.120) train_loss=50.30402756 time/batch=0.31s
16066/10943 (epoch 132.129) train_loss=109.02801514 time/batch=0.70s
16067/10943 (epoch 132.137) train_loss=54.59084702 time/batch=0.35s
16068/10943 (epoch 132.145) train_loss=78.55616760 time/batch=0.51s
16069/10943 (epoch 132.153) train_loss=109.84089661 time/batch=0.74s
16070/10943 (epoch 132.161) train_loss=55.65991211 time/batch=0.36s
16071/10943 (epoch 132.170) train_loss=57.59322357 time/batch=0.36s
16072/10943 (epoch 132.178) train_loss=50.52249527 time/batch=0.33s
16073/10943 (epoch 132.186) train_loss=196.90632629 time/batch=1.03s
16074/10943 (epoch 132.194) train_loss=88.54328918 time/batch=0.64s
16075/10943 (epoch 132.203) train_loss=122.73442078 time/batch=0.81s
16076/10943 (epoch 132.211) train_loss=139.23686218 time/batch=0.94s
16077/10943 (epoch 132.219) train_loss=96.24757385 time/batch=0.63s
16078/10943 (epoch 132.227) train_loss=121.44188690 time/batch=0.75s
16079/10943 (epoch 132.235) train_loss=197.71490479 time/batch=1.09s
16080/10943 (epoch 132.244) train_loss=163.97909546 time/batch=0.97s
16081/10943 (epoch 132.252) train_loss=71.23774719 time/batch=0.48s
16082/10943 (epoch 132.260) train_loss=65.01954651 time/batch=0.36s
16083/10943 (epoch 132.268) train_loss=81.49603271 time/batch=0.50s
16084/10943 (epoch 132.277) train_loss=66.53068542 time/batch=0.40s
16085/10943 (epoch 132.285) train_loss=110.86909485 time/batch=0.68s
16086/10943 (epoch 132.293) train_loss=162.55737305 time/batch=1.08s
16087/10943 (epoch 132.301) train_loss=105.55000305 time/batch=0.71s
16088/10943 (epoch 132.309) train_loss=66.02467346 time/batch=0.42s
16089/10943 (epoch 132.318) train_loss=68.15780640 time/batch=0.41s
16090/10943 (epoch 132.326) train_loss=142.79824829 time/batch=1.05s
16091/10943 (epoch 132.334) train_loss=76.41055298 time/batch=0.55s
16092/10943 (epoch 132.342) train_loss=88.07785034 time/batch=0.57s
16093/10943 (epoch 132.351) train_loss=135.27902222 time/batch=0.83s
16094/10943 (epoch 132.359) train_loss=72.58550262 time/batch=0.52s
16095/10943 (epoch 132.367) train_loss=80.41369629 time/batch=0.55s
16096/10943 (epoch 132.375) train_loss=73.88975525 time/batch=0.50s
16097/10943 (epoch 132.383) train_loss=58.67551422 time/batch=0.38s
16098/10943 (epoch 132.392) train_loss=88.57559967 time/batch=0.54s
16099/10943 (epoch 132.400) train_loss=80.47419739 time/batch=0.52s
16100/10943 (epoch 132.408) train_loss=114.78780365 time/batch=0.72s
16101/10943 (epoch 132.416) train_loss=120.50306702 time/batch=0.80s
16102/10943 (epoch 132.425) train_loss=106.92620850 time/batch=0.75s
16103/10943 (epoch 132.433) train_loss=136.59600830 time/batch=0.88s
16104/10943 (epoch 132.441) train_loss=129.30374146 time/batch=0.84s
16105/10943 (epoch 132.449) train_loss=140.12829590 time/batch=0.87s
16106/10943 (epoch 132.457) train_loss=137.96392822 time/batch=0.88s
16107/10943 (epoch 132.466) train_loss=90.78326416 time/batch=0.62s
16108/10943 (epoch 132.474) train_loss=89.49984741 time/batch=0.58s
16109/10943 (epoch 132.482) train_loss=96.61028290 time/batch=0.62s
16110/10943 (epoch 132.490) train_loss=97.81904602 time/batch=0.60s
16111/10943 (epoch 132.499) train_loss=102.66594696 time/batch=0.64s
16112/10943 (epoch 132.507) train_loss=85.58930969 time/batch=0.56s
16113/10943 (epoch 132.515) train_loss=95.79940796 time/batch=0.64s
16114/10943 (epoch 132.523) train_loss=109.32319641 time/batch=0.66s
16115/10943 (epoch 132.531) train_loss=110.42866516 time/batch=0.67s
16116/10943 (epoch 132.540) train_loss=80.21040344 time/batch=0.55s
16117/10943 (epoch 132.548) train_loss=87.56528473 time/batch=0.55s
16118/10943 (epoch 132.556) train_loss=82.33396912 time/batch=0.52s
16119/10943 (epoch 132.564) train_loss=123.07005310 time/batch=0.80s
16120/10943 (epoch 132.573) train_loss=105.47261047 time/batch=0.69s
16121/10943 (epoch 132.581) train_loss=124.69454193 time/batch=0.85s
16122/10943 (epoch 132.589) train_loss=61.99270248 time/batch=0.56s
16123/10943 (epoch 132.597) train_loss=106.16326904 time/batch=0.67s
16124/10943 (epoch 132.605) train_loss=114.10073853 time/batch=0.77s
16125/10943 (epoch 132.614) train_loss=79.04073334 time/batch=0.55s
16126/10943 (epoch 132.622) train_loss=92.74740601 time/batch=0.58s
16127/10943 (epoch 132.630) train_loss=89.02058411 time/batch=0.61s
16128/10943 (epoch 132.638) train_loss=125.22929382 time/batch=0.79s
16129/10943 (epoch 132.647) train_loss=99.50611115 time/batch=0.69s
setting learning rate to 0.0003781
16130/10943 (epoch 132.655) train_loss=62.88941193 time/batch=0.38s
16131/10943 (epoch 132.663) train_loss=67.53868103 time/batch=0.44s
16132/10943 (epoch 132.671) train_loss=78.29695892 time/batch=0.59s
16133/10943 (epoch 132.680) train_loss=77.96685791 time/batch=0.61s
16134/10943 (epoch 132.688) train_loss=249.24453735 time/batch=1.26s
16135/10943 (epoch 132.696) train_loss=131.05975342 time/batch=0.92s
16136/10943 (epoch 132.704) train_loss=69.46362305 time/batch=0.48s
16137/10943 (epoch 132.712) train_loss=250.00059509 time/batch=1.41s
16138/10943 (epoch 132.721) train_loss=212.44207764 time/batch=1.20s
16139/10943 (epoch 132.729) train_loss=224.12551880 time/batch=1.22s
16140/10943 (epoch 132.737) train_loss=51.40232086 time/batch=0.35s
16141/10943 (epoch 132.745) train_loss=73.20661926 time/batch=0.52s
16142/10943 (epoch 132.754) train_loss=166.23655701 time/batch=0.97s
16143/10943 (epoch 132.762) train_loss=156.59707642 time/batch=0.99s
16144/10943 (epoch 132.770) train_loss=110.27236938 time/batch=0.81s
16145/10943 (epoch 132.778) train_loss=78.73707581 time/batch=0.54s
16146/10943 (epoch 132.786) train_loss=104.89766693 time/batch=0.75s
16147/10943 (epoch 132.795) train_loss=299.76916504 time/batch=1.59s
16148/10943 (epoch 132.803) train_loss=117.86255646 time/batch=0.92s
16149/10943 (epoch 132.811) train_loss=334.69317627 time/batch=1.76s
16150/10943 (epoch 132.819) train_loss=259.03503418 time/batch=1.46s
16151/10943 (epoch 132.828) train_loss=153.26596069 time/batch=1.00s
16152/10943 (epoch 132.836) train_loss=114.51472473 time/batch=0.77s
16153/10943 (epoch 132.844) train_loss=116.57151794 time/batch=0.80s
16154/10943 (epoch 132.852) train_loss=119.53477478 time/batch=0.83s
16155/10943 (epoch 132.860) train_loss=51.70858002 time/batch=0.33s
16156/10943 (epoch 132.869) train_loss=178.09396362 time/batch=0.95s
16157/10943 (epoch 132.877) train_loss=86.43394470 time/batch=0.67s
16158/10943 (epoch 132.885) train_loss=133.16476440 time/batch=0.82s
16159/10943 (epoch 132.893) train_loss=200.23440552 time/batch=1.13s
16160/10943 (epoch 132.902) train_loss=64.06286621 time/batch=0.51s
16161/10943 (epoch 132.910) train_loss=58.05006790 time/batch=0.38s
16162/10943 (epoch 132.918) train_loss=200.07470703 time/batch=1.15s
16163/10943 (epoch 132.926) train_loss=54.38106537 time/batch=0.39s
16164/10943 (epoch 132.934) train_loss=75.95381165 time/batch=0.51s
16165/10943 (epoch 132.943) train_loss=394.11212158 time/batch=2.33s
16166/10943 (epoch 132.951) train_loss=126.57164764 time/batch=0.92s
16167/10943 (epoch 132.959) train_loss=81.46357727 time/batch=0.52s
16168/10943 (epoch 132.967) train_loss=184.22328186 time/batch=0.98s
16169/10943 (epoch 132.976) train_loss=68.21767426 time/batch=0.46s
16170/10943 (epoch 132.984) train_loss=94.51386261 time/batch=0.66s
16171/10943 (epoch 132.992) train_loss=48.59106064 time/batch=0.34s
16172/10943 (epoch 133.000) train_loss=111.31302643 time/batch=0.67s
16173/10943 (epoch 133.008) train_loss=111.43959808 time/batch=0.80s
16174/10943 (epoch 133.017) train_loss=142.11410522 time/batch=0.90s
16175/10943 (epoch 133.025) train_loss=117.59310913 time/batch=0.86s
16176/10943 (epoch 133.033) train_loss=91.27882385 time/batch=0.58s
16177/10943 (epoch 133.041) train_loss=123.83415222 time/batch=0.82s
16178/10943 (epoch 133.050) train_loss=280.14703369 time/batch=3.08s
16179/10943 (epoch 133.058) train_loss=188.06895447 time/batch=1.26s
16180/10943 (epoch 133.066) train_loss=57.14578247 time/batch=0.40s
16181/10943 (epoch 133.074) train_loss=163.87179565 time/batch=0.92s
16182/10943 (epoch 133.082) train_loss=202.72915649 time/batch=1.10s
16183/10943 (epoch 133.091) train_loss=108.72586060 time/batch=0.71s
16184/10943 (epoch 133.099) train_loss=198.67356873 time/batch=1.12s
16185/10943 (epoch 133.107) train_loss=158.11314392 time/batch=0.97s
16186/10943 (epoch 133.115) train_loss=60.75450897 time/batch=0.39s
16187/10943 (epoch 133.124) train_loss=88.48895264 time/batch=0.59s
16188/10943 (epoch 133.132) train_loss=57.03491211 time/batch=0.39s
16189/10943 (epoch 133.140) train_loss=150.26977539 time/batch=0.90s
16190/10943 (epoch 133.148) train_loss=120.43202209 time/batch=0.73s
16191/10943 (epoch 133.157) train_loss=116.02071381 time/batch=0.75s
16192/10943 (epoch 133.165) train_loss=72.04351044 time/batch=0.49s
16193/10943 (epoch 133.173) train_loss=127.78090668 time/batch=0.84s
16194/10943 (epoch 133.181) train_loss=62.45449448 time/batch=0.45s
16195/10943 (epoch 133.189) train_loss=78.12126160 time/batch=0.52s
16196/10943 (epoch 133.198) train_loss=66.85946655 time/batch=0.44s
16197/10943 (epoch 133.206) train_loss=75.63263702 time/batch=0.50s
16198/10943 (epoch 133.214) train_loss=154.43405151 time/batch=0.94s
16199/10943 (epoch 133.222) train_loss=96.02176666 time/batch=0.66s
16200/10943 (epoch 133.231) train_loss=114.58067322 time/batch=0.75s
16201/10943 (epoch 133.239) train_loss=127.27893829 time/batch=0.85s
16202/10943 (epoch 133.247) train_loss=97.89649963 time/batch=0.71s
16203/10943 (epoch 133.255) train_loss=80.77532959 time/batch=0.53s
16204/10943 (epoch 133.263) train_loss=70.99613953 time/batch=0.46s
16205/10943 (epoch 133.272) train_loss=97.53314209 time/batch=0.65s
16206/10943 (epoch 133.280) train_loss=69.14459991 time/batch=0.48s
16207/10943 (epoch 133.288) train_loss=73.02117920 time/batch=0.47s
16208/10943 (epoch 133.296) train_loss=63.08274078 time/batch=0.41s
16209/10943 (epoch 133.305) train_loss=192.67749023 time/batch=1.15s
16210/10943 (epoch 133.313) train_loss=89.84056091 time/batch=0.63s
16211/10943 (epoch 133.321) train_loss=90.22228241 time/batch=0.59s
16212/10943 (epoch 133.329) train_loss=149.67729187 time/batch=0.89s
16213/10943 (epoch 133.337) train_loss=81.71158600 time/batch=0.60s
16214/10943 (epoch 133.346) train_loss=118.65896606 time/batch=0.77s
16215/10943 (epoch 133.354) train_loss=114.65000916 time/batch=0.77s
16216/10943 (epoch 133.362) train_loss=77.24015045 time/batch=0.54s
16217/10943 (epoch 133.370) train_loss=102.11231995 time/batch=0.62s
16218/10943 (epoch 133.379) train_loss=81.15013123 time/batch=0.57s
16219/10943 (epoch 133.387) train_loss=111.55297852 time/batch=0.70s
16220/10943 (epoch 133.395) train_loss=107.37403107 time/batch=0.79s
16221/10943 (epoch 133.403) train_loss=61.93032074 time/batch=0.40s
16222/10943 (epoch 133.411) train_loss=95.41413116 time/batch=0.60s
16223/10943 (epoch 133.420) train_loss=114.21924591 time/batch=0.72s
16224/10943 (epoch 133.428) train_loss=89.61009979 time/batch=0.61s
16225/10943 (epoch 133.436) train_loss=134.92588806 time/batch=0.86s
16226/10943 (epoch 133.444) train_loss=84.64770508 time/batch=0.61s
16227/10943 (epoch 133.453) train_loss=54.91256332 time/batch=0.33s
16228/10943 (epoch 133.461) train_loss=95.26959991 time/batch=0.61s
16229/10943 (epoch 133.469) train_loss=113.24233246 time/batch=0.70s
16230/10943 (epoch 133.477) train_loss=156.08938599 time/batch=1.03s
16231/10943 (epoch 133.485) train_loss=66.32983398 time/batch=0.43s
16232/10943 (epoch 133.494) train_loss=109.69358826 time/batch=0.65s
16233/10943 (epoch 133.502) train_loss=116.63074493 time/batch=0.81s
16234/10943 (epoch 133.510) train_loss=81.28666687 time/batch=0.51s
16235/10943 (epoch 133.518) train_loss=66.65968323 time/batch=0.47s
16236/10943 (epoch 133.527) train_loss=104.99288940 time/batch=0.67s
16237/10943 (epoch 133.535) train_loss=129.28509521 time/batch=0.82s
16238/10943 (epoch 133.543) train_loss=100.19644165 time/batch=0.67s
16239/10943 (epoch 133.551) train_loss=112.07752991 time/batch=0.67s
16240/10943 (epoch 133.559) train_loss=113.03584290 time/batch=0.73s
16241/10943 (epoch 133.568) train_loss=87.51764679 time/batch=0.60s
16242/10943 (epoch 133.576) train_loss=124.92594910 time/batch=0.80s
16243/10943 (epoch 133.584) train_loss=109.49340057 time/batch=0.68s
16244/10943 (epoch 133.592) train_loss=126.02851868 time/batch=0.81s
16245/10943 (epoch 133.601) train_loss=95.57600403 time/batch=0.61s
16246/10943 (epoch 133.609) train_loss=92.32636261 time/batch=0.57s
16247/10943 (epoch 133.617) train_loss=97.09732056 time/batch=0.59s
16248/10943 (epoch 133.625) train_loss=110.83066559 time/batch=0.66s
16249/10943 (epoch 133.634) train_loss=106.12004089 time/batch=0.71s
16250/10943 (epoch 133.642) train_loss=95.43579102 time/batch=0.60s
setting learning rate to 0.0003668
  saved to metadata/gru_no_dropout-9_nov_folkwiki-20181207-192453_epoch89.pkl
