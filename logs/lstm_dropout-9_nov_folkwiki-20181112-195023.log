vocabulary size: 226
n tunes: 4083
n train tunes: 3891.0
n validation tunes: 192.0
min, max length 55 822
Building the model
  number of parameters: 13769702
  layer output shapes:               #params:   output shape:
    InputLayer                       0          (32, None)
    EmbeddingLayer                   51076      (32, None, 226)
    InputLayer                       0          (32, None)
    LSTMLayer                        3288000    (32, None, 800)
    DropoutLayer                     0          (32, None, 800)
    LSTMLayer                        5124800    (32, None, 800)
    DropoutLayer                     0          (32, None, 800)
    LSTMLayer                        5124800    (32, None, 800)
    DropoutLayer                     0          (32, None, 800)
    ReshapeLayer                     0          (None, 800)
    DenseLayer                       181026     (None, 226)
Train model
Load metadata for resuming
setting learning rate to 0.0012402
19501/10943 (epoch 160.378) train_loss=339.49468994 time/batch=1.48s
19502/10943 (epoch 160.387) train_loss=230.60008240 time/batch=1.03s
19503/10943 (epoch 160.395) train_loss=577.68188477 time/batch=2.10s
19504/10943 (epoch 160.403) train_loss=449.03851318 time/batch=1.87s
19505/10943 (epoch 160.411) train_loss=120.72408295 time/batch=0.64s
19506/10943 (epoch 160.419) train_loss=163.69671631 time/batch=0.70s
19507/10943 (epoch 160.428) train_loss=242.92605591 time/batch=1.04s
19508/10943 (epoch 160.436) train_loss=77.38169861 time/batch=0.40s
19509/10943 (epoch 160.444) train_loss=265.83605957 time/batch=1.10s
19510/10943 (epoch 160.452) train_loss=559.57690430 time/batch=2.43s
19511/10943 (epoch 160.461) train_loss=632.55090332 time/batch=4.00s
19512/10943 (epoch 160.469) train_loss=209.13890076 time/batch=1.21s
19513/10943 (epoch 160.477) train_loss=188.83122253 time/batch=0.83s
19514/10943 (epoch 160.485) train_loss=159.22454834 time/batch=0.71s
19515/10943 (epoch 160.493) train_loss=218.80204773 time/batch=0.93s
19516/10943 (epoch 160.502) train_loss=303.18994141 time/batch=1.30s
19517/10943 (epoch 160.510) train_loss=269.25085449 time/batch=1.16s
19518/10943 (epoch 160.518) train_loss=132.83935547 time/batch=0.59s
19519/10943 (epoch 160.526) train_loss=110.16403961 time/batch=0.44s
19520/10943 (epoch 160.535) train_loss=135.09120178 time/batch=0.57s
19521/10943 (epoch 160.543) train_loss=211.88301086 time/batch=0.93s
19522/10943 (epoch 160.551) train_loss=285.58523560 time/batch=1.21s
19523/10943 (epoch 160.559) train_loss=119.78958130 time/batch=0.58s
19524/10943 (epoch 160.567) train_loss=324.63623047 time/batch=1.19s
19525/10943 (epoch 160.576) train_loss=147.04129028 time/batch=0.73s
19526/10943 (epoch 160.584) train_loss=133.97564697 time/batch=0.60s
19527/10943 (epoch 160.592) train_loss=283.70532227 time/batch=1.17s
19528/10943 (epoch 160.600) train_loss=260.88003540 time/batch=1.17s
19529/10943 (epoch 160.609) train_loss=425.73019409 time/batch=1.65s
19530/10943 (epoch 160.617) train_loss=354.47583008 time/batch=1.48s
19531/10943 (epoch 160.625) train_loss=123.40824127 time/batch=0.60s
19532/10943 (epoch 160.633) train_loss=210.63513184 time/batch=0.90s
19533/10943 (epoch 160.641) train_loss=337.71627808 time/batch=1.30s
19534/10943 (epoch 160.650) train_loss=168.79325867 time/batch=0.83s
19535/10943 (epoch 160.658) train_loss=90.34973145 time/batch=0.38s
19536/10943 (epoch 160.666) train_loss=399.41860962 time/batch=1.49s
19537/10943 (epoch 160.674) train_loss=245.28695679 time/batch=1.13s
19538/10943 (epoch 160.683) train_loss=352.92614746 time/batch=1.47s
19539/10943 (epoch 160.691) train_loss=220.21875000 time/batch=1.07s
19540/10943 (epoch 160.699) train_loss=186.19883728 time/batch=0.82s
19541/10943 (epoch 160.707) train_loss=367.69116211 time/batch=1.61s
19542/10943 (epoch 160.715) train_loss=304.16296387 time/batch=1.32s
19543/10943 (epoch 160.724) train_loss=144.17095947 time/batch=0.73s
19544/10943 (epoch 160.732) train_loss=179.19755554 time/batch=0.85s
19545/10943 (epoch 160.740) train_loss=291.25671387 time/batch=1.16s
19546/10943 (epoch 160.748) train_loss=385.02593994 time/batch=1.50s
19547/10943 (epoch 160.757) train_loss=112.30997467 time/batch=0.57s
19548/10943 (epoch 160.765) train_loss=213.75028992 time/batch=0.94s
19549/10943 (epoch 160.773) train_loss=288.47979736 time/batch=1.19s
19550/10943 (epoch 160.781) train_loss=336.25592041 time/batch=1.38s
19551/10943 (epoch 160.790) train_loss=108.13278961 time/batch=0.55s
19552/10943 (epoch 160.798) train_loss=233.01860046 time/batch=0.97s
19553/10943 (epoch 160.806) train_loss=122.90098572 time/batch=0.52s
19554/10943 (epoch 160.814) train_loss=197.69607544 time/batch=0.85s
19555/10943 (epoch 160.822) train_loss=127.98506165 time/batch=0.60s
19556/10943 (epoch 160.831) train_loss=241.51290894 time/batch=0.99s
19557/10943 (epoch 160.839) train_loss=283.85083008 time/batch=1.21s
19558/10943 (epoch 160.847) train_loss=224.81138611 time/batch=1.03s
19559/10943 (epoch 160.855) train_loss=163.93150330 time/batch=0.75s
19560/10943 (epoch 160.864) train_loss=157.06367493 time/batch=0.69s
19561/10943 (epoch 160.872) train_loss=94.42533875 time/batch=0.40s
19562/10943 (epoch 160.880) train_loss=166.33050537 time/batch=0.69s
19563/10943 (epoch 160.888) train_loss=109.24456787 time/batch=0.46s
19564/10943 (epoch 160.896) train_loss=113.60020447 time/batch=0.51s
19565/10943 (epoch 160.905) train_loss=166.37452698 time/batch=0.73s
19566/10943 (epoch 160.913) train_loss=356.97930908 time/batch=1.38s
19567/10943 (epoch 160.921) train_loss=144.98965454 time/batch=0.72s
19568/10943 (epoch 160.929) train_loss=239.18917847 time/batch=1.00s
19569/10943 (epoch 160.938) train_loss=130.68743896 time/batch=0.65s
19570/10943 (epoch 160.946) train_loss=194.62905884 time/batch=0.85s
19571/10943 (epoch 160.954) train_loss=209.66136169 time/batch=0.99s
19572/10943 (epoch 160.962) train_loss=214.72058105 time/batch=0.99s
19573/10943 (epoch 160.970) train_loss=245.84991455 time/batch=1.04s
19574/10943 (epoch 160.979) train_loss=160.78298950 time/batch=0.80s
19575/10943 (epoch 160.987) train_loss=90.91262817 time/batch=0.42s
19576/10943 (epoch 160.995) train_loss=186.17987061 time/batch=0.77s
19577/10943 (epoch 161.003) train_loss=245.71995544 time/batch=1.01s
19578/10943 (epoch 161.012) train_loss=257.09759521 time/batch=1.25s
19579/10943 (epoch 161.020) train_loss=140.49505615 time/batch=0.67s
19580/10943 (epoch 161.028) train_loss=213.78897095 time/batch=0.93s
19581/10943 (epoch 161.036) train_loss=239.15498352 time/batch=1.06s
19582/10943 (epoch 161.044) train_loss=207.98168945 time/batch=0.93s
19583/10943 (epoch 161.053) train_loss=352.89813232 time/batch=1.76s
19584/10943 (epoch 161.061) train_loss=154.62031555 time/batch=0.75s
19585/10943 (epoch 161.069) train_loss=171.87850952 time/batch=0.77s
19586/10943 (epoch 161.077) train_loss=242.88372803 time/batch=1.06s
19587/10943 (epoch 161.086) train_loss=120.92726135 time/batch=0.60s
19588/10943 (epoch 161.094) train_loss=191.16210938 time/batch=0.80s
19589/10943 (epoch 161.102) train_loss=175.65037537 time/batch=0.78s
19590/10943 (epoch 161.110) train_loss=162.46563721 time/batch=0.74s
19591/10943 (epoch 161.118) train_loss=157.99520874 time/batch=0.75s
19592/10943 (epoch 161.127) train_loss=190.11756897 time/batch=0.79s
19593/10943 (epoch 161.135) train_loss=115.46385956 time/batch=0.59s
19594/10943 (epoch 161.143) train_loss=124.95143127 time/batch=0.56s
19595/10943 (epoch 161.151) train_loss=104.73733521 time/batch=0.56s
19596/10943 (epoch 161.160) train_loss=161.28619385 time/batch=0.75s
19597/10943 (epoch 161.168) train_loss=209.23229980 time/batch=0.88s
19598/10943 (epoch 161.176) train_loss=140.86553955 time/batch=0.69s
19599/10943 (epoch 161.184) train_loss=142.20767212 time/batch=0.61s
19600/10943 (epoch 161.192) train_loss=150.79826355 time/batch=0.63s
19601/10943 (epoch 161.201) train_loss=217.17366028 time/batch=0.90s
19602/10943 (epoch 161.209) train_loss=94.17384338 time/batch=0.44s
19603/10943 (epoch 161.217) train_loss=245.75384521 time/batch=1.02s
19604/10943 (epoch 161.225) train_loss=163.83244324 time/batch=0.77s
19605/10943 (epoch 161.234) train_loss=128.01924133 time/batch=0.64s
19606/10943 (epoch 161.242) train_loss=169.31640625 time/batch=0.73s
19607/10943 (epoch 161.250) train_loss=154.83418274 time/batch=0.67s
19608/10943 (epoch 161.258) train_loss=191.96566772 time/batch=0.80s
19609/10943 (epoch 161.267) train_loss=129.37135315 time/batch=0.70s
19610/10943 (epoch 161.275) train_loss=216.09027100 time/batch=0.89s
19611/10943 (epoch 161.283) train_loss=173.97813416 time/batch=0.84s
19612/10943 (epoch 161.291) train_loss=187.97164917 time/batch=0.84s
19613/10943 (epoch 161.299) train_loss=265.19186401 time/batch=1.25s
19614/10943 (epoch 161.308) train_loss=162.45014954 time/batch=0.80s
19615/10943 (epoch 161.316) train_loss=229.58306885 time/batch=1.06s
19616/10943 (epoch 161.324) train_loss=175.04298401 time/batch=0.86s
19617/10943 (epoch 161.332) train_loss=224.99960327 time/batch=0.89s
19618/10943 (epoch 161.341) train_loss=215.84417725 time/batch=1.07s
19619/10943 (epoch 161.349) train_loss=181.97825623 time/batch=0.87s
19620/10943 (epoch 161.357) train_loss=204.59794617 time/batch=0.88s
19621/10943 (epoch 161.365) train_loss=194.12377930 time/batch=0.90s
setting learning rate to 0.0012030
19622/10943 (epoch 161.373) train_loss=113.77056885 time/batch=0.55s
19623/10943 (epoch 161.382) train_loss=187.19497681 time/batch=0.80s
19624/10943 (epoch 161.390) train_loss=294.86651611 time/batch=1.27s
19625/10943 (epoch 161.398) train_loss=362.38647461 time/batch=1.56s
19626/10943 (epoch 161.406) train_loss=699.79107666 time/batch=3.87s
19627/10943 (epoch 161.415) train_loss=422.91781616 time/batch=2.01s
19628/10943 (epoch 161.423) train_loss=208.64076233 time/batch=1.09s
19629/10943 (epoch 161.431) train_loss=313.91033936 time/batch=1.26s
19630/10943 (epoch 161.439) train_loss=208.37373352 time/batch=1.01s
19631/10943 (epoch 161.447) train_loss=223.18286133 time/batch=1.05s
19632/10943 (epoch 161.456) train_loss=138.91183472 time/batch=0.68s
19633/10943 (epoch 161.464) train_loss=526.48419189 time/batch=2.03s
19634/10943 (epoch 161.472) train_loss=176.92204285 time/batch=1.05s
19635/10943 (epoch 161.480) train_loss=334.67895508 time/batch=1.37s
19636/10943 (epoch 161.489) train_loss=74.84481812 time/batch=0.42s
19637/10943 (epoch 161.497) train_loss=240.03442383 time/batch=0.97s
19638/10943 (epoch 161.505) train_loss=451.10595703 time/batch=1.92s
19639/10943 (epoch 161.513) train_loss=157.11724854 time/batch=0.85s
19640/10943 (epoch 161.521) train_loss=214.00872803 time/batch=0.95s
19641/10943 (epoch 161.530) train_loss=398.64697266 time/batch=1.70s
19642/10943 (epoch 161.538) train_loss=107.57052612 time/batch=0.57s
19643/10943 (epoch 161.546) train_loss=130.98245239 time/batch=0.56s
19644/10943 (epoch 161.554) train_loss=154.63534546 time/batch=0.75s
19645/10943 (epoch 161.563) train_loss=323.13757324 time/batch=1.30s
19646/10943 (epoch 161.571) train_loss=128.78884888 time/batch=0.61s
19647/10943 (epoch 161.579) train_loss=189.20922852 time/batch=0.83s
19648/10943 (epoch 161.587) train_loss=97.24477386 time/batch=0.44s
19649/10943 (epoch 161.595) train_loss=278.45339966 time/batch=1.14s
19650/10943 (epoch 161.604) train_loss=232.13537598 time/batch=1.10s
19651/10943 (epoch 161.612) train_loss=342.96368408 time/batch=1.46s
19652/10943 (epoch 161.620) train_loss=208.30578613 time/batch=1.04s
19653/10943 (epoch 161.628) train_loss=159.28392029 time/batch=0.75s
19654/10943 (epoch 161.637) train_loss=133.77037048 time/batch=0.60s
19655/10943 (epoch 161.645) train_loss=183.79383850 time/batch=0.77s
19656/10943 (epoch 161.653) train_loss=142.76840210 time/batch=0.64s
19657/10943 (epoch 161.661) train_loss=202.98614502 time/batch=0.87s
19658/10943 (epoch 161.669) train_loss=258.31744385 time/batch=1.10s
19659/10943 (epoch 161.678) train_loss=93.77397919 time/batch=0.45s
19660/10943 (epoch 161.686) train_loss=224.89324951 time/batch=1.01s
19661/10943 (epoch 161.694) train_loss=372.52105713 time/batch=1.47s
19662/10943 (epoch 161.702) train_loss=306.34356689 time/batch=1.28s
19663/10943 (epoch 161.711) train_loss=90.79165649 time/batch=0.48s
19664/10943 (epoch 161.719) train_loss=222.33514404 time/batch=0.93s
19665/10943 (epoch 161.727) train_loss=243.81062317 time/batch=1.12s
19666/10943 (epoch 161.735) train_loss=104.66940308 time/batch=0.51s
19667/10943 (epoch 161.744) train_loss=212.94827271 time/batch=0.96s
19668/10943 (epoch 161.752) train_loss=125.84123993 time/batch=0.60s
19669/10943 (epoch 161.760) train_loss=251.66641235 time/batch=1.09s
19670/10943 (epoch 161.768) train_loss=238.10833740 time/batch=1.10s
19671/10943 (epoch 161.776) train_loss=98.65912628 time/batch=0.50s
19672/10943 (epoch 161.785) train_loss=341.96453857 time/batch=1.29s
19673/10943 (epoch 161.793) train_loss=194.70797729 time/batch=0.93s
19674/10943 (epoch 161.801) train_loss=111.58619690 time/batch=0.52s
19675/10943 (epoch 161.809) train_loss=214.59722900 time/batch=0.84s
19676/10943 (epoch 161.818) train_loss=181.47940063 time/batch=0.84s
19677/10943 (epoch 161.826) train_loss=87.88967896 time/batch=0.40s
19678/10943 (epoch 161.834) train_loss=319.87756348 time/batch=1.29s
19679/10943 (epoch 161.842) train_loss=315.78073120 time/batch=1.43s
19680/10943 (epoch 161.850) train_loss=104.67207336 time/batch=0.56s
19681/10943 (epoch 161.859) train_loss=264.89581299 time/batch=1.10s
19682/10943 (epoch 161.867) train_loss=215.36877441 time/batch=0.98s
19683/10943 (epoch 161.875) train_loss=158.10777283 time/batch=0.76s
19684/10943 (epoch 161.883) train_loss=116.66266632 time/batch=0.55s
19685/10943 (epoch 161.892) train_loss=412.73626709 time/batch=1.71s
19686/10943 (epoch 161.900) train_loss=150.48779297 time/batch=0.81s
19687/10943 (epoch 161.908) train_loss=330.07339478 time/batch=1.49s
19688/10943 (epoch 161.916) train_loss=159.03419495 time/batch=0.83s
19689/10943 (epoch 161.924) train_loss=185.77093506 time/batch=0.81s
19690/10943 (epoch 161.933) train_loss=102.01704407 time/batch=0.48s
19691/10943 (epoch 161.941) train_loss=143.63363647 time/batch=0.67s
19692/10943 (epoch 161.949) train_loss=167.07153320 time/batch=0.78s
19693/10943 (epoch 161.957) train_loss=116.07537842 time/batch=0.54s
19694/10943 (epoch 161.966) train_loss=132.07363892 time/batch=0.59s
19695/10943 (epoch 161.974) train_loss=190.80825806 time/batch=0.90s
19696/10943 (epoch 161.982) train_loss=188.83161926 time/batch=0.86s
19697/10943 (epoch 161.990) train_loss=155.77011108 time/batch=0.76s
19698/10943 (epoch 161.998) train_loss=154.40472412 time/batch=0.69s
19699/10943 (epoch 162.007) train_loss=191.81695557 time/batch=0.86s
19700/10943 (epoch 162.015) train_loss=238.04975891 time/batch=1.07s
19701/10943 (epoch 162.023) train_loss=133.47488403 time/batch=0.71s
19702/10943 (epoch 162.031) train_loss=203.00616455 time/batch=0.86s
19703/10943 (epoch 162.040) train_loss=139.43309021 time/batch=0.67s
19704/10943 (epoch 162.048) train_loss=145.06433105 time/batch=0.63s
19705/10943 (epoch 162.056) train_loss=207.28887939 time/batch=0.89s
19706/10943 (epoch 162.064) train_loss=160.90353394 time/batch=0.77s
19707/10943 (epoch 162.072) train_loss=284.49346924 time/batch=1.14s
19708/10943 (epoch 162.081) train_loss=126.15228271 time/batch=0.65s
19709/10943 (epoch 162.089) train_loss=164.73074341 time/batch=0.75s
19710/10943 (epoch 162.097) train_loss=179.99273682 time/batch=0.77s
19711/10943 (epoch 162.105) train_loss=136.39105225 time/batch=0.61s
19712/10943 (epoch 162.114) train_loss=281.74472046 time/batch=1.19s
19713/10943 (epoch 162.122) train_loss=207.12895203 time/batch=1.03s
19714/10943 (epoch 162.130) train_loss=203.23637390 time/batch=0.99s
19715/10943 (epoch 162.138) train_loss=121.09819794 time/batch=0.60s
19716/10943 (epoch 162.146) train_loss=177.98477173 time/batch=0.77s
19717/10943 (epoch 162.155) train_loss=132.94007874 time/batch=0.62s
19718/10943 (epoch 162.163) train_loss=100.02910614 time/batch=0.46s
19719/10943 (epoch 162.171) train_loss=193.58767700 time/batch=0.80s
19720/10943 (epoch 162.179) train_loss=157.89569092 time/batch=0.78s
19721/10943 (epoch 162.188) train_loss=276.99981689 time/batch=1.20s
19722/10943 (epoch 162.196) train_loss=116.87477112 time/batch=0.55s
19723/10943 (epoch 162.204) train_loss=164.73356628 time/batch=0.69s
19724/10943 (epoch 162.212) train_loss=158.89668274 time/batch=0.67s
19725/10943 (epoch 162.221) train_loss=129.13069153 time/batch=0.66s
19726/10943 (epoch 162.229) train_loss=184.41503906 time/batch=0.82s
19727/10943 (epoch 162.237) train_loss=139.48269653 time/batch=0.68s
19728/10943 (epoch 162.245) train_loss=187.59774780 time/batch=0.80s
19729/10943 (epoch 162.253) train_loss=191.24908447 time/batch=0.83s
19730/10943 (epoch 162.262) train_loss=209.93049622 time/batch=0.90s
19731/10943 (epoch 162.270) train_loss=140.16415405 time/batch=0.75s
19732/10943 (epoch 162.278) train_loss=164.22294617 time/batch=0.77s
19733/10943 (epoch 162.286) train_loss=276.10708618 time/batch=1.15s
19734/10943 (epoch 162.295) train_loss=220.10614014 time/batch=1.01s
19735/10943 (epoch 162.303) train_loss=215.18360901 time/batch=0.95s
19736/10943 (epoch 162.311) train_loss=239.39166260 time/batch=1.04s
19737/10943 (epoch 162.319) train_loss=188.93885803 time/batch=0.94s
19738/10943 (epoch 162.327) train_loss=238.59532166 time/batch=1.02s
19739/10943 (epoch 162.336) train_loss=153.15052795 time/batch=0.77s
19740/10943 (epoch 162.344) train_loss=256.21316528 time/batch=1.14s
19741/10943 (epoch 162.352) train_loss=231.54481506 time/batch=1.04s
19742/10943 (epoch 162.360) train_loss=200.75872803 time/batch=1.03s
setting learning rate to 0.0011669
19743/10943 (epoch 162.369) train_loss=196.53125000 time/batch=0.99s
19744/10943 (epoch 162.377) train_loss=209.07913208 time/batch=1.00s
19745/10943 (epoch 162.385) train_loss=539.35632324 time/batch=2.16s
19746/10943 (epoch 162.393) train_loss=117.50702667 time/batch=0.73s
19747/10943 (epoch 162.401) train_loss=130.69216919 time/batch=0.64s
19748/10943 (epoch 162.410) train_loss=147.43257141 time/batch=0.67s
19749/10943 (epoch 162.418) train_loss=294.08557129 time/batch=1.19s
19750/10943 (epoch 162.426) train_loss=151.72326660 time/batch=0.80s
19751/10943 (epoch 162.434) train_loss=330.24188232 time/batch=1.39s
19752/10943 (epoch 162.443) train_loss=131.12960815 time/batch=0.69s
19753/10943 (epoch 162.451) train_loss=663.02941895 time/batch=3.70s
19754/10943 (epoch 162.459) train_loss=311.76129150 time/batch=1.57s
19755/10943 (epoch 162.467) train_loss=296.24813843 time/batch=1.29s
19756/10943 (epoch 162.475) train_loss=160.99475098 time/batch=0.84s
19757/10943 (epoch 162.484) train_loss=399.57901001 time/batch=1.65s
19758/10943 (epoch 162.492) train_loss=315.50448608 time/batch=1.40s
19759/10943 (epoch 162.500) train_loss=409.65270996 time/batch=1.86s
19760/10943 (epoch 162.508) train_loss=128.97441101 time/batch=0.74s
19761/10943 (epoch 162.517) train_loss=114.61576843 time/batch=0.50s
19762/10943 (epoch 162.525) train_loss=396.95333862 time/batch=1.53s
19763/10943 (epoch 162.533) train_loss=203.48376465 time/batch=1.02s
19764/10943 (epoch 162.541) train_loss=342.15911865 time/batch=1.58s
19765/10943 (epoch 162.549) train_loss=221.50823975 time/batch=1.13s
19766/10943 (epoch 162.558) train_loss=125.50628662 time/batch=0.58s
19767/10943 (epoch 162.566) train_loss=260.61767578 time/batch=1.10s
19768/10943 (epoch 162.574) train_loss=155.34008789 time/batch=0.81s
19769/10943 (epoch 162.582) train_loss=194.28892517 time/batch=0.98s
19770/10943 (epoch 162.591) train_loss=108.18102264 time/batch=0.55s
19771/10943 (epoch 162.599) train_loss=420.33978271 time/batch=1.84s
19772/10943 (epoch 162.607) train_loss=144.60279846 time/batch=0.84s
19773/10943 (epoch 162.615) train_loss=206.14532471 time/batch=0.97s
19774/10943 (epoch 162.623) train_loss=334.69024658 time/batch=1.46s
19775/10943 (epoch 162.632) train_loss=322.48632812 time/batch=1.43s
19776/10943 (epoch 162.640) train_loss=269.35681152 time/batch=1.24s
19777/10943 (epoch 162.648) train_loss=270.32025146 time/batch=1.19s
19778/10943 (epoch 162.656) train_loss=175.28964233 time/batch=0.83s
19779/10943 (epoch 162.665) train_loss=198.71197510 time/batch=0.90s
19780/10943 (epoch 162.673) train_loss=109.36233521 time/batch=0.52s
19781/10943 (epoch 162.681) train_loss=104.36776733 time/batch=0.45s
19782/10943 (epoch 162.689) train_loss=351.80041504 time/batch=1.43s
19783/10943 (epoch 162.698) train_loss=156.20198059 time/batch=0.81s
19784/10943 (epoch 162.706) train_loss=102.49682617 time/batch=0.46s
19785/10943 (epoch 162.714) train_loss=184.48550415 time/batch=0.78s
19786/10943 (epoch 162.722) train_loss=84.38668060 time/batch=0.42s
19787/10943 (epoch 162.730) train_loss=87.67289734 time/batch=0.36s
19788/10943 (epoch 162.739) train_loss=152.91206360 time/batch=0.69s
19789/10943 (epoch 162.747) train_loss=196.11637878 time/batch=0.87s
19790/10943 (epoch 162.755) train_loss=182.02499390 time/batch=0.84s
19791/10943 (epoch 162.763) train_loss=185.19407654 time/batch=0.92s
19792/10943 (epoch 162.772) train_loss=94.29620361 time/batch=0.46s
19793/10943 (epoch 162.780) train_loss=79.16629028 time/batch=0.33s
19794/10943 (epoch 162.788) train_loss=146.35739136 time/batch=0.62s
19795/10943 (epoch 162.796) train_loss=316.29287720 time/batch=1.29s
19796/10943 (epoch 162.804) train_loss=80.86801910 time/batch=0.46s
19797/10943 (epoch 162.813) train_loss=186.33569336 time/batch=0.77s
19798/10943 (epoch 162.821) train_loss=315.74835205 time/batch=1.32s
19799/10943 (epoch 162.829) train_loss=185.69186401 time/batch=0.91s
19800/10943 (epoch 162.837) train_loss=211.93302917 time/batch=0.92s
19801/10943 (epoch 162.846) train_loss=135.42221069 time/batch=0.64s
19802/10943 (epoch 162.854) train_loss=285.62057495 time/batch=1.20s
19803/10943 (epoch 162.862) train_loss=194.75431824 time/batch=0.99s
19804/10943 (epoch 162.870) train_loss=139.52499390 time/batch=0.67s
19805/10943 (epoch 162.878) train_loss=99.81338501 time/batch=0.42s
19806/10943 (epoch 162.887) train_loss=160.07904053 time/batch=0.73s
19807/10943 (epoch 162.895) train_loss=178.94946289 time/batch=0.85s
19808/10943 (epoch 162.903) train_loss=232.79550171 time/batch=1.03s
19809/10943 (epoch 162.911) train_loss=136.18014526 time/batch=0.72s
19810/10943 (epoch 162.920) train_loss=111.57501221 time/batch=0.52s
19811/10943 (epoch 162.928) train_loss=145.76396179 time/batch=0.60s
19812/10943 (epoch 162.936) train_loss=207.68109131 time/batch=0.94s
19813/10943 (epoch 162.944) train_loss=245.79418945 time/batch=1.13s
19814/10943 (epoch 162.952) train_loss=113.14309692 time/batch=0.57s
19815/10943 (epoch 162.961) train_loss=93.32868958 time/batch=0.38s
19816/10943 (epoch 162.969) train_loss=155.56790161 time/batch=0.67s
19817/10943 (epoch 162.977) train_loss=242.82788086 time/batch=1.07s
19818/10943 (epoch 162.985) train_loss=113.28896332 time/batch=0.58s
19819/10943 (epoch 162.994) train_loss=273.77664185 time/batch=1.12s
19820/10943 (epoch 163.002) train_loss=132.96652222 time/batch=0.69s
19821/10943 (epoch 163.010) train_loss=186.44786072 time/batch=0.83s
19822/10943 (epoch 163.018) train_loss=137.35188293 time/batch=0.60s
19823/10943 (epoch 163.026) train_loss=152.65611267 time/batch=0.68s
19824/10943 (epoch 163.035) train_loss=236.15026855 time/batch=0.99s
19825/10943 (epoch 163.043) train_loss=154.89505005 time/batch=0.78s
19826/10943 (epoch 163.051) train_loss=126.37874603 time/batch=0.56s
19827/10943 (epoch 163.059) train_loss=136.75956726 time/batch=0.62s
19828/10943 (epoch 163.068) train_loss=209.42266846 time/batch=0.98s
19829/10943 (epoch 163.076) train_loss=235.38426208 time/batch=1.06s
19830/10943 (epoch 163.084) train_loss=307.18011475 time/batch=1.38s
19831/10943 (epoch 163.092) train_loss=228.47125244 time/batch=1.01s
19832/10943 (epoch 163.100) train_loss=102.59808350 time/batch=0.48s
19833/10943 (epoch 163.109) train_loss=198.16979980 time/batch=0.86s
19834/10943 (epoch 163.117) train_loss=119.40425110 time/batch=0.60s
19835/10943 (epoch 163.125) train_loss=149.12867737 time/batch=0.65s
19836/10943 (epoch 163.133) train_loss=210.22891235 time/batch=0.97s
19837/10943 (epoch 163.142) train_loss=121.56967163 time/batch=0.63s
19838/10943 (epoch 163.150) train_loss=114.89979553 time/batch=0.68s
19839/10943 (epoch 163.158) train_loss=198.87483215 time/batch=0.86s
19840/10943 (epoch 163.166) train_loss=176.83343506 time/batch=0.81s
19841/10943 (epoch 163.175) train_loss=157.94210815 time/batch=0.72s
19842/10943 (epoch 163.183) train_loss=226.72085571 time/batch=1.03s
19843/10943 (epoch 163.191) train_loss=181.02951050 time/batch=0.84s
19844/10943 (epoch 163.199) train_loss=253.50779724 time/batch=1.15s
19845/10943 (epoch 163.207) train_loss=158.57263184 time/batch=0.81s
19846/10943 (epoch 163.216) train_loss=203.87785339 time/batch=0.86s
19847/10943 (epoch 163.224) train_loss=255.54006958 time/batch=1.10s
19848/10943 (epoch 163.232) train_loss=238.90451050 time/batch=1.07s
19849/10943 (epoch 163.240) train_loss=158.05072021 time/batch=0.77s
19850/10943 (epoch 163.249) train_loss=148.26895142 time/batch=0.74s
19851/10943 (epoch 163.257) train_loss=218.36354065 time/batch=0.99s
19852/10943 (epoch 163.265) train_loss=169.31570435 time/batch=0.79s
19853/10943 (epoch 163.273) train_loss=159.58786011 time/batch=0.77s
19854/10943 (epoch 163.281) train_loss=170.05725098 time/batch=0.79s
19855/10943 (epoch 163.290) train_loss=218.62327576 time/batch=1.04s
19856/10943 (epoch 163.298) train_loss=237.05174255 time/batch=1.08s
19857/10943 (epoch 163.306) train_loss=178.78944397 time/batch=0.90s
19858/10943 (epoch 163.314) train_loss=156.79040527 time/batch=0.84s
19859/10943 (epoch 163.323) train_loss=243.93528748 time/batch=1.10s
19860/10943 (epoch 163.331) train_loss=213.08514404 time/batch=0.98s
19861/10943 (epoch 163.339) train_loss=188.35408020 time/batch=0.89s
19862/10943 (epoch 163.347) train_loss=196.06874084 time/batch=0.96s
19863/10943 (epoch 163.355) train_loss=181.68295288 time/batch=0.89s
setting learning rate to 0.0011319
19864/10943 (epoch 163.364) train_loss=261.46926880 time/batch=1.18s
19865/10943 (epoch 163.372) train_loss=495.20416260 time/batch=2.02s
19866/10943 (epoch 163.380) train_loss=153.51956177 time/batch=0.83s
19867/10943 (epoch 163.388) train_loss=254.37167358 time/batch=1.11s
19868/10943 (epoch 163.397) train_loss=377.72967529 time/batch=1.69s
19869/10943 (epoch 163.405) train_loss=194.48284912 time/batch=1.10s
19870/10943 (epoch 163.413) train_loss=269.74633789 time/batch=1.21s
19871/10943 (epoch 163.421) train_loss=330.40536499 time/batch=1.40s
19872/10943 (epoch 163.429) train_loss=398.67272949 time/batch=1.82s
19873/10943 (epoch 163.438) train_loss=351.35021973 time/batch=1.57s
19874/10943 (epoch 163.446) train_loss=427.36859131 time/batch=2.11s
19875/10943 (epoch 163.454) train_loss=328.02468872 time/batch=1.46s
19876/10943 (epoch 163.462) train_loss=259.57797241 time/batch=1.22s
19877/10943 (epoch 163.471) train_loss=660.71179199 time/batch=3.80s
19878/10943 (epoch 163.479) train_loss=403.39752197 time/batch=2.41s
19879/10943 (epoch 163.487) train_loss=133.48156738 time/batch=0.80s
19880/10943 (epoch 163.495) train_loss=228.73577881 time/batch=1.00s
19881/10943 (epoch 163.503) train_loss=277.21749878 time/batch=1.28s
19882/10943 (epoch 163.512) train_loss=97.77307129 time/batch=0.49s
19883/10943 (epoch 163.520) train_loss=131.40937805 time/batch=0.60s
19884/10943 (epoch 163.528) train_loss=106.56182861 time/batch=0.47s
19885/10943 (epoch 163.536) train_loss=293.25152588 time/batch=1.17s
19886/10943 (epoch 163.545) train_loss=198.16981506 time/batch=0.96s
19887/10943 (epoch 163.553) train_loss=192.17440796 time/batch=0.92s
19888/10943 (epoch 163.561) train_loss=139.59747314 time/batch=0.67s
19889/10943 (epoch 163.569) train_loss=339.21279907 time/batch=1.45s
19890/10943 (epoch 163.577) train_loss=181.69874573 time/batch=0.90s
19891/10943 (epoch 163.586) train_loss=108.30265045 time/batch=0.54s
19892/10943 (epoch 163.594) train_loss=193.92224121 time/batch=0.93s
19893/10943 (epoch 163.602) train_loss=85.98633575 time/batch=0.42s
19894/10943 (epoch 163.610) train_loss=141.94940186 time/batch=0.62s
19895/10943 (epoch 163.619) train_loss=105.04271698 time/batch=0.48s
19896/10943 (epoch 163.627) train_loss=329.62847900 time/batch=1.47s
19897/10943 (epoch 163.635) train_loss=297.75909424 time/batch=1.41s
19898/10943 (epoch 163.643) train_loss=71.72866821 time/batch=0.43s
19899/10943 (epoch 163.652) train_loss=313.91076660 time/batch=1.22s
19900/10943 (epoch 163.660) train_loss=245.64282227 time/batch=1.13s
19901/10943 (epoch 163.668) train_loss=240.72872925 time/batch=1.15s
19902/10943 (epoch 163.676) train_loss=316.24853516 time/batch=1.44s
19903/10943 (epoch 163.684) train_loss=113.94155884 time/batch=0.61s
19904/10943 (epoch 163.693) train_loss=139.89968872 time/batch=0.65s
19905/10943 (epoch 163.701) train_loss=99.67272949 time/batch=0.46s
19906/10943 (epoch 163.709) train_loss=121.46560669 time/batch=0.55s
19907/10943 (epoch 163.717) train_loss=139.39695740 time/batch=0.68s
19908/10943 (epoch 163.726) train_loss=145.38742065 time/batch=0.70s
19909/10943 (epoch 163.734) train_loss=122.34202576 time/batch=0.54s
19910/10943 (epoch 163.742) train_loss=318.80978394 time/batch=1.29s
19911/10943 (epoch 163.750) train_loss=223.66360474 time/batch=1.09s
19912/10943 (epoch 163.758) train_loss=199.87660217 time/batch=0.97s
19913/10943 (epoch 163.767) train_loss=168.73617554 time/batch=0.88s
19914/10943 (epoch 163.775) train_loss=101.20881653 time/batch=0.51s
19915/10943 (epoch 163.783) train_loss=149.12736511 time/batch=0.69s
19916/10943 (epoch 163.791) train_loss=268.76855469 time/batch=1.21s
19917/10943 (epoch 163.800) train_loss=117.54882050 time/batch=0.62s
19918/10943 (epoch 163.808) train_loss=219.23925781 time/batch=0.90s
19919/10943 (epoch 163.816) train_loss=151.02163696 time/batch=0.76s
19920/10943 (epoch 163.824) train_loss=95.17871857 time/batch=0.44s
19921/10943 (epoch 163.832) train_loss=273.21722412 time/batch=1.18s
19922/10943 (epoch 163.841) train_loss=138.55928040 time/batch=0.73s
19923/10943 (epoch 163.849) train_loss=246.50717163 time/batch=1.07s
19924/10943 (epoch 163.857) train_loss=228.57077026 time/batch=1.09s
19925/10943 (epoch 163.865) train_loss=87.81517792 time/batch=0.44s
19926/10943 (epoch 163.874) train_loss=130.52673340 time/batch=0.65s
19927/10943 (epoch 163.882) train_loss=180.95260620 time/batch=0.84s
19928/10943 (epoch 163.890) train_loss=210.39913940 time/batch=1.00s
19929/10943 (epoch 163.898) train_loss=106.14595032 time/batch=0.49s
19930/10943 (epoch 163.906) train_loss=196.41349792 time/batch=0.84s
19931/10943 (epoch 163.915) train_loss=89.27142334 time/batch=0.45s
19932/10943 (epoch 163.923) train_loss=226.78506470 time/batch=0.97s
19933/10943 (epoch 163.931) train_loss=181.91165161 time/batch=0.84s
19934/10943 (epoch 163.939) train_loss=216.89407349 time/batch=1.02s
19935/10943 (epoch 163.948) train_loss=129.31072998 time/batch=0.63s
19936/10943 (epoch 163.956) train_loss=179.54853821 time/batch=0.79s
19937/10943 (epoch 163.964) train_loss=176.69113159 time/batch=0.84s
19938/10943 (epoch 163.972) train_loss=206.54652405 time/batch=0.95s
19939/10943 (epoch 163.980) train_loss=209.24707031 time/batch=0.98s
19940/10943 (epoch 163.989) train_loss=220.75280762 time/batch=1.06s
19941/10943 (epoch 163.997) train_loss=252.27313232 time/batch=1.16s
19942/10943 (epoch 164.005) train_loss=236.56338501 time/batch=1.13s
19943/10943 (epoch 164.013) train_loss=177.43321228 time/batch=0.88s
19944/10943 (epoch 164.022) train_loss=179.51210022 time/batch=0.82s
19945/10943 (epoch 164.030) train_loss=201.91192627 time/batch=0.99s
19946/10943 (epoch 164.038) train_loss=191.62155151 time/batch=0.97s
19947/10943 (epoch 164.046) train_loss=222.35189819 time/batch=1.08s
19948/10943 (epoch 164.054) train_loss=186.02583313 time/batch=0.95s
19949/10943 (epoch 164.063) train_loss=149.97442627 time/batch=0.75s
19950/10943 (epoch 164.071) train_loss=151.22613525 time/batch=0.71s
19951/10943 (epoch 164.079) train_loss=135.31759644 time/batch=0.60s
19952/10943 (epoch 164.087) train_loss=90.09658813 time/batch=0.39s
19953/10943 (epoch 164.096) train_loss=190.14172363 time/batch=0.82s
19954/10943 (epoch 164.104) train_loss=148.86087036 time/batch=0.73s
19955/10943 (epoch 164.112) train_loss=188.72810364 time/batch=0.85s
19956/10943 (epoch 164.120) train_loss=191.81445312 time/batch=0.97s
19957/10943 (epoch 164.129) train_loss=153.45103455 time/batch=0.74s
19958/10943 (epoch 164.137) train_loss=149.74737549 time/batch=0.73s
19959/10943 (epoch 164.145) train_loss=154.14103699 time/batch=0.76s
19960/10943 (epoch 164.153) train_loss=203.10049438 time/batch=0.88s
19961/10943 (epoch 164.161) train_loss=227.15090942 time/batch=1.03s
19962/10943 (epoch 164.170) train_loss=129.05044556 time/batch=0.65s
19963/10943 (epoch 164.178) train_loss=131.40515137 time/batch=0.72s
19964/10943 (epoch 164.186) train_loss=167.72862244 time/batch=0.77s
19965/10943 (epoch 164.194) train_loss=111.05895233 time/batch=0.57s
19966/10943 (epoch 164.203) train_loss=189.35508728 time/batch=0.88s
19967/10943 (epoch 164.211) train_loss=208.93527222 time/batch=1.04s
19968/10943 (epoch 164.219) train_loss=171.50860596 time/batch=0.83s
19969/10943 (epoch 164.227) train_loss=121.29197693 time/batch=0.58s
19970/10943 (epoch 164.235) train_loss=119.86895752 time/batch=0.56s
19971/10943 (epoch 164.244) train_loss=154.84992981 time/batch=0.72s
19972/10943 (epoch 164.252) train_loss=92.85855103 time/batch=0.50s
19973/10943 (epoch 164.260) train_loss=110.09304810 time/batch=0.53s
19974/10943 (epoch 164.268) train_loss=215.21418762 time/batch=1.00s
19975/10943 (epoch 164.277) train_loss=208.46487427 time/batch=0.95s
19976/10943 (epoch 164.285) train_loss=167.66502380 time/batch=0.79s
19977/10943 (epoch 164.293) train_loss=149.84683228 time/batch=0.78s
19978/10943 (epoch 164.301) train_loss=157.48196411 time/batch=0.77s
19979/10943 (epoch 164.309) train_loss=177.21272278 time/batch=0.83s
19980/10943 (epoch 164.318) train_loss=151.12713623 time/batch=0.76s
19981/10943 (epoch 164.326) train_loss=134.79479980 time/batch=0.74s
19982/10943 (epoch 164.334) train_loss=155.41748047 time/batch=0.78s
19983/10943 (epoch 164.342) train_loss=184.40704346 time/batch=0.89s
19984/10943 (epoch 164.351) train_loss=165.36984253 time/batch=0.81s
setting learning rate to 0.0010980
19985/10943 (epoch 164.359) train_loss=267.02148438 time/batch=1.23s
19986/10943 (epoch 164.367) train_loss=376.55627441 time/batch=1.63s
19987/10943 (epoch 164.375) train_loss=142.43054199 time/batch=0.79s
19988/10943 (epoch 164.383) train_loss=79.66390991 time/batch=0.37s
19989/10943 (epoch 164.392) train_loss=542.95672607 time/batch=2.25s
19990/10943 (epoch 164.400) train_loss=199.72628784 time/batch=1.13s
19991/10943 (epoch 164.408) train_loss=163.75177002 time/batch=0.80s
19992/10943 (epoch 164.416) train_loss=145.97169495 time/batch=0.74s
19993/10943 (epoch 164.425) train_loss=194.08680725 time/batch=0.98s
19994/10943 (epoch 164.433) train_loss=361.84692383 time/batch=1.60s
19995/10943 (epoch 164.441) train_loss=278.24517822 time/batch=1.32s
19996/10943 (epoch 164.449) train_loss=110.04785919 time/batch=0.58s
19997/10943 (epoch 164.457) train_loss=137.33013916 time/batch=0.66s
19998/10943 (epoch 164.466) train_loss=147.15766907 time/batch=0.66s
19999/10943 (epoch 164.474) train_loss=608.47900391 time/batch=3.73s
Validating
    loss:	196.968002

20000/10943 (epoch 164.482) train_loss=344.74813843 time/batch=4.32s
20001/10943 (epoch 164.490) train_loss=323.63522339 time/batch=1.52s
20002/10943 (epoch 164.499) train_loss=417.55285645 time/batch=1.95s
20003/10943 (epoch 164.507) train_loss=327.60623169 time/batch=1.47s
20004/10943 (epoch 164.515) train_loss=150.11973572 time/batch=0.80s
20005/10943 (epoch 164.523) train_loss=97.35511017 time/batch=0.46s
20006/10943 (epoch 164.531) train_loss=346.04653931 time/batch=1.59s
20007/10943 (epoch 164.540) train_loss=271.67898560 time/batch=1.25s
20008/10943 (epoch 164.548) train_loss=259.98159790 time/batch=1.20s
20009/10943 (epoch 164.556) train_loss=168.53504944 time/batch=0.86s
20010/10943 (epoch 164.564) train_loss=86.95418549 time/batch=0.41s
20011/10943 (epoch 164.573) train_loss=190.45568848 time/batch=0.90s
20012/10943 (epoch 164.581) train_loss=294.55212402 time/batch=1.26s
20013/10943 (epoch 164.589) train_loss=259.38369751 time/batch=1.22s
20014/10943 (epoch 164.597) train_loss=322.48504639 time/batch=1.67s
20015/10943 (epoch 164.605) train_loss=296.50604248 time/batch=1.35s
20016/10943 (epoch 164.614) train_loss=213.83666992 time/batch=1.10s
20017/10943 (epoch 164.622) train_loss=87.41354370 time/batch=0.46s
20018/10943 (epoch 164.630) train_loss=189.93734741 time/batch=0.89s
20019/10943 (epoch 164.638) train_loss=184.49440002 time/batch=0.94s
20020/10943 (epoch 164.647) train_loss=303.02764893 time/batch=1.33s
20021/10943 (epoch 164.655) train_loss=215.90785217 time/batch=1.13s
20022/10943 (epoch 164.663) train_loss=142.36300659 time/batch=0.77s
20023/10943 (epoch 164.671) train_loss=108.90364838 time/batch=0.53s
20024/10943 (epoch 164.680) train_loss=302.14154053 time/batch=1.31s
20025/10943 (epoch 164.688) train_loss=83.88072205 time/batch=0.49s
20026/10943 (epoch 164.696) train_loss=256.03939819 time/batch=1.14s
20027/10943 (epoch 164.704) train_loss=139.72642517 time/batch=0.73s
20028/10943 (epoch 164.712) train_loss=217.56631470 time/batch=1.00s
20029/10943 (epoch 164.721) train_loss=106.88720703 time/batch=0.51s
20030/10943 (epoch 164.729) train_loss=232.40151978 time/batch=1.09s
20031/10943 (epoch 164.737) train_loss=104.63230896 time/batch=0.53s
20032/10943 (epoch 164.745) train_loss=133.35729980 time/batch=0.59s
20033/10943 (epoch 164.754) train_loss=73.32693481 time/batch=0.37s
20034/10943 (epoch 164.762) train_loss=121.56973267 time/batch=0.55s
20035/10943 (epoch 164.770) train_loss=173.60174561 time/batch=0.81s
20036/10943 (epoch 164.778) train_loss=372.03884888 time/batch=1.71s
20037/10943 (epoch 164.786) train_loss=295.16760254 time/batch=1.47s
20038/10943 (epoch 164.795) train_loss=175.94784546 time/batch=0.91s
20039/10943 (epoch 164.803) train_loss=221.26855469 time/batch=1.05s
20040/10943 (epoch 164.811) train_loss=96.80155945 time/batch=0.48s
20041/10943 (epoch 164.819) train_loss=189.83715820 time/batch=0.93s
20042/10943 (epoch 164.828) train_loss=117.71100616 time/batch=0.59s
20043/10943 (epoch 164.836) train_loss=179.94372559 time/batch=0.83s
20044/10943 (epoch 164.844) train_loss=188.30014038 time/batch=0.91s
20045/10943 (epoch 164.852) train_loss=229.95980835 time/batch=1.09s
20046/10943 (epoch 164.860) train_loss=203.76947021 time/batch=1.02s
20047/10943 (epoch 164.869) train_loss=233.34161377 time/batch=1.14s
20048/10943 (epoch 164.877) train_loss=172.72731018 time/batch=0.90s
20049/10943 (epoch 164.885) train_loss=197.33383179 time/batch=0.99s
20050/10943 (epoch 164.893) train_loss=193.91223145 time/batch=0.91s
20051/10943 (epoch 164.902) train_loss=121.20988464 time/batch=0.63s
20052/10943 (epoch 164.910) train_loss=108.27819824 time/batch=0.47s
20053/10943 (epoch 164.918) train_loss=126.55191040 time/batch=0.63s
20054/10943 (epoch 164.926) train_loss=119.09516907 time/batch=0.57s
20055/10943 (epoch 164.934) train_loss=279.05450439 time/batch=1.69s
20056/10943 (epoch 164.943) train_loss=219.42895508 time/batch=1.12s
20057/10943 (epoch 164.951) train_loss=237.52165222 time/batch=1.12s
20058/10943 (epoch 164.959) train_loss=176.13223267 time/batch=0.85s
20059/10943 (epoch 164.967) train_loss=210.05197144 time/batch=0.95s
20060/10943 (epoch 164.976) train_loss=175.56434631 time/batch=0.84s
20061/10943 (epoch 164.984) train_loss=117.48123169 time/batch=0.57s
20062/10943 (epoch 164.992) train_loss=103.78413391 time/batch=0.48s
20063/10943 (epoch 165.000) train_loss=90.82888794 time/batch=0.41s
20064/10943 (epoch 165.008) train_loss=154.15716553 time/batch=0.67s
20065/10943 (epoch 165.017) train_loss=186.65203857 time/batch=0.87s
20066/10943 (epoch 165.025) train_loss=218.19653320 time/batch=1.06s
20067/10943 (epoch 165.033) train_loss=183.06713867 time/batch=0.92s
20068/10943 (epoch 165.041) train_loss=122.81036377 time/batch=0.62s
20069/10943 (epoch 165.050) train_loss=92.55738068 time/batch=0.45s
20070/10943 (epoch 165.058) train_loss=115.36019897 time/batch=0.54s
20071/10943 (epoch 165.066) train_loss=160.96124268 time/batch=0.83s
20072/10943 (epoch 165.074) train_loss=132.87208557 time/batch=0.66s
20073/10943 (epoch 165.082) train_loss=107.10232544 time/batch=0.55s
20074/10943 (epoch 165.091) train_loss=200.04611206 time/batch=0.96s
20075/10943 (epoch 165.099) train_loss=154.39756775 time/batch=0.81s
20076/10943 (epoch 165.107) train_loss=246.73736572 time/batch=1.09s
20077/10943 (epoch 165.115) train_loss=205.32226562 time/batch=1.00s
20078/10943 (epoch 165.124) train_loss=151.42175293 time/batch=0.75s
20079/10943 (epoch 165.132) train_loss=145.91354370 time/batch=0.74s
20080/10943 (epoch 165.140) train_loss=150.73236084 time/batch=0.73s
20081/10943 (epoch 165.148) train_loss=113.66242218 time/batch=0.59s
20082/10943 (epoch 165.157) train_loss=148.05386353 time/batch=0.69s
20083/10943 (epoch 165.165) train_loss=145.87310791 time/batch=0.72s
20084/10943 (epoch 165.173) train_loss=202.28591919 time/batch=0.90s
20085/10943 (epoch 165.181) train_loss=249.09870911 time/batch=1.75s
20086/10943 (epoch 165.189) train_loss=142.22215271 time/batch=0.74s
20087/10943 (epoch 165.198) train_loss=128.69427490 time/batch=0.62s
20088/10943 (epoch 165.206) train_loss=153.91461182 time/batch=0.73s
20089/10943 (epoch 165.214) train_loss=124.43060303 time/batch=0.64s
20090/10943 (epoch 165.222) train_loss=152.70176697 time/batch=0.75s
20091/10943 (epoch 165.231) train_loss=191.67726135 time/batch=0.95s
20092/10943 (epoch 165.239) train_loss=132.52984619 time/batch=0.69s
20093/10943 (epoch 165.247) train_loss=139.49520874 time/batch=0.72s
20094/10943 (epoch 165.255) train_loss=168.06483459 time/batch=0.80s
20095/10943 (epoch 165.263) train_loss=200.92247009 time/batch=0.90s
20096/10943 (epoch 165.272) train_loss=170.05119324 time/batch=0.83s
20097/10943 (epoch 165.280) train_loss=185.45697021 time/batch=0.84s
20098/10943 (epoch 165.288) train_loss=185.10066223 time/batch=0.88s
20099/10943 (epoch 165.296) train_loss=196.26554871 time/batch=0.88s
20100/10943 (epoch 165.305) train_loss=147.00970459 time/batch=0.78s
20101/10943 (epoch 165.313) train_loss=148.10655212 time/batch=0.76s
20102/10943 (epoch 165.321) train_loss=223.73832703 time/batch=1.04s
20103/10943 (epoch 165.329) train_loss=168.09786987 time/batch=0.94s
20104/10943 (epoch 165.337) train_loss=214.45347595 time/batch=1.03s
20105/10943 (epoch 165.346) train_loss=185.86508179 time/batch=1.01s
setting learning rate to 0.0010650
  saved to metadata/lstm_dropout-9_nov_folkwiki-20181112-195023.pkl
20106/10943 (epoch 165.354) train_loss=301.92822266 time/batch=1.46s
20107/10943 (epoch 165.362) train_loss=322.49499512 time/batch=1.40s
20108/10943 (epoch 165.370) train_loss=130.93681335 time/batch=0.70s
20109/10943 (epoch 165.379) train_loss=365.21813965 time/batch=1.53s
20110/10943 (epoch 165.387) train_loss=387.39318848 time/batch=1.91s
20111/10943 (epoch 165.395) train_loss=211.21458435 time/batch=1.17s
20112/10943 (epoch 165.403) train_loss=227.66607666 time/batch=1.11s
20113/10943 (epoch 165.411) train_loss=127.38937378 time/batch=0.70s
20114/10943 (epoch 165.420) train_loss=269.30639648 time/batch=1.23s
20115/10943 (epoch 165.428) train_loss=324.59060669 time/batch=1.47s
20116/10943 (epoch 165.436) train_loss=218.80943298 time/batch=1.12s
20117/10943 (epoch 165.444) train_loss=97.90097809 time/batch=0.50s
20118/10943 (epoch 165.453) train_loss=491.55639648 time/batch=2.00s
20119/10943 (epoch 165.461) train_loss=109.35686493 time/batch=0.69s
20120/10943 (epoch 165.469) train_loss=119.63710022 time/batch=0.56s
20121/10943 (epoch 165.477) train_loss=369.49588013 time/batch=1.56s
20122/10943 (epoch 165.485) train_loss=123.54950714 time/batch=0.69s
20123/10943 (epoch 165.494) train_loss=600.80615234 time/batch=2.88s
20124/10943 (epoch 165.502) train_loss=171.58746338 time/batch=1.07s
20125/10943 (epoch 165.510) train_loss=216.25369263 time/batch=1.03s
20126/10943 (epoch 165.518) train_loss=267.53460693 time/batch=1.23s
20127/10943 (epoch 165.527) train_loss=173.41062927 time/batch=0.88s
20128/10943 (epoch 165.535) train_loss=73.12060547 time/batch=0.37s
20129/10943 (epoch 165.543) train_loss=145.02413940 time/batch=0.72s
20130/10943 (epoch 165.551) train_loss=96.36757660 time/batch=0.48s
20131/10943 (epoch 165.559) train_loss=249.16647339 time/batch=1.11s
20132/10943 (epoch 165.568) train_loss=267.99417114 time/batch=1.32s
20133/10943 (epoch 165.576) train_loss=86.66468811 time/batch=0.50s
20134/10943 (epoch 165.584) train_loss=138.07955933 time/batch=0.73s
20135/10943 (epoch 165.592) train_loss=217.30163574 time/batch=1.08s
20136/10943 (epoch 165.601) train_loss=185.16720581 time/batch=0.96s
20137/10943 (epoch 165.609) train_loss=345.80459595 time/batch=1.66s
20138/10943 (epoch 165.617) train_loss=174.63842773 time/batch=0.95s
20139/10943 (epoch 165.625) train_loss=186.13351440 time/batch=0.92s
20140/10943 (epoch 165.634) train_loss=237.66902161 time/batch=1.12s
20141/10943 (epoch 165.642) train_loss=117.29894257 time/batch=0.65s
20142/10943 (epoch 165.650) train_loss=350.43011475 time/batch=1.64s
20143/10943 (epoch 165.658) train_loss=98.45121765 time/batch=0.60s
20144/10943 (epoch 165.666) train_loss=350.69531250 time/batch=1.79s
20145/10943 (epoch 165.675) train_loss=299.15118408 time/batch=1.37s
20146/10943 (epoch 165.683) train_loss=287.16177368 time/batch=1.35s
20147/10943 (epoch 165.691) train_loss=253.08474731 time/batch=1.25s
20148/10943 (epoch 165.699) train_loss=137.59793091 time/batch=0.69s
20149/10943 (epoch 165.708) train_loss=227.26736450 time/batch=1.07s
20150/10943 (epoch 165.716) train_loss=257.09631348 time/batch=1.22s
20151/10943 (epoch 165.724) train_loss=195.58990479 time/batch=0.99s
20152/10943 (epoch 165.732) train_loss=226.65774536 time/batch=1.14s
20153/10943 (epoch 165.740) train_loss=156.95016479 time/batch=0.83s
20154/10943 (epoch 165.749) train_loss=326.93084717 time/batch=1.85s
20155/10943 (epoch 165.757) train_loss=98.24989319 time/batch=0.58s
20156/10943 (epoch 165.765) train_loss=264.09527588 time/batch=1.25s
20157/10943 (epoch 165.773) train_loss=104.84535217 time/batch=0.57s
20158/10943 (epoch 165.782) train_loss=111.55457306 time/batch=0.53s
20159/10943 (epoch 165.790) train_loss=162.84065247 time/batch=0.77s
20160/10943 (epoch 165.798) train_loss=372.09857178 time/batch=3.76s
20161/10943 (epoch 165.806) train_loss=151.61764526 time/batch=1.10s
20162/10943 (epoch 165.814) train_loss=182.69277954 time/batch=0.89s
20163/10943 (epoch 165.823) train_loss=212.44734192 time/batch=1.02s
20164/10943 (epoch 165.831) train_loss=188.81889343 time/batch=1.02s
20165/10943 (epoch 165.839) train_loss=115.96052551 time/batch=0.65s
20166/10943 (epoch 165.847) train_loss=117.43980408 time/batch=0.59s
20167/10943 (epoch 165.856) train_loss=140.11094666 time/batch=0.72s
20168/10943 (epoch 165.864) train_loss=80.89450073 time/batch=0.41s
20169/10943 (epoch 165.872) train_loss=142.55529785 time/batch=0.66s
20170/10943 (epoch 165.880) train_loss=172.62228394 time/batch=0.84s
20171/10943 (epoch 165.888) train_loss=131.29592896 time/batch=0.67s
20172/10943 (epoch 165.897) train_loss=105.78001404 time/batch=0.48s
20173/10943 (epoch 165.905) train_loss=135.40954590 time/batch=0.68s
20174/10943 (epoch 165.913) train_loss=134.59268188 time/batch=0.68s
20175/10943 (epoch 165.921) train_loss=91.24899292 time/batch=0.41s
20176/10943 (epoch 165.930) train_loss=148.55859375 time/batch=0.68s
20177/10943 (epoch 165.938) train_loss=118.79167175 time/batch=0.61s
20178/10943 (epoch 165.946) train_loss=211.64544678 time/batch=1.03s
20179/10943 (epoch 165.954) train_loss=105.82725525 time/batch=0.58s
20180/10943 (epoch 165.962) train_loss=203.32215881 time/batch=0.92s
20181/10943 (epoch 165.971) train_loss=118.29366302 time/batch=0.57s
20182/10943 (epoch 165.979) train_loss=76.17109680 time/batch=0.36s
20183/10943 (epoch 165.987) train_loss=199.20880127 time/batch=0.92s
20184/10943 (epoch 165.995) train_loss=113.25737000 time/batch=0.57s
20185/10943 (epoch 166.004) train_loss=196.57916260 time/batch=0.95s
20186/10943 (epoch 166.012) train_loss=172.24383545 time/batch=0.89s
20187/10943 (epoch 166.020) train_loss=149.47265625 time/batch=0.73s
20188/10943 (epoch 166.028) train_loss=267.88659668 time/batch=1.29s
20189/10943 (epoch 166.036) train_loss=173.64125061 time/batch=0.91s
20190/10943 (epoch 166.045) train_loss=250.39384460 time/batch=1.15s
20191/10943 (epoch 166.053) train_loss=125.18027496 time/batch=0.66s
20192/10943 (epoch 166.061) train_loss=99.02789307 time/batch=0.47s
20193/10943 (epoch 166.069) train_loss=216.97766113 time/batch=0.99s
20194/10943 (epoch 166.078) train_loss=168.04870605 time/batch=0.83s
20195/10943 (epoch 166.086) train_loss=88.86473083 time/batch=0.55s
20196/10943 (epoch 166.094) train_loss=145.60600281 time/batch=0.66s
20197/10943 (epoch 166.102) train_loss=194.40951538 time/batch=0.93s
20198/10943 (epoch 166.111) train_loss=165.54502869 time/batch=0.89s
20199/10943 (epoch 166.119) train_loss=206.11782837 time/batch=1.09s
20200/10943 (epoch 166.127) train_loss=177.99148560 time/batch=0.94s
20201/10943 (epoch 166.135) train_loss=148.55349731 time/batch=0.75s
20202/10943 (epoch 166.143) train_loss=143.58554077 time/batch=0.71s
20203/10943 (epoch 166.152) train_loss=128.13461304 time/batch=0.65s
20204/10943 (epoch 166.160) train_loss=102.74370575 time/batch=0.61s
20205/10943 (epoch 166.168) train_loss=127.11308289 time/batch=0.62s
20206/10943 (epoch 166.176) train_loss=156.82009888 time/batch=0.75s
20207/10943 (epoch 166.185) train_loss=212.75698853 time/batch=1.00s
20208/10943 (epoch 166.193) train_loss=150.03460693 time/batch=0.77s
20209/10943 (epoch 166.201) train_loss=194.55459595 time/batch=0.95s
20210/10943 (epoch 166.209) train_loss=203.51367188 time/batch=1.01s
20211/10943 (epoch 166.217) train_loss=144.71420288 time/batch=0.79s
20212/10943 (epoch 166.226) train_loss=181.96279907 time/batch=0.81s
20213/10943 (epoch 166.234) train_loss=178.98815918 time/batch=0.90s
20214/10943 (epoch 166.242) train_loss=168.12556458 time/batch=0.83s
20215/10943 (epoch 166.250) train_loss=142.42201233 time/batch=0.74s
20216/10943 (epoch 166.259) train_loss=174.76103210 time/batch=0.82s
20217/10943 (epoch 166.267) train_loss=201.03829956 time/batch=0.93s
20218/10943 (epoch 166.275) train_loss=146.00961304 time/batch=0.79s
20219/10943 (epoch 166.283) train_loss=147.76217651 time/batch=0.81s
20220/10943 (epoch 166.291) train_loss=165.09632874 time/batch=0.84s
20221/10943 (epoch 166.300) train_loss=183.15986633 time/batch=0.99s
20222/10943 (epoch 166.308) train_loss=172.26658630 time/batch=0.87s
20223/10943 (epoch 166.316) train_loss=193.52809143 time/batch=0.91s
20224/10943 (epoch 166.324) train_loss=201.04823303 time/batch=0.98s
20225/10943 (epoch 166.333) train_loss=203.00518799 time/batch=0.90s
20226/10943 (epoch 166.341) train_loss=191.52859497 time/batch=1.01s
setting learning rate to 0.0010331
20227/10943 (epoch 166.349) train_loss=316.91342163 time/batch=1.43s
20228/10943 (epoch 166.357) train_loss=266.94482422 time/batch=1.22s
20229/10943 (epoch 166.365) train_loss=304.93112183 time/batch=1.39s
20230/10943 (epoch 166.374) train_loss=578.37689209 time/batch=2.87s
20231/10943 (epoch 166.382) train_loss=430.70681763 time/batch=2.15s
20232/10943 (epoch 166.390) train_loss=523.79064941 time/batch=3.90s
20233/10943 (epoch 166.398) train_loss=168.21643066 time/batch=1.16s
20234/10943 (epoch 166.407) train_loss=105.59417725 time/batch=0.53s
20235/10943 (epoch 166.415) train_loss=144.08154297 time/batch=0.73s
20236/10943 (epoch 166.423) train_loss=363.12741089 time/batch=1.59s
20237/10943 (epoch 166.431) train_loss=167.29144287 time/batch=0.93s
20238/10943 (epoch 166.439) train_loss=362.73547363 time/batch=1.66s
20239/10943 (epoch 166.448) train_loss=116.43248749 time/batch=0.73s
20240/10943 (epoch 166.456) train_loss=133.33425903 time/batch=0.67s
20241/10943 (epoch 166.464) train_loss=117.87371826 time/batch=0.62s
20242/10943 (epoch 166.472) train_loss=78.00760651 time/batch=0.37s
20243/10943 (epoch 166.481) train_loss=65.02639771 time/batch=0.33s
20244/10943 (epoch 166.489) train_loss=272.83743286 time/batch=1.19s
20245/10943 (epoch 166.497) train_loss=323.07360840 time/batch=1.39s
20246/10943 (epoch 166.505) train_loss=85.49173737 time/batch=0.51s
20247/10943 (epoch 166.513) train_loss=189.34516907 time/batch=0.84s
20248/10943 (epoch 166.522) train_loss=223.96408081 time/batch=1.09s
20249/10943 (epoch 166.530) train_loss=191.14639282 time/batch=0.97s
20250/10943 (epoch 166.538) train_loss=132.94903564 time/batch=0.66s
20251/10943 (epoch 166.546) train_loss=116.72659302 time/batch=0.55s
20252/10943 (epoch 166.555) train_loss=106.95783234 time/batch=0.54s
20253/10943 (epoch 166.563) train_loss=121.12787628 time/batch=0.62s
20254/10943 (epoch 166.571) train_loss=160.46347046 time/batch=0.85s
20255/10943 (epoch 166.579) train_loss=126.89886475 time/batch=0.60s
20256/10943 (epoch 166.588) train_loss=100.64453888 time/batch=0.49s
20257/10943 (epoch 166.596) train_loss=229.21777344 time/batch=1.09s
20258/10943 (epoch 166.604) train_loss=135.62745667 time/batch=0.76s
20259/10943 (epoch 166.612) train_loss=190.09884644 time/batch=0.97s
20260/10943 (epoch 166.620) train_loss=369.69873047 time/batch=1.76s
20261/10943 (epoch 166.629) train_loss=286.01760864 time/batch=1.38s
20262/10943 (epoch 166.637) train_loss=339.66680908 time/batch=1.53s
20263/10943 (epoch 166.645) train_loss=89.13397980 time/batch=0.52s
20264/10943 (epoch 166.653) train_loss=304.05917358 time/batch=1.32s
20265/10943 (epoch 166.662) train_loss=184.06457520 time/batch=0.95s
20266/10943 (epoch 166.670) train_loss=105.42407990 time/batch=0.51s
20267/10943 (epoch 166.678) train_loss=140.75102234 time/batch=0.65s
20268/10943 (epoch 166.686) train_loss=101.02204895 time/batch=0.50s
20269/10943 (epoch 166.694) train_loss=174.19046021 time/batch=0.85s
20270/10943 (epoch 166.703) train_loss=305.36816406 time/batch=1.45s
20271/10943 (epoch 166.711) train_loss=171.26403809 time/batch=0.92s
20272/10943 (epoch 166.719) train_loss=84.32708740 time/batch=0.42s
20273/10943 (epoch 166.727) train_loss=262.10159302 time/batch=1.17s
20274/10943 (epoch 166.736) train_loss=205.21261597 time/batch=1.00s
20275/10943 (epoch 166.744) train_loss=159.39671326 time/batch=0.81s
20276/10943 (epoch 166.752) train_loss=104.90243530 time/batch=0.53s
20277/10943 (epoch 166.760) train_loss=173.82373047 time/batch=0.83s
20278/10943 (epoch 166.768) train_loss=229.71568298 time/batch=1.16s
20279/10943 (epoch 166.777) train_loss=234.68531799 time/batch=1.13s
20280/10943 (epoch 166.785) train_loss=188.41590881 time/batch=0.95s
20281/10943 (epoch 166.793) train_loss=126.78115845 time/batch=0.63s
20282/10943 (epoch 166.801) train_loss=304.05065918 time/batch=1.46s
20283/10943 (epoch 166.810) train_loss=227.09661865 time/batch=1.23s
20284/10943 (epoch 166.818) train_loss=141.33078003 time/batch=0.74s
20285/10943 (epoch 166.826) train_loss=186.69485474 time/batch=0.89s
20286/10943 (epoch 166.834) train_loss=213.67205811 time/batch=1.02s
20287/10943 (epoch 166.842) train_loss=178.18267822 time/batch=0.95s
20288/10943 (epoch 166.851) train_loss=290.21136475 time/batch=1.49s
20289/10943 (epoch 166.859) train_loss=110.69774628 time/batch=0.65s
20290/10943 (epoch 166.867) train_loss=182.73951721 time/batch=0.86s
20291/10943 (epoch 166.875) train_loss=177.34118652 time/batch=0.93s
20292/10943 (epoch 166.884) train_loss=139.34718323 time/batch=0.78s
20293/10943 (epoch 166.892) train_loss=112.32862854 time/batch=0.59s
20294/10943 (epoch 166.900) train_loss=86.46633911 time/batch=0.40s
20295/10943 (epoch 166.908) train_loss=147.46482849 time/batch=0.68s
20296/10943 (epoch 166.916) train_loss=145.36334229 time/batch=0.77s
20297/10943 (epoch 166.925) train_loss=131.18908691 time/batch=0.66s
20298/10943 (epoch 166.933) train_loss=195.68118286 time/batch=0.98s
20299/10943 (epoch 166.941) train_loss=168.54336548 time/batch=0.84s
20300/10943 (epoch 166.949) train_loss=290.15081787 time/batch=1.24s
20301/10943 (epoch 166.958) train_loss=113.81858826 time/batch=0.62s
20302/10943 (epoch 166.966) train_loss=211.30693054 time/batch=1.02s
20303/10943 (epoch 166.974) train_loss=221.01016235 time/batch=1.18s
20304/10943 (epoch 166.982) train_loss=182.30476379 time/batch=0.97s
20305/10943 (epoch 166.990) train_loss=124.19763184 time/batch=0.68s
20306/10943 (epoch 166.999) train_loss=241.78469849 time/batch=1.14s
20307/10943 (epoch 167.007) train_loss=86.47569275 time/batch=0.49s
20308/10943 (epoch 167.015) train_loss=170.65634155 time/batch=0.81s
20309/10943 (epoch 167.023) train_loss=141.46105957 time/batch=0.72s
20310/10943 (epoch 167.032) train_loss=239.92727661 time/batch=1.16s
20311/10943 (epoch 167.040) train_loss=120.15451050 time/batch=0.68s
20312/10943 (epoch 167.048) train_loss=252.75350952 time/batch=1.16s
20313/10943 (epoch 167.056) train_loss=217.30242920 time/batch=1.22s
20314/10943 (epoch 167.065) train_loss=132.57456970 time/batch=0.71s
20315/10943 (epoch 167.073) train_loss=273.37359619 time/batch=1.72s
20316/10943 (epoch 167.081) train_loss=144.65159607 time/batch=0.86s
20317/10943 (epoch 167.089) train_loss=205.72915649 time/batch=1.18s
20318/10943 (epoch 167.097) train_loss=149.21740723 time/batch=0.79s
20319/10943 (epoch 167.106) train_loss=184.58975220 time/batch=0.98s
20320/10943 (epoch 167.114) train_loss=168.44400024 time/batch=0.86s
20321/10943 (epoch 167.122) train_loss=169.11238098 time/batch=0.81s
20322/10943 (epoch 167.130) train_loss=192.40013123 time/batch=0.94s
20323/10943 (epoch 167.139) train_loss=194.32505798 time/batch=1.00s
20324/10943 (epoch 167.147) train_loss=152.14472961 time/batch=0.81s
20325/10943 (epoch 167.155) train_loss=140.81193542 time/batch=0.74s
20326/10943 (epoch 167.163) train_loss=96.86055756 time/batch=0.48s
20327/10943 (epoch 167.171) train_loss=138.00036621 time/batch=0.68s
20328/10943 (epoch 167.180) train_loss=209.73980713 time/batch=1.01s
20329/10943 (epoch 167.188) train_loss=102.24640656 time/batch=0.49s
20330/10943 (epoch 167.196) train_loss=215.53164673 time/batch=0.99s
20331/10943 (epoch 167.204) train_loss=189.01821899 time/batch=1.01s
20332/10943 (epoch 167.213) train_loss=167.57870483 time/batch=0.84s
20333/10943 (epoch 167.221) train_loss=170.90393066 time/batch=0.81s
20334/10943 (epoch 167.229) train_loss=183.81260681 time/batch=0.96s
20335/10943 (epoch 167.237) train_loss=185.61108398 time/batch=0.98s
20336/10943 (epoch 167.245) train_loss=222.99748230 time/batch=1.74s
20337/10943 (epoch 167.254) train_loss=131.91853333 time/batch=0.78s
20338/10943 (epoch 167.262) train_loss=97.15701294 time/batch=0.45s
20339/10943 (epoch 167.270) train_loss=170.93771362 time/batch=0.89s
20340/10943 (epoch 167.278) train_loss=146.64764404 time/batch=0.81s
20341/10943 (epoch 167.287) train_loss=148.49832153 time/batch=0.75s
20342/10943 (epoch 167.295) train_loss=98.17134094 time/batch=0.53s
20343/10943 (epoch 167.303) train_loss=148.31185913 time/batch=0.71s
20344/10943 (epoch 167.311) train_loss=151.89364624 time/batch=0.79s
20345/10943 (epoch 167.319) train_loss=141.60037231 time/batch=0.73s
20346/10943 (epoch 167.328) train_loss=205.63418579 time/batch=1.01s
20347/10943 (epoch 167.336) train_loss=189.11355591 time/batch=1.03s
setting learning rate to 0.0010021
20348/10943 (epoch 167.344) train_loss=345.25701904 time/batch=1.56s
20349/10943 (epoch 167.352) train_loss=211.23596191 time/batch=1.11s
20350/10943 (epoch 167.361) train_loss=102.98894501 time/batch=0.52s
20351/10943 (epoch 167.369) train_loss=142.75402832 time/batch=0.73s
20352/10943 (epoch 167.377) train_loss=225.61508179 time/batch=1.08s
20353/10943 (epoch 167.385) train_loss=368.55749512 time/batch=1.81s
20354/10943 (epoch 167.393) train_loss=358.81488037 time/batch=1.72s
20355/10943 (epoch 167.402) train_loss=117.67127991 time/batch=0.71s
20356/10943 (epoch 167.410) train_loss=82.50361633 time/batch=0.39s
20357/10943 (epoch 167.418) train_loss=140.86766052 time/batch=0.74s
20358/10943 (epoch 167.426) train_loss=393.44366455 time/batch=1.89s
20359/10943 (epoch 167.435) train_loss=104.30023193 time/batch=0.69s
20360/10943 (epoch 167.443) train_loss=218.95503235 time/batch=1.05s
20361/10943 (epoch 167.451) train_loss=96.09888458 time/batch=0.49s
20362/10943 (epoch 167.459) train_loss=113.61518860 time/batch=0.51s
20363/10943 (epoch 167.467) train_loss=105.28547668 time/batch=0.53s
20364/10943 (epoch 167.476) train_loss=91.86775208 time/batch=0.41s
20365/10943 (epoch 167.484) train_loss=150.37561035 time/batch=0.75s
20366/10943 (epoch 167.492) train_loss=344.94192505 time/batch=1.65s
20367/10943 (epoch 167.500) train_loss=625.62329102 time/batch=3.86s
20368/10943 (epoch 167.509) train_loss=211.06643677 time/batch=1.36s
20369/10943 (epoch 167.517) train_loss=318.90704346 time/batch=1.36s
20370/10943 (epoch 167.525) train_loss=265.69671631 time/batch=1.29s
20371/10943 (epoch 167.533) train_loss=99.14637756 time/batch=0.52s
20372/10943 (epoch 167.542) train_loss=124.74449921 time/batch=0.56s
20373/10943 (epoch 167.550) train_loss=219.35800171 time/batch=1.08s
20374/10943 (epoch 167.558) train_loss=113.29070282 time/batch=0.62s
20375/10943 (epoch 167.566) train_loss=67.66534424 time/batch=0.33s
20376/10943 (epoch 167.574) train_loss=135.57073975 time/batch=0.70s
20377/10943 (epoch 167.583) train_loss=180.10476685 time/batch=0.97s
20378/10943 (epoch 167.591) train_loss=168.51785278 time/batch=0.83s
20379/10943 (epoch 167.599) train_loss=90.56496429 time/batch=0.48s
20380/10943 (epoch 167.607) train_loss=189.27540588 time/batch=0.89s
20381/10943 (epoch 167.616) train_loss=467.55651855 time/batch=2.06s
20382/10943 (epoch 167.624) train_loss=144.69581604 time/batch=0.93s
20383/10943 (epoch 167.632) train_loss=172.47274780 time/batch=0.85s
20384/10943 (epoch 167.640) train_loss=314.10128784 time/batch=1.40s
20385/10943 (epoch 167.648) train_loss=203.07443237 time/batch=1.02s
20386/10943 (epoch 167.657) train_loss=182.61883545 time/batch=0.92s
20387/10943 (epoch 167.665) train_loss=130.34713745 time/batch=0.65s
20388/10943 (epoch 167.673) train_loss=287.74407959 time/batch=1.29s
20389/10943 (epoch 167.681) train_loss=192.78945923 time/batch=0.96s
20390/10943 (epoch 167.690) train_loss=154.33621216 time/batch=0.80s
20391/10943 (epoch 167.698) train_loss=136.45356750 time/batch=0.70s
20392/10943 (epoch 167.706) train_loss=276.31552124 time/batch=1.18s
20393/10943 (epoch 167.714) train_loss=178.40832520 time/batch=0.89s
20394/10943 (epoch 167.722) train_loss=154.74940491 time/batch=0.82s
20395/10943 (epoch 167.731) train_loss=119.07643127 time/batch=0.63s
20396/10943 (epoch 167.739) train_loss=219.89535522 time/batch=1.06s
20397/10943 (epoch 167.747) train_loss=169.51449585 time/batch=0.85s
20398/10943 (epoch 167.755) train_loss=249.93463135 time/batch=1.18s
20399/10943 (epoch 167.764) train_loss=137.78967285 time/batch=0.82s
20400/10943 (epoch 167.772) train_loss=183.05633545 time/batch=0.88s
20401/10943 (epoch 167.780) train_loss=174.59835815 time/batch=0.97s
20402/10943 (epoch 167.788) train_loss=246.11807251 time/batch=1.20s
20403/10943 (epoch 167.796) train_loss=127.07080841 time/batch=0.73s
20404/10943 (epoch 167.805) train_loss=181.28341675 time/batch=0.86s
20405/10943 (epoch 167.813) train_loss=156.53192139 time/batch=0.87s
20406/10943 (epoch 167.821) train_loss=266.58596802 time/batch=1.28s
20407/10943 (epoch 167.829) train_loss=194.85368347 time/batch=1.04s
20408/10943 (epoch 167.838) train_loss=166.49879456 time/batch=0.91s
20409/10943 (epoch 167.846) train_loss=121.97422028 time/batch=0.63s
20410/10943 (epoch 167.854) train_loss=129.71757507 time/batch=0.62s
20411/10943 (epoch 167.862) train_loss=134.99533081 time/batch=0.70s
20412/10943 (epoch 167.870) train_loss=283.81188965 time/batch=1.25s
20413/10943 (epoch 167.879) train_loss=127.68069458 time/batch=0.72s
20414/10943 (epoch 167.887) train_loss=87.89916992 time/batch=0.46s
20415/10943 (epoch 167.895) train_loss=252.17118835 time/batch=1.17s
20416/10943 (epoch 167.903) train_loss=325.71578979 time/batch=1.50s
20417/10943 (epoch 167.912) train_loss=131.20379639 time/batch=0.79s
20418/10943 (epoch 167.920) train_loss=318.98400879 time/batch=1.45s
20419/10943 (epoch 167.928) train_loss=226.89093018 time/batch=1.18s
20420/10943 (epoch 167.936) train_loss=166.31228638 time/batch=0.83s
20421/10943 (epoch 167.944) train_loss=186.72445679 time/batch=0.95s
20422/10943 (epoch 167.953) train_loss=125.03121185 time/batch=0.69s
20423/10943 (epoch 167.961) train_loss=90.53464508 time/batch=0.46s
20424/10943 (epoch 167.969) train_loss=161.20745850 time/batch=0.79s
20425/10943 (epoch 167.977) train_loss=144.75671387 time/batch=0.68s
20426/10943 (epoch 167.986) train_loss=220.66931152 time/batch=1.01s
20427/10943 (epoch 167.994) train_loss=205.83383179 time/batch=1.08s
20428/10943 (epoch 168.002) train_loss=235.09341431 time/batch=1.28s
20429/10943 (epoch 168.010) train_loss=147.36836243 time/batch=0.78s
20430/10943 (epoch 168.019) train_loss=111.90377808 time/batch=0.52s
20431/10943 (epoch 168.027) train_loss=144.57829285 time/batch=0.74s
20432/10943 (epoch 168.035) train_loss=268.01300049 time/batch=1.25s
20433/10943 (epoch 168.043) train_loss=178.81336975 time/batch=0.96s
20434/10943 (epoch 168.051) train_loss=101.05487823 time/batch=0.53s
20435/10943 (epoch 168.060) train_loss=97.13321686 time/batch=0.48s
20436/10943 (epoch 168.068) train_loss=111.03388977 time/batch=0.61s
20437/10943 (epoch 168.076) train_loss=188.99743652 time/batch=0.93s
20438/10943 (epoch 168.084) train_loss=103.11755371 time/batch=0.58s
20439/10943 (epoch 168.093) train_loss=305.29098511 time/batch=1.43s
20440/10943 (epoch 168.101) train_loss=139.60823059 time/batch=0.80s
20441/10943 (epoch 168.109) train_loss=209.47360229 time/batch=1.08s
20442/10943 (epoch 168.117) train_loss=205.71923828 time/batch=1.13s
20443/10943 (epoch 168.125) train_loss=250.31719971 time/batch=1.31s
20444/10943 (epoch 168.134) train_loss=165.65628052 time/batch=0.89s
20445/10943 (epoch 168.142) train_loss=80.05598450 time/batch=0.39s
20446/10943 (epoch 168.150) train_loss=80.22680664 time/batch=0.37s
20447/10943 (epoch 168.158) train_loss=175.07678223 time/batch=0.83s
20448/10943 (epoch 168.167) train_loss=186.37060547 time/batch=0.93s
20449/10943 (epoch 168.175) train_loss=203.51394653 time/batch=1.04s
20450/10943 (epoch 168.183) train_loss=156.25024414 time/batch=0.82s
20451/10943 (epoch 168.191) train_loss=177.52322388 time/batch=0.98s
20452/10943 (epoch 168.199) train_loss=259.08389282 time/batch=1.35s
20453/10943 (epoch 168.208) train_loss=126.73541260 time/batch=0.77s
20454/10943 (epoch 168.216) train_loss=196.77316284 time/batch=0.99s
20455/10943 (epoch 168.224) train_loss=200.64038086 time/batch=1.01s
20456/10943 (epoch 168.232) train_loss=184.63201904 time/batch=0.94s
20457/10943 (epoch 168.241) train_loss=97.90835571 time/batch=0.59s
20458/10943 (epoch 168.249) train_loss=184.85443115 time/batch=0.95s
20459/10943 (epoch 168.257) train_loss=163.27035522 time/batch=0.94s
20460/10943 (epoch 168.265) train_loss=161.27813721 time/batch=0.86s
20461/10943 (epoch 168.273) train_loss=127.95550537 time/batch=0.74s
20462/10943 (epoch 168.282) train_loss=203.56135559 time/batch=1.02s
20463/10943 (epoch 168.290) train_loss=148.62283325 time/batch=0.77s
20464/10943 (epoch 168.298) train_loss=109.39962006 time/batch=0.58s
20465/10943 (epoch 168.306) train_loss=154.18951416 time/batch=0.95s
20466/10943 (epoch 168.315) train_loss=143.41004944 time/batch=0.76s
20467/10943 (epoch 168.323) train_loss=139.27033997 time/batch=0.73s
20468/10943 (epoch 168.331) train_loss=165.02133179 time/batch=0.97s
setting learning rate to 0.0009720
20469/10943 (epoch 168.339) train_loss=101.83168030 time/batch=0.52s
20470/10943 (epoch 168.347) train_loss=343.08380127 time/batch=1.51s
20471/10943 (epoch 168.356) train_loss=239.91265869 time/batch=1.27s
20472/10943 (epoch 168.364) train_loss=211.75021362 time/batch=1.13s
20473/10943 (epoch 168.372) train_loss=75.64930725 time/batch=0.40s
20474/10943 (epoch 168.380) train_loss=614.06622314 time/batch=3.72s
20475/10943 (epoch 168.389) train_loss=312.77282715 time/batch=1.75s
20476/10943 (epoch 168.397) train_loss=182.83752441 time/batch=0.97s
20477/10943 (epoch 168.405) train_loss=127.09965515 time/batch=0.72s
20478/10943 (epoch 168.413) train_loss=326.51522827 time/batch=1.45s
20479/10943 (epoch 168.421) train_loss=180.74548340 time/batch=1.03s
20480/10943 (epoch 168.430) train_loss=363.61138916 time/batch=1.84s
20481/10943 (epoch 168.438) train_loss=186.32385254 time/batch=1.11s
20482/10943 (epoch 168.446) train_loss=470.84185791 time/batch=2.07s
20483/10943 (epoch 168.454) train_loss=208.70693970 time/batch=1.20s
20484/10943 (epoch 168.463) train_loss=381.42108154 time/batch=1.90s
20485/10943 (epoch 168.471) train_loss=118.12727356 time/batch=0.77s
20486/10943 (epoch 168.479) train_loss=185.68450928 time/batch=0.97s
20487/10943 (epoch 168.487) train_loss=179.33239746 time/batch=0.91s
20488/10943 (epoch 168.496) train_loss=189.44082642 time/batch=1.06s
20489/10943 (epoch 168.504) train_loss=70.68200684 time/batch=0.41s
20490/10943 (epoch 168.512) train_loss=162.81451416 time/batch=0.80s
20491/10943 (epoch 168.520) train_loss=249.23385620 time/batch=1.22s
20492/10943 (epoch 168.528) train_loss=179.49832153 time/batch=0.99s
20493/10943 (epoch 168.537) train_loss=82.41830444 time/batch=0.43s
20494/10943 (epoch 168.545) train_loss=199.18403625 time/batch=0.97s
20495/10943 (epoch 168.553) train_loss=161.02888489 time/batch=0.82s
20496/10943 (epoch 168.561) train_loss=301.36437988 time/batch=1.40s
20497/10943 (epoch 168.570) train_loss=163.52194214 time/batch=0.96s
20498/10943 (epoch 168.578) train_loss=333.75262451 time/batch=1.59s
20499/10943 (epoch 168.586) train_loss=260.39282227 time/batch=1.38s
20500/10943 (epoch 168.594) train_loss=88.17456818 time/batch=0.54s
20501/10943 (epoch 168.602) train_loss=279.64865112 time/batch=1.20s
20502/10943 (epoch 168.611) train_loss=149.52957153 time/batch=0.85s
20503/10943 (epoch 168.619) train_loss=350.97518921 time/batch=1.64s
20504/10943 (epoch 168.627) train_loss=252.03157043 time/batch=1.26s
20505/10943 (epoch 168.635) train_loss=132.96098328 time/batch=0.68s
20506/10943 (epoch 168.644) train_loss=321.32534790 time/batch=1.32s
20507/10943 (epoch 168.652) train_loss=292.09240723 time/batch=1.71s
20508/10943 (epoch 168.660) train_loss=83.83753204 time/batch=0.54s
20509/10943 (epoch 168.668) train_loss=289.88781738 time/batch=1.30s
20510/10943 (epoch 168.676) train_loss=248.73326111 time/batch=1.24s
20511/10943 (epoch 168.685) train_loss=246.83108521 time/batch=1.20s
20512/10943 (epoch 168.693) train_loss=126.07411194 time/batch=0.73s
20513/10943 (epoch 168.701) train_loss=174.42765808 time/batch=0.94s
20514/10943 (epoch 168.709) train_loss=142.52288818 time/batch=0.70s
20515/10943 (epoch 168.718) train_loss=78.11453247 time/batch=0.40s
20516/10943 (epoch 168.726) train_loss=264.26443481 time/batch=1.21s
20517/10943 (epoch 168.734) train_loss=170.40054321 time/batch=0.88s
20518/10943 (epoch 168.742) train_loss=124.11293030 time/batch=0.66s
20519/10943 (epoch 168.750) train_loss=228.12997437 time/batch=1.17s
20520/10943 (epoch 168.759) train_loss=180.33184814 time/batch=0.94s
20521/10943 (epoch 168.767) train_loss=255.89895630 time/batch=1.20s
20522/10943 (epoch 168.775) train_loss=116.38308716 time/batch=0.72s
20523/10943 (epoch 168.783) train_loss=117.11515045 time/batch=0.58s
20524/10943 (epoch 168.792) train_loss=101.37104797 time/batch=0.51s
20525/10943 (epoch 168.800) train_loss=197.73329163 time/batch=0.93s
20526/10943 (epoch 168.808) train_loss=106.42475891 time/batch=0.56s
20527/10943 (epoch 168.816) train_loss=227.58499146 time/batch=1.06s
20528/10943 (epoch 168.824) train_loss=162.96513367 time/batch=0.85s
20529/10943 (epoch 168.833) train_loss=110.84383392 time/batch=0.56s
20530/10943 (epoch 168.841) train_loss=110.40051270 time/batch=0.54s
20531/10943 (epoch 168.849) train_loss=97.80720520 time/batch=0.44s
20532/10943 (epoch 168.857) train_loss=165.73065186 time/batch=0.88s
20533/10943 (epoch 168.866) train_loss=88.02674866 time/batch=0.45s
20534/10943 (epoch 168.874) train_loss=126.40519714 time/batch=0.60s
20535/10943 (epoch 168.882) train_loss=217.54949951 time/batch=1.09s
20536/10943 (epoch 168.890) train_loss=209.41085815 time/batch=1.09s
20537/10943 (epoch 168.898) train_loss=143.75335693 time/batch=0.81s
20538/10943 (epoch 168.907) train_loss=157.03726196 time/batch=0.81s
20539/10943 (epoch 168.915) train_loss=171.38064575 time/batch=0.82s
20540/10943 (epoch 168.923) train_loss=105.03025818 time/batch=0.57s
20541/10943 (epoch 168.931) train_loss=163.88964844 time/batch=0.82s
20542/10943 (epoch 168.940) train_loss=140.35377502 time/batch=0.72s
20543/10943 (epoch 168.948) train_loss=208.82226562 time/batch=1.06s
20544/10943 (epoch 168.956) train_loss=92.10034943 time/batch=0.51s
20545/10943 (epoch 168.964) train_loss=257.37200928 time/batch=1.29s
20546/10943 (epoch 168.973) train_loss=138.42855835 time/batch=0.79s
20547/10943 (epoch 168.981) train_loss=225.84005737 time/batch=1.07s
20548/10943 (epoch 168.989) train_loss=133.01257324 time/batch=0.78s
20549/10943 (epoch 168.997) train_loss=115.18685913 time/batch=0.65s
20550/10943 (epoch 169.005) train_loss=102.26887512 time/batch=0.50s
20551/10943 (epoch 169.014) train_loss=213.99749756 time/batch=1.08s
20552/10943 (epoch 169.022) train_loss=194.27619934 time/batch=0.91s
20553/10943 (epoch 169.030) train_loss=142.12084961 time/batch=0.74s
20554/10943 (epoch 169.038) train_loss=186.81791687 time/batch=0.91s
20555/10943 (epoch 169.047) train_loss=184.40390015 time/batch=0.97s
20556/10943 (epoch 169.055) train_loss=181.08602905 time/batch=1.00s
20557/10943 (epoch 169.063) train_loss=161.08329773 time/batch=0.83s
20558/10943 (epoch 169.071) train_loss=135.57394409 time/batch=0.71s
20559/10943 (epoch 169.079) train_loss=98.55362701 time/batch=0.48s
20560/10943 (epoch 169.088) train_loss=160.19949341 time/batch=0.80s
20561/10943 (epoch 169.096) train_loss=168.73516846 time/batch=0.85s
20562/10943 (epoch 169.104) train_loss=182.22883606 time/batch=0.99s
20563/10943 (epoch 169.112) train_loss=188.99464417 time/batch=0.95s
20564/10943 (epoch 169.121) train_loss=180.59230042 time/batch=1.01s
20565/10943 (epoch 169.129) train_loss=145.28013611 time/batch=0.83s
20566/10943 (epoch 169.137) train_loss=106.16883850 time/batch=0.55s
20567/10943 (epoch 169.145) train_loss=107.46623230 time/batch=0.54s
20568/10943 (epoch 169.153) train_loss=91.71631622 time/batch=0.46s
20569/10943 (epoch 169.162) train_loss=121.06416321 time/batch=0.57s
20570/10943 (epoch 169.170) train_loss=140.59317017 time/batch=0.74s
20571/10943 (epoch 169.178) train_loss=174.87295532 time/batch=0.89s
20572/10943 (epoch 169.186) train_loss=184.05200195 time/batch=0.98s
20573/10943 (epoch 169.195) train_loss=124.96222687 time/batch=0.67s
20574/10943 (epoch 169.203) train_loss=198.41537476 time/batch=0.98s
20575/10943 (epoch 169.211) train_loss=137.96409607 time/batch=0.77s
20576/10943 (epoch 169.219) train_loss=145.57765198 time/batch=0.75s
20577/10943 (epoch 169.227) train_loss=118.49568176 time/batch=0.59s
20578/10943 (epoch 169.236) train_loss=133.78062439 time/batch=0.71s
20579/10943 (epoch 169.244) train_loss=138.36595154 time/batch=0.70s
20580/10943 (epoch 169.252) train_loss=128.20011902 time/batch=0.68s
20581/10943 (epoch 169.260) train_loss=108.15719604 time/batch=0.64s
20582/10943 (epoch 169.269) train_loss=141.25256348 time/batch=0.79s
20583/10943 (epoch 169.277) train_loss=218.00856018 time/batch=1.02s
20584/10943 (epoch 169.285) train_loss=208.46813965 time/batch=1.04s
20585/10943 (epoch 169.293) train_loss=172.27038574 time/batch=0.88s
20586/10943 (epoch 169.301) train_loss=151.77687073 time/batch=0.75s
20587/10943 (epoch 169.310) train_loss=140.12257385 time/batch=0.75s
20588/10943 (epoch 169.318) train_loss=157.24502563 time/batch=0.85s
20589/10943 (epoch 169.326) train_loss=147.24551392 time/batch=0.86s
setting learning rate to 0.0009429
20590/10943 (epoch 169.334) train_loss=201.48709106 time/batch=1.03s
20591/10943 (epoch 169.343) train_loss=92.01966858 time/batch=0.53s
20592/10943 (epoch 169.351) train_loss=170.79882812 time/batch=0.92s
20593/10943 (epoch 169.359) train_loss=119.23585510 time/batch=0.62s
20594/10943 (epoch 169.367) train_loss=298.69299316 time/batch=1.29s
20595/10943 (epoch 169.375) train_loss=206.32757568 time/batch=1.08s
20596/10943 (epoch 169.384) train_loss=354.13159180 time/batch=1.63s
20597/10943 (epoch 169.392) train_loss=548.60400391 time/batch=2.76s
20598/10943 (epoch 169.400) train_loss=315.06188965 time/batch=1.64s
20599/10943 (epoch 169.408) train_loss=307.70513916 time/batch=1.56s
20600/10943 (epoch 169.417) train_loss=349.65673828 time/batch=1.77s
20601/10943 (epoch 169.425) train_loss=476.46029663 time/batch=2.79s
20602/10943 (epoch 169.433) train_loss=132.27813721 time/batch=0.98s
20603/10943 (epoch 169.441) train_loss=277.66729736 time/batch=1.30s
20604/10943 (epoch 169.449) train_loss=289.46139526 time/batch=1.49s
20605/10943 (epoch 169.458) train_loss=251.37855530 time/batch=1.30s
20606/10943 (epoch 169.466) train_loss=185.44923401 time/batch=1.05s
20607/10943 (epoch 169.474) train_loss=447.13452148 time/batch=3.78s
20608/10943 (epoch 169.482) train_loss=113.87179565 time/batch=0.89s
20609/10943 (epoch 169.491) train_loss=76.02433777 time/batch=0.34s
20610/10943 (epoch 169.499) train_loss=118.63890076 time/batch=0.61s
20611/10943 (epoch 169.507) train_loss=182.87727356 time/batch=0.95s
20612/10943 (epoch 169.515) train_loss=202.33261108 time/batch=1.08s
20613/10943 (epoch 169.524) train_loss=157.90032959 time/batch=0.85s
20614/10943 (epoch 169.532) train_loss=76.30950928 time/batch=0.41s
20615/10943 (epoch 169.540) train_loss=334.79626465 time/batch=1.48s
20616/10943 (epoch 169.548) train_loss=123.42355347 time/batch=0.70s
20617/10943 (epoch 169.556) train_loss=76.66851044 time/batch=0.38s
20618/10943 (epoch 169.565) train_loss=199.51995850 time/batch=1.00s
20619/10943 (epoch 169.573) train_loss=172.81823730 time/batch=0.92s
20620/10943 (epoch 169.581) train_loss=252.91390991 time/batch=1.16s
20621/10943 (epoch 169.589) train_loss=158.89157104 time/batch=0.89s
20622/10943 (epoch 169.598) train_loss=102.07091522 time/batch=0.52s
20623/10943 (epoch 169.606) train_loss=169.16699219 time/batch=0.79s
20624/10943 (epoch 169.614) train_loss=130.86763000 time/batch=0.73s
20625/10943 (epoch 169.622) train_loss=167.92120361 time/batch=0.96s
20626/10943 (epoch 169.630) train_loss=186.99606323 time/batch=1.00s
20627/10943 (epoch 169.639) train_loss=275.18606567 time/batch=1.35s
20628/10943 (epoch 169.647) train_loss=206.13575745 time/batch=1.13s
20629/10943 (epoch 169.655) train_loss=161.68041992 time/batch=0.94s
20630/10943 (epoch 169.663) train_loss=215.77206421 time/batch=1.13s
20631/10943 (epoch 169.672) train_loss=83.30146790 time/batch=0.46s
20632/10943 (epoch 169.680) train_loss=100.79469299 time/batch=0.50s
20633/10943 (epoch 169.688) train_loss=105.87613678 time/batch=0.55s
20634/10943 (epoch 169.696) train_loss=141.80493164 time/batch=0.75s
20635/10943 (epoch 169.704) train_loss=261.33422852 time/batch=1.20s
20636/10943 (epoch 169.713) train_loss=205.79376221 time/batch=1.08s
20637/10943 (epoch 169.721) train_loss=110.25346375 time/batch=0.66s
20638/10943 (epoch 169.729) train_loss=202.74130249 time/batch=1.04s
20639/10943 (epoch 169.737) train_loss=260.63018799 time/batch=1.27s
20640/10943 (epoch 169.746) train_loss=142.50723267 time/batch=0.83s
20641/10943 (epoch 169.754) train_loss=158.43246460 time/batch=0.82s
20642/10943 (epoch 169.762) train_loss=101.27160645 time/batch=0.50s
20643/10943 (epoch 169.770) train_loss=215.76162720 time/batch=1.09s
20644/10943 (epoch 169.778) train_loss=188.90956116 time/batch=0.99s
20645/10943 (epoch 169.787) train_loss=345.21807861 time/batch=1.76s
20646/10943 (epoch 169.795) train_loss=181.82258606 time/batch=1.02s
20647/10943 (epoch 169.803) train_loss=85.77479553 time/batch=0.45s
20648/10943 (epoch 169.811) train_loss=212.15151978 time/batch=1.05s
20649/10943 (epoch 169.820) train_loss=77.12933350 time/batch=0.44s
20650/10943 (epoch 169.828) train_loss=113.92089844 time/batch=0.57s
20651/10943 (epoch 169.836) train_loss=162.19645691 time/batch=0.78s
20652/10943 (epoch 169.844) train_loss=137.87014771 time/batch=0.76s
20653/10943 (epoch 169.852) train_loss=224.04598999 time/batch=1.09s
20654/10943 (epoch 169.861) train_loss=96.77239990 time/batch=0.51s
20655/10943 (epoch 169.869) train_loss=114.25312042 time/batch=0.64s
20656/10943 (epoch 169.877) train_loss=241.66355896 time/batch=1.16s
20657/10943 (epoch 169.885) train_loss=154.51368713 time/batch=0.85s
20658/10943 (epoch 169.894) train_loss=107.08891296 time/batch=0.59s
20659/10943 (epoch 169.902) train_loss=130.94378662 time/batch=0.61s
20660/10943 (epoch 169.910) train_loss=162.58746338 time/batch=0.83s
20661/10943 (epoch 169.918) train_loss=86.52252197 time/batch=0.45s
20662/10943 (epoch 169.926) train_loss=201.53695679 time/batch=0.96s
20663/10943 (epoch 169.935) train_loss=136.67366028 time/batch=0.78s
20664/10943 (epoch 169.943) train_loss=125.46121216 time/batch=0.64s
20665/10943 (epoch 169.951) train_loss=194.62870789 time/batch=0.98s
20666/10943 (epoch 169.959) train_loss=143.33506775 time/batch=0.79s
20667/10943 (epoch 169.968) train_loss=175.80282593 time/batch=0.90s
20668/10943 (epoch 169.976) train_loss=103.23966980 time/batch=0.59s
20669/10943 (epoch 169.984) train_loss=294.07507324 time/batch=1.40s
20670/10943 (epoch 169.992) train_loss=183.03468323 time/batch=1.01s
20671/10943 (epoch 170.001) train_loss=214.79669189 time/batch=1.11s
20672/10943 (epoch 170.009) train_loss=249.33187866 time/batch=1.24s
20673/10943 (epoch 170.017) train_loss=166.52992249 time/batch=0.87s
20674/10943 (epoch 170.025) train_loss=284.33398438 time/batch=1.34s
20675/10943 (epoch 170.033) train_loss=133.54119873 time/batch=0.78s
20676/10943 (epoch 170.042) train_loss=120.56481171 time/batch=0.63s
20677/10943 (epoch 170.050) train_loss=179.22772217 time/batch=1.07s
20678/10943 (epoch 170.058) train_loss=138.65618896 time/batch=0.77s
20679/10943 (epoch 170.066) train_loss=237.84518433 time/batch=1.16s
20680/10943 (epoch 170.075) train_loss=190.56744385 time/batch=0.99s
20681/10943 (epoch 170.083) train_loss=252.53494263 time/batch=1.26s
20682/10943 (epoch 170.091) train_loss=188.96563721 time/batch=1.04s
20683/10943 (epoch 170.099) train_loss=182.65621948 time/batch=1.01s
20684/10943 (epoch 170.107) train_loss=98.51397705 time/batch=0.56s
20685/10943 (epoch 170.116) train_loss=96.93493652 time/batch=0.43s
20686/10943 (epoch 170.124) train_loss=129.54342651 time/batch=0.68s
20687/10943 (epoch 170.132) train_loss=169.86798096 time/batch=0.86s
20688/10943 (epoch 170.140) train_loss=141.40286255 time/batch=0.79s
20689/10943 (epoch 170.149) train_loss=164.54872131 time/batch=0.87s
20690/10943 (epoch 170.157) train_loss=154.89170837 time/batch=0.82s
20691/10943 (epoch 170.165) train_loss=178.47256470 time/batch=0.96s
20692/10943 (epoch 170.173) train_loss=139.72042847 time/batch=0.74s
20693/10943 (epoch 170.181) train_loss=106.35621643 time/batch=0.60s
20694/10943 (epoch 170.190) train_loss=182.64543152 time/batch=0.89s
20695/10943 (epoch 170.198) train_loss=80.99412537 time/batch=0.49s
20696/10943 (epoch 170.206) train_loss=137.62805176 time/batch=0.64s
20697/10943 (epoch 170.214) train_loss=134.44885254 time/batch=0.69s
20698/10943 (epoch 170.223) train_loss=150.63533020 time/batch=0.78s
20699/10943 (epoch 170.231) train_loss=142.45581055 time/batch=0.73s
20700/10943 (epoch 170.239) train_loss=142.96128845 time/batch=0.73s
20701/10943 (epoch 170.247) train_loss=99.19011688 time/batch=0.52s
20702/10943 (epoch 170.255) train_loss=126.45927429 time/batch=0.63s
20703/10943 (epoch 170.264) train_loss=130.83218384 time/batch=0.67s
20704/10943 (epoch 170.272) train_loss=115.49362183 time/batch=0.67s
20705/10943 (epoch 170.280) train_loss=165.54225159 time/batch=0.83s
20706/10943 (epoch 170.288) train_loss=191.77304077 time/batch=0.88s
20707/10943 (epoch 170.297) train_loss=155.89149475 time/batch=0.89s
20708/10943 (epoch 170.305) train_loss=178.20704651 time/batch=0.88s
20709/10943 (epoch 170.313) train_loss=140.12161255 time/batch=0.80s
20710/10943 (epoch 170.321) train_loss=129.43423462 time/batch=0.75s
setting learning rate to 0.0009146
  saved to metadata/lstm_dropout-9_nov_folkwiki-20181112-195023.pkl
20711/10943 (epoch 170.329) train_loss=266.62692261 time/batch=1.31s
20712/10943 (epoch 170.338) train_loss=308.51611328 time/batch=1.52s
20713/10943 (epoch 170.346) train_loss=112.12907410 time/batch=0.70s
20714/10943 (epoch 170.354) train_loss=142.57228088 time/batch=0.83s
20715/10943 (epoch 170.362) train_loss=109.87318420 time/batch=0.57s
20716/10943 (epoch 170.371) train_loss=315.92208862 time/batch=1.50s
20717/10943 (epoch 170.379) train_loss=163.94476318 time/batch=0.92s
20718/10943 (epoch 170.387) train_loss=226.97027588 time/batch=1.16s
20719/10943 (epoch 170.395) train_loss=75.88698578 time/batch=0.46s
20720/10943 (epoch 170.403) train_loss=137.98544312 time/batch=0.74s
20721/10943 (epoch 170.412) train_loss=290.40002441 time/batch=1.39s
20722/10943 (epoch 170.420) train_loss=460.20935059 time/batch=2.13s
20723/10943 (epoch 170.428) train_loss=165.36872864 time/batch=1.05s
20724/10943 (epoch 170.436) train_loss=213.64184570 time/batch=1.14s
20725/10943 (epoch 170.445) train_loss=89.10649109 time/batch=0.51s
20726/10943 (epoch 170.453) train_loss=232.09205627 time/batch=1.13s
20727/10943 (epoch 170.461) train_loss=81.41382599 time/batch=0.47s
20728/10943 (epoch 170.469) train_loss=84.42782593 time/batch=0.42s
20729/10943 (epoch 170.478) train_loss=90.64633179 time/batch=0.43s
20730/10943 (epoch 170.486) train_loss=244.34451294 time/batch=1.20s
20731/10943 (epoch 170.494) train_loss=280.65023804 time/batch=1.35s
20732/10943 (epoch 170.502) train_loss=221.65649414 time/batch=1.20s
20733/10943 (epoch 170.510) train_loss=188.16029358 time/batch=1.09s
20734/10943 (epoch 170.519) train_loss=200.28858948 time/batch=1.08s
20735/10943 (epoch 170.527) train_loss=508.90417480 time/batch=2.56s
20736/10943 (epoch 170.535) train_loss=102.72136688 time/batch=0.72s
20737/10943 (epoch 170.543) train_loss=66.12960815 time/batch=0.33s
20738/10943 (epoch 170.552) train_loss=181.17922974 time/batch=0.90s
20739/10943 (epoch 170.560) train_loss=341.64508057 time/batch=1.74s
20740/10943 (epoch 170.568) train_loss=131.46542358 time/batch=0.80s
20741/10943 (epoch 170.576) train_loss=129.34391785 time/batch=0.71s
20742/10943 (epoch 170.584) train_loss=86.20243835 time/batch=0.42s
20743/10943 (epoch 170.593) train_loss=476.94406128 time/batch=3.71s
20744/10943 (epoch 170.601) train_loss=313.44155884 time/batch=1.82s
20745/10943 (epoch 170.609) train_loss=253.99780273 time/batch=1.22s
20746/10943 (epoch 170.617) train_loss=213.10002136 time/batch=1.11s
20747/10943 (epoch 170.626) train_loss=162.17622375 time/batch=0.88s
20748/10943 (epoch 170.634) train_loss=155.27819824 time/batch=0.80s
20749/10943 (epoch 170.642) train_loss=135.50061035 time/batch=0.74s
20750/10943 (epoch 170.650) train_loss=200.95092773 time/batch=1.05s
20751/10943 (epoch 170.658) train_loss=252.08872986 time/batch=1.25s
20752/10943 (epoch 170.667) train_loss=76.82042694 time/batch=0.44s
20753/10943 (epoch 170.675) train_loss=351.14074707 time/batch=1.69s
20754/10943 (epoch 170.683) train_loss=286.25888062 time/batch=1.48s
20755/10943 (epoch 170.691) train_loss=99.49256897 time/batch=0.64s
20756/10943 (epoch 170.700) train_loss=207.21728516 time/batch=1.03s
20757/10943 (epoch 170.708) train_loss=189.99275208 time/batch=1.06s
20758/10943 (epoch 170.716) train_loss=89.79324341 time/batch=0.50s
20759/10943 (epoch 170.724) train_loss=118.78735352 time/batch=0.60s
20760/10943 (epoch 170.732) train_loss=156.63528442 time/batch=0.83s
20761/10943 (epoch 170.741) train_loss=96.56842041 time/batch=0.52s
20762/10943 (epoch 170.749) train_loss=179.06422424 time/batch=0.90s
20763/10943 (epoch 170.757) train_loss=157.04673767 time/batch=0.85s
20764/10943 (epoch 170.765) train_loss=174.36056519 time/batch=0.99s
20765/10943 (epoch 170.774) train_loss=139.98089600 time/batch=0.79s
20766/10943 (epoch 170.782) train_loss=161.38583374 time/batch=0.92s
20767/10943 (epoch 170.790) train_loss=258.59722900 time/batch=1.28s
20768/10943 (epoch 170.798) train_loss=109.20764160 time/batch=0.64s
20769/10943 (epoch 170.806) train_loss=112.88366699 time/batch=0.59s
20770/10943 (epoch 170.815) train_loss=184.83267212 time/batch=0.96s
20771/10943 (epoch 170.823) train_loss=130.61352539 time/batch=0.76s
20772/10943 (epoch 170.831) train_loss=134.83105469 time/batch=0.69s
20773/10943 (epoch 170.839) train_loss=193.33624268 time/batch=0.93s
20774/10943 (epoch 170.848) train_loss=314.64611816 time/batch=1.35s
20775/10943 (epoch 170.856) train_loss=137.54364014 time/batch=0.78s
20776/10943 (epoch 170.864) train_loss=283.82083130 time/batch=1.35s
20777/10943 (epoch 170.872) train_loss=133.37590027 time/batch=0.76s
20778/10943 (epoch 170.880) train_loss=175.28656006 time/batch=0.97s
20779/10943 (epoch 170.889) train_loss=234.46369934 time/batch=1.20s
20780/10943 (epoch 170.897) train_loss=167.11511230 time/batch=0.91s
20781/10943 (epoch 170.905) train_loss=167.87020874 time/batch=0.88s
20782/10943 (epoch 170.913) train_loss=324.34387207 time/batch=1.57s
20783/10943 (epoch 170.922) train_loss=178.74604797 time/batch=1.00s
20784/10943 (epoch 170.930) train_loss=104.26776123 time/batch=0.54s
20785/10943 (epoch 170.938) train_loss=210.27903748 time/batch=0.98s
20786/10943 (epoch 170.946) train_loss=132.59445190 time/batch=0.74s
20787/10943 (epoch 170.955) train_loss=158.73106384 time/batch=0.80s
20788/10943 (epoch 170.963) train_loss=212.75244141 time/batch=1.09s
20789/10943 (epoch 170.971) train_loss=139.63394165 time/batch=0.80s
20790/10943 (epoch 170.979) train_loss=209.08525085 time/batch=1.03s
20791/10943 (epoch 170.987) train_loss=150.30755615 time/batch=0.81s
20792/10943 (epoch 170.996) train_loss=81.84762573 time/batch=0.48s
20793/10943 (epoch 171.004) train_loss=182.95755005 time/batch=0.94s
20794/10943 (epoch 171.012) train_loss=239.38244629 time/batch=1.22s
20795/10943 (epoch 171.020) train_loss=119.72080231 time/batch=0.72s
20796/10943 (epoch 171.029) train_loss=218.33087158 time/batch=1.18s
20797/10943 (epoch 171.037) train_loss=101.03622437 time/batch=0.60s
20798/10943 (epoch 171.045) train_loss=122.17506409 time/batch=0.62s
20799/10943 (epoch 171.053) train_loss=171.69561768 time/batch=0.90s
20800/10943 (epoch 171.061) train_loss=178.75398254 time/batch=0.97s
20801/10943 (epoch 171.070) train_loss=176.06135559 time/batch=0.89s
20802/10943 (epoch 171.078) train_loss=127.31172943 time/batch=0.65s
20803/10943 (epoch 171.086) train_loss=180.90991211 time/batch=0.95s
20804/10943 (epoch 171.094) train_loss=129.53005981 time/batch=0.72s
20805/10943 (epoch 171.103) train_loss=161.79692078 time/batch=0.81s
20806/10943 (epoch 171.111) train_loss=125.59442139 time/batch=0.65s
20807/10943 (epoch 171.119) train_loss=167.81262207 time/batch=0.86s
20808/10943 (epoch 171.127) train_loss=161.80624390 time/batch=0.85s
20809/10943 (epoch 171.135) train_loss=139.79779053 time/batch=0.76s
20810/10943 (epoch 171.144) train_loss=90.94389343 time/batch=0.48s
20811/10943 (epoch 171.152) train_loss=169.94639587 time/batch=0.94s
20812/10943 (epoch 171.160) train_loss=106.92442322 time/batch=0.58s
20813/10943 (epoch 171.168) train_loss=185.11782837 time/batch=0.86s
20814/10943 (epoch 171.177) train_loss=188.36744690 time/batch=1.03s
20815/10943 (epoch 171.185) train_loss=123.64385986 time/batch=0.68s
20816/10943 (epoch 171.193) train_loss=98.71952820 time/batch=0.55s
20817/10943 (epoch 171.201) train_loss=151.83316040 time/batch=0.77s
20818/10943 (epoch 171.209) train_loss=197.09512329 time/batch=1.09s
20819/10943 (epoch 171.218) train_loss=138.03683472 time/batch=0.76s
20820/10943 (epoch 171.226) train_loss=172.31198120 time/batch=0.88s
20821/10943 (epoch 171.234) train_loss=136.02359009 time/batch=0.73s
20822/10943 (epoch 171.242) train_loss=114.41046143 time/batch=0.59s
20823/10943 (epoch 171.251) train_loss=183.92056274 time/batch=0.96s
20824/10943 (epoch 171.259) train_loss=171.57363892 time/batch=0.93s
20825/10943 (epoch 171.267) train_loss=127.17248535 time/batch=0.74s
20826/10943 (epoch 171.275) train_loss=113.28130341 time/batch=0.58s
20827/10943 (epoch 171.283) train_loss=136.69946289 time/batch=0.74s
20828/10943 (epoch 171.292) train_loss=136.08813477 time/batch=0.74s
20829/10943 (epoch 171.300) train_loss=115.98925781 time/batch=0.61s
20830/10943 (epoch 171.308) train_loss=135.72381592 time/batch=0.76s
20831/10943 (epoch 171.316) train_loss=146.50161743 time/batch=0.89s
setting learning rate to 0.0008871
20832/10943 (epoch 171.325) train_loss=215.21798706 time/batch=1.12s
20833/10943 (epoch 171.333) train_loss=206.73858643 time/batch=1.15s
20834/10943 (epoch 171.341) train_loss=169.59271240 time/batch=0.94s
20835/10943 (epoch 171.349) train_loss=341.13845825 time/batch=1.73s
20836/10943 (epoch 171.357) train_loss=398.16485596 time/batch=2.03s
20837/10943 (epoch 171.366) train_loss=65.81414795 time/batch=0.49s
20838/10943 (epoch 171.374) train_loss=475.87011719 time/batch=2.10s
20839/10943 (epoch 171.382) train_loss=356.53759766 time/batch=2.31s
20840/10943 (epoch 171.390) train_loss=293.16195679 time/batch=1.56s
20841/10943 (epoch 171.399) train_loss=171.27713013 time/batch=0.96s
20842/10943 (epoch 171.407) train_loss=192.86599731 time/batch=1.04s
20843/10943 (epoch 171.415) train_loss=109.25388336 time/batch=0.64s
20844/10943 (epoch 171.423) train_loss=104.24828339 time/batch=0.56s
20845/10943 (epoch 171.432) train_loss=265.35195923 time/batch=1.27s
20846/10943 (epoch 171.440) train_loss=544.11865234 time/batch=3.83s
20847/10943 (epoch 171.448) train_loss=338.14239502 time/batch=1.88s
20848/10943 (epoch 171.456) train_loss=196.66650391 time/batch=1.12s
20849/10943 (epoch 171.464) train_loss=111.69927979 time/batch=0.64s
20850/10943 (epoch 171.473) train_loss=118.12940979 time/batch=0.62s
20851/10943 (epoch 171.481) train_loss=74.59338379 time/batch=0.36s
20852/10943 (epoch 171.489) train_loss=107.83702850 time/batch=0.51s
20853/10943 (epoch 171.497) train_loss=230.70762634 time/batch=1.15s
20854/10943 (epoch 171.506) train_loss=102.21302795 time/batch=0.62s
20855/10943 (epoch 171.514) train_loss=98.53477478 time/batch=0.51s
20856/10943 (epoch 171.522) train_loss=126.64645386 time/batch=0.66s
20857/10943 (epoch 171.530) train_loss=255.71865845 time/batch=1.24s
20858/10943 (epoch 171.538) train_loss=253.47665405 time/batch=1.20s
20859/10943 (epoch 171.547) train_loss=159.18023682 time/batch=0.89s
20860/10943 (epoch 171.555) train_loss=88.58090210 time/batch=0.48s
20861/10943 (epoch 171.563) train_loss=77.07616425 time/batch=0.37s
20862/10943 (epoch 171.571) train_loss=263.97122192 time/batch=1.22s
20863/10943 (epoch 171.580) train_loss=161.93898010 time/batch=0.91s
20864/10943 (epoch 171.588) train_loss=174.02304077 time/batch=0.95s
20865/10943 (epoch 171.596) train_loss=119.95083618 time/batch=0.67s
20866/10943 (epoch 171.604) train_loss=282.54956055 time/batch=1.34s
20867/10943 (epoch 171.612) train_loss=115.80781555 time/batch=0.74s
20868/10943 (epoch 171.621) train_loss=170.64013672 time/batch=0.90s
20869/10943 (epoch 171.629) train_loss=299.79022217 time/batch=1.35s
20870/10943 (epoch 171.637) train_loss=85.02284241 time/batch=0.51s
20871/10943 (epoch 171.645) train_loss=102.01856232 time/batch=0.53s
20872/10943 (epoch 171.654) train_loss=215.77130127 time/batch=1.06s
20873/10943 (epoch 171.662) train_loss=96.82234192 time/batch=0.60s
20874/10943 (epoch 171.670) train_loss=246.54644775 time/batch=1.22s
20875/10943 (epoch 171.678) train_loss=319.50631714 time/batch=1.62s
20876/10943 (epoch 171.686) train_loss=118.64317322 time/batch=0.74s
20877/10943 (epoch 171.695) train_loss=133.97552490 time/batch=0.71s
20878/10943 (epoch 171.703) train_loss=174.66879272 time/batch=0.96s
20879/10943 (epoch 171.711) train_loss=129.34542847 time/batch=0.74s
20880/10943 (epoch 171.719) train_loss=113.69704437 time/batch=0.67s
20881/10943 (epoch 171.728) train_loss=152.82521057 time/batch=0.82s
20882/10943 (epoch 171.736) train_loss=163.56478882 time/batch=0.93s
20883/10943 (epoch 171.744) train_loss=125.90592194 time/batch=0.65s
20884/10943 (epoch 171.752) train_loss=144.61231995 time/batch=0.84s
20885/10943 (epoch 171.760) train_loss=230.06591797 time/batch=1.19s
20886/10943 (epoch 171.769) train_loss=168.67169189 time/batch=1.02s
20887/10943 (epoch 171.777) train_loss=109.43132019 time/batch=0.60s
20888/10943 (epoch 171.785) train_loss=122.37245178 time/batch=0.69s
20889/10943 (epoch 171.793) train_loss=139.41755676 time/batch=0.73s
20890/10943 (epoch 171.802) train_loss=184.29907227 time/batch=0.95s
20891/10943 (epoch 171.810) train_loss=200.15499878 time/batch=1.06s
20892/10943 (epoch 171.818) train_loss=258.05371094 time/batch=1.29s
20893/10943 (epoch 171.826) train_loss=108.68553162 time/batch=0.65s
20894/10943 (epoch 171.834) train_loss=101.87954712 time/batch=0.58s
20895/10943 (epoch 171.843) train_loss=152.18872070 time/batch=0.77s
20896/10943 (epoch 171.851) train_loss=315.76623535 time/batch=1.46s
20897/10943 (epoch 171.859) train_loss=294.44940186 time/batch=1.50s
20898/10943 (epoch 171.867) train_loss=138.49847412 time/batch=0.86s
20899/10943 (epoch 171.876) train_loss=85.36598206 time/batch=0.47s
20900/10943 (epoch 171.884) train_loss=214.59527588 time/batch=1.08s
20901/10943 (epoch 171.892) train_loss=167.54417419 time/batch=0.91s
20902/10943 (epoch 171.900) train_loss=77.95272827 time/batch=0.42s
20903/10943 (epoch 171.909) train_loss=288.21109009 time/batch=1.31s
20904/10943 (epoch 171.917) train_loss=130.91876221 time/batch=0.75s
20905/10943 (epoch 171.925) train_loss=99.93670654 time/batch=0.48s
20906/10943 (epoch 171.933) train_loss=172.23516846 time/batch=0.86s
20907/10943 (epoch 171.941) train_loss=177.63993835 time/batch=0.92s
20908/10943 (epoch 171.950) train_loss=137.79046631 time/batch=0.74s
20909/10943 (epoch 171.958) train_loss=167.54200745 time/batch=0.94s
20910/10943 (epoch 171.966) train_loss=176.03656006 time/batch=0.96s
20911/10943 (epoch 171.974) train_loss=136.83792114 time/batch=0.78s
20912/10943 (epoch 171.983) train_loss=204.30670166 time/batch=1.06s
20913/10943 (epoch 171.991) train_loss=157.26765442 time/batch=0.86s
20914/10943 (epoch 171.999) train_loss=95.55574036 time/batch=0.51s
20915/10943 (epoch 172.007) train_loss=196.83663940 time/batch=0.98s
20916/10943 (epoch 172.015) train_loss=121.70983887 time/batch=0.72s
20917/10943 (epoch 172.024) train_loss=150.45874023 time/batch=0.79s
20918/10943 (epoch 172.032) train_loss=238.29971313 time/batch=1.16s
20919/10943 (epoch 172.040) train_loss=91.42546844 time/batch=0.49s
20920/10943 (epoch 172.048) train_loss=138.91058350 time/batch=0.73s
20921/10943 (epoch 172.057) train_loss=186.30668640 time/batch=0.99s
20922/10943 (epoch 172.065) train_loss=130.37817383 time/batch=0.78s
20923/10943 (epoch 172.073) train_loss=82.99734497 time/batch=0.43s
20924/10943 (epoch 172.081) train_loss=208.79974365 time/batch=1.09s
20925/10943 (epoch 172.089) train_loss=164.60862732 time/batch=0.88s
20926/10943 (epoch 172.098) train_loss=173.79766846 time/batch=0.95s
20927/10943 (epoch 172.106) train_loss=189.54550171 time/batch=1.08s
20928/10943 (epoch 172.114) train_loss=131.72805786 time/batch=0.75s
20929/10943 (epoch 172.122) train_loss=204.24667358 time/batch=1.05s
20930/10943 (epoch 172.131) train_loss=118.78472900 time/batch=0.65s
20931/10943 (epoch 172.139) train_loss=159.11866760 time/batch=0.83s
20932/10943 (epoch 172.147) train_loss=90.24818420 time/batch=0.47s
20933/10943 (epoch 172.155) train_loss=144.85807800 time/batch=0.75s
20934/10943 (epoch 172.163) train_loss=167.07345581 time/batch=0.83s
20935/10943 (epoch 172.172) train_loss=155.64445496 time/batch=0.84s
20936/10943 (epoch 172.180) train_loss=147.01382446 time/batch=0.81s
20937/10943 (epoch 172.188) train_loss=154.82537842 time/batch=0.87s
20938/10943 (epoch 172.196) train_loss=201.11877441 time/batch=1.08s
20939/10943 (epoch 172.205) train_loss=118.49870300 time/batch=0.73s
20940/10943 (epoch 172.213) train_loss=231.45013428 time/batch=1.19s
20941/10943 (epoch 172.221) train_loss=135.22351074 time/batch=0.79s
20942/10943 (epoch 172.229) train_loss=189.70756531 time/batch=1.00s
20943/10943 (epoch 172.237) train_loss=189.26596069 time/batch=1.32s
20944/10943 (epoch 172.246) train_loss=181.34930420 time/batch=1.04s
20945/10943 (epoch 172.254) train_loss=121.20346069 time/batch=0.75s
20946/10943 (epoch 172.262) train_loss=135.07690430 time/batch=0.72s
20947/10943 (epoch 172.270) train_loss=177.14923096 time/batch=0.98s
20948/10943 (epoch 172.279) train_loss=188.78289795 time/batch=0.90s
20949/10943 (epoch 172.287) train_loss=183.57394409 time/batch=1.01s
20950/10943 (epoch 172.295) train_loss=110.76026917 time/batch=0.78s
20951/10943 (epoch 172.303) train_loss=131.95364380 time/batch=0.77s
20952/10943 (epoch 172.311) train_loss=144.23226929 time/batch=0.88s
setting learning rate to 0.0008605
20953/10943 (epoch 172.320) train_loss=295.24261475 time/batch=1.35s
20954/10943 (epoch 172.328) train_loss=335.01898193 time/batch=1.80s
20955/10943 (epoch 172.336) train_loss=259.90765381 time/batch=1.33s
20956/10943 (epoch 172.344) train_loss=334.94973755 time/batch=1.65s
20957/10943 (epoch 172.353) train_loss=589.95837402 time/batch=3.89s
20958/10943 (epoch 172.361) train_loss=105.22297668 time/batch=0.98s
20959/10943 (epoch 172.369) train_loss=115.84123230 time/batch=0.69s
20960/10943 (epoch 172.377) train_loss=63.27527618 time/batch=0.34s
20961/10943 (epoch 172.386) train_loss=290.74810791 time/batch=1.35s
20962/10943 (epoch 172.394) train_loss=98.13578796 time/batch=0.61s
20963/10943 (epoch 172.402) train_loss=177.25930786 time/batch=0.88s
20964/10943 (epoch 172.410) train_loss=165.12902832 time/batch=0.99s
20965/10943 (epoch 172.418) train_loss=454.33959961 time/batch=2.08s
20966/10943 (epoch 172.427) train_loss=84.71990204 time/batch=0.64s
20967/10943 (epoch 172.435) train_loss=114.56352234 time/batch=0.60s
20968/10943 (epoch 172.443) train_loss=107.30126953 time/batch=0.56s
20969/10943 (epoch 172.451) train_loss=295.49438477 time/batch=1.47s
20970/10943 (epoch 172.460) train_loss=363.05007935 time/batch=1.97s
20971/10943 (epoch 172.468) train_loss=92.38285828 time/batch=0.65s
20972/10943 (epoch 172.476) train_loss=265.18194580 time/batch=1.27s
20973/10943 (epoch 172.484) train_loss=93.20627594 time/batch=0.59s
20974/10943 (epoch 172.492) train_loss=115.56871796 time/batch=0.62s
20975/10943 (epoch 172.501) train_loss=168.82034302 time/batch=0.98s
20976/10943 (epoch 172.509) train_loss=123.99368286 time/batch=0.76s
20977/10943 (epoch 172.517) train_loss=167.44424438 time/batch=0.94s
20978/10943 (epoch 172.525) train_loss=349.22467041 time/batch=1.67s
20979/10943 (epoch 172.534) train_loss=226.84295654 time/batch=1.32s
20980/10943 (epoch 172.542) train_loss=253.75291443 time/batch=1.29s
20981/10943 (epoch 172.550) train_loss=158.34954834 time/batch=0.88s
20982/10943 (epoch 172.558) train_loss=90.58225250 time/batch=0.46s
20983/10943 (epoch 172.566) train_loss=262.67105103 time/batch=1.31s
20984/10943 (epoch 172.575) train_loss=128.24639893 time/batch=0.84s
20985/10943 (epoch 172.583) train_loss=232.22189331 time/batch=1.18s
20986/10943 (epoch 172.591) train_loss=75.12422180 time/batch=0.44s
20987/10943 (epoch 172.599) train_loss=75.99444580 time/batch=0.37s
20988/10943 (epoch 172.608) train_loss=101.37216187 time/batch=0.52s
20989/10943 (epoch 172.616) train_loss=114.50950623 time/batch=0.60s
20990/10943 (epoch 172.624) train_loss=101.05551147 time/batch=0.57s
20991/10943 (epoch 172.632) train_loss=106.09934235 time/batch=0.58s
20992/10943 (epoch 172.640) train_loss=289.07647705 time/batch=1.39s
20993/10943 (epoch 172.649) train_loss=118.42304230 time/batch=0.68s
20994/10943 (epoch 172.657) train_loss=78.48325348 time/batch=0.41s
20995/10943 (epoch 172.665) train_loss=83.83469391 time/batch=0.40s
20996/10943 (epoch 172.673) train_loss=233.89471436 time/batch=1.14s
20997/10943 (epoch 172.682) train_loss=130.78717041 time/batch=0.76s
20998/10943 (epoch 172.690) train_loss=98.13206482 time/batch=0.48s
20999/10943 (epoch 172.698) train_loss=106.48533630 time/batch=0.53s
Validating
    loss:	205.422457

21000/10943 (epoch 172.706) train_loss=92.08259583 time/batch=2.99s
21001/10943 (epoch 172.714) train_loss=176.11810303 time/batch=0.87s
21002/10943 (epoch 172.723) train_loss=146.39230347 time/batch=0.86s
21003/10943 (epoch 172.731) train_loss=178.01501465 time/batch=0.97s
21004/10943 (epoch 172.739) train_loss=242.16116333 time/batch=1.29s
21005/10943 (epoch 172.747) train_loss=158.32559204 time/batch=0.87s
21006/10943 (epoch 172.756) train_loss=112.61332703 time/batch=0.61s
21007/10943 (epoch 172.764) train_loss=140.30172729 time/batch=0.77s
21008/10943 (epoch 172.772) train_loss=121.40306854 time/batch=0.63s
21009/10943 (epoch 172.780) train_loss=134.27510071 time/batch=0.70s
21010/10943 (epoch 172.788) train_loss=292.11767578 time/batch=1.44s
21011/10943 (epoch 172.797) train_loss=132.56219482 time/batch=0.76s
21012/10943 (epoch 172.805) train_loss=181.65200806 time/batch=0.89s
21013/10943 (epoch 172.813) train_loss=189.59225464 time/batch=1.07s
21014/10943 (epoch 172.821) train_loss=80.08189392 time/batch=0.45s
21015/10943 (epoch 172.830) train_loss=155.07571411 time/batch=0.79s
21016/10943 (epoch 172.838) train_loss=158.56149292 time/batch=0.94s
21017/10943 (epoch 172.846) train_loss=200.96237183 time/batch=1.09s
21018/10943 (epoch 172.854) train_loss=174.00289917 time/batch=0.97s
21019/10943 (epoch 172.863) train_loss=87.09439850 time/batch=0.50s
21020/10943 (epoch 172.871) train_loss=84.47335052 time/batch=0.46s
21021/10943 (epoch 172.879) train_loss=104.17692566 time/batch=0.60s
21022/10943 (epoch 172.887) train_loss=97.83843994 time/batch=0.52s
21023/10943 (epoch 172.895) train_loss=120.36177063 time/batch=0.62s
21024/10943 (epoch 172.904) train_loss=156.63482666 time/batch=0.82s
21025/10943 (epoch 172.912) train_loss=140.36621094 time/batch=0.78s
21026/10943 (epoch 172.920) train_loss=176.17541504 time/batch=0.94s
21027/10943 (epoch 172.928) train_loss=116.72615051 time/batch=0.69s
21028/10943 (epoch 172.937) train_loss=207.25897217 time/batch=1.06s
21029/10943 (epoch 172.945) train_loss=202.51486206 time/batch=1.07s
21030/10943 (epoch 172.953) train_loss=150.97952271 time/batch=0.82s
21031/10943 (epoch 172.961) train_loss=160.99458313 time/batch=0.86s
21032/10943 (epoch 172.969) train_loss=124.98573303 time/batch=0.72s
21033/10943 (epoch 172.978) train_loss=208.81115723 time/batch=1.11s
21034/10943 (epoch 172.986) train_loss=247.91653442 time/batch=1.19s
21035/10943 (epoch 172.994) train_loss=282.95870972 time/batch=1.48s
21036/10943 (epoch 173.002) train_loss=196.22088623 time/batch=1.08s
21037/10943 (epoch 173.011) train_loss=140.60015869 time/batch=0.80s
21038/10943 (epoch 173.019) train_loss=284.53222656 time/batch=1.46s
21039/10943 (epoch 173.027) train_loss=159.98780823 time/batch=0.92s
21040/10943 (epoch 173.035) train_loss=219.87849426 time/batch=1.16s
21041/10943 (epoch 173.043) train_loss=183.50811768 time/batch=1.04s
21042/10943 (epoch 173.052) train_loss=179.40417480 time/batch=0.97s
21043/10943 (epoch 173.060) train_loss=150.96037292 time/batch=0.82s
21044/10943 (epoch 173.068) train_loss=135.31718445 time/batch=0.75s
21045/10943 (epoch 173.076) train_loss=129.12548828 time/batch=0.77s
21046/10943 (epoch 173.085) train_loss=209.81030273 time/batch=1.17s
21047/10943 (epoch 173.093) train_loss=216.94406128 time/batch=1.15s
21048/10943 (epoch 173.101) train_loss=186.01119995 time/batch=0.90s
21049/10943 (epoch 173.109) train_loss=147.82902527 time/batch=0.82s
21050/10943 (epoch 173.117) train_loss=212.25482178 time/batch=1.06s
21051/10943 (epoch 173.126) train_loss=127.86495972 time/batch=0.72s
21052/10943 (epoch 173.134) train_loss=158.92904663 time/batch=0.84s
21053/10943 (epoch 173.142) train_loss=181.34025574 time/batch=0.98s
21054/10943 (epoch 173.150) train_loss=185.27250671 time/batch=1.04s
21055/10943 (epoch 173.159) train_loss=171.00125122 time/batch=1.00s
21056/10943 (epoch 173.167) train_loss=160.33428955 time/batch=0.97s
21057/10943 (epoch 173.175) train_loss=206.15841675 time/batch=1.03s
21058/10943 (epoch 173.183) train_loss=137.28674316 time/batch=0.77s
21059/10943 (epoch 173.191) train_loss=138.03930664 time/batch=0.72s
21060/10943 (epoch 173.200) train_loss=195.39064026 time/batch=1.05s
21061/10943 (epoch 173.208) train_loss=169.01290894 time/batch=1.01s
21062/10943 (epoch 173.216) train_loss=121.51278687 time/batch=0.72s
21063/10943 (epoch 173.224) train_loss=133.26188660 time/batch=0.72s
21064/10943 (epoch 173.233) train_loss=202.30215454 time/batch=1.08s
21065/10943 (epoch 173.241) train_loss=140.83013916 time/batch=0.79s
21066/10943 (epoch 173.249) train_loss=177.24237061 time/batch=1.02s
21067/10943 (epoch 173.257) train_loss=161.22756958 time/batch=0.88s
21068/10943 (epoch 173.265) train_loss=167.45518494 time/batch=0.88s
21069/10943 (epoch 173.274) train_loss=168.89379883 time/batch=1.03s
21070/10943 (epoch 173.282) train_loss=138.66574097 time/batch=0.78s
21071/10943 (epoch 173.290) train_loss=143.31881714 time/batch=0.79s
21072/10943 (epoch 173.298) train_loss=174.10690308 time/batch=0.88s
21073/10943 (epoch 173.307) train_loss=127.70247650 time/batch=0.76s
setting learning rate to 0.0008347
21074/10943 (epoch 173.315) train_loss=98.46089172 time/batch=0.55s
21075/10943 (epoch 173.323) train_loss=161.49661255 time/batch=0.95s
21076/10943 (epoch 173.331) train_loss=449.70495605 time/batch=2.04s
21077/10943 (epoch 173.340) train_loss=158.71926880 time/batch=1.03s
21078/10943 (epoch 173.348) train_loss=254.86547852 time/batch=1.22s
21079/10943 (epoch 173.356) train_loss=84.83386993 time/batch=0.48s
21080/10943 (epoch 173.364) train_loss=333.51159668 time/batch=1.53s
21081/10943 (epoch 173.372) train_loss=282.42910767 time/batch=1.49s
21082/10943 (epoch 173.381) train_loss=75.38400269 time/batch=0.47s
21083/10943 (epoch 173.389) train_loss=77.84078979 time/batch=0.40s
21084/10943 (epoch 173.397) train_loss=101.11836243 time/batch=0.55s
21085/10943 (epoch 173.405) train_loss=182.56341553 time/batch=1.02s
21086/10943 (epoch 173.414) train_loss=445.50027466 time/batch=2.40s
21087/10943 (epoch 173.422) train_loss=357.51162720 time/batch=1.98s
21088/10943 (epoch 173.430) train_loss=164.60223389 time/batch=0.96s
21089/10943 (epoch 173.438) train_loss=344.38159180 time/batch=2.48s
21090/10943 (epoch 173.446) train_loss=295.49743652 time/batch=1.71s
21091/10943 (epoch 173.455) train_loss=146.14787292 time/batch=0.92s
21092/10943 (epoch 173.463) train_loss=146.33320618 time/batch=0.82s
21093/10943 (epoch 173.471) train_loss=72.65787506 time/batch=0.40s
21094/10943 (epoch 173.479) train_loss=94.71016693 time/batch=0.47s
21095/10943 (epoch 173.488) train_loss=146.11601257 time/batch=0.78s
21096/10943 (epoch 173.496) train_loss=105.42354584 time/batch=0.58s
21097/10943 (epoch 173.504) train_loss=269.09295654 time/batch=1.32s
21098/10943 (epoch 173.512) train_loss=92.75238037 time/batch=0.58s
21099/10943 (epoch 173.520) train_loss=263.14245605 time/batch=1.28s
21100/10943 (epoch 173.529) train_loss=299.66363525 time/batch=1.56s
21101/10943 (epoch 173.537) train_loss=75.46760559 time/batch=0.50s
21102/10943 (epoch 173.545) train_loss=180.99578857 time/batch=0.83s
21103/10943 (epoch 173.553) train_loss=122.85243225 time/batch=0.65s
21104/10943 (epoch 173.562) train_loss=196.80253601 time/batch=1.01s
21105/10943 (epoch 173.570) train_loss=241.76885986 time/batch=1.18s
21106/10943 (epoch 173.578) train_loss=474.45004272 time/batch=3.84s
21107/10943 (epoch 173.586) train_loss=150.61495972 time/batch=1.15s
21108/10943 (epoch 173.594) train_loss=94.19823456 time/batch=0.51s
21109/10943 (epoch 173.603) train_loss=173.03729248 time/batch=0.93s
21110/10943 (epoch 173.611) train_loss=202.32626343 time/batch=1.15s
21111/10943 (epoch 173.619) train_loss=164.68951416 time/batch=0.92s
21112/10943 (epoch 173.627) train_loss=182.60012817 time/batch=1.06s
21113/10943 (epoch 173.636) train_loss=110.10813904 time/batch=0.64s
21114/10943 (epoch 173.644) train_loss=139.99476624 time/batch=0.76s
21115/10943 (epoch 173.652) train_loss=153.00256348 time/batch=0.84s
21116/10943 (epoch 173.660) train_loss=288.63476562 time/batch=1.32s
21117/10943 (epoch 173.668) train_loss=284.00433350 time/batch=1.57s
21118/10943 (epoch 173.677) train_loss=278.78189087 time/batch=1.45s
21119/10943 (epoch 173.685) train_loss=130.62170410 time/batch=0.79s
21120/10943 (epoch 173.693) train_loss=97.25702667 time/batch=0.53s
21121/10943 (epoch 173.701) train_loss=155.00782776 time/batch=0.83s
21122/10943 (epoch 173.710) train_loss=83.71379089 time/batch=0.49s
21123/10943 (epoch 173.718) train_loss=205.06896973 time/batch=1.12s
21124/10943 (epoch 173.726) train_loss=195.69844055 time/batch=1.09s
21125/10943 (epoch 173.734) train_loss=88.87121582 time/batch=0.49s
21126/10943 (epoch 173.742) train_loss=106.83037567 time/batch=0.54s
21127/10943 (epoch 173.751) train_loss=116.16312408 time/batch=0.65s
21128/10943 (epoch 173.759) train_loss=190.97882080 time/batch=0.99s
21129/10943 (epoch 173.767) train_loss=134.62823486 time/batch=0.78s
21130/10943 (epoch 173.775) train_loss=113.72392273 time/batch=0.65s
21131/10943 (epoch 173.784) train_loss=233.20449829 time/batch=1.14s
21132/10943 (epoch 173.792) train_loss=165.37014771 time/batch=1.01s
21133/10943 (epoch 173.800) train_loss=154.05749512 time/batch=0.95s
21134/10943 (epoch 173.808) train_loss=108.17087555 time/batch=0.64s
21135/10943 (epoch 173.816) train_loss=203.12823486 time/batch=1.07s
21136/10943 (epoch 173.825) train_loss=97.96664429 time/batch=0.56s
21137/10943 (epoch 173.833) train_loss=105.99510193 time/batch=0.57s
21138/10943 (epoch 173.841) train_loss=181.44969177 time/batch=1.00s
21139/10943 (epoch 173.849) train_loss=182.06726074 time/batch=0.99s
21140/10943 (epoch 173.858) train_loss=224.34809875 time/batch=1.21s
21141/10943 (epoch 173.866) train_loss=252.41140747 time/batch=1.45s
21142/10943 (epoch 173.874) train_loss=138.40744019 time/batch=0.83s
21143/10943 (epoch 173.882) train_loss=127.62495422 time/batch=0.69s
21144/10943 (epoch 173.891) train_loss=112.27337646 time/batch=0.69s
21145/10943 (epoch 173.899) train_loss=110.63090515 time/batch=0.59s
21146/10943 (epoch 173.907) train_loss=245.88096619 time/batch=1.22s
21147/10943 (epoch 173.915) train_loss=214.41217041 time/batch=1.17s
21148/10943 (epoch 173.923) train_loss=191.38623047 time/batch=1.03s
21149/10943 (epoch 173.932) train_loss=83.63577271 time/batch=0.48s
21150/10943 (epoch 173.940) train_loss=132.62577820 time/batch=0.70s
21151/10943 (epoch 173.948) train_loss=110.69185638 time/batch=0.62s
21152/10943 (epoch 173.956) train_loss=166.43981934 time/batch=0.87s
21153/10943 (epoch 173.965) train_loss=130.58183289 time/batch=0.69s
21154/10943 (epoch 173.973) train_loss=114.01338196 time/batch=0.65s
21155/10943 (epoch 173.981) train_loss=100.46824646 time/batch=0.60s
21156/10943 (epoch 173.989) train_loss=120.92864990 time/batch=0.67s
21157/10943 (epoch 173.997) train_loss=65.30755615 time/batch=0.40s
21158/10943 (epoch 174.006) train_loss=159.41963196 time/batch=0.80s
21159/10943 (epoch 174.014) train_loss=169.24645996 time/batch=0.98s
21160/10943 (epoch 174.022) train_loss=122.51272583 time/batch=0.78s
21161/10943 (epoch 174.030) train_loss=173.55557251 time/batch=0.91s
21162/10943 (epoch 174.039) train_loss=152.78509521 time/batch=0.87s
21163/10943 (epoch 174.047) train_loss=163.86059570 time/batch=0.89s
21164/10943 (epoch 174.055) train_loss=211.20199585 time/batch=1.13s
21165/10943 (epoch 174.063) train_loss=191.57148743 time/batch=1.04s
21166/10943 (epoch 174.071) train_loss=230.82336426 time/batch=1.24s
21167/10943 (epoch 174.080) train_loss=146.46298218 time/batch=0.84s
21168/10943 (epoch 174.088) train_loss=88.66616058 time/batch=0.54s
21169/10943 (epoch 174.096) train_loss=127.95127869 time/batch=0.71s
21170/10943 (epoch 174.104) train_loss=243.49548340 time/batch=1.22s
21171/10943 (epoch 174.113) train_loss=174.61801147 time/batch=0.98s
21172/10943 (epoch 174.121) train_loss=180.24121094 time/batch=0.92s
21173/10943 (epoch 174.129) train_loss=132.59596252 time/batch=0.74s
21174/10943 (epoch 174.137) train_loss=126.49502563 time/batch=0.76s
21175/10943 (epoch 174.145) train_loss=169.55941772 time/batch=0.90s
21176/10943 (epoch 174.154) train_loss=131.62821960 time/batch=0.73s
21177/10943 (epoch 174.162) train_loss=195.41873169 time/batch=1.05s
21178/10943 (epoch 174.170) train_loss=139.36137390 time/batch=0.78s
21179/10943 (epoch 174.178) train_loss=177.31640625 time/batch=1.00s
21180/10943 (epoch 174.187) train_loss=137.97949219 time/batch=0.76s
21181/10943 (epoch 174.195) train_loss=156.18664551 time/batch=0.83s
21182/10943 (epoch 174.203) train_loss=112.10438538 time/batch=0.62s
21183/10943 (epoch 174.211) train_loss=176.91244507 time/batch=1.03s
21184/10943 (epoch 174.219) train_loss=142.00752258 time/batch=0.90s
21185/10943 (epoch 174.228) train_loss=110.48878479 time/batch=0.70s
21186/10943 (epoch 174.236) train_loss=213.36984253 time/batch=1.22s
21187/10943 (epoch 174.244) train_loss=143.23458862 time/batch=0.86s
21188/10943 (epoch 174.252) train_loss=127.60540009 time/batch=0.71s
21189/10943 (epoch 174.261) train_loss=215.84411621 time/batch=1.23s
21190/10943 (epoch 174.269) train_loss=129.14353943 time/batch=0.82s
21191/10943 (epoch 174.277) train_loss=166.68457031 time/batch=0.94s
21192/10943 (epoch 174.285) train_loss=167.31579590 time/batch=0.98s
21193/10943 (epoch 174.293) train_loss=121.28623962 time/batch=0.80s
21194/10943 (epoch 174.302) train_loss=137.12173462 time/batch=0.96s
setting learning rate to 0.0008097
21195/10943 (epoch 174.310) train_loss=306.74810791 time/batch=1.56s
21196/10943 (epoch 174.318) train_loss=502.09960938 time/batch=2.76s
21197/10943 (epoch 174.326) train_loss=65.32115173 time/batch=0.59s
21198/10943 (epoch 174.335) train_loss=73.88320160 time/batch=0.36s
21199/10943 (epoch 174.343) train_loss=171.94026184 time/batch=0.92s
21200/10943 (epoch 174.351) train_loss=112.82307434 time/batch=0.67s
21201/10943 (epoch 174.359) train_loss=101.68977356 time/batch=0.52s
21202/10943 (epoch 174.368) train_loss=325.73034668 time/batch=1.56s
21203/10943 (epoch 174.376) train_loss=253.82138062 time/batch=1.29s
21204/10943 (epoch 174.384) train_loss=274.69201660 time/batch=1.45s
21205/10943 (epoch 174.392) train_loss=172.45046997 time/batch=1.06s
21206/10943 (epoch 174.400) train_loss=374.19763184 time/batch=1.94s
21207/10943 (epoch 174.409) train_loss=133.09515381 time/batch=0.89s
21208/10943 (epoch 174.417) train_loss=222.94036865 time/batch=1.17s
21209/10943 (epoch 174.425) train_loss=145.62513733 time/batch=0.85s
21210/10943 (epoch 174.433) train_loss=169.80680847 time/batch=0.91s
21211/10943 (epoch 174.442) train_loss=167.39050293 time/batch=1.00s
21212/10943 (epoch 174.450) train_loss=282.20983887 time/batch=1.35s
21213/10943 (epoch 174.458) train_loss=84.69480896 time/batch=0.54s
21214/10943 (epoch 174.466) train_loss=168.67456055 time/batch=0.86s
21215/10943 (epoch 174.474) train_loss=187.09452820 time/batch=1.02s
21216/10943 (epoch 174.483) train_loss=90.41368866 time/batch=0.54s
21217/10943 (epoch 174.491) train_loss=157.52584839 time/batch=0.80s
21218/10943 (epoch 174.499) train_loss=118.89568329 time/batch=0.66s
21219/10943 (epoch 174.507) train_loss=323.75634766 time/batch=1.68s
21220/10943 (epoch 174.516) train_loss=155.90313721 time/batch=1.02s
21221/10943 (epoch 174.524) train_loss=168.78994751 time/batch=0.99s
21222/10943 (epoch 174.532) train_loss=225.14434814 time/batch=1.18s
21223/10943 (epoch 174.540) train_loss=440.72409058 time/batch=2.84s
21224/10943 (epoch 174.548) train_loss=119.06439209 time/batch=0.83s
21225/10943 (epoch 174.557) train_loss=311.33825684 time/batch=1.57s
21226/10943 (epoch 174.565) train_loss=99.48280334 time/batch=0.66s
21227/10943 (epoch 174.573) train_loss=76.24241638 time/batch=0.37s
21228/10943 (epoch 174.581) train_loss=255.76300049 time/batch=1.29s
21229/10943 (epoch 174.590) train_loss=221.02148438 time/batch=1.27s
21230/10943 (epoch 174.598) train_loss=168.62904358 time/batch=0.91s
21231/10943 (epoch 174.606) train_loss=292.35052490 time/batch=1.46s
21232/10943 (epoch 174.614) train_loss=243.74464417 time/batch=1.35s
21233/10943 (epoch 174.622) train_loss=238.57141113 time/batch=1.29s
21234/10943 (epoch 174.631) train_loss=88.13168335 time/batch=0.51s
21235/10943 (epoch 174.639) train_loss=96.18072510 time/batch=0.46s
21236/10943 (epoch 174.647) train_loss=289.31475830 time/batch=1.37s
21237/10943 (epoch 174.655) train_loss=190.29568481 time/batch=1.13s
21238/10943 (epoch 174.664) train_loss=82.83145905 time/batch=0.49s
21239/10943 (epoch 174.672) train_loss=106.81382751 time/batch=0.64s
21240/10943 (epoch 174.680) train_loss=150.30625916 time/batch=0.83s
21241/10943 (epoch 174.688) train_loss=358.70916748 time/batch=3.75s
21242/10943 (epoch 174.696) train_loss=167.29736328 time/batch=1.22s
21243/10943 (epoch 174.705) train_loss=150.41876221 time/batch=0.82s
21244/10943 (epoch 174.713) train_loss=121.91931152 time/batch=0.70s
21245/10943 (epoch 174.721) train_loss=153.15199280 time/batch=0.84s
21246/10943 (epoch 174.729) train_loss=133.51113892 time/batch=0.69s
21247/10943 (epoch 174.738) train_loss=130.66470337 time/batch=0.74s
21248/10943 (epoch 174.746) train_loss=203.61013794 time/batch=1.12s
21249/10943 (epoch 174.754) train_loss=132.18278503 time/batch=0.76s
21250/10943 (epoch 174.762) train_loss=108.28217316 time/batch=0.55s
21251/10943 (epoch 174.770) train_loss=124.04916382 time/batch=0.75s
21252/10943 (epoch 174.779) train_loss=127.25638580 time/batch=0.76s
21253/10943 (epoch 174.787) train_loss=87.94411469 time/batch=0.48s
21254/10943 (epoch 174.795) train_loss=171.01248169 time/batch=0.93s
21255/10943 (epoch 174.803) train_loss=138.29882812 time/batch=0.78s
21256/10943 (epoch 174.812) train_loss=169.25440979 time/batch=0.93s
21257/10943 (epoch 174.820) train_loss=138.24150085 time/batch=0.81s
21258/10943 (epoch 174.828) train_loss=231.18756104 time/batch=1.23s
21259/10943 (epoch 174.836) train_loss=160.68701172 time/batch=1.05s
21260/10943 (epoch 174.845) train_loss=122.37172699 time/batch=0.77s
21261/10943 (epoch 174.853) train_loss=93.52975464 time/batch=0.53s
21262/10943 (epoch 174.861) train_loss=91.10717773 time/batch=0.51s
21263/10943 (epoch 174.869) train_loss=147.64141846 time/batch=0.81s
21264/10943 (epoch 174.877) train_loss=194.13285828 time/batch=1.04s
21265/10943 (epoch 174.886) train_loss=152.86526489 time/batch=0.85s
21266/10943 (epoch 174.894) train_loss=269.64044189 time/batch=1.33s
21267/10943 (epoch 174.902) train_loss=127.45553589 time/batch=0.83s
21268/10943 (epoch 174.910) train_loss=117.55734253 time/batch=0.71s
21269/10943 (epoch 174.919) train_loss=76.85673523 time/batch=0.41s
21270/10943 (epoch 174.927) train_loss=215.26071167 time/batch=1.06s
21271/10943 (epoch 174.935) train_loss=168.08174133 time/batch=0.98s
21272/10943 (epoch 174.943) train_loss=112.55262756 time/batch=0.69s
21273/10943 (epoch 174.951) train_loss=205.56393433 time/batch=1.09s
21274/10943 (epoch 174.960) train_loss=120.30897522 time/batch=0.71s
21275/10943 (epoch 174.968) train_loss=188.58549500 time/batch=1.02s
21276/10943 (epoch 174.976) train_loss=127.39033508 time/batch=0.77s
21277/10943 (epoch 174.984) train_loss=102.24888611 time/batch=0.57s
21278/10943 (epoch 174.993) train_loss=150.66592407 time/batch=0.82s
21279/10943 (epoch 175.001) train_loss=151.74545288 time/batch=0.80s
21280/10943 (epoch 175.009) train_loss=84.84037781 time/batch=0.48s
21281/10943 (epoch 175.017) train_loss=107.96746063 time/batch=0.58s
21282/10943 (epoch 175.025) train_loss=105.47355652 time/batch=0.59s
21283/10943 (epoch 175.034) train_loss=165.69424438 time/batch=0.94s
21284/10943 (epoch 175.042) train_loss=195.39729309 time/batch=1.09s
21285/10943 (epoch 175.050) train_loss=191.01396179 time/batch=1.10s
21286/10943 (epoch 175.058) train_loss=75.64503479 time/batch=0.45s
21287/10943 (epoch 175.067) train_loss=187.25692749 time/batch=1.01s
21288/10943 (epoch 175.075) train_loss=84.29181671 time/batch=0.57s
21289/10943 (epoch 175.083) train_loss=137.86688232 time/batch=0.70s
21290/10943 (epoch 175.091) train_loss=214.31063843 time/batch=1.09s
21291/10943 (epoch 175.099) train_loss=215.85241699 time/batch=1.18s
21292/10943 (epoch 175.108) train_loss=239.41378784 time/batch=1.37s
21293/10943 (epoch 175.116) train_loss=172.17692566 time/batch=0.92s
21294/10943 (epoch 175.124) train_loss=233.72851562 time/batch=1.35s
21295/10943 (epoch 175.132) train_loss=175.03833008 time/batch=1.07s
21296/10943 (epoch 175.141) train_loss=171.02671814 time/batch=0.93s
21297/10943 (epoch 175.149) train_loss=130.50494385 time/batch=0.73s
21298/10943 (epoch 175.157) train_loss=130.53309631 time/batch=0.74s
21299/10943 (epoch 175.165) train_loss=133.65402222 time/batch=0.79s
21300/10943 (epoch 175.173) train_loss=187.34443665 time/batch=1.02s
21301/10943 (epoch 175.182) train_loss=121.22546387 time/batch=0.75s
21302/10943 (epoch 175.190) train_loss=136.88507080 time/batch=0.86s
21303/10943 (epoch 175.198) train_loss=107.86081696 time/batch=0.64s
21304/10943 (epoch 175.206) train_loss=100.91297913 time/batch=0.56s
21305/10943 (epoch 175.215) train_loss=171.66094971 time/batch=0.96s
21306/10943 (epoch 175.223) train_loss=154.19038391 time/batch=0.88s
21307/10943 (epoch 175.231) train_loss=113.65779114 time/batch=0.63s
21308/10943 (epoch 175.239) train_loss=127.90244293 time/batch=0.71s
21309/10943 (epoch 175.247) train_loss=155.12173462 time/batch=0.92s
21310/10943 (epoch 175.256) train_loss=131.25906372 time/batch=0.76s
21311/10943 (epoch 175.264) train_loss=182.86732483 time/batch=1.00s
21312/10943 (epoch 175.272) train_loss=105.57558441 time/batch=0.61s
21313/10943 (epoch 175.280) train_loss=119.67724609 time/batch=0.61s
21314/10943 (epoch 175.289) train_loss=162.03323364 time/batch=0.85s
21315/10943 (epoch 175.297) train_loss=155.06024170 time/batch=0.92s
setting learning rate to 0.0007854
  saved to metadata/lstm_dropout-9_nov_folkwiki-20181112-195023.pkl
21316/10943 (epoch 175.305) train_loss=218.29150391 time/batch=1.26s
21317/10943 (epoch 175.313) train_loss=441.62982178 time/batch=2.09s
21318/10943 (epoch 175.322) train_loss=275.12939453 time/batch=1.51s
21319/10943 (epoch 175.330) train_loss=570.22698975 time/batch=3.86s
21320/10943 (epoch 175.338) train_loss=149.03207397 time/batch=1.17s
21321/10943 (epoch 175.346) train_loss=325.30242920 time/batch=1.57s
21322/10943 (epoch 175.354) train_loss=333.93963623 time/batch=1.92s
21323/10943 (epoch 175.363) train_loss=76.45953369 time/batch=0.52s
21324/10943 (epoch 175.371) train_loss=152.99496460 time/batch=0.81s
21325/10943 (epoch 175.379) train_loss=77.51826477 time/batch=0.42s
21326/10943 (epoch 175.387) train_loss=129.90765381 time/batch=0.74s
21327/10943 (epoch 175.396) train_loss=237.22314453 time/batch=1.28s
21328/10943 (epoch 175.404) train_loss=137.44465637 time/batch=0.92s
21329/10943 (epoch 175.412) train_loss=77.43964386 time/batch=0.45s
21330/10943 (epoch 175.420) train_loss=143.17416382 time/batch=0.81s
21331/10943 (epoch 175.428) train_loss=197.15652466 time/batch=1.08s
21332/10943 (epoch 175.437) train_loss=165.35098267 time/batch=0.97s
21333/10943 (epoch 175.445) train_loss=183.35379028 time/batch=1.08s
21334/10943 (epoch 175.453) train_loss=271.86810303 time/batch=1.43s
21335/10943 (epoch 175.461) train_loss=250.09866333 time/batch=1.37s
21336/10943 (epoch 175.470) train_loss=93.55130005 time/batch=0.60s
21337/10943 (epoch 175.478) train_loss=283.78314209 time/batch=1.46s
21338/10943 (epoch 175.486) train_loss=151.60494995 time/batch=0.90s
21339/10943 (epoch 175.494) train_loss=350.47888184 time/batch=1.86s
21340/10943 (epoch 175.502) train_loss=103.37071228 time/batch=0.76s
21341/10943 (epoch 175.511) train_loss=153.61846924 time/batch=0.85s
21342/10943 (epoch 175.519) train_loss=295.04589844 time/batch=1.46s
21343/10943 (epoch 175.527) train_loss=178.11193848 time/batch=0.95s
21344/10943 (epoch 175.535) train_loss=72.12988281 time/batch=0.43s
21345/10943 (epoch 175.544) train_loss=82.52179718 time/batch=0.41s
21346/10943 (epoch 175.552) train_loss=281.80603027 time/batch=1.35s
21347/10943 (epoch 175.560) train_loss=95.63114929 time/batch=0.63s
21348/10943 (epoch 175.568) train_loss=324.98876953 time/batch=1.85s
21349/10943 (epoch 175.576) train_loss=133.51135254 time/batch=0.89s
21350/10943 (epoch 175.585) train_loss=225.71304321 time/batch=1.17s
21351/10943 (epoch 175.593) train_loss=173.12895203 time/batch=1.04s
21352/10943 (epoch 175.601) train_loss=120.69326782 time/batch=0.72s
21353/10943 (epoch 175.609) train_loss=108.48957825 time/batch=0.61s
21354/10943 (epoch 175.618) train_loss=168.20164490 time/batch=0.90s
21355/10943 (epoch 175.626) train_loss=264.47756958 time/batch=1.31s
21356/10943 (epoch 175.634) train_loss=156.86019897 time/batch=0.91s
21357/10943 (epoch 175.642) train_loss=290.17626953 time/batch=1.43s
21358/10943 (epoch 175.650) train_loss=100.85289001 time/batch=0.65s
21359/10943 (epoch 175.659) train_loss=65.64190674 time/batch=0.38s
21360/10943 (epoch 175.667) train_loss=168.60995483 time/batch=0.91s
21361/10943 (epoch 175.675) train_loss=123.04000854 time/batch=0.77s
21362/10943 (epoch 175.683) train_loss=73.10858154 time/batch=0.41s
21363/10943 (epoch 175.692) train_loss=190.44558716 time/batch=0.99s
21364/10943 (epoch 175.700) train_loss=166.99792480 time/batch=0.90s
21365/10943 (epoch 175.708) train_loss=230.02679443 time/batch=1.21s
21366/10943 (epoch 175.716) train_loss=104.25630951 time/batch=0.59s
21367/10943 (epoch 175.724) train_loss=130.53442383 time/batch=0.76s
21368/10943 (epoch 175.733) train_loss=100.47636414 time/batch=0.57s
21369/10943 (epoch 175.741) train_loss=199.42413330 time/batch=1.09s
21370/10943 (epoch 175.749) train_loss=169.18531799 time/batch=1.01s
21371/10943 (epoch 175.757) train_loss=148.47265625 time/batch=0.82s
21372/10943 (epoch 175.766) train_loss=173.37506104 time/batch=0.90s
21373/10943 (epoch 175.774) train_loss=111.39718628 time/batch=0.66s
21374/10943 (epoch 175.782) train_loss=92.94412231 time/batch=0.49s
21375/10943 (epoch 175.790) train_loss=104.69245911 time/batch=0.54s
21376/10943 (epoch 175.799) train_loss=143.76870728 time/batch=0.77s
21377/10943 (epoch 175.807) train_loss=207.45790100 time/batch=1.14s
21378/10943 (epoch 175.815) train_loss=195.52957153 time/batch=1.07s
21379/10943 (epoch 175.823) train_loss=254.62091064 time/batch=1.28s
21380/10943 (epoch 175.831) train_loss=176.21078491 time/batch=1.10s
21381/10943 (epoch 175.840) train_loss=130.33085632 time/batch=0.74s
21382/10943 (epoch 175.848) train_loss=186.55256653 time/batch=0.99s
21383/10943 (epoch 175.856) train_loss=79.65382385 time/batch=0.50s
21384/10943 (epoch 175.864) train_loss=222.03164673 time/batch=1.16s
21385/10943 (epoch 175.873) train_loss=102.13903809 time/batch=0.65s
21386/10943 (epoch 175.881) train_loss=132.57527161 time/batch=0.74s
21387/10943 (epoch 175.889) train_loss=92.37232971 time/batch=0.46s
21388/10943 (epoch 175.897) train_loss=127.91140747 time/batch=0.63s
21389/10943 (epoch 175.905) train_loss=252.50215149 time/batch=1.49s
21390/10943 (epoch 175.914) train_loss=131.15921021 time/batch=0.82s
21391/10943 (epoch 175.922) train_loss=123.59661865 time/batch=0.69s
21392/10943 (epoch 175.930) train_loss=121.58483124 time/batch=0.75s
21393/10943 (epoch 175.938) train_loss=107.26484680 time/batch=0.67s
21394/10943 (epoch 175.947) train_loss=158.85682678 time/batch=0.86s
21395/10943 (epoch 175.955) train_loss=160.04238892 time/batch=0.90s
21396/10943 (epoch 175.963) train_loss=118.67021942 time/batch=0.72s
21397/10943 (epoch 175.971) train_loss=154.88391113 time/batch=0.80s
21398/10943 (epoch 175.979) train_loss=182.93560791 time/batch=1.02s
21399/10943 (epoch 175.988) train_loss=108.29039001 time/batch=0.62s
21400/10943 (epoch 175.996) train_loss=90.31544495 time/batch=0.47s
21401/10943 (epoch 176.004) train_loss=104.07185364 time/batch=0.60s
21402/10943 (epoch 176.012) train_loss=173.74282837 time/batch=0.96s
21403/10943 (epoch 176.021) train_loss=166.24314880 time/batch=0.93s
21404/10943 (epoch 176.029) train_loss=164.56362915 time/batch=0.98s
21405/10943 (epoch 176.037) train_loss=160.51602173 time/batch=0.85s
21406/10943 (epoch 176.045) train_loss=149.46147156 time/batch=0.93s
21407/10943 (epoch 176.053) train_loss=124.67895508 time/batch=0.67s
21408/10943 (epoch 176.062) train_loss=160.21679688 time/batch=0.89s
21409/10943 (epoch 176.070) train_loss=96.25440979 time/batch=0.53s
21410/10943 (epoch 176.078) train_loss=131.43487549 time/batch=0.71s
21411/10943 (epoch 176.086) train_loss=244.81115723 time/batch=1.20s
21412/10943 (epoch 176.095) train_loss=146.11895752 time/batch=0.86s
21413/10943 (epoch 176.103) train_loss=125.36578369 time/batch=0.75s
21414/10943 (epoch 176.111) train_loss=118.41702271 time/batch=0.63s
21415/10943 (epoch 176.119) train_loss=203.45159912 time/batch=1.06s
21416/10943 (epoch 176.127) train_loss=119.39759827 time/batch=0.72s
21417/10943 (epoch 176.136) train_loss=168.78569031 time/batch=0.97s
21418/10943 (epoch 176.144) train_loss=216.62750244 time/batch=1.16s
21419/10943 (epoch 176.152) train_loss=197.24835205 time/batch=1.13s
21420/10943 (epoch 176.160) train_loss=187.48495483 time/batch=1.04s
21421/10943 (epoch 176.169) train_loss=200.87759399 time/batch=1.15s
21422/10943 (epoch 176.177) train_loss=88.68106079 time/batch=0.51s
21423/10943 (epoch 176.185) train_loss=166.31817627 time/batch=0.91s
21424/10943 (epoch 176.193) train_loss=182.78215027 time/batch=1.06s
21425/10943 (epoch 176.201) train_loss=95.44879150 time/batch=0.58s
21426/10943 (epoch 176.210) train_loss=121.44136810 time/batch=0.62s
21427/10943 (epoch 176.218) train_loss=133.22512817 time/batch=0.74s
21428/10943 (epoch 176.226) train_loss=162.65026855 time/batch=0.99s
21429/10943 (epoch 176.234) train_loss=195.69277954 time/batch=1.21s
21430/10943 (epoch 176.243) train_loss=127.64620209 time/batch=0.87s
21431/10943 (epoch 176.251) train_loss=135.92669678 time/batch=0.72s
21432/10943 (epoch 176.259) train_loss=175.93719482 time/batch=0.95s
21433/10943 (epoch 176.267) train_loss=108.09518433 time/batch=0.67s
21434/10943 (epoch 176.276) train_loss=146.82281494 time/batch=0.82s
21435/10943 (epoch 176.284) train_loss=125.28413391 time/batch=0.73s
21436/10943 (epoch 176.292) train_loss=140.88488770 time/batch=0.92s
setting learning rate to 0.0007618
21437/10943 (epoch 176.300) train_loss=146.89205933 time/batch=0.85s
21438/10943 (epoch 176.308) train_loss=118.10346985 time/batch=0.75s
21439/10943 (epoch 176.317) train_loss=316.74353027 time/batch=1.58s
21440/10943 (epoch 176.325) train_loss=574.81182861 time/batch=3.83s
21441/10943 (epoch 176.333) train_loss=274.67648315 time/batch=1.70s
21442/10943 (epoch 176.341) train_loss=429.53503418 time/batch=2.10s
21443/10943 (epoch 176.350) train_loss=227.58302307 time/batch=1.33s
21444/10943 (epoch 176.358) train_loss=147.00331116 time/batch=0.86s
21445/10943 (epoch 176.366) train_loss=72.67481995 time/batch=0.39s
21446/10943 (epoch 176.374) train_loss=324.39697266 time/batch=1.60s
21447/10943 (epoch 176.382) train_loss=213.20930481 time/batch=1.30s
21448/10943 (epoch 176.391) train_loss=64.26762390 time/batch=0.44s
21449/10943 (epoch 176.399) train_loss=95.17753601 time/batch=0.55s
21450/10943 (epoch 176.407) train_loss=269.61544800 time/batch=1.36s
21451/10943 (epoch 176.415) train_loss=202.18421936 time/batch=1.19s
21452/10943 (epoch 176.424) train_loss=348.71777344 time/batch=1.91s
21453/10943 (epoch 176.432) train_loss=243.93626404 time/batch=1.39s
21454/10943 (epoch 176.440) train_loss=160.07238770 time/batch=1.04s
21455/10943 (epoch 176.448) train_loss=97.08180237 time/batch=0.58s
21456/10943 (epoch 176.456) train_loss=152.92372131 time/batch=0.81s
21457/10943 (epoch 176.465) train_loss=276.05584717 time/batch=1.43s
21458/10943 (epoch 176.473) train_loss=149.60421753 time/batch=0.97s
21459/10943 (epoch 176.481) train_loss=322.72662354 time/batch=2.06s
21460/10943 (epoch 176.489) train_loss=76.17626953 time/batch=0.57s
21461/10943 (epoch 176.498) train_loss=101.17989349 time/batch=0.51s
21462/10943 (epoch 176.506) train_loss=145.14739990 time/batch=0.78s
21463/10943 (epoch 176.514) train_loss=202.13720703 time/batch=1.10s
21464/10943 (epoch 176.522) train_loss=186.30416870 time/batch=1.09s
21465/10943 (epoch 176.530) train_loss=133.88583374 time/batch=0.83s
21466/10943 (epoch 176.539) train_loss=225.03790283 time/batch=1.22s
21467/10943 (epoch 176.547) train_loss=279.01699829 time/batch=1.39s
21468/10943 (epoch 176.555) train_loss=100.22357941 time/batch=0.64s
21469/10943 (epoch 176.563) train_loss=104.70664978 time/batch=0.58s
21470/10943 (epoch 176.572) train_loss=293.72119141 time/batch=1.44s
21471/10943 (epoch 176.580) train_loss=181.07255554 time/batch=1.12s
21472/10943 (epoch 176.588) train_loss=123.23592377 time/batch=0.74s
21473/10943 (epoch 176.596) train_loss=84.46357727 time/batch=0.45s
21474/10943 (epoch 176.604) train_loss=136.72589111 time/batch=0.83s
21475/10943 (epoch 176.613) train_loss=108.74354553 time/batch=0.63s
21476/10943 (epoch 176.621) train_loss=165.60552979 time/batch=0.97s
21477/10943 (epoch 176.629) train_loss=119.79850769 time/batch=0.80s
21478/10943 (epoch 176.637) train_loss=223.84744263 time/batch=1.19s
21479/10943 (epoch 176.646) train_loss=156.77130127 time/batch=0.92s
21480/10943 (epoch 176.654) train_loss=134.40118408 time/batch=0.79s
21481/10943 (epoch 176.662) train_loss=112.77907562 time/batch=0.71s
21482/10943 (epoch 176.670) train_loss=269.68887329 time/batch=1.41s
21483/10943 (epoch 176.678) train_loss=164.56132507 time/batch=0.98s
21484/10943 (epoch 176.687) train_loss=159.79534912 time/batch=0.97s
21485/10943 (epoch 176.695) train_loss=89.00910950 time/batch=0.50s
21486/10943 (epoch 176.703) train_loss=263.67346191 time/batch=1.43s
21487/10943 (epoch 176.711) train_loss=240.38940430 time/batch=1.32s
21488/10943 (epoch 176.720) train_loss=171.07849121 time/batch=0.96s
21489/10943 (epoch 176.728) train_loss=255.92814636 time/batch=1.49s
21490/10943 (epoch 176.736) train_loss=93.77383423 time/batch=0.62s
21491/10943 (epoch 176.744) train_loss=108.38426208 time/batch=0.59s
21492/10943 (epoch 176.753) train_loss=110.42023468 time/batch=0.62s
21493/10943 (epoch 176.761) train_loss=135.95257568 time/batch=0.76s
21494/10943 (epoch 176.769) train_loss=277.82873535 time/batch=1.49s
21495/10943 (epoch 176.777) train_loss=174.30818176 time/batch=1.03s
21496/10943 (epoch 176.785) train_loss=126.18713379 time/batch=0.77s
21497/10943 (epoch 176.794) train_loss=240.02597046 time/batch=1.15s
21498/10943 (epoch 176.802) train_loss=110.91868591 time/batch=0.69s
21499/10943 (epoch 176.810) train_loss=148.74719238 time/batch=0.79s
21500/10943 (epoch 176.818) train_loss=148.42654419 time/batch=0.84s
21501/10943 (epoch 176.827) train_loss=97.75811768 time/batch=0.59s
21502/10943 (epoch 176.835) train_loss=209.30593872 time/batch=1.07s
21503/10943 (epoch 176.843) train_loss=119.16423035 time/batch=0.74s
21504/10943 (epoch 176.851) train_loss=99.62177277 time/batch=0.59s
21505/10943 (epoch 176.859) train_loss=145.70429993 time/batch=0.80s
21506/10943 (epoch 176.868) train_loss=105.55773926 time/batch=0.67s
21507/10943 (epoch 176.876) train_loss=71.70325470 time/batch=0.41s
21508/10943 (epoch 176.884) train_loss=196.40257263 time/batch=1.08s
21509/10943 (epoch 176.892) train_loss=156.30525208 time/batch=0.90s
21510/10943 (epoch 176.901) train_loss=82.76184082 time/batch=0.47s
21511/10943 (epoch 176.909) train_loss=174.90011597 time/batch=0.92s
21512/10943 (epoch 176.917) train_loss=156.88481140 time/batch=0.89s
21513/10943 (epoch 176.925) train_loss=171.25308228 time/batch=0.99s
21514/10943 (epoch 176.933) train_loss=180.46194458 time/batch=1.10s
21515/10943 (epoch 176.942) train_loss=119.95542908 time/batch=0.72s
21516/10943 (epoch 176.950) train_loss=132.81750488 time/batch=0.74s
21517/10943 (epoch 176.958) train_loss=115.19894409 time/batch=0.64s
21518/10943 (epoch 176.966) train_loss=91.37021637 time/batch=0.49s
21519/10943 (epoch 176.975) train_loss=117.61549377 time/batch=0.66s
21520/10943 (epoch 176.983) train_loss=132.29180908 time/batch=0.71s
21521/10943 (epoch 176.991) train_loss=83.88562012 time/batch=0.42s
21522/10943 (epoch 176.999) train_loss=76.17041779 time/batch=0.44s
21523/10943 (epoch 177.007) train_loss=128.80511475 time/batch=0.73s
21524/10943 (epoch 177.016) train_loss=73.42486572 time/batch=0.48s
21525/10943 (epoch 177.024) train_loss=114.89410400 time/batch=0.62s
21526/10943 (epoch 177.032) train_loss=205.12835693 time/batch=1.17s
21527/10943 (epoch 177.040) train_loss=96.16819763 time/batch=0.56s
21528/10943 (epoch 177.049) train_loss=129.55703735 time/batch=0.68s
21529/10943 (epoch 177.057) train_loss=128.36906433 time/batch=0.74s
21530/10943 (epoch 177.065) train_loss=185.75827026 time/batch=1.00s
21531/10943 (epoch 177.073) train_loss=93.53895569 time/batch=0.55s
21532/10943 (epoch 177.081) train_loss=165.38906860 time/batch=0.89s
21533/10943 (epoch 177.090) train_loss=160.29299927 time/batch=0.90s
21534/10943 (epoch 177.098) train_loss=130.89567566 time/batch=0.79s
21535/10943 (epoch 177.106) train_loss=200.60379028 time/batch=1.13s
21536/10943 (epoch 177.114) train_loss=129.23434448 time/batch=0.73s
21537/10943 (epoch 177.123) train_loss=181.55911255 time/batch=0.99s
21538/10943 (epoch 177.131) train_loss=129.92179871 time/batch=0.77s
21539/10943 (epoch 177.139) train_loss=133.65341187 time/batch=0.78s
21540/10943 (epoch 177.147) train_loss=90.73751831 time/batch=0.49s
21541/10943 (epoch 177.155) train_loss=163.30746460 time/batch=0.91s
21542/10943 (epoch 177.164) train_loss=192.72314453 time/batch=1.04s
21543/10943 (epoch 177.172) train_loss=183.65315247 time/batch=1.09s
21544/10943 (epoch 177.180) train_loss=166.66310120 time/batch=0.91s
21545/10943 (epoch 177.188) train_loss=91.76734924 time/batch=0.60s
21546/10943 (epoch 177.197) train_loss=149.65666199 time/batch=0.90s
21547/10943 (epoch 177.205) train_loss=166.14183044 time/batch=1.00s
21548/10943 (epoch 177.213) train_loss=186.61163330 time/batch=0.98s
21549/10943 (epoch 177.221) train_loss=187.84906006 time/batch=1.03s
21550/10943 (epoch 177.230) train_loss=150.98825073 time/batch=0.87s
21551/10943 (epoch 177.238) train_loss=122.82326508 time/batch=0.73s
21552/10943 (epoch 177.246) train_loss=142.40704346 time/batch=0.84s
21553/10943 (epoch 177.254) train_loss=128.77691650 time/batch=0.85s
21554/10943 (epoch 177.262) train_loss=140.26483154 time/batch=0.88s
21555/10943 (epoch 177.271) train_loss=164.47213745 time/batch=0.97s
21556/10943 (epoch 177.279) train_loss=193.03717041 time/batch=1.04s
21557/10943 (epoch 177.287) train_loss=159.18331909 time/batch=1.03s
setting learning rate to 0.0007390
21558/10943 (epoch 177.295) train_loss=97.64144135 time/batch=0.60s
21559/10943 (epoch 177.304) train_loss=177.13284302 time/batch=0.98s
21560/10943 (epoch 177.312) train_loss=193.81713867 time/batch=1.11s
21561/10943 (epoch 177.320) train_loss=80.30747223 time/batch=0.47s
21562/10943 (epoch 177.328) train_loss=280.28765869 time/batch=1.30s
21563/10943 (epoch 177.336) train_loss=177.13919067 time/batch=1.09s
21564/10943 (epoch 177.345) train_loss=291.56198120 time/batch=1.54s
21565/10943 (epoch 177.353) train_loss=558.89971924 time/batch=3.85s
21566/10943 (epoch 177.361) train_loss=110.18585968 time/batch=0.95s
21567/10943 (epoch 177.369) train_loss=156.32344055 time/batch=0.88s
21568/10943 (epoch 177.378) train_loss=102.78338623 time/batch=0.59s
21569/10943 (epoch 177.386) train_loss=268.86697388 time/batch=1.37s
21570/10943 (epoch 177.394) train_loss=118.32278442 time/batch=0.71s
21571/10943 (epoch 177.402) train_loss=364.10156250 time/batch=1.90s
21572/10943 (epoch 177.410) train_loss=123.89965057 time/batch=0.87s
21573/10943 (epoch 177.419) train_loss=165.80360413 time/batch=0.91s
21574/10943 (epoch 177.427) train_loss=160.85546875 time/batch=0.95s
21575/10943 (epoch 177.435) train_loss=311.99154663 time/batch=1.71s
21576/10943 (epoch 177.443) train_loss=161.38984680 time/batch=1.01s
21577/10943 (epoch 177.452) train_loss=311.50747681 time/batch=1.62s
21578/10943 (epoch 177.460) train_loss=120.17698669 time/batch=0.87s
21579/10943 (epoch 177.468) train_loss=144.26080322 time/batch=0.81s
21580/10943 (epoch 177.476) train_loss=268.37854004 time/batch=1.33s
21581/10943 (epoch 177.484) train_loss=250.44961548 time/batch=1.27s
21582/10943 (epoch 177.493) train_loss=150.11767578 time/batch=0.89s
21583/10943 (epoch 177.501) train_loss=75.11111450 time/batch=0.42s
21584/10943 (epoch 177.509) train_loss=140.21292114 time/batch=0.80s
21585/10943 (epoch 177.517) train_loss=234.14331055 time/batch=1.28s
21586/10943 (epoch 177.526) train_loss=157.47406006 time/batch=0.92s
21587/10943 (epoch 177.534) train_loss=81.45606995 time/batch=0.48s
21588/10943 (epoch 177.542) train_loss=118.99160767 time/batch=0.67s
21589/10943 (epoch 177.550) train_loss=77.45692444 time/batch=0.47s
21590/10943 (epoch 177.558) train_loss=139.22801208 time/batch=0.77s
21591/10943 (epoch 177.567) train_loss=131.28405762 time/batch=0.79s
21592/10943 (epoch 177.575) train_loss=182.24273682 time/batch=1.03s
21593/10943 (epoch 177.583) train_loss=199.98138428 time/batch=1.13s
21594/10943 (epoch 177.591) train_loss=74.55799866 time/batch=0.45s
21595/10943 (epoch 177.600) train_loss=190.53579712 time/batch=1.01s
21596/10943 (epoch 177.608) train_loss=363.92413330 time/batch=1.98s
21597/10943 (epoch 177.616) train_loss=86.20649719 time/batch=0.61s
21598/10943 (epoch 177.624) train_loss=102.23742676 time/batch=0.64s
21599/10943 (epoch 177.632) train_loss=258.09368896 time/batch=1.34s
21600/10943 (epoch 177.641) train_loss=198.59959412 time/batch=1.19s
21601/10943 (epoch 177.649) train_loss=68.52734375 time/batch=0.44s
21602/10943 (epoch 177.657) train_loss=187.55828857 time/batch=1.09s
21603/10943 (epoch 177.665) train_loss=110.52288818 time/batch=0.69s
21604/10943 (epoch 177.674) train_loss=91.57789612 time/batch=0.52s
21605/10943 (epoch 177.682) train_loss=104.38502502 time/batch=0.54s
21606/10943 (epoch 177.690) train_loss=222.30532837 time/batch=1.19s
21607/10943 (epoch 177.698) train_loss=153.96502686 time/batch=0.95s
21608/10943 (epoch 177.707) train_loss=201.31968689 time/batch=1.11s
21609/10943 (epoch 177.715) train_loss=181.17251587 time/batch=1.11s
21610/10943 (epoch 177.723) train_loss=113.00028229 time/batch=0.75s
21611/10943 (epoch 177.731) train_loss=161.89007568 time/batch=0.92s
21612/10943 (epoch 177.739) train_loss=67.24094391 time/batch=0.44s
21613/10943 (epoch 177.748) train_loss=222.74673462 time/batch=1.15s
21614/10943 (epoch 177.756) train_loss=117.57513428 time/batch=0.69s
21615/10943 (epoch 177.764) train_loss=80.83419800 time/batch=0.43s
21616/10943 (epoch 177.772) train_loss=220.53134155 time/batch=1.15s
21617/10943 (epoch 177.781) train_loss=302.76245117 time/batch=1.58s
21618/10943 (epoch 177.789) train_loss=121.23780823 time/batch=0.78s
21619/10943 (epoch 177.797) train_loss=251.20446777 time/batch=1.24s
21620/10943 (epoch 177.805) train_loss=163.76962280 time/batch=1.02s
21621/10943 (epoch 177.813) train_loss=190.87139893 time/batch=1.04s
21622/10943 (epoch 177.822) train_loss=145.71205139 time/batch=0.87s
21623/10943 (epoch 177.830) train_loss=274.43817139 time/batch=1.41s
21624/10943 (epoch 177.838) train_loss=166.88671875 time/batch=1.08s
21625/10943 (epoch 177.846) train_loss=124.28451538 time/batch=0.71s
21626/10943 (epoch 177.855) train_loss=167.16116333 time/batch=0.97s
21627/10943 (epoch 177.863) train_loss=253.54928589 time/batch=1.46s
21628/10943 (epoch 177.871) train_loss=130.91773987 time/batch=0.84s
21629/10943 (epoch 177.879) train_loss=164.57559204 time/batch=0.95s
21630/10943 (epoch 177.887) train_loss=88.62493896 time/batch=0.50s
21631/10943 (epoch 177.896) train_loss=183.34757996 time/batch=0.97s
21632/10943 (epoch 177.904) train_loss=371.40115356 time/batch=2.05s
21633/10943 (epoch 177.912) train_loss=170.30203247 time/batch=1.13s
21634/10943 (epoch 177.920) train_loss=138.07977295 time/batch=0.82s
21635/10943 (epoch 177.929) train_loss=105.54219055 time/batch=0.69s
21636/10943 (epoch 177.937) train_loss=180.08293152 time/batch=1.03s
21637/10943 (epoch 177.945) train_loss=215.96615601 time/batch=1.17s
21638/10943 (epoch 177.953) train_loss=119.48014832 time/batch=0.71s
21639/10943 (epoch 177.961) train_loss=87.31577301 time/batch=0.49s
21640/10943 (epoch 177.970) train_loss=97.73001099 time/batch=0.49s
21641/10943 (epoch 177.978) train_loss=148.20074463 time/batch=0.89s
21642/10943 (epoch 177.986) train_loss=226.14726257 time/batch=1.18s
21643/10943 (epoch 177.994) train_loss=126.74305725 time/batch=0.75s
21644/10943 (epoch 178.003) train_loss=136.97169495 time/batch=0.78s
21645/10943 (epoch 178.011) train_loss=135.63497925 time/batch=0.72s
21646/10943 (epoch 178.019) train_loss=123.30245972 time/batch=0.76s
21647/10943 (epoch 178.027) train_loss=71.86765289 time/batch=0.49s
21648/10943 (epoch 178.035) train_loss=125.06101990 time/batch=0.71s
21649/10943 (epoch 178.044) train_loss=107.87694550 time/batch=0.62s
21650/10943 (epoch 178.052) train_loss=130.94151306 time/batch=0.75s
21651/10943 (epoch 178.060) train_loss=94.04165649 time/batch=0.52s
21652/10943 (epoch 178.068) train_loss=148.62139893 time/batch=0.83s
21653/10943 (epoch 178.077) train_loss=160.51324463 time/batch=0.97s
21654/10943 (epoch 178.085) train_loss=129.47274780 time/batch=0.77s
21655/10943 (epoch 178.093) train_loss=125.70164490 time/batch=0.72s
21656/10943 (epoch 178.101) train_loss=104.41280365 time/batch=0.59s
21657/10943 (epoch 178.109) train_loss=121.12324524 time/batch=0.72s
21658/10943 (epoch 178.118) train_loss=84.22869873 time/batch=0.53s
21659/10943 (epoch 178.126) train_loss=99.05668640 time/batch=0.54s
21660/10943 (epoch 178.134) train_loss=103.61772919 time/batch=0.58s
21661/10943 (epoch 178.142) train_loss=231.72296143 time/batch=1.41s
21662/10943 (epoch 178.151) train_loss=118.91934204 time/batch=0.82s
21663/10943 (epoch 178.159) train_loss=187.76600647 time/batch=1.14s
21664/10943 (epoch 178.167) train_loss=168.91778564 time/batch=0.99s
21665/10943 (epoch 178.175) train_loss=148.59619141 time/batch=0.88s
21666/10943 (epoch 178.184) train_loss=155.41687012 time/batch=0.84s
21667/10943 (epoch 178.192) train_loss=180.52413940 time/batch=2.03s
21668/10943 (epoch 178.200) train_loss=128.74038696 time/batch=0.90s
21669/10943 (epoch 178.208) train_loss=121.87788391 time/batch=0.74s
21670/10943 (epoch 178.216) train_loss=178.19676208 time/batch=0.95s
21671/10943 (epoch 178.225) train_loss=172.68020630 time/batch=0.90s
21672/10943 (epoch 178.233) train_loss=104.86595154 time/batch=0.63s
21673/10943 (epoch 178.241) train_loss=152.93109131 time/batch=0.79s
21674/10943 (epoch 178.249) train_loss=148.03997803 time/batch=0.86s
21675/10943 (epoch 178.258) train_loss=104.13678741 time/batch=0.78s
21676/10943 (epoch 178.266) train_loss=144.70809937 time/batch=0.81s
21677/10943 (epoch 178.274) train_loss=166.06680298 time/batch=0.96s
21678/10943 (epoch 178.282) train_loss=157.45755005 time/batch=0.89s
setting learning rate to 0.0007168
21679/10943 (epoch 178.290) train_loss=162.23298645 time/batch=1.00s
21680/10943 (epoch 178.299) train_loss=311.67053223 time/batch=1.67s
21681/10943 (epoch 178.307) train_loss=179.21627808 time/batch=1.11s
21682/10943 (epoch 178.315) train_loss=273.24206543 time/batch=1.39s
21683/10943 (epoch 178.323) train_loss=330.55969238 time/batch=1.89s
21684/10943 (epoch 178.332) train_loss=238.21011353 time/batch=1.41s
21685/10943 (epoch 178.340) train_loss=142.97698975 time/batch=0.89s
21686/10943 (epoch 178.348) train_loss=301.02404785 time/batch=1.54s
21687/10943 (epoch 178.356) train_loss=247.48037720 time/batch=1.37s
21688/10943 (epoch 178.364) train_loss=252.80529785 time/batch=1.35s
21689/10943 (epoch 178.373) train_loss=98.43161011 time/batch=0.65s
21690/10943 (epoch 178.381) train_loss=280.49325562 time/batch=1.51s
21691/10943 (epoch 178.389) train_loss=88.32984161 time/batch=0.62s
21692/10943 (epoch 178.397) train_loss=302.75341797 time/batch=1.65s
21693/10943 (epoch 178.406) train_loss=449.97793579 time/batch=2.50s
21694/10943 (epoch 178.414) train_loss=263.45129395 time/batch=1.53s
21695/10943 (epoch 178.422) train_loss=111.49164581 time/batch=0.77s
21696/10943 (epoch 178.430) train_loss=181.59724426 time/batch=1.06s
21697/10943 (epoch 178.438) train_loss=155.92947388 time/batch=0.96s
21698/10943 (epoch 178.447) train_loss=79.38377380 time/batch=0.44s
21699/10943 (epoch 178.455) train_loss=100.92095947 time/batch=0.55s
21700/10943 (epoch 178.463) train_loss=94.06234741 time/batch=0.54s
21701/10943 (epoch 178.471) train_loss=245.36993408 time/batch=1.18s
21702/10943 (epoch 178.480) train_loss=144.18231201 time/batch=0.85s
21703/10943 (epoch 178.488) train_loss=255.90588379 time/batch=1.31s
21704/10943 (epoch 178.496) train_loss=312.86413574 time/batch=1.90s
21705/10943 (epoch 178.504) train_loss=216.29586792 time/batch=1.30s
21706/10943 (epoch 178.512) train_loss=403.51129150 time/batch=2.57s
21707/10943 (epoch 178.521) train_loss=62.77703094 time/batch=0.58s
21708/10943 (epoch 178.529) train_loss=71.08674622 time/batch=0.36s
21709/10943 (epoch 178.537) train_loss=158.16725159 time/batch=0.91s
21710/10943 (epoch 178.545) train_loss=116.45449066 time/batch=0.77s
21711/10943 (epoch 178.554) train_loss=177.63529968 time/batch=1.03s
21712/10943 (epoch 178.562) train_loss=117.09443665 time/batch=0.73s
21713/10943 (epoch 178.570) train_loss=195.43304443 time/batch=1.11s
21714/10943 (epoch 178.578) train_loss=73.15204620 time/batch=0.46s
21715/10943 (epoch 178.586) train_loss=272.33776855 time/batch=1.38s
21716/10943 (epoch 178.595) train_loss=127.48646545 time/batch=0.85s
21717/10943 (epoch 178.603) train_loss=99.11320496 time/batch=0.58s
21718/10943 (epoch 178.611) train_loss=177.24635315 time/batch=1.04s
21719/10943 (epoch 178.619) train_loss=80.45168304 time/batch=0.49s
21720/10943 (epoch 178.628) train_loss=104.49016571 time/batch=0.63s
21721/10943 (epoch 178.636) train_loss=192.12457275 time/batch=1.07s
21722/10943 (epoch 178.644) train_loss=149.18304443 time/batch=0.90s
21723/10943 (epoch 178.652) train_loss=208.13435364 time/batch=1.23s
21724/10943 (epoch 178.660) train_loss=304.92495728 time/batch=2.69s
21725/10943 (epoch 178.669) train_loss=138.92800903 time/batch=1.05s
21726/10943 (epoch 178.677) train_loss=149.95195007 time/batch=0.92s
21727/10943 (epoch 178.685) train_loss=129.97430420 time/batch=0.79s
21728/10943 (epoch 178.693) train_loss=161.31079102 time/batch=0.98s
21729/10943 (epoch 178.702) train_loss=81.39509583 time/batch=0.51s
21730/10943 (epoch 178.710) train_loss=104.19232178 time/batch=0.59s
21731/10943 (epoch 178.718) train_loss=171.15133667 time/batch=0.85s
21732/10943 (epoch 178.726) train_loss=124.83076477 time/batch=0.68s
21733/10943 (epoch 178.735) train_loss=139.22604370 time/batch=0.80s
21734/10943 (epoch 178.743) train_loss=71.26999664 time/batch=0.42s
21735/10943 (epoch 178.751) train_loss=213.57980347 time/batch=1.14s
21736/10943 (epoch 178.759) train_loss=92.55120087 time/batch=0.57s
21737/10943 (epoch 178.767) train_loss=161.66769409 time/batch=0.78s
21738/10943 (epoch 178.776) train_loss=147.95849609 time/batch=0.84s
21739/10943 (epoch 178.784) train_loss=121.87358093 time/batch=0.70s
21740/10943 (epoch 178.792) train_loss=90.19667053 time/batch=0.52s
21741/10943 (epoch 178.800) train_loss=143.81726074 time/batch=0.79s
21742/10943 (epoch 178.809) train_loss=190.97433472 time/batch=1.02s
21743/10943 (epoch 178.817) train_loss=215.48367310 time/batch=1.21s
21744/10943 (epoch 178.825) train_loss=234.80355835 time/batch=1.26s
21745/10943 (epoch 178.833) train_loss=125.29722595 time/batch=0.81s
21746/10943 (epoch 178.841) train_loss=139.77453613 time/batch=0.80s
21747/10943 (epoch 178.850) train_loss=80.41123962 time/batch=0.46s
21748/10943 (epoch 178.858) train_loss=103.53183746 time/batch=0.56s
21749/10943 (epoch 178.866) train_loss=161.17155457 time/batch=0.93s
21750/10943 (epoch 178.874) train_loss=161.31124878 time/batch=1.00s
21751/10943 (epoch 178.883) train_loss=170.81059265 time/batch=0.97s
21752/10943 (epoch 178.891) train_loss=132.46627808 time/batch=0.80s
21753/10943 (epoch 178.899) train_loss=198.15246582 time/batch=1.13s
21754/10943 (epoch 178.907) train_loss=109.02284241 time/batch=0.69s
21755/10943 (epoch 178.915) train_loss=355.34100342 time/batch=3.75s
21756/10943 (epoch 178.924) train_loss=137.28923035 time/batch=1.20s
21757/10943 (epoch 178.932) train_loss=182.05728149 time/batch=1.02s
21758/10943 (epoch 178.940) train_loss=152.60525513 time/batch=0.93s
21759/10943 (epoch 178.948) train_loss=77.90786743 time/batch=0.48s
21760/10943 (epoch 178.957) train_loss=116.26250458 time/batch=0.62s
21761/10943 (epoch 178.965) train_loss=166.05467224 time/batch=0.99s
21762/10943 (epoch 178.973) train_loss=89.38072968 time/batch=0.55s
21763/10943 (epoch 178.981) train_loss=188.77456665 time/batch=1.04s
21764/10943 (epoch 178.989) train_loss=159.72625732 time/batch=1.00s
21765/10943 (epoch 178.998) train_loss=126.89376831 time/batch=0.78s
21766/10943 (epoch 179.006) train_loss=113.86653137 time/batch=0.67s
21767/10943 (epoch 179.014) train_loss=83.94415283 time/batch=0.52s
21768/10943 (epoch 179.022) train_loss=128.36572266 time/batch=0.70s
21769/10943 (epoch 179.031) train_loss=101.28372955 time/batch=0.59s
21770/10943 (epoch 179.039) train_loss=169.51112366 time/batch=1.02s
21771/10943 (epoch 179.047) train_loss=172.98382568 time/batch=1.05s
21772/10943 (epoch 179.055) train_loss=195.43612671 time/batch=1.17s
21773/10943 (epoch 179.063) train_loss=119.40200806 time/batch=0.70s
21774/10943 (epoch 179.072) train_loss=179.70285034 time/batch=1.06s
21775/10943 (epoch 179.080) train_loss=123.06737518 time/batch=0.81s
21776/10943 (epoch 179.088) train_loss=90.12152863 time/batch=0.54s
21777/10943 (epoch 179.096) train_loss=136.13671875 time/batch=0.75s
21778/10943 (epoch 179.105) train_loss=111.74698639 time/batch=0.68s
21779/10943 (epoch 179.113) train_loss=146.12646484 time/batch=0.84s
21780/10943 (epoch 179.121) train_loss=109.70783997 time/batch=0.63s
21781/10943 (epoch 179.129) train_loss=99.85155487 time/batch=0.60s
21782/10943 (epoch 179.137) train_loss=168.73368835 time/batch=0.91s
21783/10943 (epoch 179.146) train_loss=102.11486816 time/batch=0.64s
21784/10943 (epoch 179.154) train_loss=96.91704559 time/batch=0.57s
21785/10943 (epoch 179.162) train_loss=124.33807373 time/batch=0.74s
21786/10943 (epoch 179.170) train_loss=130.32107544 time/batch=0.73s
21787/10943 (epoch 179.179) train_loss=121.74119568 time/batch=0.72s
21788/10943 (epoch 179.187) train_loss=126.94509125 time/batch=0.79s
21789/10943 (epoch 179.195) train_loss=169.26852417 time/batch=0.91s
21790/10943 (epoch 179.203) train_loss=167.71766663 time/batch=0.94s
21791/10943 (epoch 179.212) train_loss=138.99313354 time/batch=0.83s
21792/10943 (epoch 179.220) train_loss=154.74832153 time/batch=0.87s
21793/10943 (epoch 179.228) train_loss=160.05690002 time/batch=0.90s
21794/10943 (epoch 179.236) train_loss=181.76748657 time/batch=1.14s
21795/10943 (epoch 179.244) train_loss=167.87115479 time/batch=1.01s
21796/10943 (epoch 179.253) train_loss=126.23269653 time/batch=0.73s
21797/10943 (epoch 179.261) train_loss=119.70465851 time/batch=0.73s
21798/10943 (epoch 179.269) train_loss=162.19958496 time/batch=0.87s
21799/10943 (epoch 179.277) train_loss=113.95318604 time/batch=0.86s
setting learning rate to 0.0006953
21800/10943 (epoch 179.286) train_loss=311.01196289 time/batch=1.76s
21801/10943 (epoch 179.294) train_loss=93.56036377 time/batch=0.66s
21802/10943 (epoch 179.302) train_loss=68.40427399 time/batch=0.39s
21803/10943 (epoch 179.310) train_loss=228.26051331 time/batch=1.25s
21804/10943 (epoch 179.318) train_loss=324.36621094 time/batch=1.87s
21805/10943 (epoch 179.327) train_loss=144.65618896 time/batch=1.05s
21806/10943 (epoch 179.335) train_loss=113.48915100 time/batch=0.72s
21807/10943 (epoch 179.343) train_loss=111.35123444 time/batch=0.64s
21808/10943 (epoch 179.351) train_loss=145.85803223 time/batch=0.84s
21809/10943 (epoch 179.360) train_loss=165.89874268 time/batch=1.06s
21810/10943 (epoch 179.368) train_loss=279.28186035 time/batch=1.49s
21811/10943 (epoch 179.376) train_loss=320.48757935 time/batch=1.94s
21812/10943 (epoch 179.384) train_loss=563.31884766 time/batch=3.87s
21813/10943 (epoch 179.392) train_loss=209.50096130 time/batch=1.48s
21814/10943 (epoch 179.401) train_loss=167.17515564 time/batch=1.02s
21815/10943 (epoch 179.409) train_loss=181.11883545 time/batch=1.09s
21816/10943 (epoch 179.417) train_loss=264.40179443 time/batch=1.41s
21817/10943 (epoch 179.425) train_loss=279.05590820 time/batch=1.55s
21818/10943 (epoch 179.434) train_loss=138.09855652 time/batch=0.91s
21819/10943 (epoch 179.442) train_loss=416.92358398 time/batch=2.07s
21820/10943 (epoch 179.450) train_loss=229.62150574 time/batch=1.38s
21821/10943 (epoch 179.458) train_loss=87.89860535 time/batch=0.57s
21822/10943 (epoch 179.466) train_loss=249.83132935 time/batch=1.22s
21823/10943 (epoch 179.475) train_loss=104.39138794 time/batch=0.61s
21824/10943 (epoch 179.483) train_loss=212.55241394 time/batch=1.13s
21825/10943 (epoch 179.491) train_loss=254.96560669 time/batch=1.36s
21826/10943 (epoch 179.499) train_loss=131.22488403 time/batch=0.86s
21827/10943 (epoch 179.508) train_loss=189.57827759 time/batch=1.07s
21828/10943 (epoch 179.516) train_loss=148.10177612 time/batch=0.91s
21829/10943 (epoch 179.524) train_loss=82.88535309 time/batch=0.56s
21830/10943 (epoch 179.532) train_loss=59.31556320 time/batch=0.33s
21831/10943 (epoch 179.540) train_loss=101.68190765 time/batch=0.57s
21832/10943 (epoch 179.549) train_loss=98.41057587 time/batch=0.55s
21833/10943 (epoch 179.557) train_loss=267.30813599 time/batch=1.31s
21834/10943 (epoch 179.565) train_loss=321.76092529 time/batch=1.62s
21835/10943 (epoch 179.573) train_loss=268.86889648 time/batch=1.60s
21836/10943 (epoch 179.582) train_loss=97.54981995 time/batch=0.69s
21837/10943 (epoch 179.590) train_loss=277.36123657 time/batch=1.30s
21838/10943 (epoch 179.598) train_loss=194.25863647 time/batch=1.18s
21839/10943 (epoch 179.606) train_loss=134.08930969 time/batch=0.85s
21840/10943 (epoch 179.614) train_loss=74.71486664 time/batch=0.41s
21841/10943 (epoch 179.623) train_loss=178.42929077 time/batch=0.97s
21842/10943 (epoch 179.631) train_loss=216.73193359 time/batch=1.18s
21843/10943 (epoch 179.639) train_loss=70.98237610 time/batch=0.46s
21844/10943 (epoch 179.647) train_loss=215.02548218 time/batch=1.14s
21845/10943 (epoch 179.656) train_loss=146.76864624 time/batch=0.87s
21846/10943 (epoch 179.664) train_loss=124.23466492 time/batch=0.74s
21847/10943 (epoch 179.672) train_loss=155.28079224 time/batch=0.87s
21848/10943 (epoch 179.680) train_loss=93.30955505 time/batch=0.58s
21849/10943 (epoch 179.689) train_loss=73.40708160 time/batch=0.41s
21850/10943 (epoch 179.697) train_loss=276.39770508 time/batch=1.85s
21851/10943 (epoch 179.705) train_loss=165.77941895 time/batch=1.05s
21852/10943 (epoch 179.713) train_loss=164.07490540 time/batch=0.89s
21853/10943 (epoch 179.721) train_loss=150.18362427 time/batch=0.83s
21854/10943 (epoch 179.730) train_loss=85.70376587 time/batch=0.46s
21855/10943 (epoch 179.738) train_loss=74.69612885 time/batch=0.39s
21856/10943 (epoch 179.746) train_loss=144.11099243 time/batch=0.81s
21857/10943 (epoch 179.754) train_loss=187.41767883 time/batch=1.10s
21858/10943 (epoch 179.763) train_loss=181.67854309 time/batch=1.07s
21859/10943 (epoch 179.771) train_loss=214.48043823 time/batch=1.21s
21860/10943 (epoch 179.779) train_loss=123.50358582 time/batch=0.81s
21861/10943 (epoch 179.787) train_loss=212.13525391 time/batch=1.19s
21862/10943 (epoch 179.795) train_loss=153.72668457 time/batch=1.00s
21863/10943 (epoch 179.804) train_loss=173.94685364 time/batch=1.10s
21864/10943 (epoch 179.812) train_loss=121.43540955 time/batch=0.80s
21865/10943 (epoch 179.820) train_loss=164.86442566 time/batch=0.95s
21866/10943 (epoch 179.828) train_loss=189.12286377 time/batch=1.12s
21867/10943 (epoch 179.837) train_loss=134.82400513 time/batch=0.90s
21868/10943 (epoch 179.845) train_loss=107.66265869 time/batch=0.63s
21869/10943 (epoch 179.853) train_loss=174.88087463 time/batch=0.95s
21870/10943 (epoch 179.861) train_loss=120.77423096 time/batch=0.72s
21871/10943 (epoch 179.869) train_loss=108.25012207 time/batch=0.63s
21872/10943 (epoch 179.878) train_loss=129.59051514 time/batch=0.74s
21873/10943 (epoch 179.886) train_loss=162.98510742 time/batch=0.93s
21874/10943 (epoch 179.894) train_loss=100.68760681 time/batch=0.61s
21875/10943 (epoch 179.902) train_loss=120.66999054 time/batch=0.69s
21876/10943 (epoch 179.911) train_loss=154.48266602 time/batch=0.97s
21877/10943 (epoch 179.919) train_loss=116.90522003 time/batch=0.73s
21878/10943 (epoch 179.927) train_loss=102.08753967 time/batch=0.60s
21879/10943 (epoch 179.935) train_loss=123.31125641 time/batch=0.74s
21880/10943 (epoch 179.943) train_loss=148.41636658 time/batch=0.83s
21881/10943 (epoch 179.952) train_loss=156.63455200 time/batch=1.01s
21882/10943 (epoch 179.960) train_loss=126.47848511 time/batch=0.76s
21883/10943 (epoch 179.968) train_loss=118.23181152 time/batch=0.73s
21884/10943 (epoch 179.976) train_loss=123.05647278 time/batch=0.76s
21885/10943 (epoch 179.985) train_loss=106.02024841 time/batch=0.67s
21886/10943 (epoch 179.993) train_loss=238.79660034 time/batch=1.20s
21887/10943 (epoch 180.001) train_loss=107.21276855 time/batch=0.73s
21888/10943 (epoch 180.009) train_loss=94.43814850 time/batch=0.55s
21889/10943 (epoch 180.017) train_loss=107.16968536 time/batch=0.62s
21890/10943 (epoch 180.026) train_loss=194.67623901 time/batch=1.19s
21891/10943 (epoch 180.034) train_loss=148.69012451 time/batch=0.92s
21892/10943 (epoch 180.042) train_loss=126.74542999 time/batch=0.70s
21893/10943 (epoch 180.050) train_loss=138.53601074 time/batch=0.79s
21894/10943 (epoch 180.059) train_loss=117.49595642 time/batch=0.75s
21895/10943 (epoch 180.067) train_loss=120.40783691 time/batch=0.77s
21896/10943 (epoch 180.075) train_loss=86.27687836 time/batch=0.46s
21897/10943 (epoch 180.083) train_loss=172.40486145 time/batch=0.95s
21898/10943 (epoch 180.091) train_loss=135.78248596 time/batch=0.81s
21899/10943 (epoch 180.100) train_loss=92.85028076 time/batch=0.50s
21900/10943 (epoch 180.108) train_loss=164.49368286 time/batch=0.91s
21901/10943 (epoch 180.116) train_loss=81.96154785 time/batch=0.52s
21902/10943 (epoch 180.124) train_loss=156.43624878 time/batch=0.89s
21903/10943 (epoch 180.133) train_loss=78.39159393 time/batch=0.48s
21904/10943 (epoch 180.141) train_loss=157.91744995 time/batch=0.86s
21905/10943 (epoch 180.149) train_loss=84.72689819 time/batch=0.57s
21906/10943 (epoch 180.157) train_loss=114.88246155 time/batch=0.69s
21907/10943 (epoch 180.166) train_loss=168.20028687 time/batch=0.93s
21908/10943 (epoch 180.174) train_loss=186.75895691 time/batch=1.04s
21909/10943 (epoch 180.182) train_loss=110.33381653 time/batch=0.66s
21910/10943 (epoch 180.190) train_loss=191.03053284 time/batch=1.00s
21911/10943 (epoch 180.198) train_loss=152.53311157 time/batch=1.00s
21912/10943 (epoch 180.207) train_loss=169.24462891 time/batch=1.03s
21913/10943 (epoch 180.215) train_loss=158.03393555 time/batch=0.97s
21914/10943 (epoch 180.223) train_loss=161.50299072 time/batch=1.02s
21915/10943 (epoch 180.231) train_loss=91.03988647 time/batch=0.60s
21916/10943 (epoch 180.240) train_loss=111.57923126 time/batch=0.62s
21917/10943 (epoch 180.248) train_loss=118.67298889 time/batch=0.71s
21918/10943 (epoch 180.256) train_loss=141.68490601 time/batch=0.86s
21919/10943 (epoch 180.264) train_loss=126.30554962 time/batch=0.79s
21920/10943 (epoch 180.272) train_loss=154.25381470 time/batch=0.81s
setting learning rate to 0.0006744
  saved to metadata/lstm_dropout-9_nov_folkwiki-20181112-195023.pkl
21921/10943 (epoch 180.281) train_loss=396.94805908 time/batch=2.07s
21922/10943 (epoch 180.289) train_loss=98.32950592 time/batch=0.77s
21923/10943 (epoch 180.297) train_loss=148.76608276 time/batch=0.95s
21924/10943 (epoch 180.305) train_loss=272.52395630 time/batch=1.47s
21925/10943 (epoch 180.314) train_loss=90.80294037 time/batch=0.59s
21926/10943 (epoch 180.322) train_loss=306.63031006 time/batch=1.58s
21927/10943 (epoch 180.330) train_loss=276.46090698 time/batch=1.47s
21928/10943 (epoch 180.338) train_loss=152.64001465 time/batch=0.96s
21929/10943 (epoch 180.346) train_loss=202.55422974 time/batch=1.14s
21930/10943 (epoch 180.355) train_loss=188.55975342 time/batch=1.10s
21931/10943 (epoch 180.363) train_loss=272.33038330 time/batch=1.35s
21932/10943 (epoch 180.371) train_loss=101.60301971 time/batch=0.70s
21933/10943 (epoch 180.379) train_loss=177.49682617 time/batch=0.99s
21934/10943 (epoch 180.388) train_loss=168.49008179 time/batch=0.90s
21935/10943 (epoch 180.396) train_loss=263.57928467 time/batch=1.34s
21936/10943 (epoch 180.404) train_loss=80.51876831 time/batch=0.53s
21937/10943 (epoch 180.412) train_loss=348.03793335 time/batch=1.97s
21938/10943 (epoch 180.420) train_loss=121.71630859 time/batch=0.92s
21939/10943 (epoch 180.429) train_loss=177.02307129 time/batch=1.04s
21940/10943 (epoch 180.437) train_loss=83.53497314 time/batch=0.50s
21941/10943 (epoch 180.445) train_loss=144.43225098 time/batch=0.79s
21942/10943 (epoch 180.453) train_loss=143.51037598 time/batch=0.81s
21943/10943 (epoch 180.462) train_loss=134.11563110 time/batch=0.79s
21944/10943 (epoch 180.470) train_loss=84.02054596 time/batch=0.49s
21945/10943 (epoch 180.478) train_loss=220.57324219 time/batch=1.25s
21946/10943 (epoch 180.486) train_loss=319.20489502 time/batch=1.73s
21947/10943 (epoch 180.494) train_loss=218.51560974 time/batch=1.27s
21948/10943 (epoch 180.503) train_loss=267.60833740 time/batch=1.45s
21949/10943 (epoch 180.511) train_loss=160.79208374 time/batch=0.97s
21950/10943 (epoch 180.519) train_loss=537.95037842 time/batch=3.80s
21951/10943 (epoch 180.527) train_loss=92.03083801 time/batch=0.89s
21952/10943 (epoch 180.536) train_loss=102.43873596 time/batch=0.52s
21953/10943 (epoch 180.544) train_loss=194.03703308 time/batch=1.07s
21954/10943 (epoch 180.552) train_loss=215.93838501 time/batch=1.26s
21955/10943 (epoch 180.560) train_loss=156.91406250 time/batch=0.99s
21956/10943 (epoch 180.568) train_loss=238.50747681 time/batch=1.43s
21957/10943 (epoch 180.577) train_loss=147.50909424 time/batch=0.90s
21958/10943 (epoch 180.585) train_loss=284.88696289 time/batch=1.68s
21959/10943 (epoch 180.593) train_loss=67.23533630 time/batch=0.49s
21960/10943 (epoch 180.601) train_loss=97.38976288 time/batch=0.54s
21961/10943 (epoch 180.610) train_loss=123.54542542 time/batch=0.73s
21962/10943 (epoch 180.618) train_loss=227.37145996 time/batch=1.23s
21963/10943 (epoch 180.626) train_loss=157.66151428 time/batch=1.03s
21964/10943 (epoch 180.634) train_loss=148.86422729 time/batch=1.00s
21965/10943 (epoch 180.643) train_loss=198.76693726 time/batch=1.20s
21966/10943 (epoch 180.651) train_loss=74.82806396 time/batch=0.48s
21967/10943 (epoch 180.659) train_loss=98.29867554 time/batch=0.56s
21968/10943 (epoch 180.667) train_loss=192.05239868 time/batch=1.06s
21969/10943 (epoch 180.675) train_loss=162.17961121 time/batch=1.04s
21970/10943 (epoch 180.684) train_loss=144.13143921 time/batch=0.87s
21971/10943 (epoch 180.692) train_loss=137.64205933 time/batch=0.81s
21972/10943 (epoch 180.700) train_loss=101.04502869 time/batch=0.62s
21973/10943 (epoch 180.708) train_loss=116.91694641 time/batch=0.71s
21974/10943 (epoch 180.717) train_loss=127.14624023 time/batch=0.78s
21975/10943 (epoch 180.725) train_loss=100.10862732 time/batch=0.68s
21976/10943 (epoch 180.733) train_loss=195.69412231 time/batch=1.10s
21977/10943 (epoch 180.741) train_loss=78.46935272 time/batch=0.55s
21978/10943 (epoch 180.749) train_loss=146.20320129 time/batch=0.80s
21979/10943 (epoch 180.758) train_loss=76.27179718 time/batch=0.47s
21980/10943 (epoch 180.766) train_loss=89.18635559 time/batch=0.48s
21981/10943 (epoch 180.774) train_loss=152.40667725 time/batch=0.96s
21982/10943 (epoch 180.782) train_loss=155.71569824 time/batch=0.92s
21983/10943 (epoch 180.791) train_loss=144.12033081 time/batch=0.91s
21984/10943 (epoch 180.799) train_loss=138.81716919 time/batch=0.81s
21985/10943 (epoch 180.807) train_loss=93.33051300 time/batch=0.57s
21986/10943 (epoch 180.815) train_loss=157.65892029 time/batch=0.89s
21987/10943 (epoch 180.823) train_loss=181.88735962 time/batch=1.06s
21988/10943 (epoch 180.832) train_loss=116.42717743 time/batch=0.74s
21989/10943 (epoch 180.840) train_loss=289.38269043 time/batch=1.96s
21990/10943 (epoch 180.848) train_loss=123.51025391 time/batch=0.89s
21991/10943 (epoch 180.856) train_loss=161.27746582 time/batch=0.89s
21992/10943 (epoch 180.865) train_loss=120.54402161 time/batch=0.74s
21993/10943 (epoch 180.873) train_loss=209.23931885 time/batch=1.16s
21994/10943 (epoch 180.881) train_loss=152.34968567 time/batch=0.96s
21995/10943 (epoch 180.889) train_loss=127.31781006 time/batch=0.78s
21996/10943 (epoch 180.897) train_loss=174.00662231 time/batch=1.09s
21997/10943 (epoch 180.906) train_loss=233.88438416 time/batch=1.23s
21998/10943 (epoch 180.914) train_loss=64.95541382 time/batch=0.44s
21999/10943 (epoch 180.922) train_loss=159.56225586 time/batch=0.92s
Validating
    loss:	215.465719

22000/10943 (epoch 180.930) train_loss=295.78399658 time/batch=4.34s
22001/10943 (epoch 180.939) train_loss=245.46691895 time/batch=1.34s
22002/10943 (epoch 180.947) train_loss=150.17285156 time/batch=0.92s
22003/10943 (epoch 180.955) train_loss=89.58257294 time/batch=0.55s
22004/10943 (epoch 180.963) train_loss=120.85653687 time/batch=0.72s
22005/10943 (epoch 180.971) train_loss=88.18292236 time/batch=0.54s
22006/10943 (epoch 180.980) train_loss=167.92443848 time/batch=1.08s
22007/10943 (epoch 180.988) train_loss=73.29542542 time/batch=0.46s
22008/10943 (epoch 180.996) train_loss=76.26769257 time/batch=0.44s
22009/10943 (epoch 181.004) train_loss=153.75616455 time/batch=0.89s
22010/10943 (epoch 181.013) train_loss=118.88468933 time/batch=0.75s
22011/10943 (epoch 181.021) train_loss=97.58432770 time/batch=0.60s
22012/10943 (epoch 181.029) train_loss=116.31486511 time/batch=0.63s
22013/10943 (epoch 181.037) train_loss=143.40400696 time/batch=0.81s
22014/10943 (epoch 181.045) train_loss=112.02129364 time/batch=0.71s
22015/10943 (epoch 181.054) train_loss=120.14590454 time/batch=0.66s
22016/10943 (epoch 181.062) train_loss=102.14282990 time/batch=0.58s
22017/10943 (epoch 181.070) train_loss=117.24822998 time/batch=0.65s
22018/10943 (epoch 181.078) train_loss=168.67684937 time/batch=0.93s
22019/10943 (epoch 181.087) train_loss=184.92590332 time/batch=1.03s
22020/10943 (epoch 181.095) train_loss=149.20159912 time/batch=0.87s
22021/10943 (epoch 181.103) train_loss=158.74908447 time/batch=0.98s
22022/10943 (epoch 181.111) train_loss=125.80975342 time/batch=0.85s
22023/10943 (epoch 181.120) train_loss=104.31938171 time/batch=0.69s
22024/10943 (epoch 181.128) train_loss=156.00691223 time/batch=0.93s
22025/10943 (epoch 181.136) train_loss=108.84307861 time/batch=0.65s
22026/10943 (epoch 181.144) train_loss=166.41918945 time/batch=0.96s
22027/10943 (epoch 181.152) train_loss=104.70405579 time/batch=0.67s
22028/10943 (epoch 181.161) train_loss=142.19143677 time/batch=0.83s
22029/10943 (epoch 181.169) train_loss=138.06799316 time/batch=0.86s
22030/10943 (epoch 181.177) train_loss=117.88592529 time/batch=0.70s
22031/10943 (epoch 181.185) train_loss=169.11502075 time/batch=1.02s
22032/10943 (epoch 181.194) train_loss=125.42559052 time/batch=0.75s
22033/10943 (epoch 181.202) train_loss=238.83233643 time/batch=1.24s
22034/10943 (epoch 181.210) train_loss=121.58727264 time/batch=0.78s
22035/10943 (epoch 181.218) train_loss=122.26959229 time/batch=0.77s
22036/10943 (epoch 181.226) train_loss=72.41846466 time/batch=0.41s
22037/10943 (epoch 181.235) train_loss=175.33547974 time/batch=1.08s
22038/10943 (epoch 181.243) train_loss=163.51031494 time/batch=1.07s
22039/10943 (epoch 181.251) train_loss=97.74765015 time/batch=0.76s
22040/10943 (epoch 181.259) train_loss=129.97183228 time/batch=0.85s
22041/10943 (epoch 181.268) train_loss=122.58855438 time/batch=0.75s
setting learning rate to 0.0006542
22042/10943 (epoch 181.276) train_loss=116.23240662 time/batch=0.73s
22043/10943 (epoch 181.284) train_loss=89.81276703 time/batch=0.50s
22044/10943 (epoch 181.292) train_loss=229.87060547 time/batch=1.21s
22045/10943 (epoch 181.300) train_loss=263.56439209 time/batch=1.45s
22046/10943 (epoch 181.309) train_loss=173.63058472 time/batch=1.03s
22047/10943 (epoch 181.317) train_loss=58.64671326 time/batch=0.37s
22048/10943 (epoch 181.325) train_loss=277.84161377 time/batch=1.29s
22049/10943 (epoch 181.333) train_loss=308.01278687 time/batch=1.82s
22050/10943 (epoch 181.342) train_loss=73.24823761 time/batch=0.53s
22051/10943 (epoch 181.350) train_loss=206.69628906 time/batch=1.15s
22052/10943 (epoch 181.358) train_loss=426.20587158 time/batch=2.20s
22053/10943 (epoch 181.366) train_loss=351.06695557 time/batch=2.06s
22054/10943 (epoch 181.374) train_loss=316.85079956 time/batch=1.71s
22055/10943 (epoch 181.383) train_loss=276.05346680 time/batch=1.54s
22056/10943 (epoch 181.391) train_loss=261.00067139 time/batch=1.43s
22057/10943 (epoch 181.399) train_loss=251.06811523 time/batch=1.44s
22058/10943 (epoch 181.407) train_loss=209.24700928 time/batch=1.24s
22059/10943 (epoch 181.416) train_loss=184.73727417 time/batch=1.17s
22060/10943 (epoch 181.424) train_loss=508.39483643 time/batch=3.78s
22061/10943 (epoch 181.432) train_loss=250.64743042 time/batch=1.70s
22062/10943 (epoch 181.440) train_loss=86.06974030 time/batch=0.55s
22063/10943 (epoch 181.448) train_loss=136.65112305 time/batch=0.80s
22064/10943 (epoch 181.457) train_loss=88.78833008 time/batch=0.57s
22065/10943 (epoch 181.465) train_loss=105.97050476 time/batch=0.56s
22066/10943 (epoch 181.473) train_loss=158.28030396 time/batch=1.04s
22067/10943 (epoch 181.481) train_loss=77.24174500 time/batch=0.48s
22068/10943 (epoch 181.490) train_loss=99.46208191 time/batch=0.54s
22069/10943 (epoch 181.498) train_loss=131.10484314 time/batch=0.84s
22070/10943 (epoch 181.506) train_loss=142.18063354 time/batch=0.84s
22071/10943 (epoch 181.514) train_loss=144.46246338 time/batch=0.98s
22072/10943 (epoch 181.522) train_loss=185.58381653 time/batch=1.14s
22073/10943 (epoch 181.531) train_loss=119.91007233 time/batch=0.79s
22074/10943 (epoch 181.539) train_loss=147.69760132 time/batch=0.93s
22075/10943 (epoch 181.547) train_loss=88.62742615 time/batch=0.56s
22076/10943 (epoch 181.555) train_loss=232.11338806 time/batch=1.42s
22077/10943 (epoch 181.564) train_loss=118.33418274 time/batch=0.83s
22078/10943 (epoch 181.572) train_loss=69.22936249 time/batch=0.37s
22079/10943 (epoch 181.580) train_loss=165.32957458 time/batch=0.94s
22080/10943 (epoch 181.588) train_loss=112.55696869 time/batch=0.71s
22081/10943 (epoch 181.597) train_loss=212.12506104 time/batch=1.17s
22082/10943 (epoch 181.605) train_loss=100.24562073 time/batch=0.61s
22083/10943 (epoch 181.613) train_loss=143.17810059 time/batch=0.81s
22084/10943 (epoch 181.621) train_loss=306.28778076 time/batch=1.62s
22085/10943 (epoch 181.629) train_loss=149.88383484 time/batch=0.94s
22086/10943 (epoch 181.638) train_loss=222.00000000 time/batch=1.16s
22087/10943 (epoch 181.646) train_loss=160.49314880 time/batch=1.04s
22088/10943 (epoch 181.654) train_loss=242.25073242 time/batch=1.28s
22089/10943 (epoch 181.662) train_loss=201.19418335 time/batch=1.22s
22090/10943 (epoch 181.671) train_loss=70.50569153 time/batch=0.47s
22091/10943 (epoch 181.679) train_loss=84.72380829 time/batch=0.48s
22092/10943 (epoch 181.687) train_loss=277.20666504 time/batch=1.63s
22093/10943 (epoch 181.695) train_loss=178.21340942 time/batch=1.11s
22094/10943 (epoch 181.703) train_loss=157.26333618 time/batch=0.94s
22095/10943 (epoch 181.712) train_loss=187.08895874 time/batch=1.08s
22096/10943 (epoch 181.720) train_loss=142.72134399 time/batch=0.85s
22097/10943 (epoch 181.728) train_loss=96.29261017 time/batch=0.58s
22098/10943 (epoch 181.736) train_loss=116.01144409 time/batch=0.65s
22099/10943 (epoch 181.745) train_loss=94.32943726 time/batch=0.59s
22100/10943 (epoch 181.753) train_loss=79.22544861 time/batch=0.45s
22101/10943 (epoch 181.761) train_loss=145.88644409 time/batch=0.86s
22102/10943 (epoch 181.769) train_loss=161.56286621 time/batch=0.91s
22103/10943 (epoch 181.777) train_loss=111.72622681 time/batch=0.67s
22104/10943 (epoch 181.786) train_loss=187.38098145 time/batch=1.07s
22105/10943 (epoch 181.794) train_loss=187.17095947 time/batch=1.09s
22106/10943 (epoch 181.802) train_loss=115.07247925 time/batch=0.73s
22107/10943 (epoch 181.810) train_loss=140.53448486 time/batch=0.86s
22108/10943 (epoch 181.819) train_loss=107.45266724 time/batch=0.73s
22109/10943 (epoch 181.827) train_loss=139.37673950 time/batch=0.79s
22110/10943 (epoch 181.835) train_loss=156.67117310 time/batch=0.88s
22111/10943 (epoch 181.843) train_loss=114.86841583 time/batch=0.71s
22112/10943 (epoch 181.851) train_loss=150.68339539 time/batch=0.81s
22113/10943 (epoch 181.860) train_loss=134.01168823 time/batch=0.79s
22114/10943 (epoch 181.868) train_loss=102.15969086 time/batch=0.62s
22115/10943 (epoch 181.876) train_loss=164.43531799 time/batch=0.86s
22116/10943 (epoch 181.884) train_loss=161.90603638 time/batch=0.95s
22117/10943 (epoch 181.893) train_loss=175.33660889 time/batch=1.04s
22118/10943 (epoch 181.901) train_loss=115.30935669 time/batch=0.75s
22119/10943 (epoch 181.909) train_loss=89.07162476 time/batch=0.59s
22120/10943 (epoch 181.917) train_loss=109.48526001 time/batch=0.63s
22121/10943 (epoch 181.925) train_loss=155.34359741 time/batch=0.90s
22122/10943 (epoch 181.934) train_loss=66.52751160 time/batch=0.44s
22123/10943 (epoch 181.942) train_loss=161.19657898 time/batch=0.86s
22124/10943 (epoch 181.950) train_loss=217.86398315 time/batch=1.23s
22125/10943 (epoch 181.958) train_loss=80.67480469 time/batch=0.49s
22126/10943 (epoch 181.967) train_loss=95.30300903 time/batch=0.57s
22127/10943 (epoch 181.975) train_loss=240.63189697 time/batch=1.20s
22128/10943 (epoch 181.983) train_loss=144.03500366 time/batch=0.90s
22129/10943 (epoch 181.991) train_loss=117.11901093 time/batch=0.74s
22130/10943 (epoch 181.999) train_loss=151.53836060 time/batch=0.95s
22131/10943 (epoch 182.008) train_loss=95.89804840 time/batch=0.62s
22132/10943 (epoch 182.016) train_loss=215.59259033 time/batch=1.42s
22133/10943 (epoch 182.024) train_loss=119.04504395 time/batch=0.83s
22134/10943 (epoch 182.032) train_loss=142.38098145 time/batch=0.89s
22135/10943 (epoch 182.041) train_loss=174.78692627 time/batch=1.05s
22136/10943 (epoch 182.049) train_loss=79.75886536 time/batch=0.48s
22137/10943 (epoch 182.057) train_loss=124.27186584 time/batch=0.73s
22138/10943 (epoch 182.065) train_loss=191.85078430 time/batch=1.46s
22139/10943 (epoch 182.074) train_loss=98.12516785 time/batch=0.70s
22140/10943 (epoch 182.082) train_loss=121.94175720 time/batch=0.72s
22141/10943 (epoch 182.090) train_loss=125.04117584 time/batch=0.76s
22142/10943 (epoch 182.098) train_loss=115.04216003 time/batch=0.64s
22143/10943 (epoch 182.106) train_loss=98.32166290 time/batch=0.61s
22144/10943 (epoch 182.115) train_loss=143.69104004 time/batch=0.93s
22145/10943 (epoch 182.123) train_loss=127.25701904 time/batch=0.78s
22146/10943 (epoch 182.131) train_loss=164.54409790 time/batch=0.96s
22147/10943 (epoch 182.139) train_loss=156.56286621 time/batch=1.01s
22148/10943 (epoch 182.148) train_loss=136.13102722 time/batch=0.97s
22149/10943 (epoch 182.156) train_loss=183.14572144 time/batch=1.04s
22150/10943 (epoch 182.164) train_loss=102.08578491 time/batch=0.70s
22151/10943 (epoch 182.172) train_loss=176.37945557 time/batch=1.02s
22152/10943 (epoch 182.180) train_loss=112.73574829 time/batch=0.68s
22153/10943 (epoch 182.189) train_loss=166.43072510 time/batch=0.99s
22154/10943 (epoch 182.197) train_loss=82.19097900 time/batch=0.50s
22155/10943 (epoch 182.205) train_loss=120.81942749 time/batch=0.74s
22156/10943 (epoch 182.213) train_loss=118.97658539 time/batch=0.72s
22157/10943 (epoch 182.222) train_loss=160.11186218 time/batch=0.98s
22158/10943 (epoch 182.230) train_loss=130.48818970 time/batch=0.81s
22159/10943 (epoch 182.238) train_loss=130.00811768 time/batch=0.72s
22160/10943 (epoch 182.246) train_loss=115.92089081 time/batch=0.78s
22161/10943 (epoch 182.254) train_loss=141.78633118 time/batch=0.97s
22162/10943 (epoch 182.263) train_loss=140.05613708 time/batch=0.82s
setting learning rate to 0.0006346
22163/10943 (epoch 182.271) train_loss=310.30236816 time/batch=1.57s
22164/10943 (epoch 182.279) train_loss=537.89294434 time/batch=3.86s
22165/10943 (epoch 182.287) train_loss=258.22753906 time/batch=1.63s
22166/10943 (epoch 182.296) train_loss=75.26048279 time/batch=0.50s
22167/10943 (epoch 182.304) train_loss=115.29776001 time/batch=0.64s
22168/10943 (epoch 182.312) train_loss=171.08584595 time/batch=1.01s
22169/10943 (epoch 182.320) train_loss=210.16093445 time/batch=1.24s
22170/10943 (epoch 182.328) train_loss=259.77682495 time/batch=1.46s
22171/10943 (epoch 182.337) train_loss=67.94038391 time/batch=0.45s
22172/10943 (epoch 182.345) train_loss=215.47082520 time/batch=1.12s
22173/10943 (epoch 182.353) train_loss=87.70854187 time/batch=0.59s
22174/10943 (epoch 182.361) train_loss=188.07690430 time/batch=1.08s
22175/10943 (epoch 182.370) train_loss=154.20124817 time/batch=0.95s
22176/10943 (epoch 182.378) train_loss=262.61773682 time/batch=1.35s
22177/10943 (epoch 182.386) train_loss=158.24613953 time/batch=1.01s
22178/10943 (epoch 182.394) train_loss=117.49566650 time/batch=0.75s
22179/10943 (epoch 182.402) train_loss=140.39703369 time/batch=0.83s
22180/10943 (epoch 182.411) train_loss=189.95887756 time/batch=1.09s
22181/10943 (epoch 182.419) train_loss=88.81866455 time/batch=0.55s
22182/10943 (epoch 182.427) train_loss=277.09762573 time/batch=1.43s
22183/10943 (epoch 182.435) train_loss=300.56173706 time/batch=1.77s
22184/10943 (epoch 182.444) train_loss=121.83369446 time/batch=0.89s
22185/10943 (epoch 182.452) train_loss=176.26339722 time/batch=1.02s
22186/10943 (epoch 182.460) train_loss=404.19140625 time/batch=2.08s
22187/10943 (epoch 182.468) train_loss=96.15338135 time/batch=0.77s
22188/10943 (epoch 182.476) train_loss=333.63491821 time/batch=1.85s
22189/10943 (epoch 182.485) train_loss=271.69934082 time/batch=1.69s
22190/10943 (epoch 182.493) train_loss=123.40225220 time/batch=0.86s
22191/10943 (epoch 182.501) train_loss=118.13024139 time/batch=0.73s
22192/10943 (epoch 182.509) train_loss=97.66960907 time/batch=0.54s
22193/10943 (epoch 182.518) train_loss=264.71902466 time/batch=1.53s
22194/10943 (epoch 182.526) train_loss=120.21351624 time/batch=0.87s
22195/10943 (epoch 182.534) train_loss=284.14642334 time/batch=1.73s
22196/10943 (epoch 182.542) train_loss=220.94499207 time/batch=1.40s
22197/10943 (epoch 182.551) train_loss=114.07688904 time/batch=0.70s
22198/10943 (epoch 182.559) train_loss=267.04400635 time/batch=1.35s
22199/10943 (epoch 182.567) train_loss=149.49125671 time/batch=1.04s
22200/10943 (epoch 182.575) train_loss=92.47245789 time/batch=0.58s
22201/10943 (epoch 182.583) train_loss=179.87640381 time/batch=1.05s
22202/10943 (epoch 182.592) train_loss=116.55250549 time/batch=0.78s
22203/10943 (epoch 182.600) train_loss=243.09164429 time/batch=1.29s
22204/10943 (epoch 182.608) train_loss=106.14312744 time/batch=0.70s
22205/10943 (epoch 182.616) train_loss=224.76013184 time/batch=1.21s
22206/10943 (epoch 182.625) train_loss=73.05272675 time/batch=0.48s
22207/10943 (epoch 182.633) train_loss=151.69692993 time/batch=0.91s
22208/10943 (epoch 182.641) train_loss=78.98213196 time/batch=0.48s
22209/10943 (epoch 182.649) train_loss=261.46997070 time/batch=1.28s
22210/10943 (epoch 182.657) train_loss=159.96664429 time/batch=1.05s
22211/10943 (epoch 182.666) train_loss=204.59869385 time/batch=1.20s
22212/10943 (epoch 182.674) train_loss=154.76550293 time/batch=1.04s
22213/10943 (epoch 182.682) train_loss=155.17674255 time/batch=0.94s
22214/10943 (epoch 182.690) train_loss=122.11477661 time/batch=0.77s
22215/10943 (epoch 182.699) train_loss=140.49822998 time/batch=0.82s
22216/10943 (epoch 182.707) train_loss=117.47826385 time/batch=0.70s
22217/10943 (epoch 182.715) train_loss=114.09758759 time/batch=0.67s
22218/10943 (epoch 182.723) train_loss=107.63067627 time/batch=0.70s
22219/10943 (epoch 182.731) train_loss=146.52505493 time/batch=0.89s
22220/10943 (epoch 182.740) train_loss=143.85507202 time/batch=0.88s
22221/10943 (epoch 182.748) train_loss=80.52979279 time/batch=0.51s
22222/10943 (epoch 182.756) train_loss=141.91824341 time/batch=0.83s
22223/10943 (epoch 182.764) train_loss=151.60528564 time/batch=0.97s
22224/10943 (epoch 182.773) train_loss=162.30212402 time/batch=1.07s
22225/10943 (epoch 182.781) train_loss=201.69406128 time/batch=1.16s
22226/10943 (epoch 182.789) train_loss=102.20666504 time/batch=0.70s
22227/10943 (epoch 182.797) train_loss=216.20269775 time/batch=1.13s
22228/10943 (epoch 182.805) train_loss=68.92346191 time/batch=0.46s
22229/10943 (epoch 182.814) train_loss=82.72024536 time/batch=0.43s
22230/10943 (epoch 182.822) train_loss=89.43490601 time/batch=0.53s
22231/10943 (epoch 182.830) train_loss=148.12368774 time/batch=0.94s
22232/10943 (epoch 182.838) train_loss=121.88351440 time/batch=0.79s
22233/10943 (epoch 182.847) train_loss=216.39303589 time/batch=1.19s
22234/10943 (epoch 182.855) train_loss=70.91299438 time/batch=0.47s
22235/10943 (epoch 182.863) train_loss=152.86590576 time/batch=0.88s
22236/10943 (epoch 182.871) train_loss=107.26940918 time/batch=0.67s
22237/10943 (epoch 182.879) train_loss=187.78619385 time/batch=1.15s
22238/10943 (epoch 182.888) train_loss=101.41424561 time/batch=0.73s
22239/10943 (epoch 182.896) train_loss=150.69396973 time/batch=0.88s
22240/10943 (epoch 182.904) train_loss=125.90833282 time/batch=0.79s
22241/10943 (epoch 182.912) train_loss=170.15078735 time/batch=0.97s
22242/10943 (epoch 182.921) train_loss=196.89433289 time/batch=1.20s
22243/10943 (epoch 182.929) train_loss=145.80270386 time/batch=0.88s
22244/10943 (epoch 182.937) train_loss=144.08114624 time/batch=0.82s
22245/10943 (epoch 182.945) train_loss=150.89425659 time/batch=0.81s
22246/10943 (epoch 182.953) train_loss=94.34265137 time/batch=0.59s
22247/10943 (epoch 182.962) train_loss=106.44274902 time/batch=0.60s
22248/10943 (epoch 182.970) train_loss=77.96746826 time/batch=0.45s
22249/10943 (epoch 182.978) train_loss=165.30990601 time/batch=1.02s
22250/10943 (epoch 182.986) train_loss=72.62007141 time/batch=0.50s
22251/10943 (epoch 182.995) train_loss=100.62533569 time/batch=0.58s
22252/10943 (epoch 183.003) train_loss=136.01237488 time/batch=0.78s
22253/10943 (epoch 183.011) train_loss=112.28317261 time/batch=0.75s
22254/10943 (epoch 183.019) train_loss=152.99148560 time/batch=0.97s
22255/10943 (epoch 183.027) train_loss=115.27362823 time/batch=0.74s
22256/10943 (epoch 183.036) train_loss=115.24125671 time/batch=0.72s
22257/10943 (epoch 183.044) train_loss=179.15869141 time/batch=1.04s
22258/10943 (epoch 183.052) train_loss=145.67521667 time/batch=0.88s
22259/10943 (epoch 183.060) train_loss=182.59277344 time/batch=1.06s
22260/10943 (epoch 183.069) train_loss=103.65990448 time/batch=0.65s
22261/10943 (epoch 183.077) train_loss=64.70898438 time/batch=0.46s
22262/10943 (epoch 183.085) train_loss=177.46557617 time/batch=1.06s
22263/10943 (epoch 183.093) train_loss=164.21885681 time/batch=1.04s
22264/10943 (epoch 183.102) train_loss=154.52789307 time/batch=0.92s
22265/10943 (epoch 183.110) train_loss=119.84892273 time/batch=0.81s
22266/10943 (epoch 183.118) train_loss=137.44921875 time/batch=0.80s
22267/10943 (epoch 183.126) train_loss=122.85401154 time/batch=0.76s
22268/10943 (epoch 183.134) train_loss=119.94188690 time/batch=0.76s
22269/10943 (epoch 183.143) train_loss=102.36299896 time/batch=0.61s
22270/10943 (epoch 183.151) train_loss=137.73420715 time/batch=0.81s
22271/10943 (epoch 183.159) train_loss=91.96322632 time/batch=0.50s
22272/10943 (epoch 183.167) train_loss=165.89721680 time/batch=0.96s
22273/10943 (epoch 183.176) train_loss=100.48114777 time/batch=0.74s
22274/10943 (epoch 183.184) train_loss=144.10444641 time/batch=0.91s
22275/10943 (epoch 183.192) train_loss=100.94578552 time/batch=0.73s
22276/10943 (epoch 183.200) train_loss=164.98574829 time/batch=1.00s
22277/10943 (epoch 183.208) train_loss=167.04689026 time/batch=1.04s
22278/10943 (epoch 183.217) train_loss=86.26877594 time/batch=0.55s
22279/10943 (epoch 183.225) train_loss=167.49786377 time/batch=0.85s
22280/10943 (epoch 183.233) train_loss=93.50703430 time/batch=0.73s
22281/10943 (epoch 183.241) train_loss=140.06303406 time/batch=0.83s
22282/10943 (epoch 183.250) train_loss=117.16112518 time/batch=0.73s
22283/10943 (epoch 183.258) train_loss=128.09777832 time/batch=0.85s
setting learning rate to 0.0006155
22284/10943 (epoch 183.266) train_loss=185.89776611 time/batch=1.13s
22285/10943 (epoch 183.274) train_loss=270.53369141 time/batch=1.38s
22286/10943 (epoch 183.282) train_loss=424.46411133 time/batch=2.41s
22287/10943 (epoch 183.291) train_loss=158.40847778 time/batch=1.13s
22288/10943 (epoch 183.299) train_loss=189.40422058 time/batch=1.10s
22289/10943 (epoch 183.307) train_loss=284.55596924 time/batch=1.58s
22290/10943 (epoch 183.315) train_loss=297.73501587 time/batch=1.72s
22291/10943 (epoch 183.324) train_loss=263.39208984 time/batch=1.55s
22292/10943 (epoch 183.332) train_loss=300.93157959 time/batch=1.77s
22293/10943 (epoch 183.340) train_loss=159.46020508 time/batch=1.08s
22294/10943 (epoch 183.348) train_loss=67.93404388 time/batch=0.41s
22295/10943 (epoch 183.356) train_loss=233.03128052 time/batch=1.27s
22296/10943 (epoch 183.365) train_loss=261.19812012 time/batch=1.47s
22297/10943 (epoch 183.373) train_loss=309.98901367 time/batch=1.91s
22298/10943 (epoch 183.381) train_loss=216.00334167 time/batch=1.36s
22299/10943 (epoch 183.389) train_loss=274.59069824 time/batch=1.53s
22300/10943 (epoch 183.398) train_loss=135.82424927 time/batch=0.91s
22301/10943 (epoch 183.406) train_loss=84.26199341 time/batch=0.55s
22302/10943 (epoch 183.414) train_loss=75.58984375 time/batch=0.46s
22303/10943 (epoch 183.422) train_loss=143.10607910 time/batch=0.79s
22304/10943 (epoch 183.430) train_loss=493.37850952 time/batch=3.79s
22305/10943 (epoch 183.439) train_loss=77.91168213 time/batch=0.82s
22306/10943 (epoch 183.447) train_loss=148.73631287 time/batch=0.83s
22307/10943 (epoch 183.455) train_loss=84.71516418 time/batch=0.48s
22308/10943 (epoch 183.463) train_loss=200.90660095 time/batch=1.15s
22309/10943 (epoch 183.472) train_loss=96.31181335 time/batch=0.67s
22310/10943 (epoch 183.480) train_loss=138.06091309 time/batch=0.81s
22311/10943 (epoch 183.488) train_loss=132.88636780 time/batch=0.83s
22312/10943 (epoch 183.496) train_loss=300.90307617 time/batch=1.91s
22313/10943 (epoch 183.504) train_loss=201.54302979 time/batch=1.32s
22314/10943 (epoch 183.513) train_loss=179.63742065 time/batch=1.12s
22315/10943 (epoch 183.521) train_loss=136.69757080 time/batch=0.86s
22316/10943 (epoch 183.529) train_loss=147.82992554 time/batch=0.91s
22317/10943 (epoch 183.537) train_loss=106.41151428 time/batch=0.73s
22318/10943 (epoch 183.546) train_loss=143.49090576 time/batch=0.89s
22319/10943 (epoch 183.554) train_loss=258.25836182 time/batch=1.37s
22320/10943 (epoch 183.562) train_loss=171.36114502 time/batch=1.10s
22321/10943 (epoch 183.570) train_loss=114.49763489 time/batch=0.77s
22322/10943 (epoch 183.579) train_loss=136.49159241 time/batch=0.84s
22323/10943 (epoch 183.587) train_loss=107.32534790 time/batch=0.64s
22324/10943 (epoch 183.595) train_loss=70.37823486 time/batch=0.40s
22325/10943 (epoch 183.603) train_loss=91.52725983 time/batch=0.52s
22326/10943 (epoch 183.611) train_loss=157.59725952 time/batch=0.90s
22327/10943 (epoch 183.620) train_loss=252.68142700 time/batch=1.37s
22328/10943 (epoch 183.628) train_loss=107.44664001 time/batch=0.72s
22329/10943 (epoch 183.636) train_loss=98.91590881 time/batch=0.61s
22330/10943 (epoch 183.644) train_loss=90.50492096 time/batch=0.52s
22331/10943 (epoch 183.653) train_loss=140.74368286 time/batch=0.82s
22332/10943 (epoch 183.661) train_loss=117.79995728 time/batch=0.73s
22333/10943 (epoch 183.669) train_loss=96.45700073 time/batch=0.57s
22334/10943 (epoch 183.677) train_loss=118.56963348 time/batch=0.69s
22335/10943 (epoch 183.685) train_loss=215.25663757 time/batch=1.14s
22336/10943 (epoch 183.694) train_loss=229.74813843 time/batch=1.27s
22337/10943 (epoch 183.702) train_loss=132.92248535 time/batch=0.92s
22338/10943 (epoch 183.710) train_loss=222.51893616 time/batch=1.25s
22339/10943 (epoch 183.718) train_loss=109.21770477 time/batch=0.76s
22340/10943 (epoch 183.727) train_loss=98.97933960 time/batch=0.65s
22341/10943 (epoch 183.735) train_loss=141.62777710 time/batch=0.94s
22342/10943 (epoch 183.743) train_loss=93.25257874 time/batch=0.61s
22343/10943 (epoch 183.751) train_loss=148.20895386 time/batch=0.96s
22344/10943 (epoch 183.759) train_loss=66.55120850 time/batch=0.42s
22345/10943 (epoch 183.768) train_loss=161.52416992 time/batch=0.91s
22346/10943 (epoch 183.776) train_loss=152.31054688 time/batch=0.95s
22347/10943 (epoch 183.784) train_loss=167.45292664 time/batch=1.03s
22348/10943 (epoch 183.792) train_loss=159.74533081 time/batch=0.96s
22349/10943 (epoch 183.801) train_loss=69.70009613 time/batch=0.44s
22350/10943 (epoch 183.809) train_loss=230.45578003 time/batch=1.19s
22351/10943 (epoch 183.817) train_loss=98.43098450 time/batch=0.67s
22352/10943 (epoch 183.825) train_loss=219.74699402 time/batch=1.24s
22353/10943 (epoch 183.833) train_loss=168.84878540 time/batch=1.06s
22354/10943 (epoch 183.842) train_loss=159.65121460 time/batch=0.90s
22355/10943 (epoch 183.850) train_loss=80.67304993 time/batch=0.49s
22356/10943 (epoch 183.858) train_loss=63.59246826 time/batch=0.38s
22357/10943 (epoch 183.866) train_loss=106.49606323 time/batch=0.61s
22358/10943 (epoch 183.875) train_loss=111.56001282 time/batch=0.72s
22359/10943 (epoch 183.883) train_loss=198.92387390 time/batch=1.13s
22360/10943 (epoch 183.891) train_loss=126.55255890 time/batch=0.77s
22361/10943 (epoch 183.899) train_loss=204.32977295 time/batch=1.15s
22362/10943 (epoch 183.907) train_loss=139.26547241 time/batch=0.89s
22363/10943 (epoch 183.916) train_loss=140.38574219 time/batch=0.83s
22364/10943 (epoch 183.924) train_loss=75.26463318 time/batch=0.47s
22365/10943 (epoch 183.932) train_loss=100.31118774 time/batch=0.55s
22366/10943 (epoch 183.940) train_loss=98.21443176 time/batch=0.53s
22367/10943 (epoch 183.949) train_loss=128.45175171 time/batch=0.83s
22368/10943 (epoch 183.957) train_loss=78.58772278 time/batch=0.48s
22369/10943 (epoch 183.965) train_loss=121.92346191 time/batch=0.73s
22370/10943 (epoch 183.973) train_loss=188.72070312 time/batch=1.07s
22371/10943 (epoch 183.981) train_loss=123.05843353 time/batch=0.82s
22372/10943 (epoch 183.990) train_loss=140.37612915 time/batch=0.92s
22373/10943 (epoch 183.998) train_loss=94.03836060 time/batch=0.62s
22374/10943 (epoch 184.006) train_loss=134.76298523 time/batch=0.76s
22375/10943 (epoch 184.014) train_loss=114.37681580 time/batch=0.77s
22376/10943 (epoch 184.023) train_loss=95.66082764 time/batch=0.61s
22377/10943 (epoch 184.031) train_loss=172.21536255 time/batch=1.04s
22378/10943 (epoch 184.039) train_loss=109.08711243 time/batch=0.69s
22379/10943 (epoch 184.047) train_loss=146.14431763 time/batch=0.88s
22380/10943 (epoch 184.056) train_loss=119.89666748 time/batch=0.77s
22381/10943 (epoch 184.064) train_loss=150.74594116 time/batch=0.89s
22382/10943 (epoch 184.072) train_loss=119.66270447 time/batch=0.77s
22383/10943 (epoch 184.080) train_loss=105.41726685 time/batch=0.66s
22384/10943 (epoch 184.088) train_loss=153.91656494 time/batch=0.95s
22385/10943 (epoch 184.097) train_loss=132.27908325 time/batch=0.85s
22386/10943 (epoch 184.105) train_loss=123.40347290 time/batch=0.69s
22387/10943 (epoch 184.113) train_loss=157.07281494 time/batch=0.96s
22388/10943 (epoch 184.121) train_loss=110.77415466 time/batch=0.71s
22389/10943 (epoch 184.130) train_loss=88.76644897 time/batch=0.50s
22390/10943 (epoch 184.138) train_loss=180.93696594 time/batch=1.00s
22391/10943 (epoch 184.146) train_loss=118.91245270 time/batch=0.75s
22392/10943 (epoch 184.154) train_loss=153.20628357 time/batch=0.97s
22393/10943 (epoch 184.162) train_loss=124.19539642 time/batch=0.77s
22394/10943 (epoch 184.171) train_loss=182.15682983 time/batch=1.10s
22395/10943 (epoch 184.179) train_loss=161.31254578 time/batch=1.03s
22396/10943 (epoch 184.187) train_loss=86.41148376 time/batch=0.52s
22397/10943 (epoch 184.195) train_loss=86.73260498 time/batch=0.63s
22398/10943 (epoch 184.204) train_loss=172.42115784 time/batch=1.00s
22399/10943 (epoch 184.212) train_loss=162.41793823 time/batch=1.07s
22400/10943 (epoch 184.220) train_loss=165.42254639 time/batch=1.02s
22401/10943 (epoch 184.228) train_loss=175.99603271 time/batch=1.07s
22402/10943 (epoch 184.236) train_loss=107.98168945 time/batch=0.76s
22403/10943 (epoch 184.245) train_loss=117.60834503 time/batch=0.74s
22404/10943 (epoch 184.253) train_loss=126.14814758 time/batch=0.78s
setting learning rate to 0.0005971
22405/10943 (epoch 184.261) train_loss=86.75305176 time/batch=0.51s
22406/10943 (epoch 184.269) train_loss=168.42286682 time/batch=1.00s
22407/10943 (epoch 184.278) train_loss=289.12887573 time/batch=1.65s
22408/10943 (epoch 184.286) train_loss=538.29907227 time/batch=3.88s
22409/10943 (epoch 184.294) train_loss=330.30053711 time/batch=2.16s
22410/10943 (epoch 184.302) train_loss=238.99215698 time/batch=1.33s
22411/10943 (epoch 184.310) train_loss=73.11384583 time/batch=0.46s
22412/10943 (epoch 184.319) train_loss=259.32275391 time/batch=1.45s
22413/10943 (epoch 184.327) train_loss=303.90997314 time/batch=1.89s
22414/10943 (epoch 184.335) train_loss=90.88867188 time/batch=0.71s
22415/10943 (epoch 184.343) train_loss=224.91717529 time/batch=1.24s
22416/10943 (epoch 184.352) train_loss=57.44703293 time/batch=0.42s
22417/10943 (epoch 184.360) train_loss=265.38446045 time/batch=1.40s
22418/10943 (epoch 184.368) train_loss=180.13352966 time/batch=1.13s
22419/10943 (epoch 184.376) train_loss=258.52099609 time/batch=1.44s
22420/10943 (epoch 184.384) train_loss=79.59744263 time/batch=0.57s
22421/10943 (epoch 184.393) train_loss=90.31875610 time/batch=0.53s
22422/10943 (epoch 184.401) train_loss=219.82727051 time/batch=1.19s
22423/10943 (epoch 184.409) train_loss=137.58615112 time/batch=0.94s
22424/10943 (epoch 184.417) train_loss=397.38317871 time/batch=2.05s
22425/10943 (epoch 184.426) train_loss=141.56381226 time/batch=1.01s
22426/10943 (epoch 184.434) train_loss=73.82693481 time/batch=0.44s
22427/10943 (epoch 184.442) train_loss=105.15727997 time/batch=0.66s
22428/10943 (epoch 184.450) train_loss=171.58563232 time/batch=1.07s
22429/10943 (epoch 184.458) train_loss=99.67480469 time/batch=0.66s
22430/10943 (epoch 184.467) train_loss=137.81005859 time/batch=0.83s
22431/10943 (epoch 184.475) train_loss=208.99694824 time/batch=1.15s
22432/10943 (epoch 184.483) train_loss=196.36828613 time/batch=1.23s
22433/10943 (epoch 184.491) train_loss=65.81591797 time/batch=0.43s
22434/10943 (epoch 184.500) train_loss=249.00898743 time/batch=1.30s
22435/10943 (epoch 184.508) train_loss=144.73367310 time/batch=0.94s
22436/10943 (epoch 184.516) train_loss=102.88245392 time/batch=0.67s
22437/10943 (epoch 184.524) train_loss=185.41622925 time/batch=1.10s
22438/10943 (epoch 184.533) train_loss=202.56491089 time/batch=1.23s
22439/10943 (epoch 184.541) train_loss=101.09073639 time/batch=0.72s
22440/10943 (epoch 184.549) train_loss=267.04107666 time/batch=1.34s
22441/10943 (epoch 184.557) train_loss=149.92750549 time/batch=0.99s
22442/10943 (epoch 184.565) train_loss=328.28283691 time/batch=1.90s
22443/10943 (epoch 184.574) train_loss=257.11010742 time/batch=1.51s
22444/10943 (epoch 184.582) train_loss=156.15704346 time/batch=0.99s
22445/10943 (epoch 184.590) train_loss=102.59658813 time/batch=0.67s
22446/10943 (epoch 184.598) train_loss=105.04988861 time/batch=0.69s
22447/10943 (epoch 184.607) train_loss=232.87094116 time/batch=1.42s
22448/10943 (epoch 184.615) train_loss=86.61006165 time/batch=0.62s
22449/10943 (epoch 184.623) train_loss=144.72125244 time/batch=0.95s
22450/10943 (epoch 184.631) train_loss=136.96028137 time/batch=0.84s
22451/10943 (epoch 184.639) train_loss=66.64665222 time/batch=0.42s
22452/10943 (epoch 184.648) train_loss=114.49692535 time/batch=0.68s
22453/10943 (epoch 184.656) train_loss=161.48568726 time/batch=1.01s
22454/10943 (epoch 184.664) train_loss=160.30487061 time/batch=1.02s
22455/10943 (epoch 184.672) train_loss=190.19226074 time/batch=1.11s
22456/10943 (epoch 184.681) train_loss=171.53536987 time/batch=1.05s
22457/10943 (epoch 184.689) train_loss=153.64550781 time/batch=0.95s
22458/10943 (epoch 184.697) train_loss=150.34118652 time/batch=0.99s
22459/10943 (epoch 184.705) train_loss=86.52432251 time/batch=0.56s
22460/10943 (epoch 184.713) train_loss=147.43286133 time/batch=0.95s
22461/10943 (epoch 184.722) train_loss=71.36985016 time/batch=0.45s
22462/10943 (epoch 184.730) train_loss=115.90274048 time/batch=0.71s
22463/10943 (epoch 184.738) train_loss=92.89274597 time/batch=0.60s
22464/10943 (epoch 184.746) train_loss=120.59518433 time/batch=0.76s
22465/10943 (epoch 184.755) train_loss=116.05885315 time/batch=0.73s
22466/10943 (epoch 184.763) train_loss=97.60325623 time/batch=0.61s
22467/10943 (epoch 184.771) train_loss=156.79534912 time/batch=0.95s
22468/10943 (epoch 184.779) train_loss=172.27998352 time/batch=1.05s
22469/10943 (epoch 184.787) train_loss=77.94046783 time/batch=0.53s
22470/10943 (epoch 184.796) train_loss=106.14671326 time/batch=0.60s
22471/10943 (epoch 184.804) train_loss=136.74632263 time/batch=0.82s
22472/10943 (epoch 184.812) train_loss=88.08802795 time/batch=0.51s
22473/10943 (epoch 184.820) train_loss=164.11772156 time/batch=0.91s
22474/10943 (epoch 184.829) train_loss=192.93768311 time/batch=1.16s
22475/10943 (epoch 184.837) train_loss=244.82655334 time/batch=1.30s
22476/10943 (epoch 184.845) train_loss=201.38946533 time/batch=1.28s
22477/10943 (epoch 184.853) train_loss=135.81471252 time/batch=0.98s
22478/10943 (epoch 184.861) train_loss=235.36962891 time/batch=1.48s
22479/10943 (epoch 184.870) train_loss=204.33815002 time/batch=1.58s
22480/10943 (epoch 184.878) train_loss=145.58935547 time/batch=1.03s
22481/10943 (epoch 184.886) train_loss=146.92327881 time/batch=0.98s
22482/10943 (epoch 184.894) train_loss=112.54162598 time/batch=0.79s
22483/10943 (epoch 184.903) train_loss=96.81178284 time/batch=0.56s
22484/10943 (epoch 184.911) train_loss=102.09867096 time/batch=0.57s
22485/10943 (epoch 184.919) train_loss=79.36888123 time/batch=0.45s
22486/10943 (epoch 184.927) train_loss=148.12992859 time/batch=0.78s
22487/10943 (epoch 184.935) train_loss=126.74407959 time/batch=0.79s
22488/10943 (epoch 184.944) train_loss=133.34458923 time/batch=0.80s
22489/10943 (epoch 184.952) train_loss=154.44902039 time/batch=1.00s
22490/10943 (epoch 184.960) train_loss=141.41264343 time/batch=0.88s
22491/10943 (epoch 184.968) train_loss=142.99066162 time/batch=0.91s
22492/10943 (epoch 184.977) train_loss=97.07019806 time/batch=0.63s
22493/10943 (epoch 184.985) train_loss=166.71179199 time/batch=1.02s
22494/10943 (epoch 184.993) train_loss=72.66521454 time/batch=0.47s
22495/10943 (epoch 185.001) train_loss=121.60829163 time/batch=0.64s
22496/10943 (epoch 185.010) train_loss=125.59738159 time/batch=0.77s
22497/10943 (epoch 185.018) train_loss=99.39781189 time/batch=0.68s
22498/10943 (epoch 185.026) train_loss=108.88438416 time/batch=0.68s
22499/10943 (epoch 185.034) train_loss=187.32478333 time/batch=1.08s
22500/10943 (epoch 185.042) train_loss=103.46823120 time/batch=0.67s
22501/10943 (epoch 185.051) train_loss=167.11376953 time/batch=1.04s
22502/10943 (epoch 185.059) train_loss=123.07305908 time/batch=0.79s
22503/10943 (epoch 185.067) train_loss=81.98535919 time/batch=0.46s
22504/10943 (epoch 185.075) train_loss=131.80496216 time/batch=0.77s
22505/10943 (epoch 185.084) train_loss=159.57901001 time/batch=1.04s
22506/10943 (epoch 185.092) train_loss=108.41310883 time/batch=0.68s
22507/10943 (epoch 185.100) train_loss=154.45138550 time/batch=0.86s
22508/10943 (epoch 185.108) train_loss=151.80764771 time/batch=0.94s
22509/10943 (epoch 185.116) train_loss=121.48211670 time/batch=0.76s
22510/10943 (epoch 185.125) train_loss=158.10812378 time/batch=0.87s
22511/10943 (epoch 185.133) train_loss=106.71668243 time/batch=0.71s
22512/10943 (epoch 185.141) train_loss=114.74750519 time/batch=0.73s
22513/10943 (epoch 185.149) train_loss=155.68025208 time/batch=0.96s
22514/10943 (epoch 185.158) train_loss=128.20080566 time/batch=0.88s
22515/10943 (epoch 185.166) train_loss=165.87478638 time/batch=0.90s
22516/10943 (epoch 185.174) train_loss=138.88406372 time/batch=0.82s
22517/10943 (epoch 185.182) train_loss=142.77717590 time/batch=0.90s
22518/10943 (epoch 185.190) train_loss=160.16352844 time/batch=1.05s
22519/10943 (epoch 185.199) train_loss=113.16604614 time/batch=0.75s
22520/10943 (epoch 185.207) train_loss=88.60629272 time/batch=0.70s
22521/10943 (epoch 185.215) train_loss=126.40238190 time/batch=0.80s
22522/10943 (epoch 185.223) train_loss=116.58290863 time/batch=0.73s
22523/10943 (epoch 185.232) train_loss=114.27175903 time/batch=0.73s
22524/10943 (epoch 185.240) train_loss=91.88566589 time/batch=0.73s
22525/10943 (epoch 185.248) train_loss=122.81007385 time/batch=0.75s
setting learning rate to 0.0005792
  saved to metadata/lstm_dropout-9_nov_folkwiki-20181112-195023.pkl
22526/10943 (epoch 185.256) train_loss=87.93337250 time/batch=0.64s
22527/10943 (epoch 185.264) train_loss=74.66187286 time/batch=0.43s
22528/10943 (epoch 185.273) train_loss=162.36074829 time/batch=0.96s
22529/10943 (epoch 185.281) train_loss=221.12390137 time/batch=1.30s
22530/10943 (epoch 185.289) train_loss=142.89089966 time/batch=0.99s
22531/10943 (epoch 185.297) train_loss=172.23690796 time/batch=1.08s
22532/10943 (epoch 185.306) train_loss=158.94128418 time/batch=0.91s
22533/10943 (epoch 185.314) train_loss=91.23234558 time/batch=0.55s
22534/10943 (epoch 185.322) train_loss=533.00549316 time/batch=3.73s
22535/10943 (epoch 185.330) train_loss=395.55426025 time/batch=2.29s
22536/10943 (epoch 185.338) train_loss=86.94584656 time/batch=0.65s
22537/10943 (epoch 185.347) train_loss=200.34970093 time/batch=1.10s
22538/10943 (epoch 185.355) train_loss=84.48721313 time/batch=0.51s
22539/10943 (epoch 185.363) train_loss=286.52127075 time/batch=1.51s
22540/10943 (epoch 185.371) train_loss=239.77853394 time/batch=1.40s
22541/10943 (epoch 185.380) train_loss=334.66531372 time/batch=2.05s
22542/10943 (epoch 185.388) train_loss=155.54905701 time/batch=1.19s
22543/10943 (epoch 185.396) train_loss=181.33052063 time/batch=1.15s
22544/10943 (epoch 185.404) train_loss=88.97196198 time/batch=0.57s
22545/10943 (epoch 185.412) train_loss=141.54232788 time/batch=0.83s
22546/10943 (epoch 185.421) train_loss=256.47683716 time/batch=1.38s
22547/10943 (epoch 185.429) train_loss=72.10757446 time/batch=0.48s
22548/10943 (epoch 185.437) train_loss=186.61862183 time/batch=1.04s
22549/10943 (epoch 185.445) train_loss=152.24208069 time/batch=1.02s
22550/10943 (epoch 185.454) train_loss=209.33506775 time/batch=1.25s
22551/10943 (epoch 185.462) train_loss=323.02496338 time/batch=2.11s
22552/10943 (epoch 185.470) train_loss=116.56495667 time/batch=0.87s
22553/10943 (epoch 185.478) train_loss=57.51098633 time/batch=0.35s
22554/10943 (epoch 185.487) train_loss=83.14720154 time/batch=0.47s
22555/10943 (epoch 185.495) train_loss=115.69552612 time/batch=0.74s
22556/10943 (epoch 185.503) train_loss=107.80411530 time/batch=0.71s
22557/10943 (epoch 185.511) train_loss=66.25288391 time/batch=0.37s
22558/10943 (epoch 185.519) train_loss=175.41464233 time/batch=0.98s
22559/10943 (epoch 185.528) train_loss=260.48657227 time/batch=1.44s
22560/10943 (epoch 185.536) train_loss=203.19250488 time/batch=1.25s
22561/10943 (epoch 185.544) train_loss=95.90541840 time/batch=0.65s
22562/10943 (epoch 185.552) train_loss=196.09774780 time/batch=1.16s
22563/10943 (epoch 185.561) train_loss=231.97267151 time/batch=1.48s
22564/10943 (epoch 185.569) train_loss=75.53356934 time/batch=0.52s
22565/10943 (epoch 185.577) train_loss=80.96650696 time/batch=0.49s
22566/10943 (epoch 185.585) train_loss=129.97726440 time/batch=0.81s
22567/10943 (epoch 185.593) train_loss=108.84648132 time/batch=0.74s
22568/10943 (epoch 185.602) train_loss=153.14903259 time/batch=0.94s
22569/10943 (epoch 185.610) train_loss=186.67799377 time/batch=1.11s
22570/10943 (epoch 185.618) train_loss=99.23649597 time/batch=0.71s
22571/10943 (epoch 185.626) train_loss=247.70645142 time/batch=1.31s
22572/10943 (epoch 185.635) train_loss=106.68019104 time/batch=0.72s
22573/10943 (epoch 185.643) train_loss=112.82922363 time/batch=0.65s
22574/10943 (epoch 185.651) train_loss=159.07112122 time/batch=0.94s
22575/10943 (epoch 185.659) train_loss=150.24853516 time/batch=1.00s
22576/10943 (epoch 185.667) train_loss=284.64880371 time/batch=1.60s
22577/10943 (epoch 185.676) train_loss=292.72100830 time/batch=1.74s
22578/10943 (epoch 185.684) train_loss=163.46223450 time/batch=1.11s
22579/10943 (epoch 185.692) train_loss=149.06204224 time/batch=0.99s
22580/10943 (epoch 185.700) train_loss=146.46286011 time/batch=0.98s
22581/10943 (epoch 185.709) train_loss=153.75183105 time/batch=1.03s
22582/10943 (epoch 185.717) train_loss=101.80799866 time/batch=0.65s
22583/10943 (epoch 185.725) train_loss=231.97677612 time/batch=1.22s
22584/10943 (epoch 185.733) train_loss=115.83135223 time/batch=0.82s
22585/10943 (epoch 185.741) train_loss=267.56188965 time/batch=1.45s
22586/10943 (epoch 185.750) train_loss=91.77965546 time/batch=0.65s
22587/10943 (epoch 185.758) train_loss=93.71495819 time/batch=0.57s
22588/10943 (epoch 185.766) train_loss=142.84051514 time/batch=0.95s
22589/10943 (epoch 185.774) train_loss=251.88565063 time/batch=1.49s
22590/10943 (epoch 185.783) train_loss=137.95167542 time/batch=0.93s
22591/10943 (epoch 185.791) train_loss=201.46725464 time/batch=1.17s
22592/10943 (epoch 185.799) train_loss=77.37614441 time/batch=0.52s
22593/10943 (epoch 185.807) train_loss=138.72024536 time/batch=0.79s
22594/10943 (epoch 185.815) train_loss=122.16342163 time/batch=0.78s
22595/10943 (epoch 185.824) train_loss=135.71273804 time/batch=0.89s
22596/10943 (epoch 185.832) train_loss=169.41390991 time/batch=1.04s
22597/10943 (epoch 185.840) train_loss=109.22186279 time/batch=0.80s
22598/10943 (epoch 185.848) train_loss=168.06921387 time/batch=1.05s
22599/10943 (epoch 185.857) train_loss=148.48155212 time/batch=0.93s
22600/10943 (epoch 185.865) train_loss=150.24995422 time/batch=0.92s
22601/10943 (epoch 185.873) train_loss=119.01538086 time/batch=0.77s
22602/10943 (epoch 185.881) train_loss=134.96823120 time/batch=0.96s
22603/10943 (epoch 185.889) train_loss=123.53047180 time/batch=0.81s
22604/10943 (epoch 185.898) train_loss=69.56517029 time/batch=0.44s
22605/10943 (epoch 185.906) train_loss=65.71028137 time/batch=0.43s
22606/10943 (epoch 185.914) train_loss=68.96514893 time/batch=0.45s
22607/10943 (epoch 185.922) train_loss=186.56271362 time/batch=1.06s
22608/10943 (epoch 185.931) train_loss=98.78558350 time/batch=0.67s
22609/10943 (epoch 185.939) train_loss=152.72906494 time/batch=0.88s
22610/10943 (epoch 185.947) train_loss=145.91741943 time/batch=0.99s
22611/10943 (epoch 185.955) train_loss=85.82872009 time/batch=0.56s
22612/10943 (epoch 185.964) train_loss=106.06658936 time/batch=0.66s
22613/10943 (epoch 185.972) train_loss=113.95046997 time/batch=0.68s
22614/10943 (epoch 185.980) train_loss=94.56150818 time/batch=0.57s
22615/10943 (epoch 185.988) train_loss=115.89994049 time/batch=0.73s
22616/10943 (epoch 185.996) train_loss=171.89602661 time/batch=1.06s
22617/10943 (epoch 186.005) train_loss=136.32876587 time/batch=0.83s
22618/10943 (epoch 186.013) train_loss=133.86105347 time/batch=0.80s
22619/10943 (epoch 186.021) train_loss=163.56936646 time/batch=1.04s
22620/10943 (epoch 186.029) train_loss=97.41098022 time/batch=0.63s
22621/10943 (epoch 186.038) train_loss=111.28239441 time/batch=0.68s
22622/10943 (epoch 186.046) train_loss=168.82540894 time/batch=1.08s
22623/10943 (epoch 186.054) train_loss=98.34765625 time/batch=0.75s
22624/10943 (epoch 186.062) train_loss=99.04862976 time/batch=0.60s
22625/10943 (epoch 186.070) train_loss=106.99948120 time/batch=0.61s
22626/10943 (epoch 186.079) train_loss=95.39825439 time/batch=0.59s
22627/10943 (epoch 186.087) train_loss=126.01036072 time/batch=0.78s
22628/10943 (epoch 186.095) train_loss=201.80908203 time/batch=1.24s
22629/10943 (epoch 186.103) train_loss=158.03976440 time/batch=0.97s
22630/10943 (epoch 186.112) train_loss=145.08793640 time/batch=0.88s
22631/10943 (epoch 186.120) train_loss=120.64983368 time/batch=0.74s
22632/10943 (epoch 186.128) train_loss=116.40440369 time/batch=0.72s
22633/10943 (epoch 186.136) train_loss=91.25985718 time/batch=0.61s
22634/10943 (epoch 186.144) train_loss=135.15719604 time/batch=0.81s
22635/10943 (epoch 186.153) train_loss=144.84558105 time/batch=0.91s
22636/10943 (epoch 186.161) train_loss=159.48214722 time/batch=1.11s
22637/10943 (epoch 186.169) train_loss=109.84941101 time/batch=0.78s
22638/10943 (epoch 186.177) train_loss=124.95403290 time/batch=0.90s
22639/10943 (epoch 186.186) train_loss=125.69998169 time/batch=0.82s
22640/10943 (epoch 186.194) train_loss=190.01232910 time/batch=1.23s
22641/10943 (epoch 186.202) train_loss=114.80725098 time/batch=0.79s
22642/10943 (epoch 186.210) train_loss=97.83222961 time/batch=0.64s
22643/10943 (epoch 186.218) train_loss=220.02020264 time/batch=1.23s
22644/10943 (epoch 186.227) train_loss=112.92349243 time/batch=0.80s
22645/10943 (epoch 186.235) train_loss=141.21801758 time/batch=0.82s
22646/10943 (epoch 186.243) train_loss=137.55686951 time/batch=0.83s
setting learning rate to 0.0005618
22647/10943 (epoch 186.251) train_loss=354.67739868 time/batch=1.96s
22648/10943 (epoch 186.260) train_loss=112.33432007 time/batch=0.87s
22649/10943 (epoch 186.268) train_loss=287.40954590 time/batch=1.58s
22650/10943 (epoch 186.276) train_loss=338.21765137 time/batch=2.04s
22651/10943 (epoch 186.284) train_loss=68.11573792 time/batch=0.57s
22652/10943 (epoch 186.292) train_loss=56.32424927 time/batch=0.33s
22653/10943 (epoch 186.301) train_loss=207.56640625 time/batch=1.16s
22654/10943 (epoch 186.309) train_loss=287.15802002 time/batch=1.71s
22655/10943 (epoch 186.317) train_loss=232.29739380 time/batch=1.32s
22656/10943 (epoch 186.325) train_loss=163.75444031 time/batch=1.08s
22657/10943 (epoch 186.334) train_loss=86.66741180 time/batch=0.57s
22658/10943 (epoch 186.342) train_loss=111.27832031 time/batch=0.73s
22659/10943 (epoch 186.350) train_loss=513.06787109 time/batch=3.76s
22660/10943 (epoch 186.358) train_loss=154.32087708 time/batch=1.28s
22661/10943 (epoch 186.366) train_loss=166.47621155 time/batch=1.03s
22662/10943 (epoch 186.375) train_loss=73.95138550 time/batch=0.48s
22663/10943 (epoch 186.383) train_loss=73.44924164 time/batch=0.42s
22664/10943 (epoch 186.391) train_loss=100.93737793 time/batch=0.67s
22665/10943 (epoch 186.399) train_loss=199.11215210 time/batch=1.18s
22666/10943 (epoch 186.408) train_loss=66.09176636 time/batch=0.44s
22667/10943 (epoch 186.416) train_loss=172.02693176 time/batch=0.98s
22668/10943 (epoch 186.424) train_loss=65.85611725 time/batch=0.44s
22669/10943 (epoch 186.432) train_loss=111.40142822 time/batch=0.67s
22670/10943 (epoch 186.441) train_loss=180.21922302 time/batch=1.12s
22671/10943 (epoch 186.449) train_loss=124.17570496 time/batch=0.84s
22672/10943 (epoch 186.457) train_loss=256.92276001 time/batch=1.44s
22673/10943 (epoch 186.465) train_loss=147.36557007 time/batch=0.97s
22674/10943 (epoch 186.473) train_loss=202.13409424 time/batch=1.16s
22675/10943 (epoch 186.482) train_loss=104.62820435 time/batch=0.79s
22676/10943 (epoch 186.490) train_loss=169.91407776 time/batch=1.01s
22677/10943 (epoch 186.498) train_loss=248.48730469 time/batch=1.43s
22678/10943 (epoch 186.506) train_loss=94.93752289 time/batch=0.66s
22679/10943 (epoch 186.515) train_loss=247.06915283 time/batch=1.28s
22680/10943 (epoch 186.523) train_loss=70.86695862 time/batch=0.54s
22681/10943 (epoch 186.531) train_loss=123.92417908 time/batch=0.83s
22682/10943 (epoch 186.539) train_loss=78.80053711 time/batch=0.50s
22683/10943 (epoch 186.547) train_loss=100.64579773 time/batch=0.62s
22684/10943 (epoch 186.556) train_loss=237.10958862 time/batch=1.33s
22685/10943 (epoch 186.564) train_loss=281.93112183 time/batch=1.74s
22686/10943 (epoch 186.572) train_loss=138.04452515 time/batch=0.98s
22687/10943 (epoch 186.580) train_loss=110.30860901 time/batch=0.70s
22688/10943 (epoch 186.589) train_loss=112.15913391 time/batch=0.75s
22689/10943 (epoch 186.597) train_loss=152.85650635 time/batch=1.05s
22690/10943 (epoch 186.605) train_loss=136.16769409 time/batch=0.89s
22691/10943 (epoch 186.613) train_loss=84.52561951 time/batch=0.52s
22692/10943 (epoch 186.621) train_loss=65.65263367 time/batch=0.39s
22693/10943 (epoch 186.630) train_loss=152.11563110 time/batch=0.91s
22694/10943 (epoch 186.638) train_loss=116.44401550 time/batch=0.81s
22695/10943 (epoch 186.646) train_loss=77.15085602 time/batch=0.51s
22696/10943 (epoch 186.654) train_loss=122.84778595 time/batch=0.74s
22697/10943 (epoch 186.663) train_loss=116.42013550 time/batch=0.69s
22698/10943 (epoch 186.671) train_loss=191.79107666 time/batch=1.07s
22699/10943 (epoch 186.679) train_loss=98.76657867 time/batch=0.64s
22700/10943 (epoch 186.687) train_loss=130.41024780 time/batch=0.83s
22701/10943 (epoch 186.695) train_loss=181.24734497 time/batch=1.11s
22702/10943 (epoch 186.704) train_loss=312.20565796 time/batch=2.09s
22703/10943 (epoch 186.712) train_loss=147.09962463 time/batch=1.13s
22704/10943 (epoch 186.720) train_loss=194.83335876 time/batch=1.26s
22705/10943 (epoch 186.728) train_loss=93.54530334 time/batch=0.62s
22706/10943 (epoch 186.737) train_loss=115.63734436 time/batch=0.74s
22707/10943 (epoch 186.745) train_loss=152.04910278 time/batch=0.95s
22708/10943 (epoch 186.753) train_loss=236.77458191 time/batch=1.31s
22709/10943 (epoch 186.761) train_loss=140.12503052 time/batch=0.89s
22710/10943 (epoch 186.769) train_loss=133.73095703 time/batch=0.94s
22711/10943 (epoch 186.778) train_loss=107.10466003 time/batch=0.74s
22712/10943 (epoch 186.786) train_loss=98.70475006 time/batch=0.66s
22713/10943 (epoch 186.794) train_loss=89.51594543 time/batch=0.51s
22714/10943 (epoch 186.802) train_loss=137.49533081 time/batch=0.86s
22715/10943 (epoch 186.811) train_loss=78.34214020 time/batch=0.46s
22716/10943 (epoch 186.819) train_loss=84.76958466 time/batch=0.49s
22717/10943 (epoch 186.827) train_loss=91.31753540 time/batch=0.53s
22718/10943 (epoch 186.835) train_loss=149.48641968 time/batch=0.90s
22719/10943 (epoch 186.843) train_loss=102.12515259 time/batch=0.69s
22720/10943 (epoch 186.852) train_loss=99.93940735 time/batch=0.62s
22721/10943 (epoch 186.860) train_loss=77.26130676 time/batch=0.46s
22722/10943 (epoch 186.868) train_loss=90.87676239 time/batch=0.54s
22723/10943 (epoch 186.876) train_loss=163.45773315 time/batch=0.99s
22724/10943 (epoch 186.885) train_loss=167.32513428 time/batch=1.08s
22725/10943 (epoch 186.893) train_loss=149.38296509 time/batch=0.99s
22726/10943 (epoch 186.901) train_loss=145.34265137 time/batch=0.99s
22727/10943 (epoch 186.909) train_loss=233.05999756 time/batch=1.28s
22728/10943 (epoch 186.918) train_loss=273.13052368 time/batch=1.49s
22729/10943 (epoch 186.926) train_loss=99.97186279 time/batch=0.71s
22730/10943 (epoch 186.934) train_loss=208.16744995 time/batch=1.24s
22731/10943 (epoch 186.942) train_loss=213.63516235 time/batch=1.36s
22732/10943 (epoch 186.950) train_loss=120.70960999 time/batch=0.78s
22733/10943 (epoch 186.959) train_loss=118.83943176 time/batch=0.76s
22734/10943 (epoch 186.967) train_loss=96.87074280 time/batch=0.58s
22735/10943 (epoch 186.975) train_loss=207.14640808 time/batch=1.13s
22736/10943 (epoch 186.983) train_loss=141.51135254 time/batch=0.87s
22737/10943 (epoch 186.992) train_loss=142.91621399 time/batch=0.86s
22738/10943 (epoch 187.000) train_loss=115.96000671 time/batch=0.74s
22739/10943 (epoch 187.008) train_loss=162.44908142 time/batch=1.06s
22740/10943 (epoch 187.016) train_loss=123.77432251 time/batch=0.83s
22741/10943 (epoch 187.024) train_loss=138.32437134 time/batch=0.82s
22742/10943 (epoch 187.033) train_loss=166.93898010 time/batch=1.08s
22743/10943 (epoch 187.041) train_loss=235.52288818 time/batch=1.38s
22744/10943 (epoch 187.049) train_loss=219.95071411 time/batch=1.53s
22745/10943 (epoch 187.057) train_loss=160.64538574 time/batch=1.07s
22746/10943 (epoch 187.066) train_loss=116.35914612 time/batch=0.80s
22747/10943 (epoch 187.074) train_loss=89.15344238 time/batch=0.59s
22748/10943 (epoch 187.082) train_loss=98.96894836 time/batch=0.61s
22749/10943 (epoch 187.090) train_loss=153.36051941 time/batch=0.88s
22750/10943 (epoch 187.098) train_loss=129.96423340 time/batch=0.82s
22751/10943 (epoch 187.107) train_loss=102.54985809 time/batch=0.69s
22752/10943 (epoch 187.115) train_loss=135.53762817 time/batch=0.85s
22753/10943 (epoch 187.123) train_loss=98.76890564 time/batch=0.63s
22754/10943 (epoch 187.131) train_loss=107.78172302 time/batch=0.62s
22755/10943 (epoch 187.140) train_loss=143.51753235 time/batch=0.85s
22756/10943 (epoch 187.148) train_loss=94.91070557 time/batch=0.70s
22757/10943 (epoch 187.156) train_loss=157.76681519 time/batch=0.85s
22758/10943 (epoch 187.164) train_loss=123.66031647 time/batch=0.74s
22759/10943 (epoch 187.172) train_loss=180.17059326 time/batch=1.09s
22760/10943 (epoch 187.181) train_loss=147.46627808 time/batch=0.92s
22761/10943 (epoch 187.189) train_loss=123.18331909 time/batch=0.81s
22762/10943 (epoch 187.197) train_loss=158.29141235 time/batch=0.96s
22763/10943 (epoch 187.205) train_loss=151.56256104 time/batch=1.11s
22764/10943 (epoch 187.214) train_loss=155.72454834 time/batch=1.01s
22765/10943 (epoch 187.222) train_loss=143.58941650 time/batch=0.92s
22766/10943 (epoch 187.230) train_loss=153.44029236 time/batch=0.99s
22767/10943 (epoch 187.238) train_loss=114.14705658 time/batch=0.92s
setting learning rate to 0.0005449
22768/10943 (epoch 187.246) train_loss=219.92724609 time/batch=1.25s
22769/10943 (epoch 187.255) train_loss=198.31549072 time/batch=1.20s
22770/10943 (epoch 187.263) train_loss=517.45312500 time/batch=3.80s
22771/10943 (epoch 187.271) train_loss=102.46356201 time/batch=0.99s
22772/10943 (epoch 187.279) train_loss=146.18209839 time/batch=0.91s
22773/10943 (epoch 187.288) train_loss=107.41123962 time/batch=0.70s
22774/10943 (epoch 187.296) train_loss=254.67727661 time/batch=1.36s
22775/10943 (epoch 187.304) train_loss=278.71670532 time/batch=1.72s
22776/10943 (epoch 187.312) train_loss=254.97518921 time/batch=1.44s
22777/10943 (epoch 187.320) train_loss=197.93331909 time/batch=1.24s
22778/10943 (epoch 187.329) train_loss=112.40035248 time/batch=0.75s
22779/10943 (epoch 187.337) train_loss=168.15823364 time/batch=1.01s
22780/10943 (epoch 187.345) train_loss=153.68325806 time/batch=0.90s
22781/10943 (epoch 187.353) train_loss=138.66012573 time/batch=0.98s
22782/10943 (epoch 187.362) train_loss=179.20985413 time/batch=1.11s
22783/10943 (epoch 187.370) train_loss=143.84490967 time/batch=0.98s
22784/10943 (epoch 187.378) train_loss=192.80938721 time/batch=1.19s
22785/10943 (epoch 187.386) train_loss=95.52893066 time/batch=0.66s
22786/10943 (epoch 187.395) train_loss=140.18229675 time/batch=0.91s
22787/10943 (epoch 187.403) train_loss=311.67825317 time/batch=1.86s
22788/10943 (epoch 187.411) train_loss=108.74771118 time/batch=0.87s
22789/10943 (epoch 187.419) train_loss=143.81803894 time/batch=0.87s
22790/10943 (epoch 187.427) train_loss=143.61740112 time/batch=1.00s
22791/10943 (epoch 187.436) train_loss=97.51915741 time/batch=0.72s
22792/10943 (epoch 187.444) train_loss=250.19824219 time/batch=1.41s
22793/10943 (epoch 187.452) train_loss=109.05255127 time/batch=0.81s
22794/10943 (epoch 187.460) train_loss=202.16906738 time/batch=1.19s
22795/10943 (epoch 187.469) train_loss=131.27284241 time/batch=0.89s
22796/10943 (epoch 187.477) train_loss=127.15828705 time/batch=0.82s
22797/10943 (epoch 187.485) train_loss=81.00447083 time/batch=0.55s
22798/10943 (epoch 187.493) train_loss=202.18148804 time/batch=1.18s
22799/10943 (epoch 187.501) train_loss=259.29507446 time/batch=1.53s
22800/10943 (epoch 187.510) train_loss=171.36555481 time/batch=1.10s
22801/10943 (epoch 187.518) train_loss=220.43618774 time/batch=1.26s
22802/10943 (epoch 187.526) train_loss=111.12228394 time/batch=0.76s
22803/10943 (epoch 187.534) train_loss=117.87742615 time/batch=0.67s
22804/10943 (epoch 187.543) train_loss=68.41213989 time/batch=0.37s
22805/10943 (epoch 187.551) train_loss=106.52827454 time/batch=0.71s
22806/10943 (epoch 187.559) train_loss=157.03176880 time/batch=1.04s
22807/10943 (epoch 187.567) train_loss=214.84130859 time/batch=1.32s
22808/10943 (epoch 187.575) train_loss=56.59774017 time/batch=0.43s
22809/10943 (epoch 187.584) train_loss=89.07906342 time/batch=0.48s
22810/10943 (epoch 187.592) train_loss=117.48410034 time/batch=0.72s
22811/10943 (epoch 187.600) train_loss=72.41046143 time/batch=0.44s
22812/10943 (epoch 187.608) train_loss=241.92193604 time/batch=1.39s
22813/10943 (epoch 187.617) train_loss=143.37748718 time/batch=0.89s
22814/10943 (epoch 187.625) train_loss=68.28057861 time/batch=0.41s
22815/10943 (epoch 187.633) train_loss=342.73266602 time/batch=1.91s
22816/10943 (epoch 187.641) train_loss=116.66423035 time/batch=0.91s
22817/10943 (epoch 187.649) train_loss=179.15316772 time/batch=1.11s
22818/10943 (epoch 187.658) train_loss=67.56939697 time/batch=0.48s
22819/10943 (epoch 187.666) train_loss=153.75941467 time/batch=0.96s
22820/10943 (epoch 187.674) train_loss=300.48040771 time/batch=1.59s
22821/10943 (epoch 187.682) train_loss=177.91592407 time/batch=1.17s
22822/10943 (epoch 187.691) train_loss=88.78384399 time/batch=0.59s
22823/10943 (epoch 187.699) train_loss=76.01482391 time/batch=0.46s
22824/10943 (epoch 187.707) train_loss=95.73632050 time/batch=0.58s
22825/10943 (epoch 187.715) train_loss=98.12414551 time/batch=0.62s
22826/10943 (epoch 187.723) train_loss=113.43011475 time/batch=0.76s
22827/10943 (epoch 187.732) train_loss=353.73260498 time/batch=2.04s
22828/10943 (epoch 187.740) train_loss=92.66275024 time/batch=0.72s
22829/10943 (epoch 187.748) train_loss=265.50097656 time/batch=1.47s
22830/10943 (epoch 187.756) train_loss=190.89204407 time/batch=1.23s
22831/10943 (epoch 187.765) train_loss=146.16822815 time/batch=1.00s
22832/10943 (epoch 187.773) train_loss=138.22053528 time/batch=0.92s
22833/10943 (epoch 187.781) train_loss=184.46972656 time/batch=1.09s
22834/10943 (epoch 187.789) train_loss=156.85501099 time/batch=0.98s
22835/10943 (epoch 187.797) train_loss=95.45358276 time/batch=0.60s
22836/10943 (epoch 187.806) train_loss=136.50296021 time/batch=0.80s
22837/10943 (epoch 187.814) train_loss=125.22376251 time/batch=0.87s
22838/10943 (epoch 187.822) train_loss=250.22683716 time/batch=1.45s
22839/10943 (epoch 187.830) train_loss=193.60461426 time/batch=1.30s
22840/10943 (epoch 187.839) train_loss=228.22393799 time/batch=1.35s
22841/10943 (epoch 187.847) train_loss=106.87290955 time/batch=0.70s
22842/10943 (epoch 187.855) train_loss=118.46537781 time/batch=0.71s
22843/10943 (epoch 187.863) train_loss=161.74214172 time/batch=1.05s
22844/10943 (epoch 187.871) train_loss=157.55973816 time/batch=0.94s
22845/10943 (epoch 187.880) train_loss=100.80210876 time/batch=0.67s
22846/10943 (epoch 187.888) train_loss=144.80038452 time/batch=0.97s
22847/10943 (epoch 187.896) train_loss=161.24189758 time/batch=1.08s
22848/10943 (epoch 187.904) train_loss=117.25741577 time/batch=0.75s
22849/10943 (epoch 187.913) train_loss=118.11289978 time/batch=0.75s
22850/10943 (epoch 187.921) train_loss=72.02779388 time/batch=0.48s
22851/10943 (epoch 187.929) train_loss=150.62733459 time/batch=0.94s
22852/10943 (epoch 187.937) train_loss=127.19944763 time/batch=0.80s
22853/10943 (epoch 187.946) train_loss=66.06356049 time/batch=0.43s
22854/10943 (epoch 187.954) train_loss=141.35568237 time/batch=0.86s
22855/10943 (epoch 187.962) train_loss=128.22039795 time/batch=0.82s
22856/10943 (epoch 187.970) train_loss=105.29459381 time/batch=0.72s
22857/10943 (epoch 187.978) train_loss=148.72845459 time/batch=0.93s
22858/10943 (epoch 187.987) train_loss=168.28424072 time/batch=1.03s
22859/10943 (epoch 187.995) train_loss=101.80767822 time/batch=0.63s
22860/10943 (epoch 188.003) train_loss=155.24081421 time/batch=1.01s
22861/10943 (epoch 188.011) train_loss=104.15454865 time/batch=0.69s
22862/10943 (epoch 188.020) train_loss=76.03262329 time/batch=0.44s
22863/10943 (epoch 188.028) train_loss=148.28779602 time/batch=0.87s
22864/10943 (epoch 188.036) train_loss=114.83062744 time/batch=0.78s
22865/10943 (epoch 188.044) train_loss=81.88710022 time/batch=0.50s
22866/10943 (epoch 188.052) train_loss=84.10462189 time/batch=0.47s
22867/10943 (epoch 188.061) train_loss=94.43663788 time/batch=0.63s
22868/10943 (epoch 188.069) train_loss=132.82243347 time/batch=0.84s
22869/10943 (epoch 188.077) train_loss=133.41581726 time/batch=0.85s
22870/10943 (epoch 188.085) train_loss=152.94454956 time/batch=1.00s
22871/10943 (epoch 188.094) train_loss=111.99690247 time/batch=0.79s
22872/10943 (epoch 188.102) train_loss=131.23318481 time/batch=0.81s
22873/10943 (epoch 188.110) train_loss=140.54487610 time/batch=0.84s
22874/10943 (epoch 188.118) train_loss=82.42602539 time/batch=0.49s
22875/10943 (epoch 188.126) train_loss=79.05743408 time/batch=0.45s
22876/10943 (epoch 188.135) train_loss=115.65526581 time/batch=0.69s
22877/10943 (epoch 188.143) train_loss=82.25641632 time/batch=0.53s
22878/10943 (epoch 188.151) train_loss=167.77557373 time/batch=0.96s
22879/10943 (epoch 188.159) train_loss=140.50798035 time/batch=0.86s
22880/10943 (epoch 188.168) train_loss=90.10358429 time/batch=0.59s
22881/10943 (epoch 188.176) train_loss=172.19766235 time/batch=1.20s
22882/10943 (epoch 188.184) train_loss=102.92852783 time/batch=0.76s
22883/10943 (epoch 188.192) train_loss=135.44714355 time/batch=0.88s
22884/10943 (epoch 188.200) train_loss=125.17485809 time/batch=0.80s
22885/10943 (epoch 188.209) train_loss=141.18669128 time/batch=1.01s
22886/10943 (epoch 188.217) train_loss=97.54127502 time/batch=0.82s
22887/10943 (epoch 188.225) train_loss=90.94049072 time/batch=0.54s
22888/10943 (epoch 188.233) train_loss=123.79622650 time/batch=0.82s
setting learning rate to 0.0005286
22889/10943 (epoch 188.242) train_loss=76.01377869 time/batch=0.46s
22890/10943 (epoch 188.250) train_loss=251.03280640 time/batch=1.34s
22891/10943 (epoch 188.258) train_loss=68.82170105 time/batch=0.50s
22892/10943 (epoch 188.266) train_loss=237.71037292 time/batch=1.29s
22893/10943 (epoch 188.274) train_loss=112.10892487 time/batch=0.81s
22894/10943 (epoch 188.283) train_loss=112.35591125 time/batch=0.75s
22895/10943 (epoch 188.291) train_loss=287.05590820 time/batch=1.75s
22896/10943 (epoch 188.299) train_loss=150.84498596 time/batch=1.10s
22897/10943 (epoch 188.307) train_loss=198.30191040 time/batch=1.19s
22898/10943 (epoch 188.316) train_loss=204.24417114 time/batch=1.22s
22899/10943 (epoch 188.324) train_loss=243.80522156 time/batch=1.45s
22900/10943 (epoch 188.332) train_loss=119.16519165 time/batch=0.87s
22901/10943 (epoch 188.340) train_loss=264.36471558 time/batch=1.47s
22902/10943 (epoch 188.348) train_loss=281.38378906 time/batch=1.69s
22903/10943 (epoch 188.357) train_loss=307.43981934 time/batch=1.98s
22904/10943 (epoch 188.365) train_loss=193.78549194 time/batch=1.31s
22905/10943 (epoch 188.373) train_loss=212.96447754 time/batch=1.33s
22906/10943 (epoch 188.381) train_loss=319.95739746 time/batch=1.99s
22907/10943 (epoch 188.390) train_loss=66.60366058 time/batch=0.53s
22908/10943 (epoch 188.398) train_loss=408.53912354 time/batch=2.30s
22909/10943 (epoch 188.406) train_loss=73.68904114 time/batch=0.69s
22910/10943 (epoch 188.414) train_loss=130.86633301 time/batch=0.81s
22911/10943 (epoch 188.423) train_loss=85.63078308 time/batch=0.59s
22912/10943 (epoch 188.431) train_loss=463.58343506 time/batch=3.76s
22913/10943 (epoch 188.439) train_loss=156.86337280 time/batch=1.22s
22914/10943 (epoch 188.447) train_loss=101.33457947 time/batch=0.72s
22915/10943 (epoch 188.455) train_loss=131.44189453 time/batch=0.86s
22916/10943 (epoch 188.464) train_loss=142.14457703 time/batch=0.98s
22917/10943 (epoch 188.472) train_loss=202.65304565 time/batch=1.25s
22918/10943 (epoch 188.480) train_loss=73.91553497 time/batch=0.51s
22919/10943 (epoch 188.488) train_loss=146.04930115 time/batch=0.90s
22920/10943 (epoch 188.497) train_loss=81.69877625 time/batch=0.54s
22921/10943 (epoch 188.505) train_loss=144.39944458 time/batch=0.87s
22922/10943 (epoch 188.513) train_loss=98.74073792 time/batch=0.68s
22923/10943 (epoch 188.521) train_loss=76.43620300 time/batch=0.47s
22924/10943 (epoch 188.529) train_loss=125.72792053 time/batch=0.78s
22925/10943 (epoch 188.538) train_loss=116.50032806 time/batch=0.68s
22926/10943 (epoch 188.546) train_loss=56.16327286 time/batch=0.38s
22927/10943 (epoch 188.554) train_loss=177.08636475 time/batch=1.07s
22928/10943 (epoch 188.562) train_loss=224.29919434 time/batch=1.25s
22929/10943 (epoch 188.571) train_loss=87.37381744 time/batch=0.62s
22930/10943 (epoch 188.579) train_loss=116.87644958 time/batch=0.70s
22931/10943 (epoch 188.587) train_loss=87.74624634 time/batch=0.58s
22932/10943 (epoch 188.595) train_loss=77.75952148 time/batch=0.48s
22933/10943 (epoch 188.603) train_loss=251.14825439 time/batch=1.31s
22934/10943 (epoch 188.612) train_loss=86.40768433 time/batch=0.61s
22935/10943 (epoch 188.620) train_loss=107.14620209 time/batch=0.68s
22936/10943 (epoch 188.628) train_loss=117.17439270 time/batch=0.77s
22937/10943 (epoch 188.636) train_loss=75.33213806 time/batch=0.46s
22938/10943 (epoch 188.645) train_loss=250.46923828 time/batch=1.45s
22939/10943 (epoch 188.653) train_loss=163.42123413 time/batch=1.09s
22940/10943 (epoch 188.661) train_loss=161.04147339 time/batch=1.07s
22941/10943 (epoch 188.669) train_loss=109.82332611 time/batch=0.73s
22942/10943 (epoch 188.677) train_loss=64.03511047 time/batch=0.39s
22943/10943 (epoch 188.686) train_loss=170.87121582 time/batch=1.02s
22944/10943 (epoch 188.694) train_loss=166.25921631 time/batch=1.05s
22945/10943 (epoch 188.702) train_loss=93.63024139 time/batch=0.61s
22946/10943 (epoch 188.710) train_loss=168.51525879 time/batch=0.99s
22947/10943 (epoch 188.719) train_loss=198.12646484 time/batch=1.25s
22948/10943 (epoch 188.727) train_loss=133.78955078 time/batch=0.91s
22949/10943 (epoch 188.735) train_loss=252.12316895 time/batch=1.52s
22950/10943 (epoch 188.743) train_loss=137.53048706 time/batch=0.91s
22951/10943 (epoch 188.751) train_loss=102.71859741 time/batch=0.72s
22952/10943 (epoch 188.760) train_loss=148.21868896 time/batch=0.99s
22953/10943 (epoch 188.768) train_loss=240.28442383 time/batch=1.35s
22954/10943 (epoch 188.776) train_loss=104.37030792 time/batch=0.75s
22955/10943 (epoch 188.784) train_loss=158.43954468 time/batch=1.05s
22956/10943 (epoch 188.793) train_loss=93.53573608 time/batch=0.65s
22957/10943 (epoch 188.801) train_loss=143.51861572 time/batch=0.95s
22958/10943 (epoch 188.809) train_loss=222.64604187 time/batch=1.24s
22959/10943 (epoch 188.817) train_loss=118.07545471 time/batch=0.78s
22960/10943 (epoch 188.825) train_loss=128.79016113 time/batch=0.81s
22961/10943 (epoch 188.834) train_loss=83.73596954 time/batch=0.55s
22962/10943 (epoch 188.842) train_loss=97.29243469 time/batch=0.61s
22963/10943 (epoch 188.850) train_loss=185.27572632 time/batch=1.11s
22964/10943 (epoch 188.858) train_loss=94.01214600 time/batch=0.67s
22965/10943 (epoch 188.867) train_loss=156.15916443 time/batch=0.99s
22966/10943 (epoch 188.875) train_loss=146.08425903 time/batch=0.97s
22967/10943 (epoch 188.883) train_loss=65.91503906 time/batch=0.44s
22968/10943 (epoch 188.891) train_loss=100.75842285 time/batch=0.60s
22969/10943 (epoch 188.900) train_loss=85.92608643 time/batch=0.49s
22970/10943 (epoch 188.908) train_loss=149.98266602 time/batch=0.88s
22971/10943 (epoch 188.916) train_loss=102.66390991 time/batch=0.65s
22972/10943 (epoch 188.924) train_loss=108.95937347 time/batch=0.73s
22973/10943 (epoch 188.932) train_loss=133.48980713 time/batch=0.89s
22974/10943 (epoch 188.941) train_loss=123.94409180 time/batch=0.80s
22975/10943 (epoch 188.949) train_loss=126.82589722 time/batch=0.80s
22976/10943 (epoch 188.957) train_loss=136.72918701 time/batch=0.83s
22977/10943 (epoch 188.965) train_loss=98.36267090 time/batch=0.72s
22978/10943 (epoch 188.974) train_loss=103.14807129 time/batch=0.62s
22979/10943 (epoch 188.982) train_loss=144.26150513 time/batch=0.87s
22980/10943 (epoch 188.990) train_loss=217.01702881 time/batch=1.25s
22981/10943 (epoch 188.998) train_loss=143.95050049 time/batch=1.02s
22982/10943 (epoch 189.006) train_loss=132.58551025 time/batch=0.88s
22983/10943 (epoch 189.015) train_loss=148.03697205 time/batch=0.97s
22984/10943 (epoch 189.023) train_loss=109.60953522 time/batch=0.80s
22985/10943 (epoch 189.031) train_loss=98.51614380 time/batch=0.59s
22986/10943 (epoch 189.039) train_loss=178.37640381 time/batch=1.07s
22987/10943 (epoch 189.048) train_loss=165.08538818 time/batch=1.07s
22988/10943 (epoch 189.056) train_loss=126.22207642 time/batch=0.89s
22989/10943 (epoch 189.064) train_loss=136.17549133 time/batch=0.94s
22990/10943 (epoch 189.072) train_loss=177.30471802 time/batch=1.15s
22991/10943 (epoch 189.080) train_loss=181.11312866 time/batch=1.12s
22992/10943 (epoch 189.089) train_loss=98.30975342 time/batch=0.65s
22993/10943 (epoch 189.097) train_loss=116.72135162 time/batch=0.72s
22994/10943 (epoch 189.105) train_loss=115.97136688 time/batch=0.76s
22995/10943 (epoch 189.113) train_loss=94.27302551 time/batch=0.72s
22996/10943 (epoch 189.122) train_loss=85.36711121 time/batch=0.59s
22997/10943 (epoch 189.130) train_loss=148.22778320 time/batch=1.03s
22998/10943 (epoch 189.138) train_loss=114.81979370 time/batch=0.83s
22999/10943 (epoch 189.146) train_loss=70.59856415 time/batch=0.44s
Validating
    loss:	224.043068

23000/10943 (epoch 189.154) train_loss=143.08491516 time/batch=3.42s
23001/10943 (epoch 189.163) train_loss=131.41848755 time/batch=0.85s
23002/10943 (epoch 189.171) train_loss=105.09042358 time/batch=0.76s
23003/10943 (epoch 189.179) train_loss=146.66537476 time/batch=0.87s
23004/10943 (epoch 189.187) train_loss=166.11572266 time/batch=0.99s
23005/10943 (epoch 189.196) train_loss=134.26370239 time/batch=0.86s
23006/10943 (epoch 189.204) train_loss=147.10182190 time/batch=0.95s
23007/10943 (epoch 189.212) train_loss=150.41943359 time/batch=1.02s
23008/10943 (epoch 189.220) train_loss=123.57352448 time/batch=0.92s
23009/10943 (epoch 189.228) train_loss=141.88613892 time/batch=1.00s
setting learning rate to 0.0005127
23010/10943 (epoch 189.237) train_loss=266.12966919 time/batch=1.55s
23011/10943 (epoch 189.245) train_loss=332.83959961 time/batch=2.00s
23012/10943 (epoch 189.253) train_loss=150.68194580 time/batch=1.08s
23013/10943 (epoch 189.261) train_loss=165.07864380 time/batch=1.05s
23014/10943 (epoch 189.270) train_loss=57.39141083 time/batch=0.39s
23015/10943 (epoch 189.278) train_loss=259.79553223 time/batch=1.48s
23016/10943 (epoch 189.286) train_loss=243.68312073 time/batch=1.53s
23017/10943 (epoch 189.294) train_loss=178.45974731 time/batch=1.18s
23018/10943 (epoch 189.302) train_loss=392.92846680 time/batch=2.19s
23019/10943 (epoch 189.311) train_loss=479.57696533 time/batch=3.92s
23020/10943 (epoch 189.319) train_loss=104.14485168 time/batch=1.02s
23021/10943 (epoch 189.327) train_loss=275.77328491 time/batch=1.60s
23022/10943 (epoch 189.335) train_loss=110.93315125 time/batch=0.82s
23023/10943 (epoch 189.344) train_loss=64.87686157 time/batch=0.43s
23024/10943 (epoch 189.352) train_loss=283.60375977 time/batch=1.70s
23025/10943 (epoch 189.360) train_loss=81.64282227 time/batch=0.61s
23026/10943 (epoch 189.368) train_loss=188.42840576 time/batch=1.12s
23027/10943 (epoch 189.377) train_loss=205.63967896 time/batch=1.29s
23028/10943 (epoch 189.385) train_loss=102.01527405 time/batch=0.74s
23029/10943 (epoch 189.393) train_loss=79.89840698 time/batch=0.46s
23030/10943 (epoch 189.401) train_loss=66.74739838 time/batch=0.37s
23031/10943 (epoch 189.409) train_loss=94.10598755 time/batch=0.60s
23032/10943 (epoch 189.418) train_loss=170.39825439 time/batch=1.10s
23033/10943 (epoch 189.426) train_loss=84.67677307 time/batch=0.57s
23034/10943 (epoch 189.434) train_loss=142.93315125 time/batch=0.89s
23035/10943 (epoch 189.442) train_loss=211.61880493 time/batch=1.23s
23036/10943 (epoch 189.451) train_loss=93.98452759 time/batch=0.65s
23037/10943 (epoch 189.459) train_loss=200.96832275 time/batch=1.18s
23038/10943 (epoch 189.467) train_loss=196.43757629 time/batch=1.23s
23039/10943 (epoch 189.475) train_loss=82.95277405 time/batch=0.61s
23040/10943 (epoch 189.483) train_loss=95.35232544 time/batch=0.67s
23041/10943 (epoch 189.492) train_loss=284.44348145 time/batch=1.65s
23042/10943 (epoch 189.500) train_loss=110.40382385 time/batch=0.79s
23043/10943 (epoch 189.508) train_loss=194.55416870 time/batch=1.15s
23044/10943 (epoch 189.516) train_loss=149.13421631 time/batch=0.95s
23045/10943 (epoch 189.525) train_loss=242.98312378 time/batch=1.37s
23046/10943 (epoch 189.533) train_loss=243.27970886 time/batch=1.45s
23047/10943 (epoch 189.541) train_loss=257.79251099 time/batch=1.48s
23048/10943 (epoch 189.549) train_loss=110.76634216 time/batch=0.80s
23049/10943 (epoch 189.557) train_loss=130.96514893 time/batch=0.93s
23050/10943 (epoch 189.566) train_loss=225.76364136 time/batch=1.27s
23051/10943 (epoch 189.574) train_loss=156.70922852 time/batch=1.09s
23052/10943 (epoch 189.582) train_loss=161.87057495 time/batch=1.09s
23053/10943 (epoch 189.590) train_loss=178.29049683 time/batch=1.16s
23054/10943 (epoch 189.599) train_loss=226.66874695 time/batch=1.35s
23055/10943 (epoch 189.607) train_loss=106.70439148 time/batch=0.70s
23056/10943 (epoch 189.615) train_loss=60.87464905 time/batch=0.39s
23057/10943 (epoch 189.623) train_loss=124.29869080 time/batch=0.76s
23058/10943 (epoch 189.631) train_loss=139.75335693 time/batch=0.98s
23059/10943 (epoch 189.640) train_loss=200.46582031 time/batch=1.29s
23060/10943 (epoch 189.648) train_loss=194.00497437 time/batch=1.20s
23061/10943 (epoch 189.656) train_loss=82.97443390 time/batch=0.60s
23062/10943 (epoch 189.664) train_loss=142.01535034 time/batch=0.88s
23063/10943 (epoch 189.673) train_loss=112.26197815 time/batch=0.79s
23064/10943 (epoch 189.681) train_loss=129.37768555 time/batch=0.84s
23065/10943 (epoch 189.689) train_loss=151.03137207 time/batch=1.05s
23066/10943 (epoch 189.697) train_loss=145.16802979 time/batch=0.95s
23067/10943 (epoch 189.705) train_loss=114.83207703 time/batch=0.75s
23068/10943 (epoch 189.714) train_loss=167.93557739 time/batch=1.05s
23069/10943 (epoch 189.722) train_loss=82.59341431 time/batch=0.56s
23070/10943 (epoch 189.730) train_loss=88.85702515 time/batch=0.54s
23071/10943 (epoch 189.738) train_loss=96.34449005 time/batch=0.55s
23072/10943 (epoch 189.747) train_loss=150.57873535 time/batch=0.94s
23073/10943 (epoch 189.755) train_loss=77.19570923 time/batch=0.56s
23074/10943 (epoch 189.763) train_loss=134.53346252 time/batch=0.82s
23075/10943 (epoch 189.771) train_loss=236.03366089 time/batch=1.33s
23076/10943 (epoch 189.779) train_loss=140.34553528 time/batch=0.94s
23077/10943 (epoch 189.788) train_loss=151.39967346 time/batch=1.01s
23078/10943 (epoch 189.796) train_loss=99.05378723 time/batch=0.70s
23079/10943 (epoch 189.804) train_loss=70.53991699 time/batch=0.42s
23080/10943 (epoch 189.812) train_loss=138.12333679 time/batch=0.90s
23081/10943 (epoch 189.821) train_loss=114.86575317 time/batch=0.72s
23082/10943 (epoch 189.829) train_loss=66.90310669 time/batch=0.42s
23083/10943 (epoch 189.837) train_loss=142.05935669 time/batch=0.92s
23084/10943 (epoch 189.845) train_loss=73.37074280 time/batch=0.50s
23085/10943 (epoch 189.854) train_loss=108.41430664 time/batch=0.73s
23086/10943 (epoch 189.862) train_loss=97.65670013 time/batch=0.64s
23087/10943 (epoch 189.870) train_loss=90.79408264 time/batch=0.59s
23088/10943 (epoch 189.878) train_loss=162.73352051 time/batch=1.04s
23089/10943 (epoch 189.886) train_loss=120.05384064 time/batch=0.79s
23090/10943 (epoch 189.895) train_loss=132.07217407 time/batch=0.83s
23091/10943 (epoch 189.903) train_loss=134.31951904 time/batch=0.99s
23092/10943 (epoch 189.911) train_loss=153.20924377 time/batch=0.97s
23093/10943 (epoch 189.919) train_loss=94.24795532 time/batch=0.64s
23094/10943 (epoch 189.928) train_loss=186.29946899 time/batch=1.20s
23095/10943 (epoch 189.936) train_loss=108.01643372 time/batch=0.83s
23096/10943 (epoch 189.944) train_loss=152.71774292 time/batch=0.87s
23097/10943 (epoch 189.952) train_loss=139.00932312 time/batch=0.88s
23098/10943 (epoch 189.960) train_loss=127.80329895 time/batch=0.82s
23099/10943 (epoch 189.969) train_loss=101.80261230 time/batch=0.71s
23100/10943 (epoch 189.977) train_loss=145.85229492 time/batch=0.98s
23101/10943 (epoch 189.985) train_loss=69.49393463 time/batch=0.50s
23102/10943 (epoch 189.993) train_loss=70.88175964 time/batch=0.40s
23103/10943 (epoch 190.002) train_loss=79.50529480 time/batch=0.50s
23104/10943 (epoch 190.010) train_loss=180.88464355 time/batch=1.05s
23105/10943 (epoch 190.018) train_loss=164.85006714 time/batch=1.04s
23106/10943 (epoch 190.026) train_loss=114.69641113 time/batch=0.75s
23107/10943 (epoch 190.034) train_loss=89.83144379 time/batch=0.57s
23108/10943 (epoch 190.043) train_loss=136.22003174 time/batch=0.81s
23109/10943 (epoch 190.051) train_loss=118.01958466 time/batch=0.78s
23110/10943 (epoch 190.059) train_loss=89.50123596 time/batch=0.59s
23111/10943 (epoch 190.067) train_loss=107.28292847 time/batch=0.73s
23112/10943 (epoch 190.076) train_loss=121.89710999 time/batch=0.78s
23113/10943 (epoch 190.084) train_loss=128.04080200 time/batch=0.79s
23114/10943 (epoch 190.092) train_loss=98.05649567 time/batch=0.66s
23115/10943 (epoch 190.100) train_loss=112.91539001 time/batch=0.76s
23116/10943 (epoch 190.108) train_loss=132.94017029 time/batch=0.83s
23117/10943 (epoch 190.117) train_loss=97.20255280 time/batch=0.62s
23118/10943 (epoch 190.125) train_loss=155.04454041 time/batch=0.97s
23119/10943 (epoch 190.133) train_loss=140.33972168 time/batch=0.84s
23120/10943 (epoch 190.141) train_loss=148.14889526 time/batch=1.00s
23121/10943 (epoch 190.150) train_loss=135.49121094 time/batch=0.87s
23122/10943 (epoch 190.158) train_loss=102.23890686 time/batch=0.73s
23123/10943 (epoch 190.166) train_loss=146.48159790 time/batch=0.98s
23124/10943 (epoch 190.174) train_loss=126.69174194 time/batch=0.86s
23125/10943 (epoch 190.182) train_loss=153.32696533 time/batch=1.01s
23126/10943 (epoch 190.191) train_loss=165.43408203 time/batch=1.06s
23127/10943 (epoch 190.199) train_loss=116.56594086 time/batch=0.78s
23128/10943 (epoch 190.207) train_loss=118.96076965 time/batch=0.83s
23129/10943 (epoch 190.215) train_loss=133.56958008 time/batch=0.86s
23130/10943 (epoch 190.224) train_loss=120.47351074 time/batch=0.88s
setting learning rate to 0.0004973
  saved to metadata/lstm_dropout-9_nov_folkwiki-20181112-195023.pkl
23131/10943 (epoch 190.232) train_loss=89.75598907 time/batch=0.71s
23132/10943 (epoch 190.240) train_loss=156.83045959 time/batch=1.02s
23133/10943 (epoch 190.248) train_loss=173.17465210 time/batch=1.14s
23134/10943 (epoch 190.256) train_loss=425.35247803 time/batch=2.59s
23135/10943 (epoch 190.265) train_loss=83.13056946 time/batch=0.76s
23136/10943 (epoch 190.273) train_loss=66.34858704 time/batch=0.36s
23137/10943 (epoch 190.281) train_loss=291.22183228 time/batch=1.52s
23138/10943 (epoch 190.289) train_loss=74.66957092 time/batch=0.56s
23139/10943 (epoch 190.298) train_loss=202.71270752 time/batch=1.11s
23140/10943 (epoch 190.306) train_loss=120.47674561 time/batch=0.88s
23141/10943 (epoch 190.314) train_loss=78.20578766 time/batch=0.51s
23142/10943 (epoch 190.322) train_loss=220.17922974 time/batch=1.27s
23143/10943 (epoch 190.331) train_loss=294.85314941 time/batch=1.88s
23144/10943 (epoch 190.339) train_loss=149.96078491 time/batch=1.00s
23145/10943 (epoch 190.347) train_loss=241.92404175 time/batch=1.38s
23146/10943 (epoch 190.355) train_loss=253.46394348 time/batch=1.65s
23147/10943 (epoch 190.363) train_loss=220.62030029 time/batch=1.36s
23148/10943 (epoch 190.372) train_loss=105.98434448 time/batch=0.77s
23149/10943 (epoch 190.380) train_loss=139.04718018 time/batch=0.99s
23150/10943 (epoch 190.388) train_loss=127.31903839 time/batch=0.95s
23151/10943 (epoch 190.396) train_loss=169.47686768 time/batch=1.11s
23152/10943 (epoch 190.405) train_loss=244.08383179 time/batch=1.37s
23153/10943 (epoch 190.413) train_loss=99.63692474 time/batch=0.72s
23154/10943 (epoch 190.421) train_loss=325.19982910 time/batch=1.91s
23155/10943 (epoch 190.429) train_loss=150.89505005 time/batch=1.14s
23156/10943 (epoch 190.437) train_loss=232.90576172 time/batch=1.37s
23157/10943 (epoch 190.446) train_loss=81.34605408 time/batch=0.59s
23158/10943 (epoch 190.454) train_loss=146.09091187 time/batch=0.91s
23159/10943 (epoch 190.462) train_loss=130.20060730 time/batch=0.83s
23160/10943 (epoch 190.470) train_loss=129.25885010 time/batch=0.86s
23161/10943 (epoch 190.479) train_loss=148.90304565 time/batch=0.91s
23162/10943 (epoch 190.487) train_loss=130.66906738 time/batch=0.98s
23163/10943 (epoch 190.495) train_loss=66.49678802 time/batch=0.44s
23164/10943 (epoch 190.503) train_loss=135.70445251 time/batch=0.86s
23165/10943 (epoch 190.511) train_loss=135.89512634 time/batch=0.93s
23166/10943 (epoch 190.520) train_loss=174.03530884 time/batch=1.08s
23167/10943 (epoch 190.528) train_loss=92.55541992 time/batch=0.74s
23168/10943 (epoch 190.536) train_loss=84.59784698 time/batch=0.56s
23169/10943 (epoch 190.544) train_loss=274.28002930 time/batch=1.62s
23170/10943 (epoch 190.553) train_loss=233.21838379 time/batch=1.49s
23171/10943 (epoch 190.561) train_loss=241.03648376 time/batch=1.50s
23172/10943 (epoch 190.569) train_loss=89.10934448 time/batch=0.63s
23173/10943 (epoch 190.577) train_loss=250.70120239 time/batch=1.43s
23174/10943 (epoch 190.585) train_loss=66.93164825 time/batch=0.51s
23175/10943 (epoch 190.594) train_loss=97.57881165 time/batch=0.61s
23176/10943 (epoch 190.602) train_loss=193.99263000 time/batch=1.15s
23177/10943 (epoch 190.610) train_loss=111.29155731 time/batch=0.79s
23178/10943 (epoch 190.618) train_loss=115.79823303 time/batch=0.76s
23179/10943 (epoch 190.627) train_loss=157.15188599 time/batch=0.95s
23180/10943 (epoch 190.635) train_loss=206.54878235 time/batch=1.26s
23181/10943 (epoch 190.643) train_loss=200.78213501 time/batch=1.28s
23182/10943 (epoch 190.651) train_loss=115.52900696 time/batch=0.78s
23183/10943 (epoch 190.659) train_loss=93.67322540 time/batch=0.66s
23184/10943 (epoch 190.668) train_loss=82.16511536 time/batch=0.54s
23185/10943 (epoch 190.676) train_loss=169.97506714 time/batch=1.01s
23186/10943 (epoch 190.684) train_loss=106.53108215 time/batch=0.72s
23187/10943 (epoch 190.692) train_loss=95.58897400 time/batch=0.61s
23188/10943 (epoch 190.701) train_loss=437.89093018 time/batch=3.74s
23189/10943 (epoch 190.709) train_loss=134.90377808 time/batch=1.18s
23190/10943 (epoch 190.717) train_loss=149.23962402 time/batch=1.04s
23191/10943 (epoch 190.725) train_loss=109.13105011 time/batch=0.77s
23192/10943 (epoch 190.733) train_loss=191.81727600 time/batch=1.17s
23193/10943 (epoch 190.742) train_loss=77.77575684 time/batch=0.52s
23194/10943 (epoch 190.750) train_loss=243.02490234 time/batch=1.42s
23195/10943 (epoch 190.758) train_loss=127.69836426 time/batch=0.89s
23196/10943 (epoch 190.766) train_loss=177.20353699 time/batch=1.14s
23197/10943 (epoch 190.775) train_loss=104.78320312 time/batch=0.69s
23198/10943 (epoch 190.783) train_loss=154.59323120 time/batch=1.04s
23199/10943 (epoch 190.791) train_loss=107.69563293 time/batch=0.80s
23200/10943 (epoch 190.799) train_loss=137.13665771 time/batch=0.89s
23201/10943 (epoch 190.808) train_loss=155.41699219 time/batch=1.07s
23202/10943 (epoch 190.816) train_loss=85.32918549 time/batch=0.56s
23203/10943 (epoch 190.824) train_loss=111.00842285 time/batch=0.70s
23204/10943 (epoch 190.832) train_loss=55.02095032 time/batch=0.35s
23205/10943 (epoch 190.840) train_loss=143.09997559 time/batch=0.93s
23206/10943 (epoch 190.849) train_loss=129.66564941 time/batch=0.86s
23207/10943 (epoch 190.857) train_loss=182.18157959 time/batch=1.10s
23208/10943 (epoch 190.865) train_loss=92.83708191 time/batch=0.61s
23209/10943 (epoch 190.873) train_loss=93.80776978 time/batch=0.66s
23210/10943 (epoch 190.882) train_loss=89.69316101 time/batch=0.61s
23211/10943 (epoch 190.890) train_loss=119.98980713 time/batch=0.84s
23212/10943 (epoch 190.898) train_loss=130.30035400 time/batch=0.87s
23213/10943 (epoch 190.906) train_loss=208.43713379 time/batch=1.16s
23214/10943 (epoch 190.914) train_loss=150.15185547 time/batch=0.97s
23215/10943 (epoch 190.923) train_loss=165.38540649 time/batch=1.14s
23216/10943 (epoch 190.931) train_loss=139.24876404 time/batch=1.01s
23217/10943 (epoch 190.939) train_loss=129.98193359 time/batch=0.88s
23218/10943 (epoch 190.947) train_loss=118.92921448 time/batch=0.81s
23219/10943 (epoch 190.956) train_loss=122.32038879 time/batch=0.80s
23220/10943 (epoch 190.964) train_loss=65.75147247 time/batch=0.43s
23221/10943 (epoch 190.972) train_loss=133.81085205 time/batch=0.78s
23222/10943 (epoch 190.980) train_loss=151.80545044 time/batch=0.98s
23223/10943 (epoch 190.988) train_loss=72.25681305 time/batch=0.50s
23224/10943 (epoch 190.997) train_loss=108.19587708 time/batch=0.73s
23225/10943 (epoch 191.005) train_loss=110.44779205 time/batch=0.73s
23226/10943 (epoch 191.013) train_loss=107.47624207 time/batch=0.67s
23227/10943 (epoch 191.021) train_loss=84.32646179 time/batch=0.55s
23228/10943 (epoch 191.030) train_loss=127.58895874 time/batch=0.82s
23229/10943 (epoch 191.038) train_loss=116.23970032 time/batch=0.78s
23230/10943 (epoch 191.046) train_loss=92.23983765 time/batch=0.60s
23231/10943 (epoch 191.054) train_loss=71.53875732 time/batch=0.42s
23232/10943 (epoch 191.062) train_loss=108.25518036 time/batch=0.62s
23233/10943 (epoch 191.071) train_loss=114.72563171 time/batch=0.70s
23234/10943 (epoch 191.079) train_loss=92.97764587 time/batch=0.62s
23235/10943 (epoch 191.087) train_loss=160.73081970 time/batch=0.99s
23236/10943 (epoch 191.095) train_loss=99.52641296 time/batch=0.70s
23237/10943 (epoch 191.104) train_loss=179.27877808 time/batch=1.17s
23238/10943 (epoch 191.112) train_loss=142.07809448 time/batch=1.00s
23239/10943 (epoch 191.120) train_loss=162.28390503 time/batch=1.04s
23240/10943 (epoch 191.128) train_loss=120.72520447 time/batch=0.81s
23241/10943 (epoch 191.136) train_loss=89.94099426 time/batch=0.59s
23242/10943 (epoch 191.145) train_loss=143.32327271 time/batch=0.95s
23243/10943 (epoch 191.153) train_loss=149.95085144 time/batch=0.88s
23244/10943 (epoch 191.161) train_loss=111.54080200 time/batch=0.70s
23245/10943 (epoch 191.169) train_loss=154.55918884 time/batch=0.97s
23246/10943 (epoch 191.178) train_loss=138.92292786 time/batch=0.90s
23247/10943 (epoch 191.186) train_loss=103.68415833 time/batch=0.75s
23248/10943 (epoch 191.194) train_loss=70.98190308 time/batch=0.49s
23249/10943 (epoch 191.202) train_loss=80.72825623 time/batch=0.72s
23250/10943 (epoch 191.210) train_loss=125.55650330 time/batch=0.87s
23251/10943 (epoch 191.219) train_loss=138.56184387 time/batch=1.00s
setting learning rate to 0.0004824
23252/10943 (epoch 191.227) train_loss=277.88992310 time/batch=1.61s
23253/10943 (epoch 191.235) train_loss=179.39324951 time/batch=1.22s
23254/10943 (epoch 191.243) train_loss=209.57272339 time/batch=1.19s
23255/10943 (epoch 191.252) train_loss=276.46749878 time/batch=1.72s
23256/10943 (epoch 191.260) train_loss=147.16413879 time/batch=1.07s
23257/10943 (epoch 191.268) train_loss=161.25482178 time/batch=1.15s
23258/10943 (epoch 191.276) train_loss=310.40405273 time/batch=1.92s
23259/10943 (epoch 191.285) train_loss=223.57238770 time/batch=1.46s
23260/10943 (epoch 191.293) train_loss=94.36579895 time/batch=0.74s
23261/10943 (epoch 191.301) train_loss=101.51031494 time/batch=0.64s
23262/10943 (epoch 191.309) train_loss=242.16181946 time/batch=1.41s
23263/10943 (epoch 191.317) train_loss=78.79707336 time/batch=0.57s
23264/10943 (epoch 191.326) train_loss=99.40490723 time/batch=0.74s
23265/10943 (epoch 191.334) train_loss=141.35662842 time/batch=0.94s
23266/10943 (epoch 191.342) train_loss=103.74047089 time/batch=0.78s
23267/10943 (epoch 191.350) train_loss=187.31391907 time/batch=1.16s
23268/10943 (epoch 191.359) train_loss=62.06884003 time/batch=0.42s
23269/10943 (epoch 191.367) train_loss=436.07489014 time/batch=2.63s
23270/10943 (epoch 191.375) train_loss=158.06192017 time/batch=1.11s
23271/10943 (epoch 191.383) train_loss=437.47735596 time/batch=3.77s
23272/10943 (epoch 191.391) train_loss=251.27883911 time/batch=1.81s
23273/10943 (epoch 191.400) train_loss=152.74020386 time/batch=1.12s
23274/10943 (epoch 191.408) train_loss=247.74322510 time/batch=1.51s
23275/10943 (epoch 191.416) train_loss=211.82505798 time/batch=1.33s
23276/10943 (epoch 191.424) train_loss=282.41705322 time/batch=1.75s
23277/10943 (epoch 191.433) train_loss=105.14488220 time/batch=0.83s
23278/10943 (epoch 191.441) train_loss=247.21249390 time/batch=1.33s
23279/10943 (epoch 191.449) train_loss=105.97764587 time/batch=0.74s
23280/10943 (epoch 191.457) train_loss=217.25370789 time/batch=1.19s
23281/10943 (epoch 191.465) train_loss=82.33882141 time/batch=0.59s
23282/10943 (epoch 191.474) train_loss=236.10058594 time/batch=1.33s
23283/10943 (epoch 191.482) train_loss=215.91430664 time/batch=1.30s
23284/10943 (epoch 191.490) train_loss=104.16740417 time/batch=0.78s
23285/10943 (epoch 191.498) train_loss=136.22811890 time/batch=0.82s
23286/10943 (epoch 191.507) train_loss=137.45675659 time/batch=0.88s
23287/10943 (epoch 191.515) train_loss=67.03529358 time/batch=0.50s
23288/10943 (epoch 191.523) train_loss=55.70369720 time/batch=0.35s
23289/10943 (epoch 191.531) train_loss=160.75488281 time/batch=1.01s
23290/10943 (epoch 191.539) train_loss=157.77667236 time/batch=1.04s
23291/10943 (epoch 191.548) train_loss=148.08581543 time/batch=1.07s
23292/10943 (epoch 191.556) train_loss=245.68368530 time/batch=1.77s
23293/10943 (epoch 191.564) train_loss=128.68786621 time/batch=0.92s
23294/10943 (epoch 191.572) train_loss=62.93392944 time/batch=0.42s
23295/10943 (epoch 191.581) train_loss=123.15295410 time/batch=0.76s
23296/10943 (epoch 191.589) train_loss=237.60919189 time/batch=1.36s
23297/10943 (epoch 191.597) train_loss=67.21661377 time/batch=0.49s
23298/10943 (epoch 191.605) train_loss=160.36132812 time/batch=0.98s
23299/10943 (epoch 191.613) train_loss=101.87843323 time/batch=0.73s
23300/10943 (epoch 191.622) train_loss=91.05367279 time/batch=0.61s
23301/10943 (epoch 191.630) train_loss=91.67456818 time/batch=0.54s
23302/10943 (epoch 191.638) train_loss=107.39320374 time/batch=0.71s
23303/10943 (epoch 191.646) train_loss=196.85696411 time/batch=1.24s
23304/10943 (epoch 191.655) train_loss=190.69390869 time/batch=1.24s
23305/10943 (epoch 191.663) train_loss=132.17201233 time/batch=0.86s
23306/10943 (epoch 191.671) train_loss=65.43287659 time/batch=0.41s
23307/10943 (epoch 191.679) train_loss=71.30422974 time/batch=0.43s
23308/10943 (epoch 191.687) train_loss=173.95938110 time/batch=1.05s
23309/10943 (epoch 191.696) train_loss=178.50337219 time/batch=1.13s
23310/10943 (epoch 191.704) train_loss=138.67462158 time/batch=0.99s
23311/10943 (epoch 191.712) train_loss=175.23527527 time/batch=1.12s
23312/10943 (epoch 191.720) train_loss=97.82120514 time/batch=0.68s
23313/10943 (epoch 191.729) train_loss=79.86486816 time/batch=0.49s
23314/10943 (epoch 191.737) train_loss=89.16502380 time/batch=0.55s
23315/10943 (epoch 191.745) train_loss=199.47760010 time/batch=1.15s
23316/10943 (epoch 191.753) train_loss=155.78721619 time/batch=1.06s
23317/10943 (epoch 191.762) train_loss=170.71607971 time/batch=1.10s
23318/10943 (epoch 191.770) train_loss=121.97697449 time/batch=0.82s
23319/10943 (epoch 191.778) train_loss=185.06822205 time/batch=1.28s
23320/10943 (epoch 191.786) train_loss=141.27766418 time/batch=0.96s
23321/10943 (epoch 191.794) train_loss=68.37271881 time/batch=0.46s
23322/10943 (epoch 191.803) train_loss=130.56677246 time/batch=0.81s
23323/10943 (epoch 191.811) train_loss=83.27973175 time/batch=0.54s
23324/10943 (epoch 191.819) train_loss=96.12106323 time/batch=0.66s
23325/10943 (epoch 191.827) train_loss=107.72041321 time/batch=0.72s
23326/10943 (epoch 191.836) train_loss=106.49938965 time/batch=0.68s
23327/10943 (epoch 191.844) train_loss=140.15554810 time/batch=0.97s
23328/10943 (epoch 191.852) train_loss=79.05548096 time/batch=0.57s
23329/10943 (epoch 191.860) train_loss=83.65820312 time/batch=0.53s
23330/10943 (epoch 191.868) train_loss=128.17097473 time/batch=0.89s
23331/10943 (epoch 191.877) train_loss=146.51730347 time/batch=0.91s
23332/10943 (epoch 191.885) train_loss=144.67590332 time/batch=1.01s
23333/10943 (epoch 191.893) train_loss=114.85701752 time/batch=0.78s
23334/10943 (epoch 191.901) train_loss=111.56362915 time/batch=0.73s
23335/10943 (epoch 191.910) train_loss=113.37971497 time/batch=0.80s
23336/10943 (epoch 191.918) train_loss=154.85563660 time/batch=0.96s
23337/10943 (epoch 191.926) train_loss=86.67557526 time/batch=0.60s
23338/10943 (epoch 191.934) train_loss=158.12976074 time/batch=1.02s
23339/10943 (epoch 191.942) train_loss=146.99749756 time/batch=0.95s
23340/10943 (epoch 191.951) train_loss=151.38876343 time/batch=1.02s
23341/10943 (epoch 191.959) train_loss=92.56559753 time/batch=0.64s
23342/10943 (epoch 191.967) train_loss=149.12721252 time/batch=1.00s
23343/10943 (epoch 191.975) train_loss=118.82522583 time/batch=0.81s
23344/10943 (epoch 191.984) train_loss=114.43725586 time/batch=0.72s
23345/10943 (epoch 191.992) train_loss=144.93215942 time/batch=0.97s
23346/10943 (epoch 192.000) train_loss=132.11550903 time/batch=0.87s
23347/10943 (epoch 192.008) train_loss=87.11909485 time/batch=0.60s
23348/10943 (epoch 192.016) train_loss=82.15876007 time/batch=0.53s
23349/10943 (epoch 192.025) train_loss=113.03079224 time/batch=0.66s
23350/10943 (epoch 192.033) train_loss=94.44721985 time/batch=0.62s
23351/10943 (epoch 192.041) train_loss=108.86189270 time/batch=0.73s
23352/10943 (epoch 192.049) train_loss=139.88035583 time/batch=0.96s
23353/10943 (epoch 192.058) train_loss=137.58419800 time/batch=0.85s
23354/10943 (epoch 192.066) train_loss=138.45831299 time/batch=0.89s
23355/10943 (epoch 192.074) train_loss=91.99330139 time/batch=0.63s
23356/10943 (epoch 192.082) train_loss=110.34471130 time/batch=0.74s
23357/10943 (epoch 192.090) train_loss=127.50400543 time/batch=0.86s
23358/10943 (epoch 192.099) train_loss=147.63954163 time/batch=0.99s
23359/10943 (epoch 192.107) train_loss=143.40835571 time/batch=0.98s
23360/10943 (epoch 192.115) train_loss=91.50090027 time/batch=0.70s
23361/10943 (epoch 192.123) train_loss=133.10693359 time/batch=0.87s
23362/10943 (epoch 192.132) train_loss=105.11363220 time/batch=0.64s
23363/10943 (epoch 192.140) train_loss=73.32574463 time/batch=0.43s
23364/10943 (epoch 192.148) train_loss=113.96678925 time/batch=0.69s
23365/10943 (epoch 192.156) train_loss=126.30023956 time/batch=0.83s
23366/10943 (epoch 192.164) train_loss=142.54412842 time/batch=0.90s
23367/10943 (epoch 192.173) train_loss=76.73858643 time/batch=0.58s
23368/10943 (epoch 192.181) train_loss=122.50787354 time/batch=0.80s
23369/10943 (epoch 192.189) train_loss=124.19888306 time/batch=0.85s
23370/10943 (epoch 192.197) train_loss=128.55563354 time/batch=0.97s
23371/10943 (epoch 192.206) train_loss=99.40341187 time/batch=0.78s
23372/10943 (epoch 192.214) train_loss=112.68128204 time/batch=0.75s
setting learning rate to 0.0004679
23373/10943 (epoch 192.222) train_loss=335.90985107 time/batch=1.96s
23374/10943 (epoch 192.230) train_loss=70.38481140 time/batch=0.63s
23375/10943 (epoch 192.238) train_loss=129.87751770 time/batch=0.82s
23376/10943 (epoch 192.247) train_loss=107.04711151 time/batch=0.74s
23377/10943 (epoch 192.255) train_loss=64.23454285 time/batch=0.38s
23378/10943 (epoch 192.263) train_loss=96.17861938 time/batch=0.58s
23379/10943 (epoch 192.271) train_loss=170.61842346 time/batch=1.10s
23380/10943 (epoch 192.280) train_loss=244.85379028 time/batch=1.48s
23381/10943 (epoch 192.288) train_loss=104.73846436 time/batch=0.81s
23382/10943 (epoch 192.296) train_loss=279.10009766 time/batch=1.73s
23383/10943 (epoch 192.304) train_loss=173.86239624 time/batch=1.23s
23384/10943 (epoch 192.313) train_loss=248.80596924 time/batch=1.37s
23385/10943 (epoch 192.321) train_loss=144.34277344 time/batch=1.10s
23386/10943 (epoch 192.329) train_loss=241.07673645 time/batch=1.38s
23387/10943 (epoch 192.337) train_loss=276.76080322 time/batch=1.61s
23388/10943 (epoch 192.345) train_loss=70.16416931 time/batch=0.54s
23389/10943 (epoch 192.354) train_loss=160.04234314 time/batch=1.01s
23390/10943 (epoch 192.362) train_loss=125.51478577 time/batch=0.84s
23391/10943 (epoch 192.370) train_loss=125.52383423 time/batch=0.92s
23392/10943 (epoch 192.378) train_loss=185.53671265 time/batch=1.21s
23393/10943 (epoch 192.387) train_loss=229.06135559 time/batch=1.42s
23394/10943 (epoch 192.395) train_loss=136.08853149 time/batch=1.04s
23395/10943 (epoch 192.403) train_loss=117.59239197 time/batch=0.81s
23396/10943 (epoch 192.411) train_loss=120.68612671 time/batch=0.80s
23397/10943 (epoch 192.419) train_loss=215.97135925 time/batch=1.26s
23398/10943 (epoch 192.428) train_loss=88.59511566 time/batch=0.65s
23399/10943 (epoch 192.436) train_loss=246.89715576 time/batch=1.43s
23400/10943 (epoch 192.444) train_loss=228.68087769 time/batch=1.47s
23401/10943 (epoch 192.452) train_loss=83.17091370 time/batch=0.60s
23402/10943 (epoch 192.461) train_loss=79.77933502 time/batch=0.48s
23403/10943 (epoch 192.469) train_loss=270.50366211 time/batch=1.57s
23404/10943 (epoch 192.477) train_loss=93.83523560 time/batch=0.72s
23405/10943 (epoch 192.485) train_loss=160.37725830 time/batch=1.05s
23406/10943 (epoch 192.493) train_loss=82.69917297 time/batch=0.60s
23407/10943 (epoch 192.502) train_loss=107.22601318 time/batch=0.72s
23408/10943 (epoch 192.510) train_loss=193.36437988 time/batch=1.15s
23409/10943 (epoch 192.518) train_loss=208.95912170 time/batch=1.31s
23410/10943 (epoch 192.526) train_loss=326.35296631 time/batch=2.04s
23411/10943 (epoch 192.535) train_loss=140.41291809 time/batch=1.15s
23412/10943 (epoch 192.543) train_loss=172.86965942 time/batch=1.12s
23413/10943 (epoch 192.551) train_loss=415.19854736 time/batch=2.59s
23414/10943 (epoch 192.559) train_loss=82.12579346 time/batch=0.72s
23415/10943 (epoch 192.567) train_loss=151.75122070 time/batch=0.84s
23416/10943 (epoch 192.576) train_loss=143.13410950 time/batch=1.00s
23417/10943 (epoch 192.584) train_loss=101.61645508 time/batch=0.80s
23418/10943 (epoch 192.592) train_loss=177.78009033 time/batch=1.08s
23419/10943 (epoch 192.600) train_loss=156.80325317 time/batch=1.04s
23420/10943 (epoch 192.609) train_loss=97.86435699 time/batch=0.68s
23421/10943 (epoch 192.617) train_loss=92.81900787 time/batch=0.65s
23422/10943 (epoch 192.625) train_loss=130.97142029 time/batch=0.80s
23423/10943 (epoch 192.633) train_loss=184.99414062 time/batch=1.13s
23424/10943 (epoch 192.641) train_loss=59.79423904 time/batch=0.44s
23425/10943 (epoch 192.650) train_loss=208.34121704 time/batch=1.23s
23426/10943 (epoch 192.658) train_loss=89.95085907 time/batch=0.73s
23427/10943 (epoch 192.666) train_loss=230.65957642 time/batch=1.43s
23428/10943 (epoch 192.674) train_loss=153.28437805 time/batch=1.13s
23429/10943 (epoch 192.683) train_loss=66.08762360 time/batch=0.46s
23430/10943 (epoch 192.691) train_loss=135.23760986 time/batch=0.85s
23431/10943 (epoch 192.699) train_loss=209.99752808 time/batch=1.21s
23432/10943 (epoch 192.707) train_loss=74.71032715 time/batch=0.54s
23433/10943 (epoch 192.715) train_loss=95.75328064 time/batch=0.62s
23434/10943 (epoch 192.724) train_loss=94.71714783 time/batch=0.58s
23435/10943 (epoch 192.732) train_loss=103.50143433 time/batch=0.72s
23436/10943 (epoch 192.740) train_loss=200.05245972 time/batch=1.17s
23437/10943 (epoch 192.748) train_loss=88.33039856 time/batch=0.65s
23438/10943 (epoch 192.757) train_loss=159.23971558 time/batch=0.99s
23439/10943 (epoch 192.765) train_loss=191.94132996 time/batch=1.22s
23440/10943 (epoch 192.773) train_loss=78.98196411 time/batch=0.58s
23441/10943 (epoch 192.781) train_loss=116.63825989 time/batch=0.65s
23442/10943 (epoch 192.790) train_loss=68.83475494 time/batch=0.43s
23443/10943 (epoch 192.798) train_loss=296.12185669 time/batch=2.75s
23444/10943 (epoch 192.806) train_loss=81.54141235 time/batch=0.79s
23445/10943 (epoch 192.814) train_loss=143.25436401 time/batch=0.87s
23446/10943 (epoch 192.822) train_loss=108.87397766 time/batch=0.73s
23447/10943 (epoch 192.831) train_loss=173.95285034 time/batch=1.18s
23448/10943 (epoch 192.839) train_loss=129.65814209 time/batch=0.87s
23449/10943 (epoch 192.847) train_loss=132.91360474 time/batch=0.83s
23450/10943 (epoch 192.855) train_loss=61.34542084 time/batch=0.41s
23451/10943 (epoch 192.864) train_loss=127.23239136 time/batch=0.78s
23452/10943 (epoch 192.872) train_loss=143.92121887 time/batch=0.97s
23453/10943 (epoch 192.880) train_loss=114.09620667 time/batch=0.89s
23454/10943 (epoch 192.888) train_loss=96.28773499 time/batch=0.72s
23455/10943 (epoch 192.896) train_loss=105.73492432 time/batch=0.74s
23456/10943 (epoch 192.905) train_loss=62.57905579 time/batch=0.41s
23457/10943 (epoch 192.913) train_loss=141.85398865 time/batch=0.89s
23458/10943 (epoch 192.921) train_loss=128.71185303 time/batch=0.86s
23459/10943 (epoch 192.929) train_loss=85.30480957 time/batch=0.60s
23460/10943 (epoch 192.938) train_loss=101.26213074 time/batch=0.62s
23461/10943 (epoch 192.946) train_loss=136.98516846 time/batch=0.87s
23462/10943 (epoch 192.954) train_loss=108.67788696 time/batch=0.78s
23463/10943 (epoch 192.962) train_loss=79.58826447 time/batch=0.53s
23464/10943 (epoch 192.970) train_loss=136.94471741 time/batch=0.85s
23465/10943 (epoch 192.979) train_loss=102.95494080 time/batch=0.70s
23466/10943 (epoch 192.987) train_loss=114.47958374 time/batch=0.73s
23467/10943 (epoch 192.995) train_loss=116.19810486 time/batch=0.76s
23468/10943 (epoch 193.003) train_loss=68.48201752 time/batch=0.46s
23469/10943 (epoch 193.012) train_loss=96.81433105 time/batch=0.58s
23470/10943 (epoch 193.020) train_loss=144.18696594 time/batch=0.96s
23471/10943 (epoch 193.028) train_loss=94.92497253 time/batch=0.59s
23472/10943 (epoch 193.036) train_loss=95.26351929 time/batch=0.66s
23473/10943 (epoch 193.044) train_loss=116.10896301 time/batch=0.77s
23474/10943 (epoch 193.053) train_loss=126.38601685 time/batch=0.84s
23475/10943 (epoch 193.061) train_loss=240.48764038 time/batch=3.77s
23476/10943 (epoch 193.069) train_loss=141.98802185 time/batch=1.25s
23477/10943 (epoch 193.077) train_loss=154.71379089 time/batch=1.01s
23478/10943 (epoch 193.086) train_loss=83.32137299 time/batch=0.60s
23479/10943 (epoch 193.094) train_loss=145.62719727 time/batch=0.87s
23480/10943 (epoch 193.102) train_loss=152.61865234 time/batch=0.95s
23481/10943 (epoch 193.110) train_loss=154.19259644 time/batch=0.96s
23482/10943 (epoch 193.118) train_loss=107.48818970 time/batch=0.71s
23483/10943 (epoch 193.127) train_loss=129.93339539 time/batch=0.83s
23484/10943 (epoch 193.135) train_loss=135.25030518 time/batch=0.99s
23485/10943 (epoch 193.143) train_loss=151.09349060 time/batch=1.04s
23486/10943 (epoch 193.151) train_loss=129.86337280 time/batch=0.94s
23487/10943 (epoch 193.160) train_loss=157.23553467 time/batch=1.01s
23488/10943 (epoch 193.168) train_loss=133.84793091 time/batch=0.97s
23489/10943 (epoch 193.176) train_loss=110.79916382 time/batch=0.76s
23490/10943 (epoch 193.184) train_loss=131.04495239 time/batch=0.94s
23491/10943 (epoch 193.192) train_loss=97.68533325 time/batch=0.74s
23492/10943 (epoch 193.201) train_loss=117.30729675 time/batch=0.74s
23493/10943 (epoch 193.209) train_loss=123.88694000 time/batch=0.96s
setting learning rate to 0.0004539
23494/10943 (epoch 193.217) train_loss=93.31049347 time/batch=0.64s
23495/10943 (epoch 193.225) train_loss=341.11529541 time/batch=1.93s
23496/10943 (epoch 193.234) train_loss=497.24707031 time/batch=3.90s
23497/10943 (epoch 193.242) train_loss=61.73055267 time/batch=0.75s
23498/10943 (epoch 193.250) train_loss=74.28144836 time/batch=0.42s
23499/10943 (epoch 193.258) train_loss=182.60589600 time/batch=1.10s
23500/10943 (epoch 193.267) train_loss=302.76535034 time/batch=2.02s
23501/10943 (epoch 193.275) train_loss=173.05120850 time/batch=1.23s
23502/10943 (epoch 193.283) train_loss=119.98328400 time/batch=0.85s
23503/10943 (epoch 193.291) train_loss=187.31782532 time/batch=1.18s
23504/10943 (epoch 193.299) train_loss=97.73263550 time/batch=0.69s
23505/10943 (epoch 193.308) train_loss=66.05108643 time/batch=0.38s
23506/10943 (epoch 193.316) train_loss=193.73652649 time/batch=1.18s
23507/10943 (epoch 193.324) train_loss=262.80987549 time/batch=1.57s
23508/10943 (epoch 193.332) train_loss=173.04043579 time/batch=1.16s
23509/10943 (epoch 193.341) train_loss=269.79193115 time/batch=1.71s
23510/10943 (epoch 193.349) train_loss=110.60299683 time/batch=0.85s
23511/10943 (epoch 193.357) train_loss=95.76945496 time/batch=0.65s
23512/10943 (epoch 193.365) train_loss=129.15701294 time/batch=0.95s
23513/10943 (epoch 193.373) train_loss=226.25396729 time/batch=1.32s
23514/10943 (epoch 193.382) train_loss=135.60693359 time/batch=0.97s
23515/10943 (epoch 193.390) train_loss=103.57884979 time/batch=0.73s
23516/10943 (epoch 193.398) train_loss=55.65615082 time/batch=0.40s
23517/10943 (epoch 193.406) train_loss=87.09092712 time/batch=0.50s
23518/10943 (epoch 193.415) train_loss=134.45465088 time/batch=0.92s
23519/10943 (epoch 193.423) train_loss=84.58630371 time/batch=0.54s
23520/10943 (epoch 193.431) train_loss=273.90780640 time/batch=1.54s
23521/10943 (epoch 193.439) train_loss=145.97787476 time/batch=1.00s
23522/10943 (epoch 193.447) train_loss=72.14933777 time/batch=0.50s
23523/10943 (epoch 193.456) train_loss=151.60321045 time/batch=0.97s
23524/10943 (epoch 193.464) train_loss=223.26542664 time/batch=1.34s
23525/10943 (epoch 193.472) train_loss=272.69989014 time/batch=2.07s
23526/10943 (epoch 193.480) train_loss=154.84130859 time/batch=1.18s
23527/10943 (epoch 193.489) train_loss=122.39521790 time/batch=0.87s
23528/10943 (epoch 193.497) train_loss=163.49938965 time/batch=1.09s
23529/10943 (epoch 193.505) train_loss=131.76506042 time/batch=0.85s
23530/10943 (epoch 193.513) train_loss=68.01014709 time/batch=0.44s
23531/10943 (epoch 193.521) train_loss=144.93951416 time/batch=1.03s
23532/10943 (epoch 193.530) train_loss=124.58457947 time/batch=0.88s
23533/10943 (epoch 193.538) train_loss=248.25093079 time/batch=1.35s
23534/10943 (epoch 193.546) train_loss=72.63859558 time/batch=0.56s
23535/10943 (epoch 193.554) train_loss=236.81454468 time/batch=1.33s
23536/10943 (epoch 193.563) train_loss=155.67718506 time/batch=0.94s
23537/10943 (epoch 193.571) train_loss=81.53659058 time/batch=0.56s
23538/10943 (epoch 193.579) train_loss=83.03083801 time/batch=0.57s
23539/10943 (epoch 193.587) train_loss=211.54244995 time/batch=1.18s
23540/10943 (epoch 193.595) train_loss=92.58619690 time/batch=0.72s
23541/10943 (epoch 193.604) train_loss=107.01350403 time/batch=0.75s
23542/10943 (epoch 193.612) train_loss=86.95704651 time/batch=0.58s
23543/10943 (epoch 193.620) train_loss=237.93008423 time/batch=1.42s
23544/10943 (epoch 193.628) train_loss=257.33752441 time/batch=1.54s
23545/10943 (epoch 193.637) train_loss=103.24077606 time/batch=0.77s
23546/10943 (epoch 193.645) train_loss=139.62394714 time/batch=0.87s
23547/10943 (epoch 193.653) train_loss=110.98878479 time/batch=0.74s
23548/10943 (epoch 193.661) train_loss=121.71911621 time/batch=0.85s
23549/10943 (epoch 193.669) train_loss=218.87841797 time/batch=1.26s
23550/10943 (epoch 193.678) train_loss=122.39843750 time/batch=0.86s
23551/10943 (epoch 193.686) train_loss=80.41854858 time/batch=0.58s
23552/10943 (epoch 193.694) train_loss=61.93726349 time/batch=0.39s
23553/10943 (epoch 193.702) train_loss=105.10957336 time/batch=0.69s
23554/10943 (epoch 193.711) train_loss=186.71147156 time/batch=1.17s
23555/10943 (epoch 193.719) train_loss=261.22528076 time/batch=2.07s
23556/10943 (epoch 193.727) train_loss=95.67864990 time/batch=0.79s
23557/10943 (epoch 193.735) train_loss=98.91300964 time/batch=0.62s
23558/10943 (epoch 193.744) train_loss=127.55429077 time/batch=0.87s
23559/10943 (epoch 193.752) train_loss=62.52579498 time/batch=0.44s
23560/10943 (epoch 193.760) train_loss=164.25703430 time/batch=0.99s
23561/10943 (epoch 193.768) train_loss=89.80522156 time/batch=0.64s
23562/10943 (epoch 193.776) train_loss=135.31060791 time/batch=0.88s
23563/10943 (epoch 193.785) train_loss=78.20005035 time/batch=0.54s
23564/10943 (epoch 193.793) train_loss=81.86506653 time/batch=0.48s
23565/10943 (epoch 193.801) train_loss=199.68743896 time/batch=1.34s
23566/10943 (epoch 193.809) train_loss=157.95806885 time/batch=1.13s
23567/10943 (epoch 193.818) train_loss=88.18503571 time/batch=0.66s
23568/10943 (epoch 193.826) train_loss=136.79275513 time/batch=0.91s
23569/10943 (epoch 193.834) train_loss=106.49238586 time/batch=0.76s
23570/10943 (epoch 193.842) train_loss=165.95138550 time/batch=1.09s
23571/10943 (epoch 193.850) train_loss=132.36405945 time/batch=0.90s
23572/10943 (epoch 193.859) train_loss=171.55168152 time/batch=1.12s
23573/10943 (epoch 193.867) train_loss=91.30754852 time/batch=0.62s
23574/10943 (epoch 193.875) train_loss=71.47236633 time/batch=0.42s
23575/10943 (epoch 193.883) train_loss=126.44100952 time/batch=0.86s
23576/10943 (epoch 193.892) train_loss=143.33998108 time/batch=0.95s
23577/10943 (epoch 193.900) train_loss=162.88902283 time/batch=1.15s
23578/10943 (epoch 193.908) train_loss=73.25909424 time/batch=0.53s
23579/10943 (epoch 193.916) train_loss=78.38985443 time/batch=0.51s
23580/10943 (epoch 193.924) train_loss=196.11306763 time/batch=1.20s
23581/10943 (epoch 193.933) train_loss=157.26274109 time/batch=1.06s
23582/10943 (epoch 193.941) train_loss=101.76694489 time/batch=0.71s
23583/10943 (epoch 193.949) train_loss=137.78378296 time/batch=0.94s
23584/10943 (epoch 193.957) train_loss=104.12550354 time/batch=0.73s
23585/10943 (epoch 193.966) train_loss=128.34222412 time/batch=0.93s
23586/10943 (epoch 193.974) train_loss=89.44975281 time/batch=0.65s
23587/10943 (epoch 193.982) train_loss=110.46176147 time/batch=0.72s
23588/10943 (epoch 193.990) train_loss=189.45344543 time/batch=1.18s
23589/10943 (epoch 193.998) train_loss=104.68774414 time/batch=0.77s
23590/10943 (epoch 194.007) train_loss=145.02563477 time/batch=0.96s
23591/10943 (epoch 194.015) train_loss=130.27761841 time/batch=0.86s
23592/10943 (epoch 194.023) train_loss=189.17924500 time/batch=1.16s
23593/10943 (epoch 194.031) train_loss=95.44076538 time/batch=0.70s
23594/10943 (epoch 194.040) train_loss=104.03279114 time/batch=0.67s
23595/10943 (epoch 194.048) train_loss=124.19227600 time/batch=0.80s
23596/10943 (epoch 194.056) train_loss=143.23139954 time/batch=1.00s
23597/10943 (epoch 194.064) train_loss=120.25803375 time/batch=0.83s
23598/10943 (epoch 194.072) train_loss=119.52993774 time/batch=0.79s
23599/10943 (epoch 194.081) train_loss=129.45294189 time/batch=0.91s
23600/10943 (epoch 194.089) train_loss=141.78254700 time/batch=0.93s
23601/10943 (epoch 194.097) train_loss=102.76417542 time/batch=0.77s
23602/10943 (epoch 194.105) train_loss=113.52455139 time/batch=0.78s
23603/10943 (epoch 194.114) train_loss=116.50779724 time/batch=0.77s
23604/10943 (epoch 194.122) train_loss=119.32818604 time/batch=0.83s
23605/10943 (epoch 194.130) train_loss=149.67294312 time/batch=0.99s
23606/10943 (epoch 194.138) train_loss=111.97108459 time/batch=0.79s
23607/10943 (epoch 194.146) train_loss=115.41970825 time/batch=0.76s
23608/10943 (epoch 194.155) train_loss=150.98016357 time/batch=0.99s
23609/10943 (epoch 194.163) train_loss=96.40647125 time/batch=0.74s
23610/10943 (epoch 194.171) train_loss=145.57711792 time/batch=0.93s
23611/10943 (epoch 194.179) train_loss=107.68852234 time/batch=0.84s
23612/10943 (epoch 194.188) train_loss=156.69096375 time/batch=1.00s
23613/10943 (epoch 194.196) train_loss=135.12411499 time/batch=1.02s
23614/10943 (epoch 194.204) train_loss=125.54704285 time/batch=0.85s
setting learning rate to 0.0004403
23615/10943 (epoch 194.212) train_loss=240.21322632 time/batch=1.49s
23616/10943 (epoch 194.221) train_loss=74.98809814 time/batch=0.56s
23617/10943 (epoch 194.229) train_loss=83.73461151 time/batch=0.50s
23618/10943 (epoch 194.237) train_loss=349.12744141 time/batch=1.91s
23619/10943 (epoch 194.245) train_loss=171.86416626 time/batch=1.26s
23620/10943 (epoch 194.253) train_loss=277.28524780 time/batch=1.62s
23621/10943 (epoch 194.262) train_loss=189.35317993 time/batch=1.25s
23622/10943 (epoch 194.270) train_loss=95.28739929 time/batch=0.64s
23623/10943 (epoch 194.278) train_loss=282.07000732 time/batch=1.64s
23624/10943 (epoch 194.286) train_loss=258.05410767 time/batch=1.76s
23625/10943 (epoch 194.295) train_loss=198.86759949 time/batch=1.34s
23626/10943 (epoch 194.303) train_loss=152.42630005 time/batch=1.07s
23627/10943 (epoch 194.311) train_loss=62.54731369 time/batch=0.41s
23628/10943 (epoch 194.319) train_loss=233.70446777 time/batch=1.61s
23629/10943 (epoch 194.327) train_loss=92.82079315 time/batch=0.79s
23630/10943 (epoch 194.336) train_loss=170.37051392 time/batch=1.08s
23631/10943 (epoch 194.344) train_loss=277.94708252 time/batch=1.78s
23632/10943 (epoch 194.352) train_loss=104.60810852 time/batch=0.88s
23633/10943 (epoch 194.360) train_loss=108.54133606 time/batch=0.75s
23634/10943 (epoch 194.369) train_loss=365.46124268 time/batch=2.26s
23635/10943 (epoch 194.377) train_loss=151.52154541 time/batch=1.24s
23636/10943 (epoch 194.385) train_loss=131.23489380 time/batch=1.02s
23637/10943 (epoch 194.393) train_loss=104.77638245 time/batch=0.70s
23638/10943 (epoch 194.401) train_loss=68.05459595 time/batch=0.44s
23639/10943 (epoch 194.410) train_loss=81.87430573 time/batch=0.58s
23640/10943 (epoch 194.418) train_loss=111.68328857 time/batch=0.77s
23641/10943 (epoch 194.426) train_loss=87.13427734 time/batch=0.55s
23642/10943 (epoch 194.434) train_loss=169.26142883 time/batch=1.07s
23643/10943 (epoch 194.443) train_loss=79.82237244 time/batch=0.60s
23644/10943 (epoch 194.451) train_loss=438.30450439 time/batch=3.77s
23645/10943 (epoch 194.459) train_loss=152.66140747 time/batch=1.42s
23646/10943 (epoch 194.467) train_loss=126.53839111 time/batch=0.90s
23647/10943 (epoch 194.475) train_loss=123.04835510 time/batch=0.85s
23648/10943 (epoch 194.484) train_loss=148.77436829 time/batch=0.88s
23649/10943 (epoch 194.492) train_loss=95.84321594 time/batch=0.66s
23650/10943 (epoch 194.500) train_loss=120.53909302 time/batch=0.83s
23651/10943 (epoch 194.508) train_loss=123.72990417 time/batch=0.81s
23652/10943 (epoch 194.517) train_loss=128.10559082 time/batch=0.96s
23653/10943 (epoch 194.525) train_loss=213.38861084 time/batch=1.27s
23654/10943 (epoch 194.533) train_loss=58.35541534 time/batch=0.45s
23655/10943 (epoch 194.541) train_loss=132.44201660 time/batch=0.93s
23656/10943 (epoch 194.549) train_loss=85.48309326 time/batch=0.62s
23657/10943 (epoch 194.558) train_loss=121.82495117 time/batch=0.83s
23658/10943 (epoch 194.566) train_loss=81.61061096 time/batch=0.59s
23659/10943 (epoch 194.574) train_loss=139.42373657 time/batch=0.93s
23660/10943 (epoch 194.582) train_loss=95.95626831 time/batch=0.67s
23661/10943 (epoch 194.591) train_loss=112.28105164 time/batch=0.77s
23662/10943 (epoch 194.599) train_loss=144.00933838 time/batch=0.94s
23663/10943 (epoch 194.607) train_loss=123.63194275 time/batch=0.84s
23664/10943 (epoch 194.615) train_loss=103.18011475 time/batch=0.69s
23665/10943 (epoch 194.623) train_loss=133.02940369 time/batch=0.88s
23666/10943 (epoch 194.632) train_loss=217.25628662 time/batch=1.32s
23667/10943 (epoch 194.640) train_loss=234.42083740 time/batch=1.38s
23668/10943 (epoch 194.648) train_loss=91.57230377 time/batch=0.67s
23669/10943 (epoch 194.656) train_loss=145.11813354 time/batch=0.97s
23670/10943 (epoch 194.665) train_loss=236.56999207 time/batch=1.40s
23671/10943 (epoch 194.673) train_loss=208.58128357 time/batch=1.27s
23672/10943 (epoch 194.681) train_loss=99.92860413 time/batch=0.79s
23673/10943 (epoch 194.689) train_loss=81.14149475 time/batch=0.53s
23674/10943 (epoch 194.698) train_loss=105.86921692 time/batch=0.71s
23675/10943 (epoch 194.706) train_loss=105.70755005 time/batch=0.62s
23676/10943 (epoch 194.714) train_loss=186.76797485 time/batch=1.16s
23677/10943 (epoch 194.722) train_loss=192.66354370 time/batch=1.23s
23678/10943 (epoch 194.730) train_loss=97.63249207 time/batch=0.73s
23679/10943 (epoch 194.739) train_loss=183.88546753 time/batch=1.13s
23680/10943 (epoch 194.747) train_loss=111.83195496 time/batch=0.79s
23681/10943 (epoch 194.755) train_loss=91.72834778 time/batch=0.61s
23682/10943 (epoch 194.763) train_loss=91.92612457 time/batch=0.68s
23683/10943 (epoch 194.772) train_loss=102.79883575 time/batch=0.70s
23684/10943 (epoch 194.780) train_loss=134.65809631 time/batch=0.92s
23685/10943 (epoch 194.788) train_loss=130.80868530 time/batch=0.90s
23686/10943 (epoch 194.796) train_loss=81.22327423 time/batch=0.59s
23687/10943 (epoch 194.804) train_loss=168.86032104 time/batch=1.03s
23688/10943 (epoch 194.813) train_loss=108.01655579 time/batch=0.74s
23689/10943 (epoch 194.821) train_loss=129.58273315 time/batch=0.82s
23690/10943 (epoch 194.829) train_loss=233.78320312 time/batch=1.34s
23691/10943 (epoch 194.837) train_loss=224.25051880 time/batch=1.44s
23692/10943 (epoch 194.846) train_loss=81.64678192 time/batch=0.58s
23693/10943 (epoch 194.854) train_loss=148.02920532 time/batch=1.06s
23694/10943 (epoch 194.862) train_loss=94.85922241 time/batch=0.69s
23695/10943 (epoch 194.870) train_loss=71.64476013 time/batch=0.46s
23696/10943 (epoch 194.878) train_loss=63.11430740 time/batch=0.40s
23697/10943 (epoch 194.887) train_loss=132.11537170 time/batch=0.94s
23698/10943 (epoch 194.895) train_loss=201.64314270 time/batch=1.23s
23699/10943 (epoch 194.903) train_loss=202.26795959 time/batch=1.30s
23700/10943 (epoch 194.911) train_loss=161.73773193 time/batch=1.16s
23701/10943 (epoch 194.920) train_loss=143.33099365 time/batch=0.94s
23702/10943 (epoch 194.928) train_loss=107.64937592 time/batch=0.75s
23703/10943 (epoch 194.936) train_loss=143.84049988 time/batch=0.96s
23704/10943 (epoch 194.944) train_loss=143.19128418 time/batch=0.94s
23705/10943 (epoch 194.952) train_loss=132.82507324 time/batch=0.95s
23706/10943 (epoch 194.961) train_loss=131.48080444 time/batch=0.92s
23707/10943 (epoch 194.969) train_loss=72.86170197 time/batch=0.51s
23708/10943 (epoch 194.977) train_loss=132.57298279 time/batch=0.80s
23709/10943 (epoch 194.985) train_loss=99.88587952 time/batch=0.78s
23710/10943 (epoch 194.994) train_loss=114.04072571 time/batch=0.79s
23711/10943 (epoch 195.002) train_loss=126.42070770 time/batch=0.87s
23712/10943 (epoch 195.010) train_loss=179.56210327 time/batch=1.37s
23713/10943 (epoch 195.018) train_loss=147.87696838 time/batch=1.07s
23714/10943 (epoch 195.026) train_loss=113.10113525 time/batch=0.75s
23715/10943 (epoch 195.035) train_loss=71.82608032 time/batch=0.48s
23716/10943 (epoch 195.043) train_loss=112.13121796 time/batch=0.72s
23717/10943 (epoch 195.051) train_loss=118.32751465 time/batch=0.79s
23718/10943 (epoch 195.059) train_loss=62.54688644 time/batch=0.41s
23719/10943 (epoch 195.068) train_loss=157.03416443 time/batch=0.98s
23720/10943 (epoch 195.076) train_loss=129.58427429 time/batch=0.87s
23721/10943 (epoch 195.084) train_loss=112.01088715 time/batch=0.74s
23722/10943 (epoch 195.092) train_loss=165.47549438 time/batch=1.02s
23723/10943 (epoch 195.100) train_loss=149.94255066 time/batch=1.02s
23724/10943 (epoch 195.109) train_loss=137.61694336 time/batch=1.00s
23725/10943 (epoch 195.117) train_loss=160.26278687 time/batch=1.03s
23726/10943 (epoch 195.125) train_loss=122.76156616 time/batch=0.88s
23727/10943 (epoch 195.133) train_loss=170.94192505 time/batch=1.40s
23728/10943 (epoch 195.142) train_loss=119.20951080 time/batch=0.87s
23729/10943 (epoch 195.150) train_loss=73.98904419 time/batch=0.43s
23730/10943 (epoch 195.158) train_loss=91.65144348 time/batch=0.58s
23731/10943 (epoch 195.166) train_loss=94.72288513 time/batch=0.61s
23732/10943 (epoch 195.175) train_loss=64.13661194 time/batch=0.47s
23733/10943 (epoch 195.183) train_loss=78.95474243 time/batch=0.62s
23734/10943 (epoch 195.191) train_loss=85.58578491 time/batch=0.66s
23735/10943 (epoch 195.199) train_loss=129.96026611 time/batch=0.89s
setting learning rate to 0.0004271
  saved to metadata/lstm_dropout-9_nov_folkwiki-20181112-195023.pkl
23736/10943 (epoch 195.207) train_loss=89.73083496 time/batch=0.69s
23737/10943 (epoch 195.216) train_loss=234.66479492 time/batch=1.39s
23738/10943 (epoch 195.224) train_loss=77.99404907 time/batch=0.61s
23739/10943 (epoch 195.232) train_loss=131.94964600 time/batch=0.90s
23740/10943 (epoch 195.240) train_loss=105.53271484 time/batch=0.74s
23741/10943 (epoch 195.249) train_loss=134.70120239 time/batch=0.91s
23742/10943 (epoch 195.257) train_loss=130.50268555 time/batch=0.92s
23743/10943 (epoch 195.265) train_loss=365.76995850 time/batch=2.05s
23744/10943 (epoch 195.273) train_loss=281.66943359 time/batch=1.82s
23745/10943 (epoch 195.281) train_loss=65.41229248 time/batch=0.49s
23746/10943 (epoch 195.290) train_loss=205.12319946 time/batch=1.19s
23747/10943 (epoch 195.298) train_loss=116.82022095 time/batch=0.85s
23748/10943 (epoch 195.306) train_loss=244.03085327 time/batch=1.33s
23749/10943 (epoch 195.314) train_loss=212.07806396 time/batch=1.37s
23750/10943 (epoch 195.323) train_loss=187.13720703 time/batch=1.24s
23751/10943 (epoch 195.331) train_loss=272.82043457 time/batch=1.74s
23752/10943 (epoch 195.339) train_loss=217.61444092 time/batch=1.45s
23753/10943 (epoch 195.347) train_loss=479.69183350 time/batch=3.84s
23754/10943 (epoch 195.355) train_loss=126.34957123 time/batch=1.19s
23755/10943 (epoch 195.364) train_loss=298.74411011 time/batch=2.05s
23756/10943 (epoch 195.372) train_loss=201.51492310 time/batch=1.42s
23757/10943 (epoch 195.380) train_loss=87.48532104 time/batch=0.61s
23758/10943 (epoch 195.388) train_loss=248.46066284 time/batch=1.49s
23759/10943 (epoch 195.397) train_loss=279.73980713 time/batch=2.14s
23760/10943 (epoch 195.405) train_loss=188.06945801 time/batch=1.34s
23761/10943 (epoch 195.413) train_loss=253.29885864 time/batch=1.51s
23762/10943 (epoch 195.421) train_loss=140.63034058 time/batch=1.02s
23763/10943 (epoch 195.429) train_loss=76.61016083 time/batch=0.53s
23764/10943 (epoch 195.438) train_loss=126.56643677 time/batch=0.86s
23765/10943 (epoch 195.446) train_loss=131.60629272 time/batch=0.99s
23766/10943 (epoch 195.454) train_loss=163.32524109 time/batch=1.13s
23767/10943 (epoch 195.462) train_loss=104.15037537 time/batch=0.76s
23768/10943 (epoch 195.471) train_loss=227.72276306 time/batch=1.41s
23769/10943 (epoch 195.479) train_loss=106.81537628 time/batch=0.84s
23770/10943 (epoch 195.487) train_loss=76.66432190 time/batch=0.50s
23771/10943 (epoch 195.495) train_loss=218.31410217 time/batch=1.39s
23772/10943 (epoch 195.503) train_loss=141.97665405 time/batch=0.99s
23773/10943 (epoch 195.512) train_loss=149.59925842 time/batch=1.03s
23774/10943 (epoch 195.520) train_loss=120.70424652 time/batch=0.95s
23775/10943 (epoch 195.528) train_loss=124.16826630 time/batch=0.87s
23776/10943 (epoch 195.536) train_loss=89.18959045 time/batch=0.61s
23777/10943 (epoch 195.545) train_loss=52.79179382 time/batch=0.37s
23778/10943 (epoch 195.553) train_loss=159.71542358 time/batch=1.03s
23779/10943 (epoch 195.561) train_loss=195.39071655 time/batch=1.25s
23780/10943 (epoch 195.569) train_loss=134.02014160 time/batch=1.01s
23781/10943 (epoch 195.577) train_loss=59.24676895 time/batch=0.44s
23782/10943 (epoch 195.586) train_loss=62.56740570 time/batch=0.37s
23783/10943 (epoch 195.594) train_loss=70.91586304 time/batch=0.44s
23784/10943 (epoch 195.602) train_loss=74.69746399 time/batch=0.43s
23785/10943 (epoch 195.610) train_loss=114.11602783 time/batch=0.75s
23786/10943 (epoch 195.619) train_loss=89.69129944 time/batch=0.59s
23787/10943 (epoch 195.627) train_loss=147.45288086 time/batch=0.84s
23788/10943 (epoch 195.635) train_loss=131.14413452 time/batch=0.88s
23789/10943 (epoch 195.643) train_loss=107.89788055 time/batch=0.77s
23790/10943 (epoch 195.652) train_loss=68.77236938 time/batch=0.44s
23791/10943 (epoch 195.660) train_loss=80.41390991 time/batch=0.58s
23792/10943 (epoch 195.668) train_loss=132.36557007 time/batch=0.88s
23793/10943 (epoch 195.676) train_loss=84.81443024 time/batch=0.54s
23794/10943 (epoch 195.684) train_loss=124.94992065 time/batch=0.78s
23795/10943 (epoch 195.693) train_loss=109.28506470 time/batch=0.78s
23796/10943 (epoch 195.701) train_loss=158.57649231 time/batch=1.05s
23797/10943 (epoch 195.709) train_loss=191.26165771 time/batch=1.19s
23798/10943 (epoch 195.717) train_loss=102.48811340 time/batch=0.74s
23799/10943 (epoch 195.726) train_loss=105.21353149 time/batch=0.76s
23800/10943 (epoch 195.734) train_loss=137.63247681 time/batch=0.99s
23801/10943 (epoch 195.742) train_loss=84.20225525 time/batch=0.61s
23802/10943 (epoch 195.750) train_loss=143.87245178 time/batch=1.03s
23803/10943 (epoch 195.758) train_loss=101.75418091 time/batch=0.69s
23804/10943 (epoch 195.767) train_loss=99.11982727 time/batch=0.62s
23805/10943 (epoch 195.775) train_loss=154.13378906 time/batch=1.01s
23806/10943 (epoch 195.783) train_loss=160.32678223 time/batch=1.05s
23807/10943 (epoch 195.791) train_loss=101.78559875 time/batch=0.76s
23808/10943 (epoch 195.800) train_loss=118.13486481 time/batch=0.81s
23809/10943 (epoch 195.808) train_loss=135.63426208 time/batch=0.92s
23810/10943 (epoch 195.816) train_loss=165.64297485 time/batch=1.10s
23811/10943 (epoch 195.824) train_loss=77.32310486 time/batch=0.58s
23812/10943 (epoch 195.832) train_loss=110.14993286 time/batch=0.66s
23813/10943 (epoch 195.841) train_loss=61.50635529 time/batch=0.40s
23814/10943 (epoch 195.849) train_loss=112.71430969 time/batch=0.82s
23815/10943 (epoch 195.857) train_loss=91.07704163 time/batch=0.62s
23816/10943 (epoch 195.865) train_loss=110.95606995 time/batch=0.74s
23817/10943 (epoch 195.874) train_loss=131.35926819 time/batch=0.92s
23818/10943 (epoch 195.882) train_loss=173.52381897 time/batch=1.12s
23819/10943 (epoch 195.890) train_loss=115.99728394 time/batch=0.83s
23820/10943 (epoch 195.898) train_loss=227.32292175 time/batch=1.45s
23821/10943 (epoch 195.906) train_loss=80.07151794 time/batch=0.63s
23822/10943 (epoch 195.915) train_loss=109.63916016 time/batch=0.72s
23823/10943 (epoch 195.923) train_loss=94.13248444 time/batch=0.65s
23824/10943 (epoch 195.931) train_loss=95.59354401 time/batch=0.65s
23825/10943 (epoch 195.939) train_loss=137.52026367 time/batch=0.95s
23826/10943 (epoch 195.948) train_loss=149.63949585 time/batch=1.01s
23827/10943 (epoch 195.956) train_loss=162.42108154 time/batch=1.14s
23828/10943 (epoch 195.964) train_loss=108.18310547 time/batch=0.77s
23829/10943 (epoch 195.972) train_loss=97.50599670 time/batch=0.70s
23830/10943 (epoch 195.980) train_loss=68.35600281 time/batch=0.44s
23831/10943 (epoch 195.989) train_loss=69.88706970 time/batch=0.42s
23832/10943 (epoch 195.997) train_loss=113.24917603 time/batch=0.76s
23833/10943 (epoch 196.005) train_loss=108.08094025 time/batch=0.74s
23834/10943 (epoch 196.013) train_loss=103.57574463 time/batch=0.70s
23835/10943 (epoch 196.022) train_loss=86.24752808 time/batch=0.62s
23836/10943 (epoch 196.030) train_loss=153.54010010 time/batch=1.10s
23837/10943 (epoch 196.038) train_loss=106.78848267 time/batch=0.78s
23838/10943 (epoch 196.046) train_loss=100.04027557 time/batch=0.67s
23839/10943 (epoch 196.054) train_loss=198.79000854 time/batch=1.15s
23840/10943 (epoch 196.063) train_loss=77.27651978 time/batch=0.67s
23841/10943 (epoch 196.071) train_loss=128.84033203 time/batch=0.83s
23842/10943 (epoch 196.079) train_loss=134.94491577 time/batch=0.83s
23843/10943 (epoch 196.087) train_loss=137.34107971 time/batch=1.00s
23844/10943 (epoch 196.096) train_loss=149.56045532 time/batch=1.04s
23845/10943 (epoch 196.104) train_loss=158.69880676 time/batch=0.98s
23846/10943 (epoch 196.112) train_loss=135.11425781 time/batch=0.99s
23847/10943 (epoch 196.120) train_loss=165.47880554 time/batch=1.15s
23848/10943 (epoch 196.129) train_loss=125.15222168 time/batch=0.88s
23849/10943 (epoch 196.137) train_loss=189.84443665 time/batch=1.21s
23850/10943 (epoch 196.145) train_loss=137.13172913 time/batch=1.06s
23851/10943 (epoch 196.153) train_loss=132.68617249 time/batch=1.04s
23852/10943 (epoch 196.161) train_loss=159.19909668 time/batch=1.14s
23853/10943 (epoch 196.170) train_loss=98.39776611 time/batch=0.66s
23854/10943 (epoch 196.178) train_loss=97.87455750 time/batch=0.65s
23855/10943 (epoch 196.186) train_loss=116.64019012 time/batch=0.80s
23856/10943 (epoch 196.194) train_loss=89.25457764 time/batch=0.72s
setting learning rate to 0.0004143
23857/10943 (epoch 196.203) train_loss=142.70956421 time/batch=0.97s
23858/10943 (epoch 196.211) train_loss=138.42472839 time/batch=1.01s
23859/10943 (epoch 196.219) train_loss=161.38409424 time/batch=1.14s
23860/10943 (epoch 196.227) train_loss=138.71099854 time/batch=1.09s
23861/10943 (epoch 196.235) train_loss=203.33811951 time/batch=1.28s
23862/10943 (epoch 196.244) train_loss=447.94689941 time/batch=2.94s
23863/10943 (epoch 196.252) train_loss=90.23583984 time/batch=0.85s
23864/10943 (epoch 196.260) train_loss=106.28167725 time/batch=0.71s
23865/10943 (epoch 196.268) train_loss=182.89126587 time/batch=1.16s
23866/10943 (epoch 196.277) train_loss=137.56098938 time/batch=0.97s
23867/10943 (epoch 196.285) train_loss=107.03800201 time/batch=0.79s
23868/10943 (epoch 196.293) train_loss=114.93098450 time/batch=0.86s
23869/10943 (epoch 196.301) train_loss=214.13348389 time/batch=1.25s
23870/10943 (epoch 196.309) train_loss=189.97378540 time/batch=1.31s
23871/10943 (epoch 196.318) train_loss=170.61941528 time/batch=1.14s
23872/10943 (epoch 196.326) train_loss=156.35920715 time/batch=1.10s
23873/10943 (epoch 196.334) train_loss=270.02276611 time/batch=1.66s
23874/10943 (epoch 196.342) train_loss=214.20898438 time/batch=1.42s
23875/10943 (epoch 196.351) train_loss=266.69799805 time/batch=1.60s
23876/10943 (epoch 196.359) train_loss=112.22062683 time/batch=0.88s
23877/10943 (epoch 196.367) train_loss=52.85045624 time/batch=0.35s
23878/10943 (epoch 196.375) train_loss=235.90902710 time/batch=1.33s
23879/10943 (epoch 196.383) train_loss=149.47280884 time/batch=1.08s
23880/10943 (epoch 196.392) train_loss=190.00366211 time/batch=1.21s
23881/10943 (epoch 196.400) train_loss=105.45614624 time/batch=0.78s
23882/10943 (epoch 196.408) train_loss=276.04995728 time/batch=1.83s
23883/10943 (epoch 196.416) train_loss=147.76338196 time/batch=1.09s
23884/10943 (epoch 196.425) train_loss=122.05108643 time/batch=0.87s
23885/10943 (epoch 196.433) train_loss=104.93122864 time/batch=0.75s
23886/10943 (epoch 196.441) train_loss=146.15408325 time/batch=0.99s
23887/10943 (epoch 196.449) train_loss=244.03752136 time/batch=1.47s
23888/10943 (epoch 196.457) train_loss=89.15261841 time/batch=0.68s
23889/10943 (epoch 196.466) train_loss=62.21909714 time/batch=0.39s
23890/10943 (epoch 196.474) train_loss=67.57864380 time/batch=0.41s
23891/10943 (epoch 196.482) train_loss=77.09051514 time/batch=0.50s
23892/10943 (epoch 196.490) train_loss=102.77325439 time/batch=0.64s
23893/10943 (epoch 196.499) train_loss=144.82507324 time/batch=1.03s
23894/10943 (epoch 196.507) train_loss=68.77172089 time/batch=0.51s
23895/10943 (epoch 196.515) train_loss=95.60636902 time/batch=0.65s
23896/10943 (epoch 196.523) train_loss=68.81655884 time/batch=0.44s
23897/10943 (epoch 196.531) train_loss=77.82199097 time/batch=0.46s
23898/10943 (epoch 196.540) train_loss=205.32528687 time/batch=1.17s
23899/10943 (epoch 196.548) train_loss=119.43120575 time/batch=0.89s
23900/10943 (epoch 196.556) train_loss=229.94087219 time/batch=1.40s
23901/10943 (epoch 196.564) train_loss=179.00585938 time/batch=1.21s
23902/10943 (epoch 196.573) train_loss=184.49954224 time/batch=1.31s
23903/10943 (epoch 196.581) train_loss=195.53015137 time/batch=1.23s
23904/10943 (epoch 196.589) train_loss=130.74099731 time/batch=0.94s
23905/10943 (epoch 196.597) train_loss=87.07698822 time/batch=0.61s
23906/10943 (epoch 196.605) train_loss=81.69467926 time/batch=0.53s
23907/10943 (epoch 196.614) train_loss=61.90000534 time/batch=0.36s
23908/10943 (epoch 196.622) train_loss=104.21917725 time/batch=0.67s
23909/10943 (epoch 196.630) train_loss=122.53735352 time/batch=0.83s
23910/10943 (epoch 196.638) train_loss=268.98901367 time/batch=1.68s
23911/10943 (epoch 196.647) train_loss=85.21630859 time/batch=0.67s
23912/10943 (epoch 196.655) train_loss=130.10694885 time/batch=0.79s
23913/10943 (epoch 196.663) train_loss=417.87933350 time/batch=3.76s
23914/10943 (epoch 196.671) train_loss=99.99765015 time/batch=1.02s
23915/10943 (epoch 196.680) train_loss=142.28182983 time/batch=0.92s
23916/10943 (epoch 196.688) train_loss=79.69239044 time/batch=0.62s
23917/10943 (epoch 196.696) train_loss=175.22207642 time/batch=1.07s
23918/10943 (epoch 196.704) train_loss=76.80821991 time/batch=0.51s
23919/10943 (epoch 196.712) train_loss=142.01644897 time/batch=0.93s
23920/10943 (epoch 196.721) train_loss=251.97521973 time/batch=1.70s
23921/10943 (epoch 196.729) train_loss=71.86097717 time/batch=0.58s
23922/10943 (epoch 196.737) train_loss=253.19090271 time/batch=1.83s
23923/10943 (epoch 196.745) train_loss=248.54927063 time/batch=1.44s
23924/10943 (epoch 196.754) train_loss=105.07756805 time/batch=0.81s
23925/10943 (epoch 196.762) train_loss=127.50514221 time/batch=0.82s
23926/10943 (epoch 196.770) train_loss=100.61924744 time/batch=0.75s
23927/10943 (epoch 196.778) train_loss=103.88776398 time/batch=0.78s
23928/10943 (epoch 196.786) train_loss=77.38876343 time/batch=0.52s
23929/10943 (epoch 196.795) train_loss=98.13493347 time/batch=0.65s
23930/10943 (epoch 196.803) train_loss=225.83486938 time/batch=1.34s
23931/10943 (epoch 196.811) train_loss=97.02848816 time/batch=0.80s
23932/10943 (epoch 196.819) train_loss=93.33721924 time/batch=0.60s
23933/10943 (epoch 196.828) train_loss=150.04798889 time/batch=1.07s
23934/10943 (epoch 196.836) train_loss=125.10255432 time/batch=0.84s
23935/10943 (epoch 196.844) train_loss=93.86365509 time/batch=0.65s
23936/10943 (epoch 196.852) train_loss=128.96836853 time/batch=0.85s
23937/10943 (epoch 196.860) train_loss=138.28204346 time/batch=0.91s
23938/10943 (epoch 196.869) train_loss=62.62929535 time/batch=0.43s
23939/10943 (epoch 196.877) train_loss=128.06565857 time/batch=0.82s
23940/10943 (epoch 196.885) train_loss=74.09523010 time/batch=0.51s
23941/10943 (epoch 196.893) train_loss=122.87277222 time/batch=0.88s
23942/10943 (epoch 196.902) train_loss=166.44085693 time/batch=1.29s
23943/10943 (epoch 196.910) train_loss=161.31869507 time/batch=1.14s
23944/10943 (epoch 196.918) train_loss=133.89236450 time/batch=0.97s
23945/10943 (epoch 196.926) train_loss=106.58598328 time/batch=0.73s
23946/10943 (epoch 196.934) train_loss=125.30081940 time/batch=0.95s
23947/10943 (epoch 196.943) train_loss=98.76748657 time/batch=0.72s
23948/10943 (epoch 196.951) train_loss=61.43090820 time/batch=0.40s
23949/10943 (epoch 196.959) train_loss=152.07998657 time/batch=0.83s
23950/10943 (epoch 196.967) train_loss=143.40505981 time/batch=0.94s
23951/10943 (epoch 196.976) train_loss=111.08734131 time/batch=0.78s
23952/10943 (epoch 196.984) train_loss=106.90509033 time/batch=0.73s
23953/10943 (epoch 196.992) train_loss=126.25651550 time/batch=0.81s
23954/10943 (epoch 197.000) train_loss=85.38291168 time/batch=0.63s
23955/10943 (epoch 197.008) train_loss=129.98107910 time/batch=0.96s
23956/10943 (epoch 197.017) train_loss=90.51203918 time/batch=0.65s
23957/10943 (epoch 197.025) train_loss=89.49026489 time/batch=0.61s
23958/10943 (epoch 197.033) train_loss=124.48345184 time/batch=0.81s
23959/10943 (epoch 197.041) train_loss=134.57824707 time/batch=0.89s
23960/10943 (epoch 197.050) train_loss=88.48816681 time/batch=0.56s
23961/10943 (epoch 197.058) train_loss=135.54571533 time/batch=0.94s
23962/10943 (epoch 197.066) train_loss=98.49975586 time/batch=0.66s
23963/10943 (epoch 197.074) train_loss=121.75911713 time/batch=0.77s
23964/10943 (epoch 197.082) train_loss=133.96475220 time/batch=0.99s
23965/10943 (epoch 197.091) train_loss=159.98651123 time/batch=1.07s
23966/10943 (epoch 197.099) train_loss=106.43261719 time/batch=0.80s
23967/10943 (epoch 197.107) train_loss=132.40496826 time/batch=0.88s
23968/10943 (epoch 197.115) train_loss=108.62963867 time/batch=0.76s
23969/10943 (epoch 197.124) train_loss=102.71647644 time/batch=0.74s
23970/10943 (epoch 197.132) train_loss=161.37707520 time/batch=1.02s
23971/10943 (epoch 197.140) train_loss=73.93523407 time/batch=0.57s
23972/10943 (epoch 197.148) train_loss=156.01696777 time/batch=0.99s
23973/10943 (epoch 197.157) train_loss=98.23490906 time/batch=0.68s
23974/10943 (epoch 197.165) train_loss=138.55943298 time/batch=0.96s
23975/10943 (epoch 197.173) train_loss=97.89934540 time/batch=0.79s
23976/10943 (epoch 197.181) train_loss=106.40489197 time/batch=0.80s
23977/10943 (epoch 197.189) train_loss=125.17440796 time/batch=0.87s
setting learning rate to 0.0004018
23978/10943 (epoch 197.198) train_loss=178.70617676 time/batch=1.18s
23979/10943 (epoch 197.206) train_loss=100.32910156 time/batch=0.78s
23980/10943 (epoch 197.214) train_loss=132.20263672 time/batch=0.82s
23981/10943 (epoch 197.222) train_loss=237.21090698 time/batch=1.48s
23982/10943 (epoch 197.231) train_loss=245.39927673 time/batch=1.43s
23983/10943 (epoch 197.239) train_loss=218.83483887 time/batch=1.42s
23984/10943 (epoch 197.247) train_loss=118.52510071 time/batch=0.87s
23985/10943 (epoch 197.255) train_loss=209.87164307 time/batch=1.30s
23986/10943 (epoch 197.263) train_loss=87.46048737 time/batch=0.66s
23987/10943 (epoch 197.272) train_loss=73.94820404 time/batch=0.51s
23988/10943 (epoch 197.280) train_loss=222.44740295 time/batch=1.41s
23989/10943 (epoch 197.288) train_loss=267.54037476 time/batch=1.75s
23990/10943 (epoch 197.296) train_loss=67.65503693 time/batch=0.59s
23991/10943 (epoch 197.305) train_loss=274.33227539 time/batch=1.76s
23992/10943 (epoch 197.313) train_loss=187.64089966 time/batch=1.31s
23993/10943 (epoch 197.321) train_loss=75.94954681 time/batch=0.53s
23994/10943 (epoch 197.329) train_loss=131.60510254 time/batch=0.88s
23995/10943 (epoch 197.337) train_loss=329.92703247 time/batch=1.96s
23996/10943 (epoch 197.346) train_loss=102.73542023 time/batch=0.91s
23997/10943 (epoch 197.354) train_loss=195.28614807 time/batch=1.19s
23998/10943 (epoch 197.362) train_loss=64.09584808 time/batch=0.46s
23999/10943 (epoch 197.370) train_loss=471.75585938 time/batch=3.72s
Validating
    loss:	237.133008

24000/10943 (epoch 197.379) train_loss=62.09913635 time/batch=3.31s
24001/10943 (epoch 197.387) train_loss=244.08673096 time/batch=1.47s
24002/10943 (epoch 197.395) train_loss=313.96435547 time/batch=2.14s
24003/10943 (epoch 197.403) train_loss=153.16786194 time/batch=1.23s
24004/10943 (epoch 197.411) train_loss=129.32522583 time/batch=1.01s
24005/10943 (epoch 197.420) train_loss=85.57958221 time/batch=0.64s
24006/10943 (epoch 197.428) train_loss=105.44236755 time/batch=0.71s
24007/10943 (epoch 197.436) train_loss=140.49079895 time/batch=0.89s
24008/10943 (epoch 197.444) train_loss=117.01075745 time/batch=0.82s
24009/10943 (epoch 197.453) train_loss=184.39625549 time/batch=1.22s
24010/10943 (epoch 197.461) train_loss=136.46923828 time/batch=0.92s
24011/10943 (epoch 197.469) train_loss=77.10759735 time/batch=0.51s
24012/10943 (epoch 197.477) train_loss=142.18959045 time/batch=0.91s
24013/10943 (epoch 197.485) train_loss=146.33482361 time/batch=1.06s
24014/10943 (epoch 197.494) train_loss=91.32969666 time/batch=0.66s
24015/10943 (epoch 197.502) train_loss=170.76992798 time/batch=1.06s
24016/10943 (epoch 197.510) train_loss=282.23495483 time/batch=1.59s
24017/10943 (epoch 197.518) train_loss=102.83673859 time/batch=0.79s
24018/10943 (epoch 197.527) train_loss=221.99996948 time/batch=1.55s
24019/10943 (epoch 197.535) train_loss=194.62225342 time/batch=1.38s
24020/10943 (epoch 197.543) train_loss=120.66949463 time/batch=0.98s
24021/10943 (epoch 197.551) train_loss=123.81458282 time/batch=0.92s
24022/10943 (epoch 197.559) train_loss=234.65196228 time/batch=1.38s
24023/10943 (epoch 197.568) train_loss=128.42498779 time/batch=1.02s
24024/10943 (epoch 197.576) train_loss=83.17869568 time/batch=0.60s
24025/10943 (epoch 197.584) train_loss=95.09031677 time/batch=0.63s
24026/10943 (epoch 197.592) train_loss=163.78509521 time/batch=1.08s
24027/10943 (epoch 197.601) train_loss=91.22659302 time/batch=0.68s
24028/10943 (epoch 197.609) train_loss=72.31591034 time/batch=0.51s
24029/10943 (epoch 197.617) train_loss=182.67126465 time/batch=1.12s
24030/10943 (epoch 197.625) train_loss=132.53515625 time/batch=0.96s
24031/10943 (epoch 197.634) train_loss=100.41116333 time/batch=0.79s
24032/10943 (epoch 197.642) train_loss=177.86465454 time/batch=1.14s
24033/10943 (epoch 197.650) train_loss=121.37444305 time/batch=0.91s
24034/10943 (epoch 197.658) train_loss=78.64952087 time/batch=0.55s
24035/10943 (epoch 197.666) train_loss=105.98115540 time/batch=0.75s
24036/10943 (epoch 197.675) train_loss=162.91595459 time/batch=1.13s
24037/10943 (epoch 197.683) train_loss=119.84616852 time/batch=0.86s
24038/10943 (epoch 197.691) train_loss=120.83285522 time/batch=0.83s
24039/10943 (epoch 197.699) train_loss=104.01969910 time/batch=0.75s
24040/10943 (epoch 197.708) train_loss=107.97348022 time/batch=0.68s
24041/10943 (epoch 197.716) train_loss=61.41838455 time/batch=0.41s
24042/10943 (epoch 197.724) train_loss=134.86949158 time/batch=0.83s
24043/10943 (epoch 197.732) train_loss=191.61625671 time/batch=1.23s
24044/10943 (epoch 197.740) train_loss=88.73634338 time/batch=0.64s
24045/10943 (epoch 197.749) train_loss=110.00460052 time/batch=0.76s
24046/10943 (epoch 197.757) train_loss=190.01119995 time/batch=1.22s
24047/10943 (epoch 197.765) train_loss=134.15031433 time/batch=0.93s
24048/10943 (epoch 197.773) train_loss=120.58102417 time/batch=0.83s
24049/10943 (epoch 197.782) train_loss=100.12498474 time/batch=0.65s
24050/10943 (epoch 197.790) train_loss=175.39556885 time/batch=1.22s
24051/10943 (epoch 197.798) train_loss=125.03002930 time/batch=0.90s
24052/10943 (epoch 197.806) train_loss=110.65814972 time/batch=0.79s
24053/10943 (epoch 197.814) train_loss=137.84391785 time/batch=0.95s
24054/10943 (epoch 197.823) train_loss=69.91034698 time/batch=0.45s
24055/10943 (epoch 197.831) train_loss=68.67961884 time/batch=0.41s
24056/10943 (epoch 197.839) train_loss=73.63124084 time/batch=0.47s
24057/10943 (epoch 197.847) train_loss=137.52960205 time/batch=0.90s
24058/10943 (epoch 197.856) train_loss=78.64661407 time/batch=0.54s
24059/10943 (epoch 197.864) train_loss=149.85754395 time/batch=0.98s
24060/10943 (epoch 197.872) train_loss=91.30296326 time/batch=0.70s
24061/10943 (epoch 197.880) train_loss=72.04122925 time/batch=0.45s
24062/10943 (epoch 197.888) train_loss=146.00814819 time/batch=0.92s
24063/10943 (epoch 197.897) train_loss=52.74707031 time/batch=0.44s
24064/10943 (epoch 197.905) train_loss=150.08581543 time/batch=0.97s
24065/10943 (epoch 197.913) train_loss=137.87878418 time/batch=1.02s
24066/10943 (epoch 197.921) train_loss=136.09518433 time/batch=0.99s
24067/10943 (epoch 197.930) train_loss=197.40129089 time/batch=1.27s
24068/10943 (epoch 197.938) train_loss=87.16976929 time/batch=0.65s
24069/10943 (epoch 197.946) train_loss=110.27255249 time/batch=0.70s
24070/10943 (epoch 197.954) train_loss=64.26329041 time/batch=0.51s
24071/10943 (epoch 197.962) train_loss=109.82400513 time/batch=0.70s
24072/10943 (epoch 197.971) train_loss=89.47505188 time/batch=0.69s
24073/10943 (epoch 197.979) train_loss=100.76886749 time/batch=0.69s
24074/10943 (epoch 197.987) train_loss=78.88157654 time/batch=0.55s
24075/10943 (epoch 197.995) train_loss=155.49073792 time/batch=0.99s
24076/10943 (epoch 198.004) train_loss=77.95425415 time/batch=0.58s
24077/10943 (epoch 198.012) train_loss=136.09877014 time/batch=0.95s
24078/10943 (epoch 198.020) train_loss=134.93493652 time/batch=0.99s
24079/10943 (epoch 198.028) train_loss=96.25723267 time/batch=0.70s
24080/10943 (epoch 198.036) train_loss=136.88606262 time/batch=1.04s
24081/10943 (epoch 198.045) train_loss=89.42901611 time/batch=0.65s
24082/10943 (epoch 198.053) train_loss=121.96098328 time/batch=0.83s
24083/10943 (epoch 198.061) train_loss=101.91197205 time/batch=0.74s
24084/10943 (epoch 198.069) train_loss=154.25769043 time/batch=1.01s
24085/10943 (epoch 198.078) train_loss=96.42950439 time/batch=0.68s
24086/10943 (epoch 198.086) train_loss=161.92950439 time/batch=1.03s
24087/10943 (epoch 198.094) train_loss=86.48283386 time/batch=0.65s
24088/10943 (epoch 198.102) train_loss=124.68852997 time/batch=0.82s
24089/10943 (epoch 198.111) train_loss=124.97875977 time/batch=0.86s
24090/10943 (epoch 198.119) train_loss=117.61067200 time/batch=0.84s
24091/10943 (epoch 198.127) train_loss=155.93289185 time/batch=1.02s
24092/10943 (epoch 198.135) train_loss=115.84994507 time/batch=0.98s
24093/10943 (epoch 198.143) train_loss=96.17584229 time/batch=0.73s
24094/10943 (epoch 198.152) train_loss=120.58078003 time/batch=0.83s
24095/10943 (epoch 198.160) train_loss=101.97358704 time/batch=0.76s
24096/10943 (epoch 198.168) train_loss=149.05770874 time/batch=1.05s
24097/10943 (epoch 198.176) train_loss=111.91246033 time/batch=0.79s
24098/10943 (epoch 198.185) train_loss=104.70536041 time/batch=0.75s
setting learning rate to 0.0003898
24099/10943 (epoch 198.193) train_loss=76.00549316 time/batch=0.50s
24100/10943 (epoch 198.201) train_loss=195.74668884 time/batch=1.24s
24101/10943 (epoch 198.209) train_loss=135.20315552 time/batch=1.10s
24102/10943 (epoch 198.217) train_loss=60.68427658 time/batch=0.43s
24103/10943 (epoch 198.226) train_loss=183.50506592 time/batch=1.10s
24104/10943 (epoch 198.234) train_loss=261.84484863 time/batch=1.65s
24105/10943 (epoch 198.242) train_loss=106.24551392 time/batch=0.83s
24106/10943 (epoch 198.250) train_loss=116.47743225 time/batch=0.84s
24107/10943 (epoch 198.259) train_loss=226.34291077 time/batch=1.33s
24108/10943 (epoch 198.267) train_loss=96.54458618 time/batch=0.77s
24109/10943 (epoch 198.275) train_loss=96.23687744 time/batch=0.62s
24110/10943 (epoch 198.283) train_loss=132.23719788 time/batch=0.93s
24111/10943 (epoch 198.291) train_loss=470.90225220 time/batch=3.80s
24112/10943 (epoch 198.300) train_loss=234.44024658 time/batch=1.70s
24113/10943 (epoch 198.308) train_loss=118.39474487 time/batch=0.92s
24114/10943 (epoch 198.316) train_loss=135.91943359 time/batch=0.91s
24115/10943 (epoch 198.324) train_loss=79.54808044 time/batch=0.55s
24116/10943 (epoch 198.333) train_loss=59.40300751 time/batch=0.36s
24117/10943 (epoch 198.341) train_loss=118.38569641 time/batch=0.77s
24118/10943 (epoch 198.349) train_loss=362.88928223 time/batch=2.05s
24119/10943 (epoch 198.357) train_loss=57.13462830 time/batch=0.58s
24120/10943 (epoch 198.365) train_loss=255.86486816 time/batch=1.49s
24121/10943 (epoch 198.374) train_loss=95.11313629 time/batch=0.78s
24122/10943 (epoch 198.382) train_loss=130.77381897 time/batch=0.88s
24123/10943 (epoch 198.390) train_loss=223.80052185 time/batch=1.41s
24124/10943 (epoch 198.398) train_loss=138.91484070 time/batch=1.01s
24125/10943 (epoch 198.407) train_loss=100.12946320 time/batch=0.77s
24126/10943 (epoch 198.415) train_loss=71.19526672 time/batch=0.51s
24127/10943 (epoch 198.423) train_loss=291.52465820 time/batch=1.86s
24128/10943 (epoch 198.431) train_loss=264.81311035 time/batch=1.77s
24129/10943 (epoch 198.439) train_loss=231.12525940 time/batch=1.45s
24130/10943 (epoch 198.448) train_loss=78.95606995 time/batch=0.64s
24131/10943 (epoch 198.456) train_loss=130.85272217 time/batch=0.89s
24132/10943 (epoch 198.464) train_loss=87.04611969 time/batch=0.61s
24133/10943 (epoch 198.472) train_loss=235.38807678 time/batch=1.44s
24134/10943 (epoch 198.481) train_loss=237.14468384 time/batch=1.74s
24135/10943 (epoch 198.489) train_loss=129.09408569 time/batch=1.07s
24136/10943 (epoch 198.497) train_loss=176.57676697 time/batch=1.20s
24137/10943 (epoch 198.505) train_loss=81.33699799 time/batch=0.64s
24138/10943 (epoch 198.513) train_loss=98.86186218 time/batch=0.61s
24139/10943 (epoch 198.522) train_loss=65.26340485 time/batch=0.42s
24140/10943 (epoch 198.530) train_loss=148.81048584 time/batch=1.02s
24141/10943 (epoch 198.538) train_loss=189.17832947 time/batch=1.20s
24142/10943 (epoch 198.546) train_loss=88.48255920 time/batch=0.71s
24143/10943 (epoch 198.555) train_loss=131.78451538 time/batch=0.95s
24144/10943 (epoch 198.563) train_loss=200.30023193 time/batch=1.21s
24145/10943 (epoch 198.571) train_loss=155.33166504 time/batch=1.11s
24146/10943 (epoch 198.579) train_loss=264.57601929 time/batch=1.77s
24147/10943 (epoch 198.588) train_loss=77.01533508 time/batch=0.59s
24148/10943 (epoch 198.596) train_loss=99.73957062 time/batch=0.70s
24149/10943 (epoch 198.604) train_loss=126.91924286 time/batch=0.88s
24150/10943 (epoch 198.612) train_loss=215.68415833 time/batch=1.34s
24151/10943 (epoch 198.620) train_loss=88.17971802 time/batch=0.63s
24152/10943 (epoch 198.629) train_loss=141.30456543 time/batch=0.88s
24153/10943 (epoch 198.637) train_loss=148.69314575 time/batch=1.02s
24154/10943 (epoch 198.645) train_loss=85.50460052 time/batch=0.67s
24155/10943 (epoch 198.653) train_loss=139.84542847 time/batch=0.99s
24156/10943 (epoch 198.662) train_loss=122.89495850 time/batch=0.89s
24157/10943 (epoch 198.670) train_loss=197.39347839 time/batch=1.23s
24158/10943 (epoch 198.678) train_loss=101.37593842 time/batch=0.76s
24159/10943 (epoch 198.686) train_loss=165.24372864 time/batch=1.10s
24160/10943 (epoch 198.694) train_loss=135.28804016 time/batch=1.00s
24161/10943 (epoch 198.703) train_loss=173.80506897 time/batch=1.18s
24162/10943 (epoch 198.711) train_loss=218.35681152 time/batch=1.39s
24163/10943 (epoch 198.719) train_loss=75.86133575 time/batch=0.62s
24164/10943 (epoch 198.727) train_loss=85.46982574 time/batch=0.62s
24165/10943 (epoch 198.736) train_loss=131.69644165 time/batch=0.96s
24166/10943 (epoch 198.744) train_loss=59.91816711 time/batch=0.44s
24167/10943 (epoch 198.752) train_loss=102.55210876 time/batch=0.76s
24168/10943 (epoch 198.760) train_loss=77.33654785 time/batch=0.55s
24169/10943 (epoch 198.768) train_loss=123.24294281 time/batch=0.77s
24170/10943 (epoch 198.777) train_loss=171.64511108 time/batch=1.08s
24171/10943 (epoch 198.785) train_loss=124.71858215 time/batch=0.88s
24172/10943 (epoch 198.793) train_loss=127.96839905 time/batch=0.95s
24173/10943 (epoch 198.801) train_loss=91.66433716 time/batch=0.64s
24174/10943 (epoch 198.810) train_loss=129.41200256 time/batch=0.88s
24175/10943 (epoch 198.818) train_loss=95.65366364 time/batch=0.74s
24176/10943 (epoch 198.826) train_loss=187.66729736 time/batch=1.21s
24177/10943 (epoch 198.834) train_loss=71.67984009 time/batch=0.52s
24178/10943 (epoch 198.842) train_loss=162.45167542 time/batch=1.08s
24179/10943 (epoch 198.851) train_loss=98.40177155 time/batch=0.79s
24180/10943 (epoch 198.859) train_loss=143.61221313 time/batch=0.88s
24181/10943 (epoch 198.867) train_loss=121.81659698 time/batch=0.81s
24182/10943 (epoch 198.875) train_loss=103.02554321 time/batch=0.68s
24183/10943 (epoch 198.884) train_loss=150.31701660 time/batch=1.04s
24184/10943 (epoch 198.892) train_loss=87.22307587 time/batch=0.65s
24185/10943 (epoch 198.900) train_loss=179.74072266 time/batch=1.22s
24186/10943 (epoch 198.908) train_loss=121.71643066 time/batch=0.86s
24187/10943 (epoch 198.916) train_loss=150.78404236 time/batch=1.03s
24188/10943 (epoch 198.925) train_loss=118.07102203 time/batch=0.90s
24189/10943 (epoch 198.933) train_loss=96.52818298 time/batch=0.68s
24190/10943 (epoch 198.941) train_loss=63.38470078 time/batch=0.45s
24191/10943 (epoch 198.949) train_loss=107.69865417 time/batch=0.72s
24192/10943 (epoch 198.958) train_loss=141.68588257 time/batch=1.00s
24193/10943 (epoch 198.966) train_loss=139.30816650 time/batch=0.91s
24194/10943 (epoch 198.974) train_loss=105.95884705 time/batch=0.73s
24195/10943 (epoch 198.982) train_loss=85.68894958 time/batch=0.58s
24196/10943 (epoch 198.990) train_loss=94.36225891 time/batch=0.63s
24197/10943 (epoch 198.999) train_loss=85.07897949 time/batch=0.57s
24198/10943 (epoch 199.007) train_loss=109.77136230 time/batch=0.75s
24199/10943 (epoch 199.015) train_loss=111.14178467 time/batch=0.75s
24200/10943 (epoch 199.023) train_loss=121.80052185 time/batch=0.82s
24201/10943 (epoch 199.032) train_loss=120.22655487 time/batch=0.82s
24202/10943 (epoch 199.040) train_loss=70.96151733 time/batch=0.48s
24203/10943 (epoch 199.048) train_loss=164.96755981 time/batch=0.99s
24204/10943 (epoch 199.056) train_loss=110.08279419 time/batch=0.81s
24205/10943 (epoch 199.065) train_loss=75.44429016 time/batch=0.49s
24206/10943 (epoch 199.073) train_loss=161.86273193 time/batch=1.04s
24207/10943 (epoch 199.081) train_loss=96.84685516 time/batch=0.71s
24208/10943 (epoch 199.089) train_loss=125.34125519 time/batch=0.85s
24209/10943 (epoch 199.097) train_loss=132.18316650 time/batch=0.96s
24210/10943 (epoch 199.106) train_loss=131.49084473 time/batch=1.00s
24211/10943 (epoch 199.114) train_loss=104.56921387 time/batch=0.74s
24212/10943 (epoch 199.122) train_loss=139.50581360 time/batch=0.97s
24213/10943 (epoch 199.130) train_loss=130.85289001 time/batch=0.86s
24214/10943 (epoch 199.139) train_loss=109.67681885 time/batch=0.76s
24215/10943 (epoch 199.147) train_loss=100.15550995 time/batch=0.76s
24216/10943 (epoch 199.155) train_loss=145.09448242 time/batch=1.01s
24217/10943 (epoch 199.163) train_loss=123.36596680 time/batch=0.92s
24218/10943 (epoch 199.171) train_loss=65.52690887 time/batch=0.49s
24219/10943 (epoch 199.180) train_loss=85.23889160 time/batch=0.72s
setting learning rate to 0.0003781
24220/10943 (epoch 199.188) train_loss=59.19227982 time/batch=0.39s
24221/10943 (epoch 199.196) train_loss=187.16416931 time/batch=1.11s
24222/10943 (epoch 199.204) train_loss=157.19573975 time/batch=1.10s
24223/10943 (epoch 199.213) train_loss=94.30783081 time/batch=0.74s
24224/10943 (epoch 199.221) train_loss=221.72946167 time/batch=1.39s
24225/10943 (epoch 199.229) train_loss=52.53761673 time/batch=0.43s
24226/10943 (epoch 199.237) train_loss=75.12939453 time/batch=0.46s
24227/10943 (epoch 199.245) train_loss=471.53765869 time/batch=3.73s
24228/10943 (epoch 199.254) train_loss=238.16761780 time/batch=1.71s
24229/10943 (epoch 199.262) train_loss=77.56147003 time/batch=0.61s
24230/10943 (epoch 199.270) train_loss=83.09313202 time/batch=0.57s
24231/10943 (epoch 199.278) train_loss=138.21670532 time/batch=0.93s
24232/10943 (epoch 199.287) train_loss=264.12142944 time/batch=1.71s
24233/10943 (epoch 199.295) train_loss=165.28289795 time/batch=1.21s
24234/10943 (epoch 199.303) train_loss=256.07098389 time/batch=1.63s
24235/10943 (epoch 199.311) train_loss=129.99423218 time/batch=0.99s
24236/10943 (epoch 199.319) train_loss=201.03926086 time/batch=1.22s
24237/10943 (epoch 199.328) train_loss=96.28425598 time/batch=0.81s
24238/10943 (epoch 199.336) train_loss=173.20022583 time/batch=1.20s
24239/10943 (epoch 199.344) train_loss=131.19895935 time/batch=1.01s
24240/10943 (epoch 199.352) train_loss=233.20056152 time/batch=1.51s
24241/10943 (epoch 199.361) train_loss=245.77142334 time/batch=1.43s
24242/10943 (epoch 199.369) train_loss=105.20742798 time/batch=0.81s
24243/10943 (epoch 199.377) train_loss=284.20471191 time/batch=1.85s
24244/10943 (epoch 199.385) train_loss=227.83312988 time/batch=1.56s
24245/10943 (epoch 199.393) train_loss=138.09109497 time/batch=1.01s
24246/10943 (epoch 199.402) train_loss=134.07611084 time/batch=0.97s
24247/10943 (epoch 199.410) train_loss=87.41677856 time/batch=0.66s
24248/10943 (epoch 199.418) train_loss=348.90539551 time/batch=1.97s
24249/10943 (epoch 199.426) train_loss=91.10815430 time/batch=0.77s
24250/10943 (epoch 199.435) train_loss=242.04315186 time/batch=1.44s
24251/10943 (epoch 199.443) train_loss=132.36657715 time/batch=0.97s
24252/10943 (epoch 199.451) train_loss=62.72604370 time/batch=0.49s
24253/10943 (epoch 199.459) train_loss=66.87399292 time/batch=0.42s
24254/10943 (epoch 199.467) train_loss=160.02137756 time/batch=1.05s
24255/10943 (epoch 199.476) train_loss=121.66299438 time/batch=0.83s
24256/10943 (epoch 199.484) train_loss=218.30151367 time/batch=1.52s
24257/10943 (epoch 199.492) train_loss=104.50237274 time/batch=0.82s
24258/10943 (epoch 199.500) train_loss=91.24136353 time/batch=0.61s
24259/10943 (epoch 199.509) train_loss=196.58245850 time/batch=1.22s
24260/10943 (epoch 199.517) train_loss=94.23183441 time/batch=0.66s
24261/10943 (epoch 199.525) train_loss=95.41279602 time/batch=0.72s
24262/10943 (epoch 199.533) train_loss=189.80761719 time/batch=1.15s
24263/10943 (epoch 199.542) train_loss=65.18612671 time/batch=0.46s
24264/10943 (epoch 199.550) train_loss=226.27749634 time/batch=1.47s
24265/10943 (epoch 199.558) train_loss=56.99285507 time/batch=0.51s
24266/10943 (epoch 199.566) train_loss=78.51557159 time/batch=0.50s
24267/10943 (epoch 199.574) train_loss=118.19161987 time/batch=0.80s
24268/10943 (epoch 199.583) train_loss=126.40065002 time/batch=0.84s
24269/10943 (epoch 199.591) train_loss=214.12756348 time/batch=1.55s
24270/10943 (epoch 199.599) train_loss=67.56478882 time/batch=0.56s
24271/10943 (epoch 199.607) train_loss=95.39910126 time/batch=0.62s
24272/10943 (epoch 199.616) train_loss=121.73051453 time/batch=0.82s
24273/10943 (epoch 199.624) train_loss=110.23774719 time/batch=0.87s
24274/10943 (epoch 199.632) train_loss=93.31083679 time/batch=0.67s
24275/10943 (epoch 199.640) train_loss=97.88742065 time/batch=0.71s
24276/10943 (epoch 199.648) train_loss=126.42554474 time/batch=0.96s
24277/10943 (epoch 199.657) train_loss=150.90682983 time/batch=1.09s
24278/10943 (epoch 199.665) train_loss=72.59407806 time/batch=0.54s
24279/10943 (epoch 199.673) train_loss=136.39270020 time/batch=0.96s
24280/10943 (epoch 199.681) train_loss=208.66656494 time/batch=1.27s
24281/10943 (epoch 199.690) train_loss=120.27598572 time/batch=0.92s
24282/10943 (epoch 199.698) train_loss=117.28623962 time/batch=0.82s
24283/10943 (epoch 199.706) train_loss=64.63133240 time/batch=0.44s
24284/10943 (epoch 199.714) train_loss=136.44613647 time/batch=1.01s
24285/10943 (epoch 199.722) train_loss=71.70396423 time/batch=0.50s
24286/10943 (epoch 199.731) train_loss=147.01318359 time/batch=1.01s
24287/10943 (epoch 199.739) train_loss=79.75847626 time/batch=0.61s
24288/10943 (epoch 199.747) train_loss=154.77819824 time/batch=1.05s
24289/10943 (epoch 199.755) train_loss=258.13488770 time/batch=2.09s
24290/10943 (epoch 199.764) train_loss=134.87261963 time/batch=1.07s
24291/10943 (epoch 199.772) train_loss=109.51158142 time/batch=0.78s
24292/10943 (epoch 199.780) train_loss=106.20510864 time/batch=0.78s
24293/10943 (epoch 199.788) train_loss=73.09001160 time/batch=0.54s
24294/10943 (epoch 199.796) train_loss=189.10229492 time/batch=1.18s
24295/10943 (epoch 199.805) train_loss=135.42472839 time/batch=0.95s
24296/10943 (epoch 199.813) train_loss=77.35847473 time/batch=0.57s
24297/10943 (epoch 199.821) train_loss=149.26409912 time/batch=0.98s
24298/10943 (epoch 199.829) train_loss=114.22917938 time/batch=0.81s
24299/10943 (epoch 199.838) train_loss=166.87167358 time/batch=1.13s
24300/10943 (epoch 199.846) train_loss=165.17053223 time/batch=1.15s
24301/10943 (epoch 199.854) train_loss=107.12520599 time/batch=0.83s
24302/10943 (epoch 199.862) train_loss=101.42790985 time/batch=0.73s
24303/10943 (epoch 199.870) train_loss=129.73715210 time/batch=0.86s
24304/10943 (epoch 199.879) train_loss=139.85885620 time/batch=1.00s
24305/10943 (epoch 199.887) train_loss=103.57591248 time/batch=0.78s
24306/10943 (epoch 199.895) train_loss=103.62017822 time/batch=0.72s
24307/10943 (epoch 199.903) train_loss=79.60238647 time/batch=0.54s
24308/10943 (epoch 199.912) train_loss=132.92596436 time/batch=0.90s
24309/10943 (epoch 199.920) train_loss=168.68902588 time/batch=1.20s
24310/10943 (epoch 199.928) train_loss=132.87953186 time/batch=0.95s
24311/10943 (epoch 199.936) train_loss=153.09336853 time/batch=1.13s
24312/10943 (epoch 199.944) train_loss=81.56838226 time/batch=0.62s
24313/10943 (epoch 199.953) train_loss=102.58424377 time/batch=0.70s
24314/10943 (epoch 199.961) train_loss=123.96734619 time/batch=0.83s
24315/10943 (epoch 199.969) train_loss=104.31948090 time/batch=0.68s
24316/10943 (epoch 199.977) train_loss=97.15200806 time/batch=0.67s
24317/10943 (epoch 199.986) train_loss=83.66697693 time/batch=0.58s
24318/10943 (epoch 199.994) train_loss=111.23785400 time/batch=0.77s
24319/10943 (epoch 200.002) train_loss=77.31140900 time/batch=0.56s
24320/10943 (epoch 200.010) train_loss=94.70167542 time/batch=0.65s
24321/10943 (epoch 200.019) train_loss=96.10266113 time/batch=0.69s
24322/10943 (epoch 200.027) train_loss=107.08152771 time/batch=0.75s
24323/10943 (epoch 200.035) train_loss=72.62072754 time/batch=0.59s
24324/10943 (epoch 200.043) train_loss=148.31112671 time/batch=0.84s
24325/10943 (epoch 200.051) train_loss=133.18273926 time/batch=0.98s
24326/10943 (epoch 200.060) train_loss=155.86727905 time/batch=1.05s
24327/10943 (epoch 200.068) train_loss=137.44650269 time/batch=1.01s
24328/10943 (epoch 200.076) train_loss=84.35302734 time/batch=0.65s
24329/10943 (epoch 200.084) train_loss=122.65722656 time/batch=0.90s
24330/10943 (epoch 200.093) train_loss=118.34171295 time/batch=0.83s
24331/10943 (epoch 200.101) train_loss=121.81157684 time/batch=0.86s
24332/10943 (epoch 200.109) train_loss=94.19012451 time/batch=0.68s
24333/10943 (epoch 200.117) train_loss=124.38713074 time/batch=0.96s
24334/10943 (epoch 200.125) train_loss=148.43199158 time/batch=1.03s
24335/10943 (epoch 200.134) train_loss=100.48983002 time/batch=0.67s
24336/10943 (epoch 200.142) train_loss=100.13681030 time/batch=0.74s
24337/10943 (epoch 200.150) train_loss=131.64857483 time/batch=0.92s
24338/10943 (epoch 200.158) train_loss=157.52043152 time/batch=1.05s
24339/10943 (epoch 200.167) train_loss=118.49857330 time/batch=0.85s
24340/10943 (epoch 200.175) train_loss=133.66714478 time/batch=0.99s
setting learning rate to 0.0003668
  saved to metadata/lstm_dropout-9_nov_folkwiki-20181112-195023.pkl
