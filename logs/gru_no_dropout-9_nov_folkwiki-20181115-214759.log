vocabulary size: 226
n tunes: 4083
n train tunes: 3891.0
n validation tunes: 192.0
min, max length 55 822
Building the model
  number of parameters: 10384102
  layer output shapes:               #params:   output shape:
    InputLayer                       0          (32, None)
    EmbeddingLayer                   51076      (32, None, 226)
    InputLayer                       0          (32, None)
    GRULayer                         2465600    (32, None, 800)
    GRULayer                         3843200    (32, None, 800)
    GRULayer                         3843200    (32, None, 800)
    ReshapeLayer                     0          (None, 800)
    DenseLayer                       181026     (None, 226)
Train model
Load metadata for resuming
setting learning rate to 0.0012402
19451/10943 (epoch 159.967) train_loss=614.59472656 time/batch=1.24s
19452/10943 (epoch 159.975) train_loss=650.22717285 time/batch=0.86s
19453/10943 (epoch 159.984) train_loss=1058.04748535 time/batch=1.69s
19454/10943 (epoch 159.992) train_loss=884.80725098 time/batch=1.49s
19455/10943 (epoch 160.000) train_loss=218.65457153 time/batch=0.49s
19456/10943 (epoch 160.008) train_loss=318.89721680 time/batch=0.55s
19457/10943 (epoch 160.016) train_loss=458.90515137 time/batch=0.84s
19458/10943 (epoch 160.025) train_loss=127.42412567 time/batch=0.31s
19459/10943 (epoch 160.033) train_loss=499.55938721 time/batch=0.89s
19460/10943 (epoch 160.041) train_loss=974.97082520 time/batch=1.94s
19461/10943 (epoch 160.049) train_loss=1193.20959473 time/batch=3.22s
19462/10943 (epoch 160.058) train_loss=440.77014160 time/batch=0.98s
19463/10943 (epoch 160.066) train_loss=379.83911133 time/batch=0.67s
19464/10943 (epoch 160.074) train_loss=291.24542236 time/batch=0.57s
19465/10943 (epoch 160.082) train_loss=423.04962158 time/batch=0.75s
19466/10943 (epoch 160.090) train_loss=577.05773926 time/batch=1.04s
19467/10943 (epoch 160.099) train_loss=501.03308105 time/batch=0.95s
19468/10943 (epoch 160.107) train_loss=231.47665405 time/batch=0.48s
19469/10943 (epoch 160.115) train_loss=179.52639771 time/batch=0.35s
19470/10943 (epoch 160.123) train_loss=246.16914368 time/batch=0.46s
19471/10943 (epoch 160.132) train_loss=399.86120605 time/batch=0.76s
19472/10943 (epoch 160.140) train_loss=527.48138428 time/batch=0.96s
19473/10943 (epoch 160.148) train_loss=212.69900513 time/batch=0.47s
19474/10943 (epoch 160.156) train_loss=578.13928223 time/batch=0.96s
19475/10943 (epoch 160.164) train_loss=297.79278564 time/batch=0.60s
19476/10943 (epoch 160.173) train_loss=244.43103027 time/batch=0.48s
19477/10943 (epoch 160.181) train_loss=518.42260742 time/batch=0.95s
19478/10943 (epoch 160.189) train_loss=503.20849609 time/batch=0.94s
19479/10943 (epoch 160.197) train_loss=780.64898682 time/batch=1.33s
19480/10943 (epoch 160.206) train_loss=652.73950195 time/batch=1.19s
19481/10943 (epoch 160.214) train_loss=211.44015503 time/batch=0.47s
19482/10943 (epoch 160.222) train_loss=394.91644287 time/batch=0.73s
19483/10943 (epoch 160.230) train_loss=580.91418457 time/batch=1.04s
19484/10943 (epoch 160.238) train_loss=319.72607422 time/batch=0.67s
19485/10943 (epoch 160.247) train_loss=138.45538330 time/batch=0.31s
19486/10943 (epoch 160.255) train_loss=704.17047119 time/batch=1.22s
19487/10943 (epoch 160.263) train_loss=473.49200439 time/batch=0.92s
19488/10943 (epoch 160.271) train_loss=626.70660400 time/batch=1.20s
19489/10943 (epoch 160.280) train_loss=427.36785889 time/batch=0.88s
19490/10943 (epoch 160.288) train_loss=353.50726318 time/batch=0.68s
19491/10943 (epoch 160.296) train_loss=674.71020508 time/batch=1.31s
19492/10943 (epoch 160.304) train_loss=545.46545410 time/batch=1.08s
19493/10943 (epoch 160.313) train_loss=272.49224854 time/batch=0.60s
19494/10943 (epoch 160.321) train_loss=352.91320801 time/batch=0.68s
19495/10943 (epoch 160.329) train_loss=505.26519775 time/batch=0.95s
19496/10943 (epoch 160.337) train_loss=652.89758301 time/batch=1.22s
19497/10943 (epoch 160.345) train_loss=198.92437744 time/batch=0.46s
19498/10943 (epoch 160.354) train_loss=404.08633423 time/batch=0.76s
19499/10943 (epoch 160.362) train_loss=510.06591797 time/batch=0.98s
19500/10943 (epoch 160.370) train_loss=601.01220703 time/batch=1.13s
19501/10943 (epoch 160.378) train_loss=194.17782593 time/batch=0.44s
19502/10943 (epoch 160.387) train_loss=431.85693359 time/batch=0.79s
19503/10943 (epoch 160.395) train_loss=198.60504150 time/batch=0.42s
19504/10943 (epoch 160.403) train_loss=364.28790283 time/batch=0.70s
19505/10943 (epoch 160.411) train_loss=229.77441406 time/batch=0.48s
19506/10943 (epoch 160.419) train_loss=427.74072266 time/batch=0.80s
19507/10943 (epoch 160.428) train_loss=496.31442261 time/batch=0.99s
19508/10943 (epoch 160.436) train_loss=415.67828369 time/batch=0.85s
19509/10943 (epoch 160.444) train_loss=305.10723877 time/batch=0.62s
19510/10943 (epoch 160.452) train_loss=275.68200684 time/batch=0.57s
19511/10943 (epoch 160.461) train_loss=147.88479614 time/batch=0.32s
19512/10943 (epoch 160.469) train_loss=287.88531494 time/batch=0.55s
19513/10943 (epoch 160.477) train_loss=172.45391846 time/batch=0.38s
19514/10943 (epoch 160.485) train_loss=198.64035034 time/batch=0.41s
19515/10943 (epoch 160.493) train_loss=301.53540039 time/batch=0.59s
19516/10943 (epoch 160.502) train_loss=566.10864258 time/batch=1.12s
19517/10943 (epoch 160.510) train_loss=259.45153809 time/batch=0.60s
19518/10943 (epoch 160.518) train_loss=413.80346680 time/batch=0.81s
19519/10943 (epoch 160.526) train_loss=252.82434082 time/batch=0.53s
19520/10943 (epoch 160.535) train_loss=361.81848145 time/batch=0.68s
19521/10943 (epoch 160.543) train_loss=393.48571777 time/batch=0.80s
19522/10943 (epoch 160.551) train_loss=404.06213379 time/batch=0.81s
19523/10943 (epoch 160.559) train_loss=433.15075684 time/batch=0.86s
19524/10943 (epoch 160.567) train_loss=318.13842773 time/batch=0.65s
19525/10943 (epoch 160.576) train_loss=149.27841187 time/batch=0.33s
19526/10943 (epoch 160.584) train_loss=330.15289307 time/batch=0.63s
19527/10943 (epoch 160.592) train_loss=421.85494995 time/batch=0.83s
19528/10943 (epoch 160.600) train_loss=499.70632935 time/batch=1.03s
19529/10943 (epoch 160.609) train_loss=273.06936646 time/batch=0.54s
19530/10943 (epoch 160.617) train_loss=407.85684204 time/batch=0.75s
19531/10943 (epoch 160.625) train_loss=465.96746826 time/batch=0.87s
19532/10943 (epoch 160.633) train_loss=400.47271729 time/batch=0.75s
19533/10943 (epoch 160.641) train_loss=622.47802734 time/batch=1.43s
19534/10943 (epoch 160.650) train_loss=284.12152100 time/batch=0.61s
19535/10943 (epoch 160.658) train_loss=327.40219116 time/batch=0.62s
19536/10943 (epoch 160.666) train_loss=458.57104492 time/batch=0.86s
19537/10943 (epoch 160.674) train_loss=213.20339966 time/batch=0.48s
19538/10943 (epoch 160.683) train_loss=346.62625122 time/batch=0.65s
19539/10943 (epoch 160.691) train_loss=321.10766602 time/batch=0.63s
19540/10943 (epoch 160.699) train_loss=299.75006104 time/batch=0.60s
19541/10943 (epoch 160.707) train_loss=309.71179199 time/batch=0.60s
19542/10943 (epoch 160.715) train_loss=337.68728638 time/batch=0.65s
19543/10943 (epoch 160.724) train_loss=202.44810486 time/batch=0.45s
19544/10943 (epoch 160.732) train_loss=221.71493530 time/batch=0.45s
19545/10943 (epoch 160.740) train_loss=182.42958069 time/batch=0.45s
19546/10943 (epoch 160.748) train_loss=309.33117676 time/batch=0.61s
19547/10943 (epoch 160.757) train_loss=371.69696045 time/batch=0.71s
19548/10943 (epoch 160.765) train_loss=261.19735718 time/batch=0.56s
19549/10943 (epoch 160.773) train_loss=248.87132263 time/batch=0.49s
19550/10943 (epoch 160.781) train_loss=256.39425659 time/batch=0.51s
19551/10943 (epoch 160.790) train_loss=378.55877686 time/batch=0.73s
19552/10943 (epoch 160.798) train_loss=156.28164673 time/batch=0.35s
19553/10943 (epoch 160.806) train_loss=435.43746948 time/batch=0.83s
19554/10943 (epoch 160.814) train_loss=296.01461792 time/batch=0.62s
19555/10943 (epoch 160.822) train_loss=217.30967712 time/batch=0.52s
19556/10943 (epoch 160.831) train_loss=285.80087280 time/batch=0.60s
19557/10943 (epoch 160.839) train_loss=260.74810791 time/batch=0.54s
19558/10943 (epoch 160.847) train_loss=343.99707031 time/batch=0.66s
19559/10943 (epoch 160.855) train_loss=214.00613403 time/batch=0.57s
19560/10943 (epoch 160.864) train_loss=381.70355225 time/batch=0.72s
19561/10943 (epoch 160.872) train_loss=325.87277222 time/batch=0.67s
19562/10943 (epoch 160.880) train_loss=348.73422241 time/batch=0.67s
19563/10943 (epoch 160.888) train_loss=464.97320557 time/batch=0.99s
19564/10943 (epoch 160.896) train_loss=309.02072144 time/batch=0.63s
19565/10943 (epoch 160.905) train_loss=394.73254395 time/batch=0.84s
19566/10943 (epoch 160.913) train_loss=313.58880615 time/batch=0.69s
19567/10943 (epoch 160.921) train_loss=365.11520386 time/batch=0.72s
19568/10943 (epoch 160.929) train_loss=370.95596313 time/batch=0.86s
19569/10943 (epoch 160.938) train_loss=326.36798096 time/batch=0.71s
19570/10943 (epoch 160.946) train_loss=359.42675781 time/batch=0.70s
19571/10943 (epoch 160.954) train_loss=344.16864014 time/batch=0.73s
setting learning rate to 0.0012030
19572/10943 (epoch 160.962) train_loss=199.37142944 time/batch=0.44s
19573/10943 (epoch 160.970) train_loss=329.09332275 time/batch=0.63s
19574/10943 (epoch 160.979) train_loss=532.10095215 time/batch=1.01s
19575/10943 (epoch 160.987) train_loss=688.56805420 time/batch=1.24s
19576/10943 (epoch 160.995) train_loss=1339.17871094 time/batch=3.07s
19577/10943 (epoch 161.003) train_loss=843.79467773 time/batch=1.60s
19578/10943 (epoch 161.012) train_loss=419.72265625 time/batch=0.87s
19579/10943 (epoch 161.020) train_loss=537.37213135 time/batch=1.01s
19580/10943 (epoch 161.028) train_loss=380.21087646 time/batch=0.80s
19581/10943 (epoch 161.036) train_loss=404.08032227 time/batch=0.83s
19582/10943 (epoch 161.044) train_loss=245.48439026 time/batch=0.54s
19583/10943 (epoch 161.053) train_loss=877.80102539 time/batch=1.63s
19584/10943 (epoch 161.061) train_loss=358.29437256 time/batch=0.84s
19585/10943 (epoch 161.069) train_loss=546.46038818 time/batch=1.11s
19586/10943 (epoch 161.077) train_loss=114.81916809 time/batch=0.33s
19587/10943 (epoch 161.086) train_loss=411.00985718 time/batch=0.79s
19588/10943 (epoch 161.094) train_loss=767.42395020 time/batch=1.53s
19589/10943 (epoch 161.102) train_loss=300.61682129 time/batch=0.68s
19590/10943 (epoch 161.110) train_loss=381.00881958 time/batch=0.76s
19591/10943 (epoch 161.118) train_loss=693.33941650 time/batch=1.36s
19592/10943 (epoch 161.127) train_loss=174.76145935 time/batch=0.45s
19593/10943 (epoch 161.135) train_loss=224.73103333 time/batch=0.45s
19594/10943 (epoch 161.143) train_loss=290.82077026 time/batch=0.60s
19595/10943 (epoch 161.151) train_loss=537.88049316 time/batch=1.04s
19596/10943 (epoch 161.160) train_loss=219.54730225 time/batch=0.50s
19597/10943 (epoch 161.168) train_loss=339.04492188 time/batch=0.67s
19598/10943 (epoch 161.176) train_loss=150.32986450 time/batch=0.35s
19599/10943 (epoch 161.184) train_loss=473.91659546 time/batch=0.90s
19600/10943 (epoch 161.192) train_loss=427.16845703 time/batch=0.88s
19601/10943 (epoch 161.201) train_loss=590.91687012 time/batch=1.16s
19602/10943 (epoch 161.209) train_loss=415.03875732 time/batch=0.82s
19603/10943 (epoch 161.217) train_loss=288.76965332 time/batch=0.60s
19604/10943 (epoch 161.225) train_loss=228.72294617 time/batch=0.48s
19605/10943 (epoch 161.234) train_loss=321.88153076 time/batch=0.62s
19606/10943 (epoch 161.242) train_loss=248.57125854 time/batch=0.52s
19607/10943 (epoch 161.250) train_loss=374.83242798 time/batch=0.71s
19608/10943 (epoch 161.258) train_loss=457.95870972 time/batch=0.89s
19609/10943 (epoch 161.267) train_loss=150.97381592 time/batch=0.35s
19610/10943 (epoch 161.275) train_loss=416.88583374 time/batch=0.81s
19611/10943 (epoch 161.283) train_loss=623.05358887 time/batch=1.19s
19612/10943 (epoch 161.291) train_loss=566.15393066 time/batch=1.03s
19613/10943 (epoch 161.299) train_loss=154.03765869 time/batch=0.38s
19614/10943 (epoch 161.308) train_loss=393.61291504 time/batch=0.74s
19615/10943 (epoch 161.316) train_loss=448.07406616 time/batch=0.89s
19616/10943 (epoch 161.324) train_loss=168.62170410 time/batch=0.40s
19617/10943 (epoch 161.332) train_loss=380.19842529 time/batch=0.76s
19618/10943 (epoch 161.341) train_loss=218.56401062 time/batch=0.48s
19619/10943 (epoch 161.349) train_loss=446.10919189 time/batch=0.87s
19620/10943 (epoch 161.357) train_loss=431.40625000 time/batch=0.88s
19621/10943 (epoch 161.365) train_loss=158.66439819 time/batch=0.40s
19622/10943 (epoch 161.373) train_loss=551.10156250 time/batch=1.04s
19623/10943 (epoch 161.382) train_loss=362.14102173 time/batch=0.75s
19624/10943 (epoch 161.390) train_loss=185.38848877 time/batch=0.42s
19625/10943 (epoch 161.398) train_loss=350.45654297 time/batch=0.67s
19626/10943 (epoch 161.406) train_loss=321.10705566 time/batch=0.68s
19627/10943 (epoch 161.415) train_loss=133.47973633 time/batch=0.31s
19628/10943 (epoch 161.423) train_loss=547.14941406 time/batch=1.03s
19629/10943 (epoch 161.431) train_loss=548.38934326 time/batch=1.15s
19630/10943 (epoch 161.439) train_loss=184.80770874 time/batch=0.44s
19631/10943 (epoch 161.447) train_loss=454.89117432 time/batch=0.88s
19632/10943 (epoch 161.456) train_loss=389.66833496 time/batch=0.78s
19633/10943 (epoch 161.464) train_loss=280.86206055 time/batch=0.61s
19634/10943 (epoch 161.472) train_loss=193.01416016 time/batch=0.44s
19635/10943 (epoch 161.480) train_loss=668.79620361 time/batch=1.37s
19636/10943 (epoch 161.489) train_loss=272.64599609 time/batch=0.64s
19637/10943 (epoch 161.497) train_loss=565.54022217 time/batch=1.19s
19638/10943 (epoch 161.505) train_loss=292.25851440 time/batch=0.66s
19639/10943 (epoch 161.513) train_loss=329.77899170 time/batch=0.66s
19640/10943 (epoch 161.521) train_loss=160.84729004 time/batch=0.38s
19641/10943 (epoch 161.530) train_loss=258.25311279 time/batch=0.54s
19642/10943 (epoch 161.538) train_loss=295.02151489 time/batch=0.63s
19643/10943 (epoch 161.546) train_loss=188.76193237 time/batch=0.42s
19644/10943 (epoch 161.554) train_loss=226.86444092 time/batch=0.47s
19645/10943 (epoch 161.563) train_loss=347.05718994 time/batch=0.72s
19646/10943 (epoch 161.571) train_loss=343.95379639 time/batch=0.69s
19647/10943 (epoch 161.579) train_loss=289.10357666 time/batch=0.60s
19648/10943 (epoch 161.587) train_loss=262.91076660 time/batch=0.56s
19649/10943 (epoch 161.595) train_loss=351.05511475 time/batch=0.69s
19650/10943 (epoch 161.604) train_loss=447.82318115 time/batch=0.85s
19651/10943 (epoch 161.612) train_loss=257.02035522 time/batch=0.57s
19652/10943 (epoch 161.620) train_loss=346.08306885 time/batch=0.69s
19653/10943 (epoch 161.628) train_loss=245.03096008 time/batch=0.54s
19654/10943 (epoch 161.637) train_loss=231.14607239 time/batch=0.51s
19655/10943 (epoch 161.645) train_loss=342.78274536 time/batch=0.72s
19656/10943 (epoch 161.653) train_loss=289.81408691 time/batch=0.61s
19657/10943 (epoch 161.661) train_loss=467.10934448 time/batch=0.91s
19658/10943 (epoch 161.669) train_loss=231.41467285 time/batch=0.51s
19659/10943 (epoch 161.678) train_loss=285.82598877 time/batch=0.59s
19660/10943 (epoch 161.686) train_loss=303.11367798 time/batch=0.63s
19661/10943 (epoch 161.694) train_loss=236.54028320 time/batch=0.49s
19662/10943 (epoch 161.702) train_loss=485.30572510 time/batch=0.95s
19663/10943 (epoch 161.711) train_loss=400.98638916 time/batch=0.82s
19664/10943 (epoch 161.719) train_loss=395.05926514 time/batch=0.80s
19665/10943 (epoch 161.727) train_loss=206.08331299 time/batch=0.48s
19666/10943 (epoch 161.735) train_loss=306.45574951 time/batch=0.62s
19667/10943 (epoch 161.744) train_loss=221.59158325 time/batch=0.49s
19668/10943 (epoch 161.752) train_loss=163.36276245 time/batch=0.37s
19669/10943 (epoch 161.760) train_loss=323.19635010 time/batch=0.64s
19670/10943 (epoch 161.768) train_loss=286.92266846 time/batch=0.63s
19671/10943 (epoch 161.776) train_loss=473.44079590 time/batch=0.97s
19672/10943 (epoch 161.785) train_loss=190.88183594 time/batch=0.44s
19673/10943 (epoch 161.793) train_loss=273.88772583 time/batch=0.56s
19674/10943 (epoch 161.801) train_loss=257.93090820 time/batch=0.54s
19675/10943 (epoch 161.809) train_loss=214.24325562 time/batch=0.53s
19676/10943 (epoch 161.818) train_loss=315.59744263 time/batch=0.67s
19677/10943 (epoch 161.826) train_loss=235.57513428 time/batch=0.55s
19678/10943 (epoch 161.834) train_loss=323.14929199 time/batch=0.64s
19679/10943 (epoch 161.842) train_loss=329.13421631 time/batch=0.66s
19680/10943 (epoch 161.850) train_loss=369.48626709 time/batch=0.73s
19681/10943 (epoch 161.859) train_loss=246.96826172 time/batch=0.61s
19682/10943 (epoch 161.867) train_loss=286.59030151 time/batch=0.63s
19683/10943 (epoch 161.875) train_loss=471.15557861 time/batch=0.92s
19684/10943 (epoch 161.883) train_loss=405.89691162 time/batch=0.83s
19685/10943 (epoch 161.892) train_loss=406.02923584 time/batch=0.77s
19686/10943 (epoch 161.900) train_loss=424.77310181 time/batch=0.83s
19687/10943 (epoch 161.908) train_loss=330.69268799 time/batch=0.75s
19688/10943 (epoch 161.916) train_loss=395.70202637 time/batch=0.82s
19689/10943 (epoch 161.924) train_loss=264.50845337 time/batch=0.62s
19690/10943 (epoch 161.933) train_loss=431.66946411 time/batch=0.91s
19691/10943 (epoch 161.941) train_loss=394.11334229 time/batch=0.83s
19692/10943 (epoch 161.949) train_loss=348.30691528 time/batch=0.82s
setting learning rate to 0.0011669
19693/10943 (epoch 161.957) train_loss=360.60034180 time/batch=0.80s
19694/10943 (epoch 161.966) train_loss=360.73516846 time/batch=0.80s
19695/10943 (epoch 161.974) train_loss=877.92584229 time/batch=1.74s
19696/10943 (epoch 161.982) train_loss=231.51119995 time/batch=0.59s
19697/10943 (epoch 161.990) train_loss=242.17843628 time/batch=0.51s
19698/10943 (epoch 161.998) train_loss=259.96279907 time/batch=0.55s
19699/10943 (epoch 162.007) train_loss=508.87896729 time/batch=0.96s
19700/10943 (epoch 162.015) train_loss=282.01467896 time/batch=0.63s
19701/10943 (epoch 162.023) train_loss=562.79589844 time/batch=1.12s
19702/10943 (epoch 162.031) train_loss=248.55474854 time/batch=0.56s
19703/10943 (epoch 162.040) train_loss=1093.69860840 time/batch=3.00s
19704/10943 (epoch 162.048) train_loss=581.64294434 time/batch=1.27s
19705/10943 (epoch 162.056) train_loss=545.07305908 time/batch=1.04s
19706/10943 (epoch 162.064) train_loss=315.24508667 time/batch=0.67s
19707/10943 (epoch 162.072) train_loss=691.70227051 time/batch=1.34s
19708/10943 (epoch 162.081) train_loss=538.82751465 time/batch=1.14s
19709/10943 (epoch 162.089) train_loss=721.44738770 time/batch=1.50s
19710/10943 (epoch 162.097) train_loss=244.43244934 time/batch=0.60s
19711/10943 (epoch 162.105) train_loss=193.39727783 time/batch=0.39s
19712/10943 (epoch 162.114) train_loss=671.17059326 time/batch=1.22s
19713/10943 (epoch 162.122) train_loss=386.93688965 time/batch=0.82s
19714/10943 (epoch 162.130) train_loss=605.95666504 time/batch=1.27s
19715/10943 (epoch 162.138) train_loss=421.53381348 time/batch=0.91s
19716/10943 (epoch 162.146) train_loss=208.82131958 time/batch=0.47s
19717/10943 (epoch 162.155) train_loss=440.47729492 time/batch=0.89s
19718/10943 (epoch 162.163) train_loss=280.44165039 time/batch=0.66s
19719/10943 (epoch 162.171) train_loss=366.53222656 time/batch=0.78s
19720/10943 (epoch 162.179) train_loss=180.49548340 time/batch=0.44s
19721/10943 (epoch 162.188) train_loss=727.64483643 time/batch=1.50s
19722/10943 (epoch 162.196) train_loss=282.14672852 time/batch=0.68s
19723/10943 (epoch 162.204) train_loss=372.85610962 time/batch=0.78s
19724/10943 (epoch 162.212) train_loss=562.41735840 time/batch=1.17s
19725/10943 (epoch 162.221) train_loss=539.53009033 time/batch=1.14s
19726/10943 (epoch 162.229) train_loss=498.62728882 time/batch=1.01s
19727/10943 (epoch 162.237) train_loss=480.00793457 time/batch=0.97s
19728/10943 (epoch 162.245) train_loss=307.04394531 time/batch=0.68s
19729/10943 (epoch 162.253) train_loss=342.08581543 time/batch=0.73s
19730/10943 (epoch 162.262) train_loss=171.57083130 time/batch=0.41s
19731/10943 (epoch 162.270) train_loss=164.20692444 time/batch=0.36s
19732/10943 (epoch 162.278) train_loss=603.84313965 time/batch=1.15s
19733/10943 (epoch 162.286) train_loss=267.99609375 time/batch=0.66s
19734/10943 (epoch 162.295) train_loss=167.04672241 time/batch=0.38s
19735/10943 (epoch 162.303) train_loss=312.15338135 time/batch=0.64s
19736/10943 (epoch 162.311) train_loss=139.59686279 time/batch=0.33s
19737/10943 (epoch 162.319) train_loss=127.88407898 time/batch=0.29s
19738/10943 (epoch 162.327) train_loss=263.97561646 time/batch=0.57s
19739/10943 (epoch 162.336) train_loss=336.71682739 time/batch=0.71s
19740/10943 (epoch 162.344) train_loss=326.41601562 time/batch=0.67s
19741/10943 (epoch 162.352) train_loss=361.30328369 time/batch=0.75s
19742/10943 (epoch 162.360) train_loss=154.55038452 time/batch=0.37s
19743/10943 (epoch 162.369) train_loss=113.66534424 time/batch=0.27s
19744/10943 (epoch 162.377) train_loss=243.09542847 time/batch=0.50s
19745/10943 (epoch 162.385) train_loss=525.61651611 time/batch=1.04s
19746/10943 (epoch 162.393) train_loss=139.53308105 time/batch=0.36s
19747/10943 (epoch 162.401) train_loss=324.68881226 time/batch=0.62s
19748/10943 (epoch 162.410) train_loss=532.52905273 time/batch=1.08s
19749/10943 (epoch 162.418) train_loss=368.13751221 time/batch=0.74s
19750/10943 (epoch 162.426) train_loss=364.93417358 time/batch=0.75s
19751/10943 (epoch 162.434) train_loss=231.77104187 time/batch=0.52s
19752/10943 (epoch 162.443) train_loss=478.20693970 time/batch=0.96s
19753/10943 (epoch 162.451) train_loss=362.80484009 time/batch=0.79s
19754/10943 (epoch 162.459) train_loss=248.65919495 time/batch=0.54s
19755/10943 (epoch 162.467) train_loss=155.77532959 time/batch=0.34s
19756/10943 (epoch 162.475) train_loss=285.31707764 time/batch=0.59s
19757/10943 (epoch 162.484) train_loss=315.00317383 time/batch=0.68s
19758/10943 (epoch 162.492) train_loss=406.28082275 time/batch=0.83s
19759/10943 (epoch 162.500) train_loss=268.82293701 time/batch=0.58s
19760/10943 (epoch 162.508) train_loss=194.10639954 time/batch=0.42s
19761/10943 (epoch 162.517) train_loss=239.74598694 time/batch=0.49s
19762/10943 (epoch 162.525) train_loss=362.79809570 time/batch=0.75s
19763/10943 (epoch 162.533) train_loss=460.27679443 time/batch=0.91s
19764/10943 (epoch 162.541) train_loss=194.39041138 time/batch=0.46s
19765/10943 (epoch 162.549) train_loss=140.22634888 time/batch=0.32s
19766/10943 (epoch 162.558) train_loss=269.80078125 time/batch=0.55s
19767/10943 (epoch 162.566) train_loss=425.24063110 time/batch=0.87s
19768/10943 (epoch 162.574) train_loss=184.59001160 time/batch=0.47s
19769/10943 (epoch 162.582) train_loss=461.77639771 time/batch=0.92s
19770/10943 (epoch 162.591) train_loss=230.34207153 time/batch=0.55s
19771/10943 (epoch 162.599) train_loss=324.92944336 time/batch=0.67s
19772/10943 (epoch 162.607) train_loss=225.04193115 time/batch=0.48s
19773/10943 (epoch 162.615) train_loss=255.28507996 time/batch=0.55s
19774/10943 (epoch 162.623) train_loss=387.48413086 time/batch=0.80s
19775/10943 (epoch 162.632) train_loss=279.65249634 time/batch=0.63s
19776/10943 (epoch 162.640) train_loss=210.41905212 time/batch=0.46s
19777/10943 (epoch 162.648) train_loss=227.22235107 time/batch=0.50s
19778/10943 (epoch 162.656) train_loss=368.11932373 time/batch=0.79s
19779/10943 (epoch 162.665) train_loss=394.19085693 time/batch=0.86s
19780/10943 (epoch 162.673) train_loss=515.77575684 time/batch=1.11s
19781/10943 (epoch 162.681) train_loss=405.35299683 time/batch=0.82s
19782/10943 (epoch 162.689) train_loss=167.89227295 time/batch=0.38s
19783/10943 (epoch 162.698) train_loss=351.96392822 time/batch=0.70s
19784/10943 (epoch 162.706) train_loss=209.14434814 time/batch=0.48s
19785/10943 (epoch 162.714) train_loss=244.62791443 time/batch=0.52s
19786/10943 (epoch 162.722) train_loss=367.83996582 time/batch=0.79s
19787/10943 (epoch 162.730) train_loss=214.94927979 time/batch=0.51s
19788/10943 (epoch 162.739) train_loss=184.99729919 time/batch=0.55s
19789/10943 (epoch 162.747) train_loss=326.32806396 time/batch=0.69s
19790/10943 (epoch 162.755) train_loss=305.01028442 time/batch=0.66s
19791/10943 (epoch 162.763) train_loss=279.51489258 time/batch=0.58s
19792/10943 (epoch 162.772) train_loss=410.61315918 time/batch=0.84s
19793/10943 (epoch 162.780) train_loss=323.56640625 time/batch=0.68s
19794/10943 (epoch 162.788) train_loss=437.43481445 time/batch=0.93s
19795/10943 (epoch 162.796) train_loss=289.89724731 time/batch=0.65s
19796/10943 (epoch 162.804) train_loss=343.53057861 time/batch=0.69s
19797/10943 (epoch 162.813) train_loss=435.15359497 time/batch=0.88s
19798/10943 (epoch 162.821) train_loss=415.97131348 time/batch=0.86s
19799/10943 (epoch 162.829) train_loss=297.72308350 time/batch=0.62s
19800/10943 (epoch 162.837) train_loss=249.85246277 time/batch=0.59s
19801/10943 (epoch 162.846) train_loss=375.25399780 time/batch=0.80s
19802/10943 (epoch 162.854) train_loss=294.34985352 time/batch=0.64s
19803/10943 (epoch 162.862) train_loss=278.07983398 time/batch=0.63s
19804/10943 (epoch 162.870) train_loss=294.97924805 time/batch=0.64s
19805/10943 (epoch 162.878) train_loss=395.89602661 time/batch=0.84s
19806/10943 (epoch 162.887) train_loss=423.49783325 time/batch=0.87s
19807/10943 (epoch 162.895) train_loss=321.59616089 time/batch=0.72s
19808/10943 (epoch 162.903) train_loss=275.75488281 time/batch=0.67s
19809/10943 (epoch 162.911) train_loss=414.30294800 time/batch=0.88s
19810/10943 (epoch 162.920) train_loss=348.77603149 time/batch=0.79s
19811/10943 (epoch 162.928) train_loss=322.56787109 time/batch=0.70s
19812/10943 (epoch 162.936) train_loss=358.49081421 time/batch=0.77s
19813/10943 (epoch 162.944) train_loss=316.06814575 time/batch=0.72s
setting learning rate to 0.0011319
19814/10943 (epoch 162.952) train_loss=468.09124756 time/batch=0.95s
19815/10943 (epoch 162.961) train_loss=873.39007568 time/batch=1.62s
19816/10943 (epoch 162.969) train_loss=304.64056396 time/batch=0.66s
19817/10943 (epoch 162.977) train_loss=463.48425293 time/batch=0.89s
19818/10943 (epoch 162.985) train_loss=709.90954590 time/batch=1.36s
19819/10943 (epoch 162.994) train_loss=414.25134277 time/batch=0.87s
19820/10943 (epoch 163.002) train_loss=471.50610352 time/batch=0.98s
19821/10943 (epoch 163.010) train_loss=545.46337891 time/batch=1.13s
19822/10943 (epoch 163.018) train_loss=689.65283203 time/batch=1.45s
19823/10943 (epoch 163.026) train_loss=629.31036377 time/batch=1.25s
19824/10943 (epoch 163.035) train_loss=821.25988770 time/batch=1.69s
19825/10943 (epoch 163.043) train_loss=590.14953613 time/batch=1.18s
19826/10943 (epoch 163.051) train_loss=496.90899658 time/batch=0.99s
19827/10943 (epoch 163.059) train_loss=1120.61547852 time/batch=3.06s
19828/10943 (epoch 163.068) train_loss=752.29907227 time/batch=1.92s
19829/10943 (epoch 163.076) train_loss=250.15899658 time/batch=0.64s
19830/10943 (epoch 163.084) train_loss=417.39916992 time/batch=0.81s
19831/10943 (epoch 163.092) train_loss=512.25939941 time/batch=1.04s
19832/10943 (epoch 163.100) train_loss=158.77810669 time/batch=0.39s
19833/10943 (epoch 163.109) train_loss=243.23968506 time/batch=0.49s
19834/10943 (epoch 163.117) train_loss=182.38516235 time/batch=0.38s
19835/10943 (epoch 163.125) train_loss=518.88342285 time/batch=0.92s
19836/10943 (epoch 163.133) train_loss=358.17663574 time/batch=0.78s
19837/10943 (epoch 163.142) train_loss=347.10769653 time/batch=0.75s
19838/10943 (epoch 163.150) train_loss=248.10821533 time/batch=0.54s
19839/10943 (epoch 163.158) train_loss=608.91766357 time/batch=1.16s
19840/10943 (epoch 163.166) train_loss=343.60952759 time/batch=0.72s
19841/10943 (epoch 163.175) train_loss=190.84962463 time/batch=0.42s
19842/10943 (epoch 163.183) train_loss=368.45867920 time/batch=0.76s
19843/10943 (epoch 163.191) train_loss=134.76716614 time/batch=0.34s
19844/10943 (epoch 163.199) train_loss=236.38192749 time/batch=0.49s
19845/10943 (epoch 163.207) train_loss=172.91778564 time/batch=0.38s
19846/10943 (epoch 163.216) train_loss=593.30090332 time/batch=1.17s
19847/10943 (epoch 163.224) train_loss=539.66430664 time/batch=1.13s
19848/10943 (epoch 163.232) train_loss=118.72540283 time/batch=0.38s
19849/10943 (epoch 163.240) train_loss=547.54370117 time/batch=1.04s
19850/10943 (epoch 163.249) train_loss=455.90206909 time/batch=0.93s
19851/10943 (epoch 163.257) train_loss=453.20922852 time/batch=0.96s
19852/10943 (epoch 163.265) train_loss=575.56585693 time/batch=1.17s
19853/10943 (epoch 163.273) train_loss=210.68904114 time/batch=0.49s
19854/10943 (epoch 163.281) train_loss=263.36798096 time/batch=0.54s
19855/10943 (epoch 163.290) train_loss=166.26969910 time/batch=0.37s
19856/10943 (epoch 163.298) train_loss=217.24520874 time/batch=0.46s
19857/10943 (epoch 163.306) train_loss=266.62695312 time/batch=0.56s
19858/10943 (epoch 163.314) train_loss=262.90054321 time/batch=0.58s
19859/10943 (epoch 163.323) train_loss=206.53649902 time/batch=0.44s
19860/10943 (epoch 163.331) train_loss=544.36779785 time/batch=1.08s
19861/10943 (epoch 163.339) train_loss=449.97216797 time/batch=0.90s
19862/10943 (epoch 163.347) train_loss=384.41235352 time/batch=0.79s
19863/10943 (epoch 163.355) train_loss=330.32287598 time/batch=0.72s
19864/10943 (epoch 163.364) train_loss=173.47473145 time/batch=0.41s
19865/10943 (epoch 163.372) train_loss=265.87997437 time/batch=0.57s
19866/10943 (epoch 163.380) train_loss=471.54870605 time/batch=0.99s
19867/10943 (epoch 163.388) train_loss=205.04975891 time/batch=0.52s
19868/10943 (epoch 163.397) train_loss=363.80566406 time/batch=0.76s
19869/10943 (epoch 163.405) train_loss=266.77746582 time/batch=0.62s
19870/10943 (epoch 163.413) train_loss=157.39254761 time/batch=0.36s
19871/10943 (epoch 163.421) train_loss=490.07989502 time/batch=0.97s
19872/10943 (epoch 163.429) train_loss=253.43405151 time/batch=0.61s
19873/10943 (epoch 163.438) train_loss=431.90109253 time/batch=0.89s
19874/10943 (epoch 163.446) train_loss=424.57687378 time/batch=0.90s
19875/10943 (epoch 163.454) train_loss=148.08143616 time/batch=0.36s
19876/10943 (epoch 163.462) train_loss=238.04884338 time/batch=0.54s
19877/10943 (epoch 163.471) train_loss=333.35809326 time/batch=0.70s
19878/10943 (epoch 163.479) train_loss=385.19757080 time/batch=0.82s
19879/10943 (epoch 163.487) train_loss=176.10267639 time/batch=0.39s
19880/10943 (epoch 163.495) train_loss=336.49267578 time/batch=0.69s
19881/10943 (epoch 163.503) train_loss=141.77273560 time/batch=0.37s
19882/10943 (epoch 163.512) train_loss=396.80728149 time/batch=0.80s
19883/10943 (epoch 163.520) train_loss=326.44952393 time/batch=0.70s
19884/10943 (epoch 163.528) train_loss=399.83267212 time/batch=0.85s
19885/10943 (epoch 163.536) train_loss=243.09829712 time/batch=0.52s
19886/10943 (epoch 163.545) train_loss=315.15133667 time/batch=0.66s
19887/10943 (epoch 163.553) train_loss=313.22134399 time/batch=0.69s
19888/10943 (epoch 163.561) train_loss=364.48358154 time/batch=0.78s
19889/10943 (epoch 163.569) train_loss=388.12866211 time/batch=0.82s
19890/10943 (epoch 163.577) train_loss=414.66467285 time/batch=0.87s
19891/10943 (epoch 163.586) train_loss=446.97259521 time/batch=0.96s
19892/10943 (epoch 163.594) train_loss=432.43035889 time/batch=0.94s
19893/10943 (epoch 163.602) train_loss=320.51916504 time/batch=0.71s
19894/10943 (epoch 163.610) train_loss=314.87966919 time/batch=0.68s
19895/10943 (epoch 163.619) train_loss=383.10418701 time/batch=0.82s
19896/10943 (epoch 163.627) train_loss=377.28497314 time/batch=0.81s
19897/10943 (epoch 163.635) train_loss=424.64932251 time/batch=0.88s
19898/10943 (epoch 163.643) train_loss=364.58001709 time/batch=0.78s
19899/10943 (epoch 163.652) train_loss=276.15078735 time/batch=0.61s
19900/10943 (epoch 163.660) train_loss=276.54150391 time/batch=0.58s
19901/10943 (epoch 163.668) train_loss=233.47933960 time/batch=0.49s
19902/10943 (epoch 163.676) train_loss=136.21662903 time/batch=0.32s
19903/10943 (epoch 163.684) train_loss=341.58544922 time/batch=0.68s
19904/10943 (epoch 163.693) train_loss=263.27822876 time/batch=0.59s
19905/10943 (epoch 163.701) train_loss=337.81512451 time/batch=0.70s
19906/10943 (epoch 163.709) train_loss=377.01730347 time/batch=0.80s
19907/10943 (epoch 163.717) train_loss=288.18899536 time/batch=0.62s
19908/10943 (epoch 163.726) train_loss=278.49078369 time/batch=0.60s
19909/10943 (epoch 163.734) train_loss=288.17687988 time/batch=0.62s
19910/10943 (epoch 163.742) train_loss=352.81060791 time/batch=0.72s
19911/10943 (epoch 163.750) train_loss=400.03002930 time/batch=0.85s
19912/10943 (epoch 163.758) train_loss=239.04455566 time/batch=0.54s
19913/10943 (epoch 163.767) train_loss=239.66806030 time/batch=0.59s
19914/10943 (epoch 163.775) train_loss=298.29986572 time/batch=0.64s
19915/10943 (epoch 163.783) train_loss=193.59388733 time/batch=0.45s
19916/10943 (epoch 163.791) train_loss=342.56347656 time/batch=0.71s
19917/10943 (epoch 163.800) train_loss=371.08758545 time/batch=0.85s
19918/10943 (epoch 163.808) train_loss=321.58380127 time/batch=0.69s
19919/10943 (epoch 163.816) train_loss=209.17990112 time/batch=0.48s
19920/10943 (epoch 163.824) train_loss=204.70492554 time/batch=0.46s
19921/10943 (epoch 163.832) train_loss=280.72869873 time/batch=0.60s
19922/10943 (epoch 163.841) train_loss=153.50929260 time/batch=0.40s
19923/10943 (epoch 163.849) train_loss=183.69143677 time/batch=0.45s
19924/10943 (epoch 163.857) train_loss=382.84829712 time/batch=0.82s
19925/10943 (epoch 163.865) train_loss=367.28381348 time/batch=0.79s
19926/10943 (epoch 163.874) train_loss=310.26629639 time/batch=0.66s
19927/10943 (epoch 163.882) train_loss=286.05828857 time/batch=0.63s
19928/10943 (epoch 163.890) train_loss=288.72650146 time/batch=0.63s
19929/10943 (epoch 163.898) train_loss=309.70471191 time/batch=0.68s
19930/10943 (epoch 163.906) train_loss=282.82754517 time/batch=0.62s
19931/10943 (epoch 163.915) train_loss=222.79788208 time/batch=0.60s
19932/10943 (epoch 163.923) train_loss=273.42715454 time/batch=0.64s
19933/10943 (epoch 163.931) train_loss=325.69216919 time/batch=0.73s
19934/10943 (epoch 163.939) train_loss=298.32418823 time/batch=0.66s
setting learning rate to 0.0010980
19935/10943 (epoch 163.948) train_loss=496.04367065 time/batch=1.01s
19936/10943 (epoch 163.956) train_loss=714.14715576 time/batch=1.33s
19937/10943 (epoch 163.964) train_loss=283.87359619 time/batch=0.64s
19938/10943 (epoch 163.972) train_loss=120.88934326 time/batch=0.30s
19939/10943 (epoch 163.980) train_loss=932.20526123 time/batch=1.84s
19940/10943 (epoch 163.989) train_loss=405.21374512 time/batch=0.93s
19941/10943 (epoch 163.997) train_loss=314.35937500 time/batch=0.67s
19942/10943 (epoch 164.005) train_loss=286.84213257 time/batch=0.61s
19943/10943 (epoch 164.013) train_loss=367.90643311 time/batch=0.82s
19944/10943 (epoch 164.022) train_loss=667.26062012 time/batch=1.31s
19945/10943 (epoch 164.030) train_loss=527.93920898 time/batch=1.09s
19946/10943 (epoch 164.038) train_loss=197.36720276 time/batch=0.47s
19947/10943 (epoch 164.046) train_loss=260.59759521 time/batch=0.54s
19948/10943 (epoch 164.054) train_loss=254.01779175 time/batch=0.54s
19949/10943 (epoch 164.063) train_loss=1055.76538086 time/batch=3.07s
19950/10943 (epoch 164.071) train_loss=662.39001465 time/batch=1.50s
19951/10943 (epoch 164.079) train_loss=608.82055664 time/batch=1.25s
19952/10943 (epoch 164.087) train_loss=811.45263672 time/batch=1.59s
19953/10943 (epoch 164.096) train_loss=606.98754883 time/batch=1.19s
19954/10943 (epoch 164.104) train_loss=282.18298340 time/batch=0.65s
19955/10943 (epoch 164.112) train_loss=162.89788818 time/batch=0.36s
19956/10943 (epoch 164.120) train_loss=613.24072266 time/batch=1.30s
19957/10943 (epoch 164.129) train_loss=462.61047363 time/batch=1.01s
19958/10943 (epoch 164.137) train_loss=478.07208252 time/batch=0.98s
19959/10943 (epoch 164.145) train_loss=328.52584839 time/batch=0.69s
19960/10943 (epoch 164.153) train_loss=145.76234436 time/batch=0.33s
19961/10943 (epoch 164.161) train_loss=369.87036133 time/batch=0.74s
19962/10943 (epoch 164.170) train_loss=515.63891602 time/batch=1.04s
19963/10943 (epoch 164.178) train_loss=472.53338623 time/batch=1.02s
19964/10943 (epoch 164.186) train_loss=577.31311035 time/batch=1.37s
19965/10943 (epoch 164.194) train_loss=549.62066650 time/batch=1.10s
19966/10943 (epoch 164.203) train_loss=438.48986816 time/batch=0.89s
19967/10943 (epoch 164.211) train_loss=150.56762695 time/batch=0.37s
19968/10943 (epoch 164.219) train_loss=368.99340820 time/batch=0.73s
19969/10943 (epoch 164.227) train_loss=363.10510254 time/batch=0.76s
19970/10943 (epoch 164.235) train_loss=542.77282715 time/batch=1.08s
19971/10943 (epoch 164.244) train_loss=449.79284668 time/batch=0.92s
19972/10943 (epoch 164.252) train_loss=287.99145508 time/batch=0.61s
19973/10943 (epoch 164.260) train_loss=195.50454712 time/batch=0.42s
19974/10943 (epoch 164.268) train_loss=536.07897949 time/batch=1.07s
19975/10943 (epoch 164.277) train_loss=143.84466553 time/batch=0.40s
19976/10943 (epoch 164.285) train_loss=478.78497314 time/batch=0.93s
19977/10943 (epoch 164.293) train_loss=262.21939087 time/batch=0.59s
19978/10943 (epoch 164.301) train_loss=399.45306396 time/batch=0.81s
19979/10943 (epoch 164.309) train_loss=179.01034546 time/batch=0.41s
19980/10943 (epoch 164.318) train_loss=444.41021729 time/batch=0.90s
19981/10943 (epoch 164.326) train_loss=187.35858154 time/batch=0.43s
19982/10943 (epoch 164.334) train_loss=238.13043213 time/batch=0.49s
19983/10943 (epoch 164.342) train_loss=116.05177307 time/batch=0.30s
19984/10943 (epoch 164.351) train_loss=217.29078674 time/batch=0.45s
19985/10943 (epoch 164.359) train_loss=322.94238281 time/batch=0.67s
19986/10943 (epoch 164.367) train_loss=656.00805664 time/batch=1.39s
19987/10943 (epoch 164.375) train_loss=588.49273682 time/batch=1.20s
19988/10943 (epoch 164.383) train_loss=368.00415039 time/batch=0.74s
19989/10943 (epoch 164.392) train_loss=409.70916748 time/batch=0.86s
19990/10943 (epoch 164.400) train_loss=152.61477661 time/batch=0.37s
19991/10943 (epoch 164.408) train_loss=366.17449951 time/batch=0.76s
19992/10943 (epoch 164.416) train_loss=204.29870605 time/batch=0.48s
19993/10943 (epoch 164.425) train_loss=335.09509277 time/batch=0.67s
19994/10943 (epoch 164.433) train_loss=349.76324463 time/batch=0.74s
19995/10943 (epoch 164.441) train_loss=425.37402344 time/batch=0.90s
19996/10943 (epoch 164.449) train_loss=373.87237549 time/batch=0.83s
19997/10943 (epoch 164.457) train_loss=434.90527344 time/batch=0.93s
19998/10943 (epoch 164.466) train_loss=342.28924561 time/batch=0.74s
19999/10943 (epoch 164.474) train_loss=373.21371460 time/batch=0.81s
Validating
    loss:	357.429977

20000/10943 (epoch 164.482) train_loss=336.15692139 time/batch=2.60s
20001/10943 (epoch 164.490) train_loss=218.15417480 time/batch=0.52s
20002/10943 (epoch 164.499) train_loss=175.65977478 time/batch=0.39s
20003/10943 (epoch 164.507) train_loss=231.18307495 time/batch=0.52s
20004/10943 (epoch 164.515) train_loss=200.67422485 time/batch=0.46s
20005/10943 (epoch 164.523) train_loss=473.50323486 time/batch=1.37s
20006/10943 (epoch 164.531) train_loss=400.82604980 time/batch=0.91s
20007/10943 (epoch 164.540) train_loss=455.28625488 time/batch=0.91s
20008/10943 (epoch 164.548) train_loss=346.56311035 time/batch=0.69s
20009/10943 (epoch 164.556) train_loss=369.13644409 time/batch=0.78s
20010/10943 (epoch 164.564) train_loss=316.68621826 time/batch=0.69s
20011/10943 (epoch 164.573) train_loss=202.98295593 time/batch=0.46s
20012/10943 (epoch 164.581) train_loss=168.70379639 time/batch=0.39s
20013/10943 (epoch 164.589) train_loss=150.62409973 time/batch=0.34s
20014/10943 (epoch 164.597) train_loss=272.00503540 time/batch=0.55s
20015/10943 (epoch 164.605) train_loss=343.05081177 time/batch=0.70s
20016/10943 (epoch 164.614) train_loss=406.08666992 time/batch=0.86s
20017/10943 (epoch 164.622) train_loss=347.36688232 time/batch=0.75s
20018/10943 (epoch 164.630) train_loss=224.63426208 time/batch=0.50s
20019/10943 (epoch 164.638) train_loss=158.91738892 time/batch=0.38s
20020/10943 (epoch 164.647) train_loss=195.24612427 time/batch=0.43s
20021/10943 (epoch 164.655) train_loss=299.22210693 time/batch=0.68s
20022/10943 (epoch 164.663) train_loss=231.83010864 time/batch=0.54s
20023/10943 (epoch 164.671) train_loss=186.25991821 time/batch=0.46s
20024/10943 (epoch 164.680) train_loss=374.23916626 time/batch=0.79s
20025/10943 (epoch 164.688) train_loss=299.75375366 time/batch=0.67s
20026/10943 (epoch 164.696) train_loss=449.20336914 time/batch=0.89s
20027/10943 (epoch 164.704) train_loss=408.33227539 time/batch=0.82s
20028/10943 (epoch 164.712) train_loss=293.66970825 time/batch=0.62s
20029/10943 (epoch 164.721) train_loss=283.81951904 time/batch=0.61s
20030/10943 (epoch 164.729) train_loss=272.76721191 time/batch=0.60s
20031/10943 (epoch 164.737) train_loss=198.96128845 time/batch=0.48s
20032/10943 (epoch 164.745) train_loss=265.01971436 time/batch=0.57s
20033/10943 (epoch 164.754) train_loss=263.33111572 time/batch=0.58s
20034/10943 (epoch 164.762) train_loss=353.70611572 time/batch=0.74s
20035/10943 (epoch 164.770) train_loss=460.87268066 time/batch=1.43s
20036/10943 (epoch 164.778) train_loss=256.24365234 time/batch=0.60s
20037/10943 (epoch 164.786) train_loss=227.43908691 time/batch=0.50s
20038/10943 (epoch 164.795) train_loss=282.95776367 time/batch=0.61s
20039/10943 (epoch 164.803) train_loss=215.81594849 time/batch=0.51s
20040/10943 (epoch 164.811) train_loss=287.45129395 time/batch=0.62s
20041/10943 (epoch 164.819) train_loss=369.67868042 time/batch=0.77s
20042/10943 (epoch 164.828) train_loss=250.26969910 time/batch=0.56s
20043/10943 (epoch 164.836) train_loss=245.82250977 time/batch=0.58s
20044/10943 (epoch 164.844) train_loss=305.21508789 time/batch=0.64s
20045/10943 (epoch 164.852) train_loss=349.33312988 time/batch=0.74s
20046/10943 (epoch 164.860) train_loss=317.74291992 time/batch=0.68s
20047/10943 (epoch 164.869) train_loss=332.66445923 time/batch=0.67s
20048/10943 (epoch 164.877) train_loss=328.97406006 time/batch=0.71s
20049/10943 (epoch 164.885) train_loss=330.93493652 time/batch=0.72s
20050/10943 (epoch 164.893) train_loss=284.06243896 time/batch=0.65s
20051/10943 (epoch 164.902) train_loss=281.49844360 time/batch=0.61s
20052/10943 (epoch 164.910) train_loss=399.90985107 time/batch=0.85s
20053/10943 (epoch 164.918) train_loss=307.18539429 time/batch=0.76s
20054/10943 (epoch 164.926) train_loss=397.00799561 time/batch=0.84s
20055/10943 (epoch 164.934) train_loss=352.75854492 time/batch=0.81s
setting learning rate to 0.0010650
  saved to metadata/gru_no_dropout-9_nov_folkwiki-20181115-214759_epoch54.pkl
20056/10943 (epoch 164.943) train_loss=550.00836182 time/batch=1.17s
20057/10943 (epoch 164.951) train_loss=568.12524414 time/batch=1.13s
20058/10943 (epoch 164.959) train_loss=246.25491333 time/batch=0.57s
20059/10943 (epoch 164.967) train_loss=630.81762695 time/batch=1.24s
20060/10943 (epoch 164.976) train_loss=698.22326660 time/batch=1.55s
20061/10943 (epoch 164.984) train_loss=413.82067871 time/batch=0.96s
20062/10943 (epoch 164.992) train_loss=435.28076172 time/batch=0.90s
20063/10943 (epoch 165.000) train_loss=236.78982544 time/batch=0.57s
20064/10943 (epoch 165.008) train_loss=489.93075562 time/batch=1.00s
20065/10943 (epoch 165.017) train_loss=551.01922607 time/batch=1.20s
20066/10943 (epoch 165.025) train_loss=408.87762451 time/batch=0.91s
20067/10943 (epoch 165.033) train_loss=165.93371582 time/batch=0.41s
20068/10943 (epoch 165.041) train_loss=832.18066406 time/batch=1.63s
20069/10943 (epoch 165.050) train_loss=198.42433167 time/batch=0.56s
20070/10943 (epoch 165.058) train_loss=213.93505859 time/batch=0.45s
20071/10943 (epoch 165.066) train_loss=677.07940674 time/batch=1.30s
20072/10943 (epoch 165.074) train_loss=222.75624084 time/batch=0.56s
20073/10943 (epoch 165.082) train_loss=1042.70507812 time/batch=2.35s
20074/10943 (epoch 165.091) train_loss=336.28463745 time/batch=0.88s
20075/10943 (epoch 165.099) train_loss=392.73602295 time/batch=0.83s
20076/10943 (epoch 165.107) train_loss=485.08944702 time/batch=1.01s
20077/10943 (epoch 165.115) train_loss=326.49346924 time/batch=0.71s
20078/10943 (epoch 165.124) train_loss=109.85562134 time/batch=0.29s
20079/10943 (epoch 165.132) train_loss=278.56723022 time/batch=0.58s
20080/10943 (epoch 165.140) train_loss=165.94274902 time/batch=0.38s
20081/10943 (epoch 165.148) train_loss=430.45111084 time/batch=0.90s
20082/10943 (epoch 165.157) train_loss=489.19088745 time/batch=1.07s
20083/10943 (epoch 165.165) train_loss=157.17555237 time/batch=0.41s
20084/10943 (epoch 165.173) train_loss=266.77844238 time/batch=0.60s
20085/10943 (epoch 165.181) train_loss=408.61837769 time/batch=0.88s
20086/10943 (epoch 165.189) train_loss=365.38189697 time/batch=0.82s
20087/10943 (epoch 165.198) train_loss=657.10168457 time/batch=1.36s
20088/10943 (epoch 165.206) train_loss=358.56542969 time/batch=0.77s
20089/10943 (epoch 165.214) train_loss=343.07348633 time/batch=0.75s
20090/10943 (epoch 165.222) train_loss=428.86407471 time/batch=0.92s
20091/10943 (epoch 165.231) train_loss=219.62326050 time/batch=0.53s
20092/10943 (epoch 165.239) train_loss=638.67761230 time/batch=1.35s
20093/10943 (epoch 165.247) train_loss=173.57128906 time/batch=0.48s
20094/10943 (epoch 165.255) train_loss=614.14514160 time/batch=1.46s
20095/10943 (epoch 165.263) train_loss=524.27929688 time/batch=1.15s
20096/10943 (epoch 165.272) train_loss=525.06024170 time/batch=1.09s
20097/10943 (epoch 165.280) train_loss=474.63830566 time/batch=1.01s
20098/10943 (epoch 165.288) train_loss=241.18005371 time/batch=0.55s
20099/10943 (epoch 165.296) train_loss=411.11724854 time/batch=0.87s
20100/10943 (epoch 165.305) train_loss=454.13171387 time/batch=1.00s
20101/10943 (epoch 165.313) train_loss=360.89297485 time/batch=0.81s
20102/10943 (epoch 165.321) train_loss=422.58340454 time/batch=0.92s
20103/10943 (epoch 165.329) train_loss=299.02258301 time/batch=0.68s
20104/10943 (epoch 165.337) train_loss=557.76794434 time/batch=1.51s
20105/10943 (epoch 165.346) train_loss=157.94335938 time/batch=0.46s
20106/10943 (epoch 165.354) train_loss=472.47668457 time/batch=1.01s
20107/10943 (epoch 165.362) train_loss=169.09072876 time/batch=0.37s
20108/10943 (epoch 165.370) train_loss=190.16886902 time/batch=0.36s
20109/10943 (epoch 165.379) train_loss=291.35241699 time/batch=0.63s
20110/10943 (epoch 165.387) train_loss=611.14355469 time/batch=3.09s
20111/10943 (epoch 165.395) train_loss=290.48910522 time/batch=0.92s
20112/10943 (epoch 165.403) train_loss=331.18780518 time/batch=0.73s
20113/10943 (epoch 165.411) train_loss=383.85305786 time/batch=0.83s
20114/10943 (epoch 165.420) train_loss=373.76123047 time/batch=0.83s
20115/10943 (epoch 165.428) train_loss=220.54046631 time/batch=0.53s
20116/10943 (epoch 165.436) train_loss=208.86230469 time/batch=0.48s
20117/10943 (epoch 165.444) train_loss=262.96282959 time/batch=0.58s
20118/10943 (epoch 165.453) train_loss=132.79492188 time/batch=0.33s
20119/10943 (epoch 165.461) train_loss=242.03045654 time/batch=0.54s
20120/10943 (epoch 165.469) train_loss=303.85150146 time/batch=0.67s
20121/10943 (epoch 165.477) train_loss=239.45056152 time/batch=0.53s
20122/10943 (epoch 165.485) train_loss=177.82221985 time/batch=0.38s
20123/10943 (epoch 165.494) train_loss=251.70050049 time/batch=0.55s
20124/10943 (epoch 165.502) train_loss=244.22705078 time/batch=0.54s
20125/10943 (epoch 165.510) train_loss=136.04217529 time/batch=0.33s
20126/10943 (epoch 165.518) train_loss=262.80749512 time/batch=0.54s
20127/10943 (epoch 165.527) train_loss=204.05760193 time/batch=0.49s
20128/10943 (epoch 165.535) train_loss=389.87139893 time/batch=0.83s
20129/10943 (epoch 165.543) train_loss=194.32064819 time/batch=0.47s
20130/10943 (epoch 165.551) train_loss=354.72808838 time/batch=0.76s
20131/10943 (epoch 165.559) train_loss=210.90983582 time/batch=0.47s
20132/10943 (epoch 165.568) train_loss=117.31471252 time/batch=0.29s
20133/10943 (epoch 165.576) train_loss=357.37820435 time/batch=0.75s
20134/10943 (epoch 165.584) train_loss=187.23226929 time/batch=0.46s
20135/10943 (epoch 165.592) train_loss=352.33172607 time/batch=0.78s
20136/10943 (epoch 165.601) train_loss=332.03027344 time/batch=0.73s
20137/10943 (epoch 165.609) train_loss=277.96664429 time/batch=0.60s
20138/10943 (epoch 165.617) train_loss=470.62747192 time/batch=1.05s
20139/10943 (epoch 165.625) train_loss=350.61166382 time/batch=0.75s
20140/10943 (epoch 165.634) train_loss=440.18899536 time/batch=0.94s
20141/10943 (epoch 165.642) train_loss=222.58668518 time/batch=0.54s
20142/10943 (epoch 165.650) train_loss=161.85136414 time/batch=0.38s
20143/10943 (epoch 165.658) train_loss=370.40826416 time/batch=0.82s
20144/10943 (epoch 165.666) train_loss=302.64276123 time/batch=0.67s
20145/10943 (epoch 165.675) train_loss=147.15258789 time/batch=0.45s
20146/10943 (epoch 165.683) train_loss=249.76383972 time/batch=0.54s
20147/10943 (epoch 165.691) train_loss=346.01364136 time/batch=0.76s
20148/10943 (epoch 165.699) train_loss=311.72436523 time/batch=0.73s
20149/10943 (epoch 165.708) train_loss=382.25640869 time/batch=0.89s
20150/10943 (epoch 165.716) train_loss=337.66986084 time/batch=0.79s
20151/10943 (epoch 165.724) train_loss=265.39721680 time/batch=0.61s
20152/10943 (epoch 165.732) train_loss=252.98416138 time/batch=0.57s
20153/10943 (epoch 165.740) train_loss=227.93510437 time/batch=0.53s
20154/10943 (epoch 165.749) train_loss=167.04827881 time/batch=0.50s
20155/10943 (epoch 165.757) train_loss=226.19567871 time/batch=0.51s
20156/10943 (epoch 165.765) train_loss=274.17086792 time/batch=0.61s
20157/10943 (epoch 165.773) train_loss=372.75976562 time/batch=0.81s
20158/10943 (epoch 165.782) train_loss=278.33761597 time/batch=0.64s
20159/10943 (epoch 165.790) train_loss=369.14093018 time/batch=0.77s
20160/10943 (epoch 165.798) train_loss=397.80181885 time/batch=0.82s
20161/10943 (epoch 165.806) train_loss=298.12042236 time/batch=0.63s
20162/10943 (epoch 165.814) train_loss=317.82794189 time/batch=0.66s
20163/10943 (epoch 165.823) train_loss=328.83621216 time/batch=0.73s
20164/10943 (epoch 165.831) train_loss=301.84857178 time/batch=0.66s
20165/10943 (epoch 165.839) train_loss=273.09548950 time/batch=0.60s
20166/10943 (epoch 165.847) train_loss=317.48461914 time/batch=0.66s
20167/10943 (epoch 165.856) train_loss=352.02377319 time/batch=0.74s
20168/10943 (epoch 165.864) train_loss=261.53210449 time/batch=0.64s
20169/10943 (epoch 165.872) train_loss=278.56198120 time/batch=0.66s
20170/10943 (epoch 165.880) train_loss=306.37387085 time/batch=0.67s
20171/10943 (epoch 165.888) train_loss=365.89318848 time/batch=0.80s
20172/10943 (epoch 165.897) train_loss=315.64538574 time/batch=0.70s
20173/10943 (epoch 165.905) train_loss=348.36486816 time/batch=0.75s
20174/10943 (epoch 165.913) train_loss=350.51049805 time/batch=0.81s
20175/10943 (epoch 165.921) train_loss=340.21783447 time/batch=0.73s
20176/10943 (epoch 165.930) train_loss=348.54003906 time/batch=0.82s
setting learning rate to 0.0010331
20177/10943 (epoch 165.938) train_loss=554.71350098 time/batch=1.16s
20178/10943 (epoch 165.946) train_loss=494.04724121 time/batch=0.98s
20179/10943 (epoch 165.954) train_loss=539.99639893 time/batch=1.13s
20180/10943 (epoch 165.962) train_loss=1047.87268066 time/batch=2.34s
20181/10943 (epoch 165.971) train_loss=845.22161865 time/batch=1.74s
20182/10943 (epoch 165.979) train_loss=943.48046875 time/batch=3.18s
20183/10943 (epoch 165.987) train_loss=325.74978638 time/batch=0.92s
20184/10943 (epoch 165.995) train_loss=189.91438293 time/batch=0.43s
20185/10943 (epoch 166.004) train_loss=283.14208984 time/batch=0.59s
20186/10943 (epoch 166.012) train_loss=653.79760742 time/batch=1.28s
20187/10943 (epoch 166.020) train_loss=301.76409912 time/batch=0.76s
20188/10943 (epoch 166.028) train_loss=653.65307617 time/batch=1.35s
20189/10943 (epoch 166.036) train_loss=212.54200745 time/batch=0.57s
20190/10943 (epoch 166.045) train_loss=244.23870850 time/batch=0.55s
20191/10943 (epoch 166.053) train_loss=216.63035583 time/batch=0.49s
20192/10943 (epoch 166.061) train_loss=121.22975922 time/batch=0.30s
20193/10943 (epoch 166.069) train_loss=101.46038818 time/batch=0.26s
20194/10943 (epoch 166.078) train_loss=485.29498291 time/batch=0.96s
20195/10943 (epoch 166.086) train_loss=538.66625977 time/batch=1.12s
20196/10943 (epoch 166.094) train_loss=144.86203003 time/batch=0.41s
20197/10943 (epoch 166.102) train_loss=329.99835205 time/batch=0.68s
20198/10943 (epoch 166.111) train_loss=413.98492432 time/batch=0.89s
20199/10943 (epoch 166.119) train_loss=349.48406982 time/batch=0.79s
20200/10943 (epoch 166.127) train_loss=231.18736267 time/batch=0.54s
20201/10943 (epoch 166.135) train_loss=198.32772827 time/batch=0.43s
20202/10943 (epoch 166.143) train_loss=185.89569092 time/batch=0.44s
20203/10943 (epoch 166.152) train_loss=223.71939087 time/batch=0.51s
20204/10943 (epoch 166.160) train_loss=305.09118652 time/batch=0.68s
20205/10943 (epoch 166.168) train_loss=219.50198364 time/batch=0.49s
20206/10943 (epoch 166.176) train_loss=162.25390625 time/batch=0.39s
20207/10943 (epoch 166.185) train_loss=417.11312866 time/batch=0.88s
20208/10943 (epoch 166.193) train_loss=259.42962646 time/batch=0.61s
20209/10943 (epoch 166.201) train_loss=356.55810547 time/batch=0.79s
20210/10943 (epoch 166.209) train_loss=682.86010742 time/batch=1.44s
20211/10943 (epoch 166.217) train_loss=570.76733398 time/batch=1.12s
20212/10943 (epoch 166.226) train_loss=647.22595215 time/batch=1.24s
20213/10943 (epoch 166.234) train_loss=155.38790894 time/batch=0.40s
20214/10943 (epoch 166.242) train_loss=541.33203125 time/batch=1.07s
20215/10943 (epoch 166.250) train_loss=351.49057007 time/batch=0.77s
20216/10943 (epoch 166.259) train_loss=179.73461914 time/batch=0.41s
20217/10943 (epoch 166.267) train_loss=250.28024292 time/batch=0.53s
20218/10943 (epoch 166.275) train_loss=176.39987183 time/batch=0.42s
20219/10943 (epoch 166.283) train_loss=333.92379761 time/batch=0.69s
20220/10943 (epoch 166.291) train_loss=545.71423340 time/batch=1.17s
20221/10943 (epoch 166.300) train_loss=334.41125488 time/batch=0.76s
20222/10943 (epoch 166.308) train_loss=142.01504517 time/batch=0.34s
20223/10943 (epoch 166.316) train_loss=481.97479248 time/batch=0.94s
20224/10943 (epoch 166.324) train_loss=390.87805176 time/batch=0.82s
20225/10943 (epoch 166.333) train_loss=321.00747681 time/batch=0.66s
20226/10943 (epoch 166.341) train_loss=192.69961548 time/batch=0.43s
20227/10943 (epoch 166.349) train_loss=331.95330811 time/batch=0.68s
20228/10943 (epoch 166.357) train_loss=438.86419678 time/batch=0.95s
20229/10943 (epoch 166.365) train_loss=445.63433838 time/batch=0.93s
20230/10943 (epoch 166.374) train_loss=359.84512329 time/batch=0.78s
20231/10943 (epoch 166.382) train_loss=225.37426758 time/batch=0.51s
20232/10943 (epoch 166.390) train_loss=554.03906250 time/batch=1.19s
20233/10943 (epoch 166.398) train_loss=442.88708496 time/batch=1.00s
20234/10943 (epoch 166.407) train_loss=258.62707520 time/batch=0.61s
20235/10943 (epoch 166.415) train_loss=349.11190796 time/batch=0.73s
20236/10943 (epoch 166.423) train_loss=393.47381592 time/batch=0.83s
20237/10943 (epoch 166.431) train_loss=341.83428955 time/batch=0.76s
20238/10943 (epoch 166.439) train_loss=536.50769043 time/batch=1.23s
20239/10943 (epoch 166.448) train_loss=207.12365723 time/batch=0.53s
20240/10943 (epoch 166.456) train_loss=341.17211914 time/batch=0.70s
20241/10943 (epoch 166.464) train_loss=333.30749512 time/batch=0.76s
20242/10943 (epoch 166.472) train_loss=272.73782349 time/batch=0.64s
20243/10943 (epoch 166.481) train_loss=204.56475830 time/batch=0.47s
20244/10943 (epoch 166.489) train_loss=138.82611084 time/batch=0.33s
20245/10943 (epoch 166.497) train_loss=263.49621582 time/batch=0.56s
20246/10943 (epoch 166.505) train_loss=277.42742920 time/batch=0.63s
20247/10943 (epoch 166.513) train_loss=222.71618652 time/batch=0.53s
20248/10943 (epoch 166.522) train_loss=368.88482666 time/batch=0.80s
20249/10943 (epoch 166.530) train_loss=327.65289307 time/batch=0.69s
20250/10943 (epoch 166.538) train_loss=521.41400146 time/batch=1.01s
20251/10943 (epoch 166.546) train_loss=207.02752686 time/batch=0.51s
20252/10943 (epoch 166.555) train_loss=387.55661011 time/batch=0.82s
20253/10943 (epoch 166.563) train_loss=431.37133789 time/batch=0.96s
20254/10943 (epoch 166.571) train_loss=375.80850220 time/batch=0.79s
20255/10943 (epoch 166.579) train_loss=238.27972412 time/batch=0.56s
20256/10943 (epoch 166.588) train_loss=434.37088013 time/batch=0.93s
20257/10943 (epoch 166.596) train_loss=141.01730347 time/batch=0.40s
20258/10943 (epoch 166.604) train_loss=313.08740234 time/batch=0.66s
20259/10943 (epoch 166.612) train_loss=250.69744873 time/batch=0.59s
20260/10943 (epoch 166.620) train_loss=433.13720703 time/batch=0.92s
20261/10943 (epoch 166.629) train_loss=216.98171997 time/batch=0.56s
20262/10943 (epoch 166.637) train_loss=440.52404785 time/batch=0.94s
20263/10943 (epoch 166.645) train_loss=422.94985962 time/batch=1.00s
20264/10943 (epoch 166.653) train_loss=236.86660767 time/batch=0.57s
20265/10943 (epoch 166.662) train_loss=494.33563232 time/batch=1.38s
20266/10943 (epoch 166.670) train_loss=282.96679688 time/batch=0.69s
20267/10943 (epoch 166.678) train_loss=402.71224976 time/batch=0.95s
20268/10943 (epoch 166.686) train_loss=285.99655151 time/batch=0.65s
20269/10943 (epoch 166.694) train_loss=351.99237061 time/batch=0.79s
20270/10943 (epoch 166.703) train_loss=312.33868408 time/batch=0.70s
20271/10943 (epoch 166.711) train_loss=305.58499146 time/batch=0.66s
20272/10943 (epoch 166.719) train_loss=349.17565918 time/batch=0.76s
20273/10943 (epoch 166.727) train_loss=360.43157959 time/batch=0.83s
20274/10943 (epoch 166.736) train_loss=279.43911743 time/batch=0.66s
20275/10943 (epoch 166.744) train_loss=255.68228149 time/batch=0.60s
20276/10943 (epoch 166.752) train_loss=165.39215088 time/batch=0.38s
20277/10943 (epoch 166.760) train_loss=256.49850464 time/batch=0.56s
20278/10943 (epoch 166.768) train_loss=373.22344971 time/batch=0.81s
20279/10943 (epoch 166.777) train_loss=163.34388733 time/batch=0.40s
20280/10943 (epoch 166.785) train_loss=381.77783203 time/batch=0.81s
20281/10943 (epoch 166.793) train_loss=365.54168701 time/batch=0.82s
20282/10943 (epoch 166.801) train_loss=323.22906494 time/batch=0.68s
20283/10943 (epoch 166.810) train_loss=305.25375366 time/batch=0.66s
20284/10943 (epoch 166.818) train_loss=361.93353271 time/batch=0.78s
20285/10943 (epoch 166.826) train_loss=368.51202393 time/batch=0.79s
20286/10943 (epoch 166.834) train_loss=416.03396606 time/batch=1.42s
20287/10943 (epoch 166.842) train_loss=249.40536499 time/batch=0.64s
20288/10943 (epoch 166.851) train_loss=154.88580322 time/batch=0.35s
20289/10943 (epoch 166.859) train_loss=301.08255005 time/batch=0.74s
20290/10943 (epoch 166.867) train_loss=271.16604614 time/batch=0.66s
20291/10943 (epoch 166.875) train_loss=270.28131104 time/batch=0.61s
20292/10943 (epoch 166.884) train_loss=166.05441284 time/batch=0.43s
20293/10943 (epoch 166.892) train_loss=258.42178345 time/batch=0.58s
20294/10943 (epoch 166.900) train_loss=273.20788574 time/batch=0.64s
20295/10943 (epoch 166.908) train_loss=262.61459351 time/batch=0.59s
20296/10943 (epoch 166.916) train_loss=378.31289673 time/batch=0.81s
20297/10943 (epoch 166.925) train_loss=363.55505371 time/batch=0.84s
setting learning rate to 0.0010021
20298/10943 (epoch 166.933) train_loss=630.60321045 time/batch=1.27s
20299/10943 (epoch 166.941) train_loss=421.72222900 time/batch=0.89s
20300/10943 (epoch 166.949) train_loss=190.40805054 time/batch=0.41s
20301/10943 (epoch 166.958) train_loss=271.90280151 time/batch=0.61s
20302/10943 (epoch 166.966) train_loss=419.80328369 time/batch=0.88s
20303/10943 (epoch 166.974) train_loss=675.13958740 time/batch=1.47s
20304/10943 (epoch 166.982) train_loss=740.70800781 time/batch=1.40s
20305/10943 (epoch 166.990) train_loss=238.51126099 time/batch=0.58s
20306/10943 (epoch 166.999) train_loss=130.97087097 time/batch=0.32s
20307/10943 (epoch 167.007) train_loss=273.63388062 time/batch=0.60s
20308/10943 (epoch 167.015) train_loss=711.27050781 time/batch=1.53s
20309/10943 (epoch 167.023) train_loss=194.21626282 time/batch=0.55s
20310/10943 (epoch 167.032) train_loss=406.68429565 time/batch=0.86s
20311/10943 (epoch 167.040) train_loss=157.76699829 time/batch=0.40s
20312/10943 (epoch 167.048) train_loss=191.40963745 time/batch=0.42s
20313/10943 (epoch 167.056) train_loss=182.58618164 time/batch=0.43s
20314/10943 (epoch 167.065) train_loss=143.60116577 time/batch=0.33s
20315/10943 (epoch 167.073) train_loss=275.85095215 time/batch=0.61s
20316/10943 (epoch 167.081) train_loss=600.17871094 time/batch=1.34s
20317/10943 (epoch 167.089) train_loss=1096.59204102 time/batch=3.15s
20318/10943 (epoch 167.097) train_loss=433.08123779 time/batch=1.10s
20319/10943 (epoch 167.106) train_loss=563.77893066 time/batch=1.10s
20320/10943 (epoch 167.114) train_loss=517.15881348 time/batch=1.05s
20321/10943 (epoch 167.122) train_loss=168.10009766 time/batch=0.42s
20322/10943 (epoch 167.130) train_loss=219.48834229 time/batch=0.45s
20323/10943 (epoch 167.139) train_loss=410.16662598 time/batch=0.88s
20324/10943 (epoch 167.147) train_loss=198.89282227 time/batch=0.50s
20325/10943 (epoch 167.155) train_loss=102.41049957 time/batch=0.26s
20326/10943 (epoch 167.163) train_loss=256.63482666 time/batch=0.57s
20327/10943 (epoch 167.171) train_loss=347.91961670 time/batch=0.79s
20328/10943 (epoch 167.180) train_loss=312.61227417 time/batch=0.68s
20329/10943 (epoch 167.188) train_loss=157.09146118 time/batch=0.38s
20330/10943 (epoch 167.196) train_loss=342.47888184 time/batch=0.73s
20331/10943 (epoch 167.204) train_loss=793.79852295 time/batch=1.68s
20332/10943 (epoch 167.213) train_loss=301.77224731 time/batch=0.75s
20333/10943 (epoch 167.221) train_loss=323.19015503 time/batch=0.69s
20334/10943 (epoch 167.229) train_loss=528.02429199 time/batch=1.15s
20335/10943 (epoch 167.237) train_loss=359.40469360 time/batch=0.83s
20336/10943 (epoch 167.245) train_loss=349.53952026 time/batch=0.74s
20337/10943 (epoch 167.254) train_loss=220.96594238 time/batch=0.52s
20338/10943 (epoch 167.262) train_loss=490.65255737 time/batch=1.05s
20339/10943 (epoch 167.270) train_loss=336.82748413 time/batch=0.78s
20340/10943 (epoch 167.278) train_loss=279.83789062 time/batch=0.65s
20341/10943 (epoch 167.287) train_loss=235.45669556 time/batch=0.56s
20342/10943 (epoch 167.295) train_loss=488.73870850 time/batch=0.96s
20343/10943 (epoch 167.303) train_loss=305.71414185 time/batch=0.73s
20344/10943 (epoch 167.311) train_loss=299.38574219 time/batch=0.66s
20345/10943 (epoch 167.319) train_loss=218.11627197 time/batch=0.51s
20346/10943 (epoch 167.328) train_loss=397.63836670 time/batch=0.87s
20347/10943 (epoch 167.336) train_loss=316.61224365 time/batch=0.69s
20348/10943 (epoch 167.344) train_loss=445.77813721 time/batch=0.96s
20349/10943 (epoch 167.352) train_loss=290.43716431 time/batch=0.67s
20350/10943 (epoch 167.361) train_loss=333.06951904 time/batch=0.71s
20351/10943 (epoch 167.369) train_loss=336.47384644 time/batch=0.78s
20352/10943 (epoch 167.377) train_loss=466.47155762 time/batch=0.97s
20353/10943 (epoch 167.385) train_loss=252.58471680 time/batch=0.60s
20354/10943 (epoch 167.393) train_loss=327.49734497 time/batch=0.70s
20355/10943 (epoch 167.402) train_loss=299.56518555 time/batch=0.71s
20356/10943 (epoch 167.410) train_loss=478.04016113 time/batch=1.04s
20357/10943 (epoch 167.418) train_loss=374.47247314 time/batch=0.84s
20358/10943 (epoch 167.426) train_loss=327.20764160 time/batch=0.74s
20359/10943 (epoch 167.435) train_loss=214.61729431 time/batch=0.50s
20360/10943 (epoch 167.443) train_loss=227.33990479 time/batch=0.49s
20361/10943 (epoch 167.451) train_loss=258.19766235 time/batch=0.56s
20362/10943 (epoch 167.459) train_loss=491.30957031 time/batch=1.00s
20363/10943 (epoch 167.467) train_loss=240.32786560 time/batch=0.57s
20364/10943 (epoch 167.476) train_loss=151.09657288 time/batch=0.37s
20365/10943 (epoch 167.484) train_loss=436.68405151 time/batch=0.95s
20366/10943 (epoch 167.492) train_loss=556.04052734 time/batch=1.22s
20367/10943 (epoch 167.500) train_loss=262.38037109 time/batch=0.64s
20368/10943 (epoch 167.509) train_loss=557.16741943 time/batch=1.17s
20369/10943 (epoch 167.517) train_loss=456.02703857 time/batch=0.96s
20370/10943 (epoch 167.525) train_loss=328.27734375 time/batch=0.68s
20371/10943 (epoch 167.533) train_loss=367.11489868 time/batch=0.78s
20372/10943 (epoch 167.542) train_loss=233.36065674 time/batch=0.56s
20373/10943 (epoch 167.550) train_loss=145.60644531 time/batch=0.37s
20374/10943 (epoch 167.558) train_loss=291.53466797 time/batch=0.63s
20375/10943 (epoch 167.566) train_loss=250.05374146 time/batch=0.55s
20376/10943 (epoch 167.574) train_loss=390.63681030 time/batch=0.83s
20377/10943 (epoch 167.583) train_loss=396.27783203 time/batch=0.88s
20378/10943 (epoch 167.591) train_loss=448.33239746 time/batch=1.04s
20379/10943 (epoch 167.599) train_loss=273.29437256 time/batch=0.64s
20380/10943 (epoch 167.607) train_loss=185.22384644 time/batch=0.42s
20381/10943 (epoch 167.616) train_loss=268.10046387 time/batch=0.60s
20382/10943 (epoch 167.624) train_loss=433.48370361 time/batch=1.01s
20383/10943 (epoch 167.632) train_loss=326.96118164 time/batch=0.77s
20384/10943 (epoch 167.640) train_loss=168.51411438 time/batch=0.43s
20385/10943 (epoch 167.648) train_loss=170.31365967 time/batch=0.39s
20386/10943 (epoch 167.657) train_loss=205.34988403 time/batch=0.49s
20387/10943 (epoch 167.665) train_loss=363.47195435 time/batch=0.77s
20388/10943 (epoch 167.673) train_loss=183.83299255 time/batch=0.47s
20389/10943 (epoch 167.681) train_loss=532.41906738 time/batch=1.16s
20390/10943 (epoch 167.690) train_loss=267.69464111 time/batch=0.65s
20391/10943 (epoch 167.698) train_loss=382.82968140 time/batch=0.89s
20392/10943 (epoch 167.706) train_loss=396.84786987 time/batch=0.94s
20393/10943 (epoch 167.714) train_loss=459.71612549 time/batch=1.07s
20394/10943 (epoch 167.722) train_loss=325.46276855 time/batch=0.73s
20395/10943 (epoch 167.731) train_loss=124.07779694 time/batch=0.31s
20396/10943 (epoch 167.739) train_loss=129.54832458 time/batch=0.31s
20397/10943 (epoch 167.747) train_loss=322.75274658 time/batch=0.66s
20398/10943 (epoch 167.755) train_loss=326.65106201 time/batch=0.76s
20399/10943 (epoch 167.764) train_loss=365.05279541 time/batch=0.84s
20400/10943 (epoch 167.772) train_loss=293.30474854 time/batch=0.67s
20401/10943 (epoch 167.780) train_loss=346.80957031 time/batch=0.79s
20402/10943 (epoch 167.788) train_loss=479.66564941 time/batch=1.11s
20403/10943 (epoch 167.796) train_loss=251.11299133 time/batch=0.62s
20404/10943 (epoch 167.805) train_loss=356.11090088 time/batch=0.81s
20405/10943 (epoch 167.813) train_loss=357.03347778 time/batch=0.82s
20406/10943 (epoch 167.821) train_loss=341.68823242 time/batch=0.77s
20407/10943 (epoch 167.829) train_loss=165.69094849 time/batch=0.48s
20408/10943 (epoch 167.838) train_loss=350.81082153 time/batch=0.78s
20409/10943 (epoch 167.846) train_loss=308.81372070 time/batch=0.77s
20410/10943 (epoch 167.854) train_loss=303.46148682 time/batch=0.70s
20411/10943 (epoch 167.862) train_loss=226.28176880 time/batch=0.60s
20412/10943 (epoch 167.870) train_loss=371.81680298 time/batch=0.83s
20413/10943 (epoch 167.879) train_loss=266.38586426 time/batch=0.63s
20414/10943 (epoch 167.887) train_loss=194.53579712 time/batch=0.47s
20415/10943 (epoch 167.895) train_loss=271.35916138 time/batch=0.79s
20416/10943 (epoch 167.903) train_loss=249.90447998 time/batch=0.61s
20417/10943 (epoch 167.912) train_loss=249.20182800 time/batch=0.59s
20418/10943 (epoch 167.920) train_loss=291.82568359 time/batch=0.80s
setting learning rate to 0.0009720
20419/10943 (epoch 167.928) train_loss=176.93241882 time/batch=0.41s
20420/10943 (epoch 167.936) train_loss=604.43322754 time/batch=1.23s
20421/10943 (epoch 167.944) train_loss=481.99594116 time/batch=1.04s
20422/10943 (epoch 167.953) train_loss=429.57913208 time/batch=0.91s
20423/10943 (epoch 167.961) train_loss=118.89739990 time/batch=0.32s
20424/10943 (epoch 167.969) train_loss=1076.73999023 time/batch=3.04s
20425/10943 (epoch 167.977) train_loss=600.95214844 time/batch=1.41s
20426/10943 (epoch 167.986) train_loss=362.35156250 time/batch=0.78s
20427/10943 (epoch 167.994) train_loss=255.23188782 time/batch=0.59s
20428/10943 (epoch 168.002) train_loss=594.72436523 time/batch=1.07s
20429/10943 (epoch 168.010) train_loss=363.76293945 time/batch=0.81s
20430/10943 (epoch 168.019) train_loss=666.76885986 time/batch=1.42s
20431/10943 (epoch 168.027) train_loss=370.67846680 time/batch=0.87s
20432/10943 (epoch 168.035) train_loss=822.09106445 time/batch=1.62s
20433/10943 (epoch 168.043) train_loss=406.66381836 time/batch=0.93s
20434/10943 (epoch 168.051) train_loss=698.31604004 time/batch=1.49s
20435/10943 (epoch 168.060) train_loss=233.86564636 time/batch=0.60s
20436/10943 (epoch 168.068) train_loss=359.73638916 time/batch=0.76s
20437/10943 (epoch 168.076) train_loss=331.84603882 time/batch=0.71s
20438/10943 (epoch 168.084) train_loss=378.90350342 time/batch=0.84s
20439/10943 (epoch 168.093) train_loss=120.12136841 time/batch=0.33s
20440/10943 (epoch 168.101) train_loss=303.92861938 time/batch=0.63s
20441/10943 (epoch 168.109) train_loss=451.73101807 time/batch=0.97s
20442/10943 (epoch 168.117) train_loss=361.65173340 time/batch=0.78s
20443/10943 (epoch 168.125) train_loss=134.55931091 time/batch=0.33s
20444/10943 (epoch 168.134) train_loss=376.51519775 time/batch=0.77s
20445/10943 (epoch 168.142) train_loss=306.52694702 time/batch=0.65s
20446/10943 (epoch 168.150) train_loss=522.72460938 time/batch=1.10s
20447/10943 (epoch 168.158) train_loss=335.66110229 time/batch=0.78s
20448/10943 (epoch 168.167) train_loss=627.97149658 time/batch=1.23s
20449/10943 (epoch 168.175) train_loss=509.73413086 time/batch=1.08s
20450/10943 (epoch 168.183) train_loss=164.40734863 time/batch=0.42s
20451/10943 (epoch 168.191) train_loss=492.70471191 time/batch=0.95s
20452/10943 (epoch 168.199) train_loss=299.85589600 time/batch=0.66s
20453/10943 (epoch 168.208) train_loss=624.87145996 time/batch=1.28s
20454/10943 (epoch 168.216) train_loss=451.45269775 time/batch=0.98s
20455/10943 (epoch 168.224) train_loss=236.05657959 time/batch=0.54s
20456/10943 (epoch 168.232) train_loss=529.63122559 time/batch=1.05s
20457/10943 (epoch 168.241) train_loss=536.87292480 time/batch=1.33s
20458/10943 (epoch 168.249) train_loss=152.13150024 time/batch=0.42s
20459/10943 (epoch 168.257) train_loss=494.78167725 time/batch=1.02s
20460/10943 (epoch 168.265) train_loss=464.31890869 time/batch=0.97s
20461/10943 (epoch 168.273) train_loss=469.86877441 time/batch=0.95s
20462/10943 (epoch 168.282) train_loss=258.39746094 time/batch=0.57s
20463/10943 (epoch 168.290) train_loss=355.97531128 time/batch=0.74s
20464/10943 (epoch 168.298) train_loss=243.64874268 time/batch=0.57s
20465/10943 (epoch 168.306) train_loss=129.92678833 time/batch=0.31s
20466/10943 (epoch 168.315) train_loss=487.39385986 time/batch=0.96s
20467/10943 (epoch 168.323) train_loss=314.32421875 time/batch=0.69s
20468/10943 (epoch 168.331) train_loss=231.12985229 time/batch=0.52s
20469/10943 (epoch 168.339) train_loss=437.91506958 time/batch=0.92s
20470/10943 (epoch 168.347) train_loss=335.89270020 time/batch=0.75s
20471/10943 (epoch 168.356) train_loss=457.70855713 time/batch=0.96s
20472/10943 (epoch 168.364) train_loss=235.68338013 time/batch=0.57s
20473/10943 (epoch 168.372) train_loss=203.06124878 time/batch=0.44s
20474/10943 (epoch 168.380) train_loss=176.09893799 time/batch=0.41s
20475/10943 (epoch 168.389) train_loss=356.19476318 time/batch=0.73s
20476/10943 (epoch 168.397) train_loss=182.38833618 time/batch=0.44s
20477/10943 (epoch 168.405) train_loss=411.33438110 time/batch=0.84s
20478/10943 (epoch 168.413) train_loss=301.10574341 time/batch=0.68s
20479/10943 (epoch 168.421) train_loss=198.64042664 time/batch=0.44s
20480/10943 (epoch 168.430) train_loss=194.33503723 time/batch=0.43s
20481/10943 (epoch 168.438) train_loss=157.51095581 time/batch=0.35s
20482/10943 (epoch 168.446) train_loss=332.12854004 time/batch=0.69s
20483/10943 (epoch 168.454) train_loss=142.48562622 time/batch=0.34s
20484/10943 (epoch 168.463) train_loss=213.70932007 time/batch=0.48s
20485/10943 (epoch 168.471) train_loss=406.65234375 time/batch=0.85s
20486/10943 (epoch 168.479) train_loss=401.31079102 time/batch=0.86s
20487/10943 (epoch 168.487) train_loss=287.53250122 time/batch=0.64s
20488/10943 (epoch 168.496) train_loss=304.52154541 time/batch=0.64s
20489/10943 (epoch 168.504) train_loss=319.32031250 time/batch=0.64s
20490/10943 (epoch 168.512) train_loss=194.50729370 time/batch=0.44s
20491/10943 (epoch 168.520) train_loss=299.92559814 time/batch=0.65s
20492/10943 (epoch 168.528) train_loss=264.88006592 time/batch=0.58s
20493/10943 (epoch 168.537) train_loss=394.35217285 time/batch=0.84s
20494/10943 (epoch 168.545) train_loss=161.25827026 time/batch=0.39s
20495/10943 (epoch 168.553) train_loss=484.89999390 time/batch=1.03s
20496/10943 (epoch 168.561) train_loss=260.28515625 time/batch=0.65s
20497/10943 (epoch 168.570) train_loss=419.27084351 time/batch=0.84s
20498/10943 (epoch 168.578) train_loss=265.94824219 time/batch=0.62s
20499/10943 (epoch 168.586) train_loss=216.55235291 time/batch=0.50s
20500/10943 (epoch 168.594) train_loss=169.94638062 time/batch=0.39s
20501/10943 (epoch 168.602) train_loss=403.71307373 time/batch=0.85s
20502/10943 (epoch 168.611) train_loss=345.17864990 time/batch=0.71s
20503/10943 (epoch 168.619) train_loss=260.86087036 time/batch=0.58s
20504/10943 (epoch 168.627) train_loss=334.63146973 time/batch=0.72s
20505/10943 (epoch 168.635) train_loss=348.26779175 time/batch=0.77s
20506/10943 (epoch 168.644) train_loss=354.57330322 time/batch=0.79s
20507/10943 (epoch 168.652) train_loss=306.49530029 time/batch=0.66s
20508/10943 (epoch 168.660) train_loss=245.71266174 time/batch=0.56s
20509/10943 (epoch 168.668) train_loss=158.13900757 time/batch=0.36s
20510/10943 (epoch 168.676) train_loss=306.80505371 time/batch=0.64s
20511/10943 (epoch 168.685) train_loss=312.28353882 time/batch=0.68s
20512/10943 (epoch 168.693) train_loss=357.57022095 time/batch=0.78s
20513/10943 (epoch 168.701) train_loss=352.01126099 time/batch=0.75s
20514/10943 (epoch 168.709) train_loss=354.66989136 time/batch=0.78s
20515/10943 (epoch 168.718) train_loss=281.59063721 time/batch=0.65s
20516/10943 (epoch 168.726) train_loss=177.17002869 time/batch=0.43s
20517/10943 (epoch 168.734) train_loss=176.73872375 time/batch=0.43s
20518/10943 (epoch 168.742) train_loss=142.50143433 time/batch=0.36s
20519/10943 (epoch 168.750) train_loss=206.80151367 time/batch=0.45s
20520/10943 (epoch 168.759) train_loss=269.34637451 time/batch=0.59s
20521/10943 (epoch 168.767) train_loss=328.82791138 time/batch=0.73s
20522/10943 (epoch 168.775) train_loss=346.40960693 time/batch=0.80s
20523/10943 (epoch 168.783) train_loss=233.53933716 time/batch=0.55s
20524/10943 (epoch 168.792) train_loss=370.94964600 time/batch=0.80s
20525/10943 (epoch 168.800) train_loss=264.28491211 time/batch=0.61s
20526/10943 (epoch 168.808) train_loss=281.02734375 time/batch=0.61s
20527/10943 (epoch 168.816) train_loss=210.83026123 time/batch=0.48s
20528/10943 (epoch 168.824) train_loss=268.70034790 time/batch=0.57s
20529/10943 (epoch 168.833) train_loss=250.34193420 time/batch=0.57s
20530/10943 (epoch 168.841) train_loss=235.95040894 time/batch=0.56s
20531/10943 (epoch 168.849) train_loss=199.66207886 time/batch=0.52s
20532/10943 (epoch 168.857) train_loss=259.26535034 time/batch=0.64s
20533/10943 (epoch 168.866) train_loss=388.22979736 time/batch=0.83s
20534/10943 (epoch 168.874) train_loss=381.17297363 time/batch=0.85s
20535/10943 (epoch 168.882) train_loss=328.07470703 time/batch=0.72s
20536/10943 (epoch 168.890) train_loss=252.70445251 time/batch=0.62s
20537/10943 (epoch 168.898) train_loss=274.00152588 time/batch=0.61s
20538/10943 (epoch 168.907) train_loss=301.10894775 time/batch=0.70s
20539/10943 (epoch 168.915) train_loss=269.44396973 time/batch=0.71s
setting learning rate to 0.0009429
20540/10943 (epoch 168.923) train_loss=389.80847168 time/batch=0.84s
20541/10943 (epoch 168.931) train_loss=173.72564697 time/batch=0.41s
20542/10943 (epoch 168.940) train_loss=351.68475342 time/batch=0.76s
20543/10943 (epoch 168.948) train_loss=218.77764893 time/batch=0.49s
20544/10943 (epoch 168.956) train_loss=501.97766113 time/batch=1.05s
20545/10943 (epoch 168.964) train_loss=395.66311646 time/batch=0.87s
20546/10943 (epoch 168.973) train_loss=670.62304688 time/batch=1.32s
20547/10943 (epoch 168.981) train_loss=1012.39642334 time/batch=2.26s
20548/10943 (epoch 168.989) train_loss=633.28753662 time/batch=1.34s
20549/10943 (epoch 168.997) train_loss=613.62847900 time/batch=1.28s
20550/10943 (epoch 169.005) train_loss=677.03747559 time/batch=1.45s
20551/10943 (epoch 169.014) train_loss=864.98217773 time/batch=2.28s
20552/10943 (epoch 169.022) train_loss=264.48992920 time/batch=0.80s
20553/10943 (epoch 169.030) train_loss=495.12515259 time/batch=1.05s
20554/10943 (epoch 169.038) train_loss=518.45812988 time/batch=1.20s
20555/10943 (epoch 169.047) train_loss=461.93771362 time/batch=1.06s
20556/10943 (epoch 169.055) train_loss=347.57101440 time/batch=0.84s
20557/10943 (epoch 169.063) train_loss=805.67700195 time/batch=3.06s
20558/10943 (epoch 169.071) train_loss=199.40150452 time/batch=0.73s
20559/10943 (epoch 169.079) train_loss=114.92228699 time/batch=0.27s
20560/10943 (epoch 169.088) train_loss=217.95616150 time/batch=0.50s
20561/10943 (epoch 169.096) train_loss=342.44879150 time/batch=0.77s
20562/10943 (epoch 169.104) train_loss=376.84039307 time/batch=0.88s
20563/10943 (epoch 169.112) train_loss=293.65826416 time/batch=0.71s
20564/10943 (epoch 169.121) train_loss=132.38703918 time/batch=0.34s
20565/10943 (epoch 169.129) train_loss=589.82202148 time/batch=1.21s
20566/10943 (epoch 169.137) train_loss=223.91812134 time/batch=0.58s
20567/10943 (epoch 169.145) train_loss=123.39559937 time/batch=0.31s
20568/10943 (epoch 169.153) train_loss=377.32421875 time/batch=0.81s
20569/10943 (epoch 169.162) train_loss=319.85540771 time/batch=0.75s
20570/10943 (epoch 169.170) train_loss=428.24044800 time/batch=0.94s
20571/10943 (epoch 169.178) train_loss=310.83514404 time/batch=0.73s
20572/10943 (epoch 169.186) train_loss=176.88751221 time/batch=0.42s
20573/10943 (epoch 169.195) train_loss=301.25753784 time/batch=0.64s
20574/10943 (epoch 169.203) train_loss=248.11195374 time/batch=0.60s
20575/10943 (epoch 169.211) train_loss=337.86309814 time/batch=0.78s
20576/10943 (epoch 169.219) train_loss=346.63726807 time/batch=0.80s
20577/10943 (epoch 169.227) train_loss=516.58538818 time/batch=1.10s
20578/10943 (epoch 169.236) train_loss=423.85046387 time/batch=0.91s
20579/10943 (epoch 169.244) train_loss=345.50457764 time/batch=0.78s
20580/10943 (epoch 169.252) train_loss=410.65734863 time/batch=0.93s
20581/10943 (epoch 169.260) train_loss=135.30764771 time/batch=0.37s
20582/10943 (epoch 169.269) train_loss=175.21707153 time/batch=0.40s
20583/10943 (epoch 169.277) train_loss=193.00889587 time/batch=0.45s
20584/10943 (epoch 169.285) train_loss=270.48825073 time/batch=0.61s
20585/10943 (epoch 169.293) train_loss=458.89172363 time/batch=0.97s
20586/10943 (epoch 169.301) train_loss=376.92599487 time/batch=0.87s
20587/10943 (epoch 169.310) train_loss=220.35504150 time/batch=0.53s
20588/10943 (epoch 169.318) train_loss=384.12823486 time/batch=0.86s
20589/10943 (epoch 169.326) train_loss=465.27291870 time/batch=1.04s
20590/10943 (epoch 169.334) train_loss=279.12762451 time/batch=0.67s
20591/10943 (epoch 169.343) train_loss=300.60949707 time/batch=0.67s
20592/10943 (epoch 169.351) train_loss=172.06951904 time/batch=0.40s
20593/10943 (epoch 169.359) train_loss=397.89685059 time/batch=0.90s
20594/10943 (epoch 169.367) train_loss=342.98345947 time/batch=0.80s
20595/10943 (epoch 169.375) train_loss=614.36596680 time/batch=1.42s
20596/10943 (epoch 169.384) train_loss=370.97821045 time/batch=0.82s
20597/10943 (epoch 169.392) train_loss=148.99847412 time/batch=0.37s
20598/10943 (epoch 169.400) train_loss=403.23132324 time/batch=0.85s
20599/10943 (epoch 169.408) train_loss=127.56404114 time/batch=0.36s
20600/10943 (epoch 169.417) train_loss=207.67764282 time/batch=0.47s
20601/10943 (epoch 169.425) train_loss=289.49304199 time/batch=0.63s
20602/10943 (epoch 169.433) train_loss=272.39889526 time/batch=0.62s
20603/10943 (epoch 169.441) train_loss=405.21435547 time/batch=0.89s
20604/10943 (epoch 169.449) train_loss=157.63128662 time/batch=0.41s
20605/10943 (epoch 169.458) train_loss=218.48403931 time/batch=0.52s
20606/10943 (epoch 169.466) train_loss=427.70669556 time/batch=0.95s
20607/10943 (epoch 169.474) train_loss=296.97906494 time/batch=0.70s
20608/10943 (epoch 169.482) train_loss=198.46101379 time/batch=0.48s
20609/10943 (epoch 169.491) train_loss=226.43597412 time/batch=0.51s
20610/10943 (epoch 169.499) train_loss=293.67810059 time/batch=0.68s
20611/10943 (epoch 169.507) train_loss=135.14175415 time/batch=0.36s
20612/10943 (epoch 169.515) train_loss=368.75970459 time/batch=0.78s
20613/10943 (epoch 169.524) train_loss=275.15481567 time/batch=0.64s
20614/10943 (epoch 169.532) train_loss=213.05673218 time/batch=0.52s
20615/10943 (epoch 169.540) train_loss=357.81103516 time/batch=0.80s
20616/10943 (epoch 169.548) train_loss=274.01617432 time/batch=0.65s
20617/10943 (epoch 169.556) train_loss=317.95639038 time/batch=0.73s
20618/10943 (epoch 169.565) train_loss=191.21340942 time/batch=0.47s
20619/10943 (epoch 169.573) train_loss=495.89349365 time/batch=1.15s
20620/10943 (epoch 169.581) train_loss=354.14224243 time/batch=0.83s
20621/10943 (epoch 169.589) train_loss=399.86834717 time/batch=0.91s
20622/10943 (epoch 169.598) train_loss=485.63229370 time/batch=1.01s
20623/10943 (epoch 169.606) train_loss=316.06616211 time/batch=0.72s
20624/10943 (epoch 169.614) train_loss=486.57086182 time/batch=1.10s
20625/10943 (epoch 169.622) train_loss=253.76419067 time/batch=0.65s
20626/10943 (epoch 169.630) train_loss=216.79187012 time/batch=0.52s
20627/10943 (epoch 169.639) train_loss=346.52590942 time/batch=0.88s
20628/10943 (epoch 169.647) train_loss=251.53553772 time/batch=0.64s
20629/10943 (epoch 169.655) train_loss=433.29614258 time/batch=0.94s
20630/10943 (epoch 169.663) train_loss=351.41201782 time/batch=0.81s
20631/10943 (epoch 169.672) train_loss=450.86267090 time/batch=1.02s
20632/10943 (epoch 169.680) train_loss=349.79156494 time/batch=0.85s
20633/10943 (epoch 169.688) train_loss=357.39340210 time/batch=0.82s
20634/10943 (epoch 169.696) train_loss=180.02151489 time/batch=0.45s
20635/10943 (epoch 169.704) train_loss=155.42416382 time/batch=0.36s
20636/10943 (epoch 169.713) train_loss=246.84475708 time/batch=0.56s
20637/10943 (epoch 169.721) train_loss=315.07128906 time/batch=0.70s
20638/10943 (epoch 169.729) train_loss=262.71688843 time/batch=0.64s
20639/10943 (epoch 169.737) train_loss=303.27349854 time/batch=0.70s
20640/10943 (epoch 169.746) train_loss=276.32369995 time/batch=0.66s
20641/10943 (epoch 169.754) train_loss=324.68280029 time/batch=0.79s
20642/10943 (epoch 169.762) train_loss=267.54046631 time/batch=0.61s
20643/10943 (epoch 169.770) train_loss=192.85415649 time/batch=0.48s
20644/10943 (epoch 169.778) train_loss=317.90820312 time/batch=0.72s
20645/10943 (epoch 169.787) train_loss=149.52629089 time/batch=0.39s
20646/10943 (epoch 169.795) train_loss=229.79174805 time/batch=0.52s
20647/10943 (epoch 169.803) train_loss=231.65075684 time/batch=0.55s
20648/10943 (epoch 169.811) train_loss=269.96234131 time/batch=0.63s
20649/10943 (epoch 169.820) train_loss=245.30378723 time/batch=0.60s
20650/10943 (epoch 169.828) train_loss=250.43487549 time/batch=0.59s
20651/10943 (epoch 169.836) train_loss=155.33450317 time/batch=0.43s
20652/10943 (epoch 169.844) train_loss=211.88290405 time/batch=0.51s
20653/10943 (epoch 169.852) train_loss=236.09826660 time/batch=0.55s
20654/10943 (epoch 169.861) train_loss=203.89581299 time/batch=0.55s
20655/10943 (epoch 169.869) train_loss=286.92169189 time/batch=0.68s
20656/10943 (epoch 169.877) train_loss=333.79675293 time/batch=0.72s
20657/10943 (epoch 169.885) train_loss=305.92340088 time/batch=0.72s
20658/10943 (epoch 169.894) train_loss=330.09124756 time/batch=0.73s
20659/10943 (epoch 169.902) train_loss=275.90615845 time/batch=0.65s
20660/10943 (epoch 169.910) train_loss=241.74589539 time/batch=0.60s
setting learning rate to 0.0009146
  saved to metadata/gru_no_dropout-9_nov_folkwiki-20181115-214759_epoch59.pkl
20661/10943 (epoch 169.918) train_loss=489.69213867 time/batch=1.08s
20662/10943 (epoch 169.926) train_loss=620.18920898 time/batch=1.24s
20663/10943 (epoch 169.935) train_loss=219.97985840 time/batch=0.55s
20664/10943 (epoch 169.943) train_loss=287.11639404 time/batch=0.69s
20665/10943 (epoch 169.951) train_loss=187.71807861 time/batch=0.46s
20666/10943 (epoch 169.959) train_loss=594.15026855 time/batch=1.22s
20667/10943 (epoch 169.968) train_loss=320.08410645 time/batch=0.74s
20668/10943 (epoch 169.976) train_loss=443.18652344 time/batch=0.96s
20669/10943 (epoch 169.984) train_loss=133.34202576 time/batch=0.37s
20670/10943 (epoch 169.992) train_loss=270.67236328 time/batch=0.60s
20671/10943 (epoch 170.001) train_loss=515.04901123 time/batch=1.14s
20672/10943 (epoch 170.009) train_loss=815.94573975 time/batch=1.73s
20673/10943 (epoch 170.017) train_loss=336.71099854 time/batch=0.84s
20674/10943 (epoch 170.025) train_loss=414.89025879 time/batch=0.93s
20675/10943 (epoch 170.033) train_loss=153.69873047 time/batch=0.40s
20676/10943 (epoch 170.042) train_loss=433.91119385 time/batch=0.92s
20677/10943 (epoch 170.050) train_loss=135.17285156 time/batch=0.38s
20678/10943 (epoch 170.058) train_loss=144.35223389 time/batch=0.34s
20679/10943 (epoch 170.066) train_loss=154.04919434 time/batch=0.35s
20680/10943 (epoch 170.075) train_loss=446.86437988 time/batch=0.96s
20681/10943 (epoch 170.083) train_loss=490.46203613 time/batch=1.10s
20682/10943 (epoch 170.091) train_loss=412.55505371 time/batch=0.98s
20683/10943 (epoch 170.099) train_loss=374.57995605 time/batch=0.89s
20684/10943 (epoch 170.107) train_loss=392.72875977 time/batch=0.89s
20685/10943 (epoch 170.116) train_loss=879.91937256 time/batch=2.12s
20686/10943 (epoch 170.124) train_loss=191.57649231 time/batch=0.58s
20687/10943 (epoch 170.132) train_loss=103.74717712 time/batch=0.27s
20688/10943 (epoch 170.140) train_loss=333.81353760 time/batch=0.73s
20689/10943 (epoch 170.149) train_loss=597.69140625 time/batch=1.41s
20690/10943 (epoch 170.157) train_loss=237.32946777 time/batch=0.64s
20691/10943 (epoch 170.165) train_loss=252.58499146 time/batch=0.58s
20692/10943 (epoch 170.173) train_loss=134.64346313 time/batch=0.34s
20693/10943 (epoch 170.181) train_loss=861.45361328 time/batch=3.05s
20694/10943 (epoch 170.190) train_loss=587.72106934 time/batch=1.49s
20695/10943 (epoch 170.198) train_loss=439.25177002 time/batch=1.01s
20696/10943 (epoch 170.206) train_loss=398.39364624 time/batch=0.92s
20697/10943 (epoch 170.214) train_loss=290.38421631 time/batch=0.72s
20698/10943 (epoch 170.223) train_loss=279.72924805 time/batch=0.66s
20699/10943 (epoch 170.231) train_loss=253.76953125 time/batch=0.62s
20700/10943 (epoch 170.239) train_loss=373.43548584 time/batch=0.86s
20701/10943 (epoch 170.247) train_loss=472.93237305 time/batch=1.04s
20702/10943 (epoch 170.255) train_loss=125.00465393 time/batch=0.36s
20703/10943 (epoch 170.264) train_loss=643.82867432 time/batch=1.39s
20704/10943 (epoch 170.272) train_loss=508.48791504 time/batch=1.19s
20705/10943 (epoch 170.280) train_loss=191.81755066 time/batch=0.53s
20706/10943 (epoch 170.288) train_loss=387.59841919 time/batch=0.84s
20707/10943 (epoch 170.297) train_loss=363.45489502 time/batch=0.86s
20708/10943 (epoch 170.305) train_loss=152.12426758 time/batch=0.40s
20709/10943 (epoch 170.313) train_loss=215.15582275 time/batch=0.49s
20710/10943 (epoch 170.321) train_loss=295.08392334 time/batch=0.68s
20711/10943 (epoch 170.329) train_loss=163.44912720 time/batch=0.41s
20712/10943 (epoch 170.338) train_loss=340.03521729 time/batch=0.74s
20713/10943 (epoch 170.346) train_loss=286.44512939 time/batch=0.68s
20714/10943 (epoch 170.354) train_loss=326.16363525 time/batch=0.81s
20715/10943 (epoch 170.362) train_loss=262.56381226 time/batch=0.64s
20716/10943 (epoch 170.371) train_loss=317.25808716 time/batch=0.75s
20717/10943 (epoch 170.379) train_loss=465.12652588 time/batch=1.04s
20718/10943 (epoch 170.387) train_loss=196.73211670 time/batch=0.51s
20719/10943 (epoch 170.395) train_loss=196.38885498 time/batch=0.47s
20720/10943 (epoch 170.403) train_loss=332.60900879 time/batch=0.78s
20721/10943 (epoch 170.412) train_loss=252.06475830 time/batch=0.62s
20722/10943 (epoch 170.420) train_loss=240.95332336 time/batch=0.56s
20723/10943 (epoch 170.428) train_loss=337.97409058 time/batch=0.76s
20724/10943 (epoch 170.436) train_loss=527.82385254 time/batch=1.09s
20725/10943 (epoch 170.445) train_loss=270.43957520 time/batch=0.64s
20726/10943 (epoch 170.453) train_loss=478.08386230 time/batch=1.10s
20727/10943 (epoch 170.461) train_loss=236.49688721 time/batch=0.63s
20728/10943 (epoch 170.469) train_loss=332.29714966 time/batch=0.78s
20729/10943 (epoch 170.478) train_loss=434.89630127 time/batch=0.97s
20730/10943 (epoch 170.486) train_loss=334.71160889 time/batch=0.73s
20731/10943 (epoch 170.494) train_loss=310.79660034 time/batch=0.72s
20732/10943 (epoch 170.502) train_loss=564.25268555 time/batch=1.27s
20733/10943 (epoch 170.510) train_loss=335.63632202 time/batch=0.81s
20734/10943 (epoch 170.519) train_loss=177.76499939 time/batch=0.43s
20735/10943 (epoch 170.527) train_loss=358.49414062 time/batch=0.79s
20736/10943 (epoch 170.535) train_loss=245.65826416 time/batch=0.60s
20737/10943 (epoch 170.543) train_loss=281.16909790 time/batch=0.65s
20738/10943 (epoch 170.552) train_loss=396.80389404 time/batch=0.89s
20739/10943 (epoch 170.560) train_loss=270.48309326 time/batch=0.65s
20740/10943 (epoch 170.568) train_loss=367.92132568 time/batch=0.84s
20741/10943 (epoch 170.576) train_loss=277.69448853 time/batch=0.67s
20742/10943 (epoch 170.584) train_loss=133.78971863 time/batch=0.38s
20743/10943 (epoch 170.593) train_loss=332.09576416 time/batch=0.77s
20744/10943 (epoch 170.601) train_loss=418.54251099 time/batch=0.99s
20745/10943 (epoch 170.609) train_loss=224.49243164 time/batch=0.59s
20746/10943 (epoch 170.617) train_loss=399.27307129 time/batch=0.95s
20747/10943 (epoch 170.626) train_loss=181.70748901 time/batch=0.49s
20748/10943 (epoch 170.634) train_loss=216.27432251 time/batch=0.51s
20749/10943 (epoch 170.642) train_loss=305.50280762 time/batch=0.72s
20750/10943 (epoch 170.650) train_loss=337.88253784 time/batch=0.80s
20751/10943 (epoch 170.658) train_loss=319.89367676 time/batch=0.73s
20752/10943 (epoch 170.667) train_loss=228.46078491 time/batch=0.53s
20753/10943 (epoch 170.675) train_loss=335.18005371 time/batch=0.78s
20754/10943 (epoch 170.683) train_loss=243.09928894 time/batch=0.59s
20755/10943 (epoch 170.691) train_loss=294.30187988 time/batch=0.65s
20756/10943 (epoch 170.700) train_loss=212.59710693 time/batch=0.52s
20757/10943 (epoch 170.708) train_loss=283.09704590 time/batch=0.70s
20758/10943 (epoch 170.716) train_loss=290.69055176 time/batch=0.69s
20759/10943 (epoch 170.724) train_loss=261.53070068 time/batch=0.62s
20760/10943 (epoch 170.732) train_loss=162.17384338 time/batch=0.39s
20761/10943 (epoch 170.741) train_loss=334.43673706 time/batch=0.76s
20762/10943 (epoch 170.749) train_loss=177.77371216 time/batch=0.47s
20763/10943 (epoch 170.757) train_loss=316.92584229 time/batch=0.70s
20764/10943 (epoch 170.765) train_loss=356.29135132 time/batch=0.85s
20765/10943 (epoch 170.774) train_loss=219.76841736 time/batch=0.56s
20766/10943 (epoch 170.782) train_loss=162.40966797 time/batch=0.44s
20767/10943 (epoch 170.790) train_loss=271.59628296 time/batch=0.61s
20768/10943 (epoch 170.798) train_loss=350.33081055 time/batch=0.88s
20769/10943 (epoch 170.806) train_loss=246.65676880 time/batch=0.62s
20770/10943 (epoch 170.815) train_loss=323.65274048 time/batch=0.72s
20771/10943 (epoch 170.823) train_loss=251.96012878 time/batch=0.60s
20772/10943 (epoch 170.831) train_loss=197.17680359 time/batch=0.47s
20773/10943 (epoch 170.839) train_loss=342.57922363 time/batch=0.78s
20774/10943 (epoch 170.848) train_loss=305.78405762 time/batch=0.76s
20775/10943 (epoch 170.856) train_loss=235.41772461 time/batch=0.60s
20776/10943 (epoch 170.864) train_loss=201.88128662 time/batch=0.47s
20777/10943 (epoch 170.872) train_loss=249.24865723 time/batch=0.61s
20778/10943 (epoch 170.880) train_loss=244.48645020 time/batch=0.61s
20779/10943 (epoch 170.889) train_loss=205.07255554 time/batch=0.50s
20780/10943 (epoch 170.897) train_loss=244.80892944 time/batch=0.60s
20781/10943 (epoch 170.905) train_loss=258.67068481 time/batch=0.73s
setting learning rate to 0.0008871
20782/10943 (epoch 170.913) train_loss=399.45651245 time/batch=0.91s
20783/10943 (epoch 170.922) train_loss=417.73114014 time/batch=0.94s
20784/10943 (epoch 170.930) train_loss=346.97723389 time/batch=0.76s
20785/10943 (epoch 170.938) train_loss=617.66906738 time/batch=1.42s
20786/10943 (epoch 170.946) train_loss=756.18896484 time/batch=1.63s
20787/10943 (epoch 170.955) train_loss=112.47196198 time/batch=0.39s
20788/10943 (epoch 170.963) train_loss=827.62036133 time/batch=1.72s
20789/10943 (epoch 170.971) train_loss=674.16101074 time/batch=1.88s
20790/10943 (epoch 170.979) train_loss=521.18176270 time/batch=1.27s
20791/10943 (epoch 170.987) train_loss=307.21398926 time/batch=0.78s
20792/10943 (epoch 170.996) train_loss=356.19091797 time/batch=0.84s
20793/10943 (epoch 171.004) train_loss=201.14308167 time/batch=0.52s
20794/10943 (epoch 171.012) train_loss=187.70173645 time/batch=0.45s
20795/10943 (epoch 171.020) train_loss=468.12496948 time/batch=1.04s
20796/10943 (epoch 171.029) train_loss=962.78173828 time/batch=3.14s
20797/10943 (epoch 171.037) train_loss=617.63793945 time/batch=1.54s
20798/10943 (epoch 171.045) train_loss=373.80706787 time/batch=0.91s
20799/10943 (epoch 171.053) train_loss=205.43826294 time/batch=0.53s
20800/10943 (epoch 171.061) train_loss=205.81921387 time/batch=0.49s
20801/10943 (epoch 171.070) train_loss=116.30647278 time/batch=0.29s
20802/10943 (epoch 171.078) train_loss=190.81256104 time/batch=0.41s
20803/10943 (epoch 171.086) train_loss=422.38525391 time/batch=0.94s
20804/10943 (epoch 171.094) train_loss=181.68084717 time/batch=0.49s
20805/10943 (epoch 171.103) train_loss=168.69967651 time/batch=0.41s
20806/10943 (epoch 171.111) train_loss=222.98358154 time/batch=0.53s
20807/10943 (epoch 171.119) train_loss=457.46005249 time/batch=0.99s
20808/10943 (epoch 171.127) train_loss=416.68499756 time/batch=0.98s
20809/10943 (epoch 171.135) train_loss=287.17053223 time/batch=0.72s
20810/10943 (epoch 171.144) train_loss=147.12399292 time/batch=0.37s
20811/10943 (epoch 171.152) train_loss=122.04634094 time/batch=0.30s
20812/10943 (epoch 171.160) train_loss=452.72601318 time/batch=0.98s
20813/10943 (epoch 171.168) train_loss=299.49548340 time/batch=0.74s
20814/10943 (epoch 171.177) train_loss=333.99993896 time/batch=0.77s
20815/10943 (epoch 171.185) train_loss=213.80389404 time/batch=0.54s
20816/10943 (epoch 171.193) train_loss=469.55395508 time/batch=1.10s
20817/10943 (epoch 171.201) train_loss=217.99482727 time/batch=0.60s
20818/10943 (epoch 171.209) train_loss=307.46591187 time/batch=0.72s
20819/10943 (epoch 171.218) train_loss=498.18838501 time/batch=1.10s
20820/10943 (epoch 171.226) train_loss=142.57043457 time/batch=0.41s
20821/10943 (epoch 171.234) train_loss=171.57183838 time/batch=0.44s
20822/10943 (epoch 171.242) train_loss=389.36492920 time/batch=0.86s
20823/10943 (epoch 171.251) train_loss=182.03704834 time/batch=0.49s
20824/10943 (epoch 171.259) train_loss=439.83666992 time/batch=0.99s
20825/10943 (epoch 171.267) train_loss=597.50134277 time/batch=1.31s
20826/10943 (epoch 171.275) train_loss=242.88656616 time/batch=0.62s
20827/10943 (epoch 171.283) train_loss=246.16650391 time/batch=0.58s
20828/10943 (epoch 171.292) train_loss=333.55041504 time/batch=0.79s
20829/10943 (epoch 171.300) train_loss=243.51177979 time/batch=0.60s
20830/10943 (epoch 171.308) train_loss=219.94778442 time/batch=0.54s
20831/10943 (epoch 171.316) train_loss=282.03106689 time/batch=0.66s
20832/10943 (epoch 171.325) train_loss=314.11676025 time/batch=0.75s
20833/10943 (epoch 171.333) train_loss=219.48001099 time/batch=0.53s
20834/10943 (epoch 171.341) train_loss=284.32012939 time/batch=0.69s
20835/10943 (epoch 171.349) train_loss=422.56631470 time/batch=0.97s
20836/10943 (epoch 171.357) train_loss=334.34576416 time/batch=0.82s
20837/10943 (epoch 171.366) train_loss=186.48446655 time/batch=0.49s
20838/10943 (epoch 171.374) train_loss=230.40814209 time/batch=0.56s
20839/10943 (epoch 171.382) train_loss=255.73867798 time/batch=0.62s
20840/10943 (epoch 171.390) train_loss=331.19302368 time/batch=0.77s
20841/10943 (epoch 171.399) train_loss=363.46173096 time/batch=0.86s
20842/10943 (epoch 171.407) train_loss=473.26422119 time/batch=1.04s
20843/10943 (epoch 171.415) train_loss=203.20166016 time/batch=0.52s
20844/10943 (epoch 171.423) train_loss=172.54325867 time/batch=0.46s
20845/10943 (epoch 171.432) train_loss=277.19018555 time/batch=0.63s
20846/10943 (epoch 171.440) train_loss=561.60363770 time/batch=1.19s
20847/10943 (epoch 171.448) train_loss=531.70654297 time/batch=1.23s
20848/10943 (epoch 171.456) train_loss=273.88098145 time/batch=0.69s
20849/10943 (epoch 171.464) train_loss=151.57397461 time/batch=0.38s
20850/10943 (epoch 171.473) train_loss=397.87274170 time/batch=0.88s
20851/10943 (epoch 171.481) train_loss=318.63079834 time/batch=0.74s
20852/10943 (epoch 171.489) train_loss=126.05004120 time/batch=0.34s
20853/10943 (epoch 171.497) train_loss=469.34643555 time/batch=1.09s
20854/10943 (epoch 171.506) train_loss=233.42764282 time/batch=0.61s
20855/10943 (epoch 171.514) train_loss=165.34344482 time/batch=0.38s
20856/10943 (epoch 171.522) train_loss=306.15838623 time/batch=0.72s
20857/10943 (epoch 171.530) train_loss=324.22143555 time/batch=0.76s
20858/10943 (epoch 171.538) train_loss=245.98791504 time/batch=0.61s
20859/10943 (epoch 171.547) train_loss=331.13854980 time/batch=0.77s
20860/10943 (epoch 171.555) train_loss=326.19250488 time/batch=0.79s
20861/10943 (epoch 171.563) train_loss=256.25119019 time/batch=0.63s
20862/10943 (epoch 171.571) train_loss=370.86999512 time/batch=0.86s
20863/10943 (epoch 171.580) train_loss=288.52267456 time/batch=0.70s
20864/10943 (epoch 171.588) train_loss=157.84609985 time/batch=0.41s
20865/10943 (epoch 171.596) train_loss=361.10961914 time/batch=0.80s
20866/10943 (epoch 171.604) train_loss=231.16680908 time/batch=0.58s
20867/10943 (epoch 171.612) train_loss=280.29937744 time/batch=0.65s
20868/10943 (epoch 171.621) train_loss=435.29129028 time/batch=0.94s
20869/10943 (epoch 171.629) train_loss=150.64418030 time/batch=0.39s
20870/10943 (epoch 171.637) train_loss=255.72993469 time/batch=0.60s
20871/10943 (epoch 171.645) train_loss=326.27517700 time/batch=0.80s
20872/10943 (epoch 171.654) train_loss=245.11599731 time/batch=0.64s
20873/10943 (epoch 171.662) train_loss=130.82995605 time/batch=0.33s
20874/10943 (epoch 171.670) train_loss=385.33612061 time/batch=0.89s
20875/10943 (epoch 171.678) train_loss=291.37429810 time/batch=0.71s
20876/10943 (epoch 171.686) train_loss=313.53305054 time/batch=0.77s
20877/10943 (epoch 171.695) train_loss=356.78411865 time/batch=0.86s
20878/10943 (epoch 171.703) train_loss=246.31079102 time/batch=0.60s
20879/10943 (epoch 171.711) train_loss=374.27056885 time/batch=0.87s
20880/10943 (epoch 171.719) train_loss=201.25225830 time/batch=0.53s
20881/10943 (epoch 171.728) train_loss=286.17816162 time/batch=0.67s
20882/10943 (epoch 171.736) train_loss=150.71971130 time/batch=0.38s
20883/10943 (epoch 171.744) train_loss=273.90130615 time/batch=0.61s
20884/10943 (epoch 171.752) train_loss=287.31692505 time/batch=0.67s
20885/10943 (epoch 171.760) train_loss=286.00906372 time/batch=0.69s
20886/10943 (epoch 171.769) train_loss=269.12753296 time/batch=0.66s
20887/10943 (epoch 171.777) train_loss=280.70672607 time/batch=0.71s
20888/10943 (epoch 171.785) train_loss=364.58923340 time/batch=0.87s
20889/10943 (epoch 171.793) train_loss=219.92784119 time/batch=0.59s
20890/10943 (epoch 171.802) train_loss=411.89715576 time/batch=0.96s
20891/10943 (epoch 171.810) train_loss=239.73799133 time/batch=0.64s
20892/10943 (epoch 171.818) train_loss=342.48126221 time/batch=0.80s
20893/10943 (epoch 171.826) train_loss=349.14767456 time/batch=1.08s
20894/10943 (epoch 171.834) train_loss=340.17315674 time/batch=0.86s
20895/10943 (epoch 171.843) train_loss=231.03359985 time/batch=0.61s
20896/10943 (epoch 171.851) train_loss=247.44674683 time/batch=0.59s
20897/10943 (epoch 171.859) train_loss=339.12603760 time/batch=0.79s
20898/10943 (epoch 171.867) train_loss=316.67834473 time/batch=0.74s
20899/10943 (epoch 171.876) train_loss=330.03057861 time/batch=0.81s
20900/10943 (epoch 171.884) train_loss=189.00627136 time/batch=0.63s
20901/10943 (epoch 171.892) train_loss=271.38085938 time/batch=0.62s
20902/10943 (epoch 171.900) train_loss=279.45269775 time/batch=0.72s
setting learning rate to 0.0008605
20903/10943 (epoch 171.909) train_loss=524.38555908 time/batch=1.09s
20904/10943 (epoch 171.917) train_loss=648.43084717 time/batch=1.47s
20905/10943 (epoch 171.925) train_loss=512.73742676 time/batch=1.08s
20906/10943 (epoch 171.933) train_loss=648.78295898 time/batch=1.34s
20907/10943 (epoch 171.941) train_loss=1049.35217285 time/batch=3.16s
20908/10943 (epoch 171.950) train_loss=218.56706238 time/batch=0.78s
20909/10943 (epoch 171.958) train_loss=244.40333557 time/batch=0.56s
20910/10943 (epoch 171.966) train_loss=104.47708130 time/batch=0.28s
20911/10943 (epoch 171.974) train_loss=501.30175781 time/batch=1.11s
20912/10943 (epoch 171.983) train_loss=180.67431641 time/batch=0.49s
20913/10943 (epoch 171.991) train_loss=322.27722168 time/batch=0.72s
20914/10943 (epoch 171.999) train_loss=332.54571533 time/batch=0.80s
20915/10943 (epoch 172.007) train_loss=777.19659424 time/batch=1.68s
20916/10943 (epoch 172.015) train_loss=164.91452026 time/batch=0.51s
20917/10943 (epoch 172.024) train_loss=211.27714539 time/batch=0.49s
20918/10943 (epoch 172.032) train_loss=188.26513672 time/batch=0.45s
20919/10943 (epoch 172.040) train_loss=535.47033691 time/batch=1.20s
20920/10943 (epoch 172.048) train_loss=684.36242676 time/batch=1.60s
20921/10943 (epoch 172.057) train_loss=164.01623535 time/batch=0.52s
20922/10943 (epoch 172.065) train_loss=473.65975952 time/batch=1.04s
20923/10943 (epoch 172.073) train_loss=171.97419739 time/batch=0.47s
20924/10943 (epoch 172.081) train_loss=211.65460205 time/batch=0.50s
20925/10943 (epoch 172.089) train_loss=325.92587280 time/batch=0.80s
20926/10943 (epoch 172.098) train_loss=242.37300110 time/batch=0.62s
20927/10943 (epoch 172.106) train_loss=333.00640869 time/batch=0.75s
20928/10943 (epoch 172.114) train_loss=598.80792236 time/batch=1.35s
20929/10943 (epoch 172.122) train_loss=428.51763916 time/batch=1.07s
20930/10943 (epoch 172.131) train_loss=475.48800659 time/batch=1.05s
20931/10943 (epoch 172.139) train_loss=295.82104492 time/batch=0.72s
20932/10943 (epoch 172.147) train_loss=148.38827515 time/batch=0.37s
20933/10943 (epoch 172.155) train_loss=465.13400269 time/batch=1.06s
20934/10943 (epoch 172.163) train_loss=253.61213684 time/batch=0.69s
20935/10943 (epoch 172.172) train_loss=412.28082275 time/batch=0.95s
20936/10943 (epoch 172.180) train_loss=119.31266785 time/batch=0.35s
20937/10943 (epoch 172.188) train_loss=125.80624390 time/batch=0.30s
20938/10943 (epoch 172.196) train_loss=178.56369019 time/batch=0.43s
20939/10943 (epoch 172.205) train_loss=207.61135864 time/batch=0.49s
20940/10943 (epoch 172.213) train_loss=183.58757019 time/batch=0.45s
20941/10943 (epoch 172.221) train_loss=194.89093018 time/batch=0.47s
20942/10943 (epoch 172.229) train_loss=481.63861084 time/batch=1.12s
20943/10943 (epoch 172.237) train_loss=213.62200928 time/batch=0.55s
20944/10943 (epoch 172.246) train_loss=126.92134857 time/batch=0.32s
20945/10943 (epoch 172.254) train_loss=135.60148621 time/batch=0.32s
20946/10943 (epoch 172.262) train_loss=434.12667847 time/batch=0.93s
20947/10943 (epoch 172.270) train_loss=239.81140137 time/batch=0.62s
20948/10943 (epoch 172.279) train_loss=163.46685791 time/batch=0.40s
20949/10943 (epoch 172.287) train_loss=183.39770508 time/batch=0.43s
20950/10943 (epoch 172.295) train_loss=149.64376831 time/batch=0.36s
20951/10943 (epoch 172.303) train_loss=314.79235840 time/batch=0.70s
20952/10943 (epoch 172.311) train_loss=287.96850586 time/batch=0.71s
20953/10943 (epoch 172.320) train_loss=336.00982666 time/batch=0.78s
20954/10943 (epoch 172.328) train_loss=469.45593262 time/batch=1.04s
20955/10943 (epoch 172.336) train_loss=311.36224365 time/batch=0.71s
20956/10943 (epoch 172.344) train_loss=196.50402832 time/batch=0.50s
20957/10943 (epoch 172.353) train_loss=263.15802002 time/batch=0.62s
20958/10943 (epoch 172.361) train_loss=200.44622803 time/batch=0.50s
20959/10943 (epoch 172.369) train_loss=234.78739929 time/batch=0.56s
20960/10943 (epoch 172.377) train_loss=507.03039551 time/batch=1.16s
20961/10943 (epoch 172.386) train_loss=234.62902832 time/batch=0.62s
20962/10943 (epoch 172.394) train_loss=319.75912476 time/batch=0.72s
20963/10943 (epoch 172.402) train_loss=351.76666260 time/batch=0.86s
20964/10943 (epoch 172.410) train_loss=130.02239990 time/batch=0.36s
20965/10943 (epoch 172.418) train_loss=280.46484375 time/batch=0.65s
20966/10943 (epoch 172.427) train_loss=310.57385254 time/batch=0.75s
20967/10943 (epoch 172.435) train_loss=380.69610596 time/batch=0.88s
20968/10943 (epoch 172.443) train_loss=338.95718384 time/batch=0.78s
20969/10943 (epoch 172.451) train_loss=155.26843262 time/batch=0.40s
20970/10943 (epoch 172.460) train_loss=141.34197998 time/batch=0.38s
20971/10943 (epoch 172.468) train_loss=182.88555908 time/batch=0.49s
20972/10943 (epoch 172.476) train_loss=164.58137512 time/batch=0.42s
20973/10943 (epoch 172.484) train_loss=208.36454773 time/batch=0.50s
20974/10943 (epoch 172.492) train_loss=283.54666138 time/batch=0.66s
20975/10943 (epoch 172.501) train_loss=259.54714966 time/batch=0.63s
20976/10943 (epoch 172.509) train_loss=322.52514648 time/batch=0.76s
20977/10943 (epoch 172.517) train_loss=221.61943054 time/batch=0.57s
20978/10943 (epoch 172.525) train_loss=388.27502441 time/batch=0.87s
20979/10943 (epoch 172.534) train_loss=383.81347656 time/batch=0.84s
20980/10943 (epoch 172.542) train_loss=290.04769897 time/batch=0.68s
20981/10943 (epoch 172.550) train_loss=313.74212646 time/batch=0.71s
20982/10943 (epoch 172.558) train_loss=232.21029663 time/batch=0.59s
20983/10943 (epoch 172.566) train_loss=388.39376831 time/batch=0.91s
20984/10943 (epoch 172.575) train_loss=411.98901367 time/batch=0.95s
20985/10943 (epoch 172.583) train_loss=496.77612305 time/batch=1.20s
20986/10943 (epoch 172.591) train_loss=371.36871338 time/batch=0.87s
20987/10943 (epoch 172.599) train_loss=259.73492432 time/batch=0.66s
20988/10943 (epoch 172.608) train_loss=515.86791992 time/batch=1.19s
20989/10943 (epoch 172.616) train_loss=293.03967285 time/batch=0.75s
20990/10943 (epoch 172.624) train_loss=403.87896729 time/batch=0.94s
20991/10943 (epoch 172.632) train_loss=350.88430786 time/batch=0.84s
20992/10943 (epoch 172.640) train_loss=340.51470947 time/batch=0.81s
20993/10943 (epoch 172.649) train_loss=280.15927124 time/batch=0.69s
20994/10943 (epoch 172.657) train_loss=247.26635742 time/batch=0.61s
20995/10943 (epoch 172.665) train_loss=246.48449707 time/batch=0.63s
20996/10943 (epoch 172.673) train_loss=391.04840088 time/batch=0.97s
20997/10943 (epoch 172.682) train_loss=394.36660767 time/batch=0.95s
20998/10943 (epoch 172.690) train_loss=320.38577271 time/batch=0.75s
20999/10943 (epoch 172.698) train_loss=285.60556030 time/batch=0.68s
Validating
    loss:	332.622635

21000/10943 (epoch 172.706) train_loss=398.43130493 time/batch=2.76s
21001/10943 (epoch 172.714) train_loss=234.90293884 time/batch=0.59s
21002/10943 (epoch 172.723) train_loss=291.42498779 time/batch=0.69s
21003/10943 (epoch 172.731) train_loss=330.47055054 time/batch=0.80s
21004/10943 (epoch 172.739) train_loss=361.54229736 time/batch=0.85s
21005/10943 (epoch 172.747) train_loss=343.50659180 time/batch=0.81s
21006/10943 (epoch 172.756) train_loss=319.03765869 time/batch=0.79s
21007/10943 (epoch 172.764) train_loss=361.57513428 time/batch=0.85s
21008/10943 (epoch 172.772) train_loss=252.66693115 time/batch=0.62s
21009/10943 (epoch 172.780) train_loss=248.00024414 time/batch=0.59s
21010/10943 (epoch 172.788) train_loss=365.53533936 time/batch=0.84s
21011/10943 (epoch 172.797) train_loss=338.49658203 time/batch=0.83s
21012/10943 (epoch 172.805) train_loss=226.56558228 time/batch=0.58s
21013/10943 (epoch 172.813) train_loss=255.19015503 time/batch=0.59s
21014/10943 (epoch 172.821) train_loss=374.41076660 time/batch=0.88s
21015/10943 (epoch 172.830) train_loss=266.05664062 time/batch=0.65s
21016/10943 (epoch 172.838) train_loss=338.42047119 time/batch=0.83s
21017/10943 (epoch 172.846) train_loss=295.70385742 time/batch=0.73s
21018/10943 (epoch 172.854) train_loss=288.19378662 time/batch=0.71s
21019/10943 (epoch 172.863) train_loss=304.69525146 time/batch=0.83s
21020/10943 (epoch 172.871) train_loss=243.90823364 time/batch=0.63s
21021/10943 (epoch 172.879) train_loss=267.50143433 time/batch=0.64s
21022/10943 (epoch 172.887) train_loss=304.69140625 time/batch=0.72s
21023/10943 (epoch 172.895) train_loss=242.10459900 time/batch=0.62s
setting learning rate to 0.0008347
21024/10943 (epoch 172.904) train_loss=181.88552856 time/batch=0.45s
21025/10943 (epoch 172.912) train_loss=326.26562500 time/batch=0.78s
21026/10943 (epoch 172.920) train_loss=776.87622070 time/batch=1.69s
21027/10943 (epoch 172.928) train_loss=329.64404297 time/batch=0.85s
21028/10943 (epoch 172.937) train_loss=467.72607422 time/batch=0.99s
21029/10943 (epoch 172.945) train_loss=141.49060059 time/batch=0.38s
21030/10943 (epoch 172.953) train_loss=602.53076172 time/batch=1.25s
21031/10943 (epoch 172.961) train_loss=528.04626465 time/batch=1.20s
21032/10943 (epoch 172.969) train_loss=121.64627075 time/batch=0.37s
21033/10943 (epoch 172.978) train_loss=134.12979126 time/batch=0.33s
21034/10943 (epoch 172.986) train_loss=187.50610352 time/batch=0.44s
21035/10943 (epoch 172.994) train_loss=357.03448486 time/batch=0.83s
21036/10943 (epoch 173.002) train_loss=772.30725098 time/batch=1.95s
21037/10943 (epoch 173.011) train_loss=676.64105225 time/batch=1.59s
21038/10943 (epoch 173.019) train_loss=306.51702881 time/batch=0.78s
21039/10943 (epoch 173.027) train_loss=630.08050537 time/batch=2.02s
21040/10943 (epoch 173.035) train_loss=542.57757568 time/batch=1.38s
21041/10943 (epoch 173.043) train_loss=279.92901611 time/batch=0.75s
21042/10943 (epoch 173.052) train_loss=274.70727539 time/batch=0.66s
21043/10943 (epoch 173.060) train_loss=115.55903625 time/batch=0.32s
21044/10943 (epoch 173.068) train_loss=161.03645325 time/batch=0.39s
21045/10943 (epoch 173.076) train_loss=271.88726807 time/batch=0.62s
21046/10943 (epoch 173.085) train_loss=182.51266479 time/batch=0.46s
21047/10943 (epoch 173.093) train_loss=477.19396973 time/batch=1.08s
21048/10943 (epoch 173.101) train_loss=156.69960022 time/batch=0.47s
21049/10943 (epoch 173.109) train_loss=457.71496582 time/batch=1.04s
21050/10943 (epoch 173.117) train_loss=531.63507080 time/batch=1.27s
21051/10943 (epoch 173.126) train_loss=128.18830872 time/batch=0.40s
21052/10943 (epoch 173.134) train_loss=309.39709473 time/batch=0.68s
21053/10943 (epoch 173.142) train_loss=211.39242554 time/batch=0.52s
21054/10943 (epoch 173.150) train_loss=359.39584351 time/batch=0.82s
21055/10943 (epoch 173.159) train_loss=413.36413574 time/batch=0.95s
21056/10943 (epoch 173.167) train_loss=848.75726318 time/batch=3.11s
21057/10943 (epoch 173.175) train_loss=313.25341797 time/batch=0.93s
21058/10943 (epoch 173.183) train_loss=166.03909302 time/batch=0.40s
21059/10943 (epoch 173.191) train_loss=328.72595215 time/batch=0.75s
21060/10943 (epoch 173.200) train_loss=384.98236084 time/batch=0.91s
21061/10943 (epoch 173.208) train_loss=305.95953369 time/batch=0.75s
21062/10943 (epoch 173.216) train_loss=362.62298584 time/batch=0.87s
21063/10943 (epoch 173.224) train_loss=200.10360718 time/batch=0.50s
21064/10943 (epoch 173.233) train_loss=259.64068604 time/batch=0.61s
21065/10943 (epoch 173.241) train_loss=280.79678345 time/batch=0.68s
21066/10943 (epoch 173.249) train_loss=476.33999634 time/batch=1.08s
21067/10943 (epoch 173.257) train_loss=514.52838135 time/batch=1.27s
21068/10943 (epoch 173.265) train_loss=498.05670166 time/batch=1.17s
21069/10943 (epoch 173.274) train_loss=252.03256226 time/batch=0.65s
21070/10943 (epoch 173.282) train_loss=167.86943054 time/batch=0.43s
21071/10943 (epoch 173.290) train_loss=287.58502197 time/batch=0.67s
21072/10943 (epoch 173.298) train_loss=147.43429565 time/batch=0.39s
21073/10943 (epoch 173.307) train_loss=387.21942139 time/batch=0.92s
21074/10943 (epoch 173.315) train_loss=359.68399048 time/batch=0.89s
21075/10943 (epoch 173.323) train_loss=146.13180542 time/batch=0.40s
21076/10943 (epoch 173.331) train_loss=184.47421265 time/batch=0.44s
21077/10943 (epoch 173.340) train_loss=211.54615784 time/batch=0.53s
21078/10943 (epoch 173.348) train_loss=344.15850830 time/batch=0.80s
21079/10943 (epoch 173.356) train_loss=254.49774170 time/batch=0.63s
21080/10943 (epoch 173.364) train_loss=206.43295288 time/batch=0.52s
21081/10943 (epoch 173.372) train_loss=429.76879883 time/batch=0.94s
21082/10943 (epoch 173.381) train_loss=324.66632080 time/batch=0.83s
21083/10943 (epoch 173.389) train_loss=311.59185791 time/batch=0.77s
21084/10943 (epoch 173.397) train_loss=202.76828003 time/batch=0.52s
21085/10943 (epoch 173.405) train_loss=380.44073486 time/batch=0.87s
21086/10943 (epoch 173.414) train_loss=171.45758057 time/batch=0.44s
21087/10943 (epoch 173.422) train_loss=192.79278564 time/batch=0.46s
21088/10943 (epoch 173.430) train_loss=346.08279419 time/batch=0.81s
21089/10943 (epoch 173.438) train_loss=347.52941895 time/batch=0.80s
21090/10943 (epoch 173.446) train_loss=424.43756104 time/batch=0.99s
21091/10943 (epoch 173.455) train_loss=475.39196777 time/batch=1.18s
21092/10943 (epoch 173.463) train_loss=266.03533936 time/batch=0.69s
21093/10943 (epoch 173.471) train_loss=226.37045288 time/batch=0.56s
21094/10943 (epoch 173.479) train_loss=220.72119141 time/batch=0.55s
21095/10943 (epoch 173.488) train_loss=188.30455017 time/batch=0.48s
21096/10943 (epoch 173.496) train_loss=454.20523071 time/batch=0.99s
21097/10943 (epoch 173.504) train_loss=402.92941284 time/batch=0.95s
21098/10943 (epoch 173.512) train_loss=340.81381226 time/batch=0.84s
21099/10943 (epoch 173.520) train_loss=140.70443726 time/batch=0.38s
21100/10943 (epoch 173.529) train_loss=241.06924438 time/batch=0.57s
21101/10943 (epoch 173.537) train_loss=198.43652344 time/batch=0.50s
21102/10943 (epoch 173.545) train_loss=300.92129517 time/batch=0.71s
21103/10943 (epoch 173.553) train_loss=224.01892090 time/batch=0.56s
21104/10943 (epoch 173.562) train_loss=203.31031799 time/batch=0.53s
21105/10943 (epoch 173.570) train_loss=176.34341431 time/batch=0.48s
21106/10943 (epoch 173.578) train_loss=216.83209229 time/batch=0.53s
21107/10943 (epoch 173.586) train_loss=109.69897461 time/batch=0.33s
21108/10943 (epoch 173.594) train_loss=279.92767334 time/batch=0.65s
21109/10943 (epoch 173.603) train_loss=323.40319824 time/batch=0.81s
21110/10943 (epoch 173.611) train_loss=242.04655457 time/batch=0.63s
21111/10943 (epoch 173.619) train_loss=313.87994385 time/batch=0.74s
21112/10943 (epoch 173.627) train_loss=292.41790771 time/batch=0.72s
21113/10943 (epoch 173.636) train_loss=301.29162598 time/batch=0.73s
21114/10943 (epoch 173.644) train_loss=395.56707764 time/batch=0.92s
21115/10943 (epoch 173.652) train_loss=365.93521118 time/batch=0.86s
21116/10943 (epoch 173.660) train_loss=421.16595459 time/batch=1.01s
21117/10943 (epoch 173.668) train_loss=276.07733154 time/batch=0.69s
21118/10943 (epoch 173.677) train_loss=152.75245667 time/batch=0.43s
21119/10943 (epoch 173.685) train_loss=237.01770020 time/batch=0.58s
21120/10943 (epoch 173.693) train_loss=427.33276367 time/batch=1.00s
21121/10943 (epoch 173.701) train_loss=323.27127075 time/batch=0.80s
21122/10943 (epoch 173.710) train_loss=312.56811523 time/batch=0.75s
21123/10943 (epoch 173.718) train_loss=236.67117310 time/batch=0.61s
21124/10943 (epoch 173.726) train_loss=237.61508179 time/batch=0.62s
21125/10943 (epoch 173.734) train_loss=299.58615112 time/batch=0.74s
21126/10943 (epoch 173.742) train_loss=249.66731262 time/batch=0.61s
21127/10943 (epoch 173.751) train_loss=367.08325195 time/batch=0.85s
21128/10943 (epoch 173.759) train_loss=261.33465576 time/batch=0.65s
21129/10943 (epoch 173.767) train_loss=333.36926270 time/batch=0.83s
21130/10943 (epoch 173.775) train_loss=243.86720276 time/batch=0.63s
21131/10943 (epoch 173.784) train_loss=277.76391602 time/batch=0.67s
21132/10943 (epoch 173.792) train_loss=190.26309204 time/batch=0.50s
21133/10943 (epoch 173.800) train_loss=325.75598145 time/batch=0.84s
21134/10943 (epoch 173.808) train_loss=283.13317871 time/batch=0.73s
21135/10943 (epoch 173.816) train_loss=182.96546936 time/batch=0.55s
21136/10943 (epoch 173.825) train_loss=395.38534546 time/batch=1.00s
21137/10943 (epoch 173.833) train_loss=276.33230591 time/batch=0.70s
21138/10943 (epoch 173.841) train_loss=226.61090088 time/batch=0.57s
21139/10943 (epoch 173.849) train_loss=366.06494141 time/batch=1.00s
21140/10943 (epoch 173.858) train_loss=245.48202515 time/batch=0.67s
21141/10943 (epoch 173.866) train_loss=310.53155518 time/batch=0.76s
21142/10943 (epoch 173.874) train_loss=326.67047119 time/batch=0.81s
21143/10943 (epoch 173.882) train_loss=247.39453125 time/batch=0.64s
21144/10943 (epoch 173.891) train_loss=270.33026123 time/batch=0.78s
setting learning rate to 0.0008097
21145/10943 (epoch 173.899) train_loss=559.51873779 time/batch=1.26s
21146/10943 (epoch 173.907) train_loss=921.42102051 time/batch=2.25s
21147/10943 (epoch 173.915) train_loss=111.66315460 time/batch=0.45s
21148/10943 (epoch 173.923) train_loss=120.67816925 time/batch=0.29s
21149/10943 (epoch 173.932) train_loss=335.35452271 time/batch=0.75s
21150/10943 (epoch 173.940) train_loss=209.76071167 time/batch=0.53s
21151/10943 (epoch 173.948) train_loss=169.37074280 time/batch=0.41s
21152/10943 (epoch 173.956) train_loss=585.64294434 time/batch=1.26s
21153/10943 (epoch 173.965) train_loss=456.81500244 time/batch=1.06s
21154/10943 (epoch 173.973) train_loss=479.86029053 time/batch=1.18s
21155/10943 (epoch 173.981) train_loss=326.68334961 time/batch=0.86s
21156/10943 (epoch 173.989) train_loss=680.37829590 time/batch=1.57s
21157/10943 (epoch 173.997) train_loss=263.12719727 time/batch=0.73s
21158/10943 (epoch 174.006) train_loss=400.05560303 time/batch=0.95s
21159/10943 (epoch 174.014) train_loss=271.15130615 time/batch=0.69s
21160/10943 (epoch 174.022) train_loss=310.22052002 time/batch=0.74s
21161/10943 (epoch 174.030) train_loss=325.85449219 time/batch=0.81s
21162/10943 (epoch 174.039) train_loss=469.69921875 time/batch=1.09s
21163/10943 (epoch 174.047) train_loss=151.92781067 time/batch=0.44s
21164/10943 (epoch 174.055) train_loss=307.28375244 time/batch=0.70s
21165/10943 (epoch 174.063) train_loss=333.92291260 time/batch=0.83s
21166/10943 (epoch 174.071) train_loss=147.11090088 time/batch=0.44s
21167/10943 (epoch 174.080) train_loss=279.00198364 time/batch=0.65s
21168/10943 (epoch 174.088) train_loss=206.95291138 time/batch=0.54s
21169/10943 (epoch 174.096) train_loss=580.23571777 time/batch=1.34s
21170/10943 (epoch 174.104) train_loss=295.81378174 time/batch=0.82s
21171/10943 (epoch 174.113) train_loss=324.92163086 time/batch=0.83s
21172/10943 (epoch 174.121) train_loss=425.37863159 time/batch=0.96s
21173/10943 (epoch 174.129) train_loss=783.48016357 time/batch=2.33s
21174/10943 (epoch 174.137) train_loss=233.89540100 time/batch=0.69s
21175/10943 (epoch 174.145) train_loss=581.05755615 time/batch=1.28s
21176/10943 (epoch 174.154) train_loss=180.43652344 time/batch=0.53s
21177/10943 (epoch 174.162) train_loss=123.04371643 time/batch=0.31s
21178/10943 (epoch 174.170) train_loss=455.60958862 time/batch=1.05s
21179/10943 (epoch 174.178) train_loss=410.93338013 time/batch=1.04s
21180/10943 (epoch 174.187) train_loss=314.99194336 time/batch=0.75s
21181/10943 (epoch 174.195) train_loss=525.60729980 time/batch=1.20s
21182/10943 (epoch 174.203) train_loss=464.94531250 time/batch=1.09s
21183/10943 (epoch 174.211) train_loss=473.55792236 time/batch=1.05s
21184/10943 (epoch 174.219) train_loss=146.37216187 time/batch=0.42s
21185/10943 (epoch 174.228) train_loss=160.16458130 time/batch=0.38s
21186/10943 (epoch 174.236) train_loss=480.05242920 time/batch=1.12s
21187/10943 (epoch 174.244) train_loss=370.29296875 time/batch=0.93s
21188/10943 (epoch 174.252) train_loss=144.93304443 time/batch=0.40s
21189/10943 (epoch 174.261) train_loss=205.41271973 time/batch=0.51s
21190/10943 (epoch 174.269) train_loss=272.30688477 time/batch=0.68s
21191/10943 (epoch 174.277) train_loss=617.90429688 time/batch=3.08s
21192/10943 (epoch 174.285) train_loss=311.22741699 time/batch=0.99s
21193/10943 (epoch 174.293) train_loss=277.60726929 time/batch=0.67s
21194/10943 (epoch 174.302) train_loss=225.37335205 time/batch=0.57s
21195/10943 (epoch 174.310) train_loss=284.73663330 time/batch=0.69s
21196/10943 (epoch 174.318) train_loss=228.68005371 time/batch=0.55s
21197/10943 (epoch 174.326) train_loss=251.37686157 time/batch=0.62s
21198/10943 (epoch 174.335) train_loss=377.77655029 time/batch=0.91s
21199/10943 (epoch 174.343) train_loss=237.40844727 time/batch=0.61s
21200/10943 (epoch 174.351) train_loss=187.16494751 time/batch=0.44s
21201/10943 (epoch 174.359) train_loss=241.19448853 time/batch=0.60s
21202/10943 (epoch 174.368) train_loss=243.95034790 time/batch=0.62s
21203/10943 (epoch 174.376) train_loss=141.05650330 time/batch=0.37s
21204/10943 (epoch 174.384) train_loss=314.00787354 time/batch=0.74s
21205/10943 (epoch 174.392) train_loss=257.19158936 time/batch=0.65s
21206/10943 (epoch 174.400) train_loss=323.69528198 time/batch=0.76s
21207/10943 (epoch 174.409) train_loss=261.73559570 time/batch=0.66s
21208/10943 (epoch 174.417) train_loss=421.84313965 time/batch=0.99s
21209/10943 (epoch 174.425) train_loss=337.46539307 time/batch=0.85s
21210/10943 (epoch 174.433) train_loss=248.38446045 time/batch=0.63s
21211/10943 (epoch 174.442) train_loss=160.73753357 time/batch=0.42s
21212/10943 (epoch 174.450) train_loss=164.40728760 time/batch=0.42s
21213/10943 (epoch 174.458) train_loss=276.33776855 time/batch=0.66s
21214/10943 (epoch 174.466) train_loss=354.77142334 time/batch=0.84s
21215/10943 (epoch 174.474) train_loss=280.49719238 time/batch=0.70s
21216/10943 (epoch 174.483) train_loss=459.26559448 time/batch=1.07s
21217/10943 (epoch 174.491) train_loss=248.71078491 time/batch=0.68s
21218/10943 (epoch 174.499) train_loss=229.67379761 time/batch=0.57s
21219/10943 (epoch 174.507) train_loss=124.04888916 time/batch=0.33s
21220/10943 (epoch 174.516) train_loss=387.63549805 time/batch=0.87s
21221/10943 (epoch 174.524) train_loss=329.57403564 time/batch=0.80s
21222/10943 (epoch 174.532) train_loss=208.24118042 time/batch=0.57s
21223/10943 (epoch 174.540) train_loss=381.00744629 time/batch=0.87s
21224/10943 (epoch 174.548) train_loss=225.29702759 time/batch=0.59s
21225/10943 (epoch 174.557) train_loss=345.18548584 time/batch=0.82s
21226/10943 (epoch 174.565) train_loss=233.61810303 time/batch=0.63s
21227/10943 (epoch 174.573) train_loss=183.71295166 time/batch=0.46s
21228/10943 (epoch 174.581) train_loss=271.58386230 time/batch=0.67s
21229/10943 (epoch 174.590) train_loss=272.18133545 time/batch=0.66s
21230/10943 (epoch 174.598) train_loss=138.39501953 time/batch=0.39s
21231/10943 (epoch 174.606) train_loss=192.36077881 time/batch=0.46s
21232/10943 (epoch 174.614) train_loss=187.80819702 time/batch=0.47s
21233/10943 (epoch 174.622) train_loss=312.82971191 time/batch=0.78s
21234/10943 (epoch 174.631) train_loss=355.75482178 time/batch=0.87s
21235/10943 (epoch 174.639) train_loss=373.45538330 time/batch=0.90s
21236/10943 (epoch 174.647) train_loss=130.72776794 time/batch=0.35s
21237/10943 (epoch 174.655) train_loss=348.61599731 time/batch=0.82s
21238/10943 (epoch 174.664) train_loss=158.02947998 time/batch=0.46s
21239/10943 (epoch 174.672) train_loss=241.45193481 time/batch=0.58s
21240/10943 (epoch 174.680) train_loss=385.93881226 time/batch=0.90s
21241/10943 (epoch 174.688) train_loss=394.80706787 time/batch=0.96s
21242/10943 (epoch 174.696) train_loss=435.78540039 time/batch=1.13s
21243/10943 (epoch 174.705) train_loss=327.13983154 time/batch=0.75s
21244/10943 (epoch 174.713) train_loss=432.58526611 time/batch=1.10s
21245/10943 (epoch 174.721) train_loss=331.84466553 time/batch=0.87s
21246/10943 (epoch 174.729) train_loss=305.05975342 time/batch=0.76s
21247/10943 (epoch 174.738) train_loss=231.79956055 time/batch=0.60s
21248/10943 (epoch 174.746) train_loss=248.23901367 time/batch=0.60s
21249/10943 (epoch 174.754) train_loss=250.57336426 time/batch=0.64s
21250/10943 (epoch 174.762) train_loss=345.04122925 time/batch=0.83s
21251/10943 (epoch 174.770) train_loss=225.83911133 time/batch=0.61s
21252/10943 (epoch 174.779) train_loss=274.23596191 time/batch=0.70s
21253/10943 (epoch 174.787) train_loss=193.81277466 time/batch=0.51s
21254/10943 (epoch 174.795) train_loss=167.72096252 time/batch=0.45s
21255/10943 (epoch 174.803) train_loss=324.95623779 time/batch=0.79s
21256/10943 (epoch 174.812) train_loss=278.32012939 time/batch=0.71s
21257/10943 (epoch 174.820) train_loss=205.75173950 time/batch=0.52s
21258/10943 (epoch 174.828) train_loss=242.35769653 time/batch=0.59s
21259/10943 (epoch 174.836) train_loss=302.26605225 time/batch=0.75s
21260/10943 (epoch 174.845) train_loss=239.86874390 time/batch=0.62s
21261/10943 (epoch 174.853) train_loss=335.40487671 time/batch=0.81s
21262/10943 (epoch 174.861) train_loss=184.87802124 time/batch=0.50s
21263/10943 (epoch 174.869) train_loss=201.06512451 time/batch=0.49s
21264/10943 (epoch 174.877) train_loss=287.80694580 time/batch=0.70s
21265/10943 (epoch 174.886) train_loss=280.93066406 time/batch=0.74s
setting learning rate to 0.0007854
  saved to metadata/gru_no_dropout-9_nov_folkwiki-20181115-214759_epoch64.pkl
21266/10943 (epoch 174.894) train_loss=425.77130127 time/batch=1.02s
21267/10943 (epoch 174.902) train_loss=784.04266357 time/batch=1.71s
21268/10943 (epoch 174.910) train_loss=522.64685059 time/batch=1.21s
21269/10943 (epoch 174.919) train_loss=1017.60522461 time/batch=3.14s
21270/10943 (epoch 174.927) train_loss=289.82354736 time/batch=0.95s
21271/10943 (epoch 174.935) train_loss=605.92877197 time/batch=1.28s
21272/10943 (epoch 174.943) train_loss=627.93212891 time/batch=1.56s
21273/10943 (epoch 174.951) train_loss=113.64176941 time/batch=0.41s
21274/10943 (epoch 174.960) train_loss=279.80114746 time/batch=0.65s
21275/10943 (epoch 174.968) train_loss=128.18550110 time/batch=0.34s
21276/10943 (epoch 174.976) train_loss=254.44366455 time/batch=0.60s
21277/10943 (epoch 174.984) train_loss=444.52978516 time/batch=1.03s
21278/10943 (epoch 174.993) train_loss=282.77331543 time/batch=0.74s
21279/10943 (epoch 175.001) train_loss=134.50039673 time/batch=0.36s
21280/10943 (epoch 175.009) train_loss=277.09710693 time/batch=0.66s
21281/10943 (epoch 175.017) train_loss=389.21929932 time/batch=0.88s
21282/10943 (epoch 175.025) train_loss=320.70397949 time/batch=0.79s
21283/10943 (epoch 175.034) train_loss=349.64294434 time/batch=0.86s
21284/10943 (epoch 175.042) train_loss=476.23254395 time/batch=1.16s
21285/10943 (epoch 175.050) train_loss=451.54302979 time/batch=1.11s
21286/10943 (epoch 175.058) train_loss=170.52447510 time/batch=0.49s
21287/10943 (epoch 175.067) train_loss=521.09008789 time/batch=1.19s
21288/10943 (epoch 175.075) train_loss=280.05688477 time/batch=0.74s
21289/10943 (epoch 175.083) train_loss=630.74328613 time/batch=1.52s
21290/10943 (epoch 175.091) train_loss=203.54101562 time/batch=0.61s
21291/10943 (epoch 175.099) train_loss=303.15100098 time/batch=0.69s
21292/10943 (epoch 175.108) train_loss=527.12573242 time/batch=1.19s
21293/10943 (epoch 175.116) train_loss=303.97817993 time/batch=0.78s
21294/10943 (epoch 175.124) train_loss=126.35115051 time/batch=0.34s
21295/10943 (epoch 175.132) train_loss=144.73104858 time/batch=0.33s
21296/10943 (epoch 175.141) train_loss=488.81970215 time/batch=1.11s
21297/10943 (epoch 175.149) train_loss=174.14108276 time/batch=0.50s
21298/10943 (epoch 175.157) train_loss=597.18170166 time/batch=1.51s
21299/10943 (epoch 175.165) train_loss=264.37591553 time/batch=0.72s
21300/10943 (epoch 175.173) train_loss=410.64611816 time/batch=0.94s
21301/10943 (epoch 175.182) train_loss=324.37750244 time/batch=0.85s
21302/10943 (epoch 175.190) train_loss=229.92698669 time/batch=0.58s
21303/10943 (epoch 175.198) train_loss=195.16253662 time/batch=0.49s
21304/10943 (epoch 175.206) train_loss=308.49389648 time/batch=0.73s
21305/10943 (epoch 175.215) train_loss=466.60583496 time/batch=1.09s
21306/10943 (epoch 175.223) train_loss=309.10949707 time/batch=0.76s
21307/10943 (epoch 175.231) train_loss=499.11853027 time/batch=1.16s
21308/10943 (epoch 175.239) train_loss=190.19689941 time/batch=0.54s
21309/10943 (epoch 175.247) train_loss=100.42532349 time/batch=0.32s
21310/10943 (epoch 175.256) train_loss=311.31335449 time/batch=0.74s
21311/10943 (epoch 175.264) train_loss=237.88888550 time/batch=0.63s
21312/10943 (epoch 175.272) train_loss=119.48037720 time/batch=0.33s
21313/10943 (epoch 175.280) train_loss=367.68847656 time/batch=0.82s
21314/10943 (epoch 175.289) train_loss=294.21411133 time/batch=0.75s
21315/10943 (epoch 175.297) train_loss=414.92428589 time/batch=0.98s
21316/10943 (epoch 175.305) train_loss=179.82603455 time/batch=0.48s
21317/10943 (epoch 175.313) train_loss=256.85278320 time/batch=0.61s
21318/10943 (epoch 175.322) train_loss=175.09066772 time/batch=0.46s
21319/10943 (epoch 175.330) train_loss=377.41845703 time/batch=0.89s
21320/10943 (epoch 175.338) train_loss=323.30163574 time/batch=0.83s
21321/10943 (epoch 175.346) train_loss=279.15206909 time/batch=0.67s
21322/10943 (epoch 175.354) train_loss=316.19699097 time/batch=0.73s
21323/10943 (epoch 175.363) train_loss=208.57635498 time/batch=0.53s
21324/10943 (epoch 175.371) train_loss=150.59196472 time/batch=0.39s
21325/10943 (epoch 175.379) train_loss=175.69879150 time/batch=0.43s
21326/10943 (epoch 175.387) train_loss=260.07189941 time/batch=0.62s
21327/10943 (epoch 175.396) train_loss=384.64721680 time/batch=0.92s
21328/10943 (epoch 175.404) train_loss=371.12982178 time/batch=0.88s
21329/10943 (epoch 175.412) train_loss=477.36303711 time/batch=1.04s
21330/10943 (epoch 175.420) train_loss=362.42724609 time/batch=0.89s
21331/10943 (epoch 175.428) train_loss=241.00708008 time/batch=0.61s
21332/10943 (epoch 175.437) train_loss=349.39309692 time/batch=0.81s
21333/10943 (epoch 175.445) train_loss=143.23947144 time/batch=0.41s
21334/10943 (epoch 175.453) train_loss=398.05267334 time/batch=0.95s
21335/10943 (epoch 175.461) train_loss=186.87719727 time/batch=0.52s
21336/10943 (epoch 175.470) train_loss=251.38980103 time/batch=0.60s
21337/10943 (epoch 175.478) train_loss=142.68620300 time/batch=0.37s
21338/10943 (epoch 175.486) train_loss=219.50209045 time/batch=0.53s
21339/10943 (epoch 175.494) train_loss=458.00360107 time/batch=1.22s
21340/10943 (epoch 175.502) train_loss=241.22265625 time/batch=0.67s
21341/10943 (epoch 175.511) train_loss=226.65614319 time/batch=0.55s
21342/10943 (epoch 175.519) train_loss=235.50753784 time/batch=0.61s
21343/10943 (epoch 175.527) train_loss=203.02302551 time/batch=0.53s
21344/10943 (epoch 175.535) train_loss=281.03359985 time/batch=0.70s
21345/10943 (epoch 175.544) train_loss=296.64562988 time/batch=0.74s
21346/10943 (epoch 175.552) train_loss=228.03387451 time/batch=0.58s
21347/10943 (epoch 175.560) train_loss=276.27087402 time/batch=0.65s
21348/10943 (epoch 175.568) train_loss=351.05438232 time/batch=0.82s
21349/10943 (epoch 175.576) train_loss=195.56329346 time/batch=0.49s
21350/10943 (epoch 175.585) train_loss=153.29443359 time/batch=0.37s
21351/10943 (epoch 175.593) train_loss=191.63110352 time/batch=0.47s
21352/10943 (epoch 175.601) train_loss=318.30438232 time/batch=0.77s
21353/10943 (epoch 175.609) train_loss=301.97833252 time/batch=0.77s
21354/10943 (epoch 175.618) train_loss=323.44403076 time/batch=0.79s
21355/10943 (epoch 175.626) train_loss=289.72439575 time/batch=0.68s
21356/10943 (epoch 175.634) train_loss=301.12475586 time/batch=0.76s
21357/10943 (epoch 175.642) train_loss=215.88049316 time/batch=0.54s
21358/10943 (epoch 175.650) train_loss=299.82736206 time/batch=0.72s
21359/10943 (epoch 175.659) train_loss=162.54748535 time/batch=0.42s
21360/10943 (epoch 175.667) train_loss=242.93334961 time/batch=0.58s
21361/10943 (epoch 175.675) train_loss=434.24725342 time/batch=0.98s
21362/10943 (epoch 175.683) train_loss=277.22915649 time/batch=0.71s
21363/10943 (epoch 175.692) train_loss=243.13092041 time/batch=0.61s
21364/10943 (epoch 175.700) train_loss=208.30046082 time/batch=0.51s
21365/10943 (epoch 175.708) train_loss=371.17205811 time/batch=0.87s
21366/10943 (epoch 175.716) train_loss=219.82168579 time/batch=0.59s
21367/10943 (epoch 175.724) train_loss=317.25061035 time/batch=0.78s
21368/10943 (epoch 175.733) train_loss=384.23150635 time/batch=0.95s
21369/10943 (epoch 175.741) train_loss=377.09399414 time/batch=0.92s
21370/10943 (epoch 175.749) train_loss=338.65399170 time/batch=0.85s
21371/10943 (epoch 175.757) train_loss=376.12927246 time/batch=0.95s
21372/10943 (epoch 175.766) train_loss=145.89178467 time/batch=0.41s
21373/10943 (epoch 175.774) train_loss=316.74694824 time/batch=0.75s
21374/10943 (epoch 175.782) train_loss=347.60647583 time/batch=0.86s
21375/10943 (epoch 175.790) train_loss=165.83239746 time/batch=0.47s
21376/10943 (epoch 175.799) train_loss=199.55235291 time/batch=0.50s
21377/10943 (epoch 175.807) train_loss=241.68516541 time/batch=0.62s
21378/10943 (epoch 175.815) train_loss=308.86044312 time/batch=0.80s
21379/10943 (epoch 175.823) train_loss=358.60238647 time/batch=1.00s
21380/10943 (epoch 175.831) train_loss=240.89552307 time/batch=0.70s
21381/10943 (epoch 175.840) train_loss=239.63954163 time/batch=0.60s
21382/10943 (epoch 175.848) train_loss=332.82635498 time/batch=0.79s
21383/10943 (epoch 175.856) train_loss=192.01211548 time/batch=0.56s
21384/10943 (epoch 175.864) train_loss=275.17019653 time/batch=0.67s
21385/10943 (epoch 175.873) train_loss=241.38003540 time/batch=0.59s
21386/10943 (epoch 175.881) train_loss=260.19232178 time/batch=0.75s
setting learning rate to 0.0007618
21387/10943 (epoch 175.889) train_loss=270.68218994 time/batch=0.71s
21388/10943 (epoch 175.897) train_loss=224.95584106 time/batch=0.60s
21389/10943 (epoch 175.905) train_loss=591.98504639 time/batch=1.29s
21390/10943 (epoch 175.914) train_loss=1029.51489258 time/batch=3.17s
21391/10943 (epoch 175.922) train_loss=533.12377930 time/batch=1.39s
21392/10943 (epoch 175.930) train_loss=801.16687012 time/batch=1.73s
21393/10943 (epoch 175.938) train_loss=454.04156494 time/batch=1.08s
21394/10943 (epoch 175.947) train_loss=277.83599854 time/batch=0.70s
21395/10943 (epoch 175.955) train_loss=110.21493530 time/batch=0.31s
21396/10943 (epoch 175.963) train_loss=576.33715820 time/batch=1.32s
21397/10943 (epoch 175.971) train_loss=408.20404053 time/batch=1.04s
21398/10943 (epoch 175.979) train_loss=102.41207123 time/batch=0.35s
21399/10943 (epoch 175.988) train_loss=181.62722778 time/batch=0.45s
21400/10943 (epoch 175.996) train_loss=464.56082153 time/batch=1.11s
21401/10943 (epoch 176.004) train_loss=389.39434814 time/batch=0.97s
21402/10943 (epoch 176.012) train_loss=648.84265137 time/batch=1.56s
21403/10943 (epoch 176.021) train_loss=458.04800415 time/batch=1.15s
21404/10943 (epoch 176.029) train_loss=319.58200073 time/batch=0.85s
21405/10943 (epoch 176.037) train_loss=180.74818420 time/batch=0.48s
21406/10943 (epoch 176.045) train_loss=278.10583496 time/batch=0.65s
21407/10943 (epoch 176.053) train_loss=480.50219727 time/batch=1.15s
21408/10943 (epoch 176.062) train_loss=301.98309326 time/batch=0.79s
21409/10943 (epoch 176.070) train_loss=578.53710938 time/batch=1.68s
21410/10943 (epoch 176.078) train_loss=135.12921143 time/batch=0.46s
21411/10943 (epoch 176.086) train_loss=180.60182190 time/batch=0.42s
21412/10943 (epoch 176.095) train_loss=269.90515137 time/batch=0.64s
21413/10943 (epoch 176.103) train_loss=382.28344727 time/batch=0.90s
21414/10943 (epoch 176.111) train_loss=351.82153320 time/batch=0.89s
21415/10943 (epoch 176.119) train_loss=263.55676270 time/batch=0.67s
21416/10943 (epoch 176.127) train_loss=407.11151123 time/batch=1.00s
21417/10943 (epoch 176.136) train_loss=467.80499268 time/batch=1.13s
21418/10943 (epoch 176.144) train_loss=183.86859131 time/batch=0.51s
21419/10943 (epoch 176.152) train_loss=190.63385010 time/batch=0.47s
21420/10943 (epoch 176.160) train_loss=539.56958008 time/batch=1.17s
21421/10943 (epoch 176.169) train_loss=361.26977539 time/batch=0.91s
21422/10943 (epoch 176.177) train_loss=235.67185974 time/batch=0.61s
21423/10943 (epoch 176.185) train_loss=145.79446411 time/batch=0.35s
21424/10943 (epoch 176.193) train_loss=270.64147949 time/batch=0.68s
21425/10943 (epoch 176.201) train_loss=197.22563171 time/batch=0.51s
21426/10943 (epoch 176.210) train_loss=318.74911499 time/batch=0.79s
21427/10943 (epoch 176.218) train_loss=236.58374023 time/batch=0.65s
21428/10943 (epoch 176.226) train_loss=398.94812012 time/batch=0.96s
21429/10943 (epoch 176.234) train_loss=293.82855225 time/batch=0.75s
21430/10943 (epoch 176.243) train_loss=257.67581177 time/batch=0.66s
21431/10943 (epoch 176.251) train_loss=228.67706299 time/batch=0.58s
21432/10943 (epoch 176.259) train_loss=483.21200562 time/batch=1.15s
21433/10943 (epoch 176.267) train_loss=312.84106445 time/batch=0.81s
21434/10943 (epoch 176.276) train_loss=322.34982300 time/batch=0.80s
21435/10943 (epoch 176.284) train_loss=149.82775879 time/batch=0.39s
21436/10943 (epoch 176.292) train_loss=457.12036133 time/batch=1.18s
21437/10943 (epoch 176.300) train_loss=448.34487915 time/batch=1.08s
21438/10943 (epoch 176.308) train_loss=315.66476440 time/batch=0.79s
21439/10943 (epoch 176.317) train_loss=467.96881104 time/batch=1.21s
21440/10943 (epoch 176.325) train_loss=172.15481567 time/batch=0.51s
21441/10943 (epoch 176.333) train_loss=200.19749451 time/batch=0.48s
21442/10943 (epoch 176.341) train_loss=197.79962158 time/batch=0.50s
21443/10943 (epoch 176.350) train_loss=252.25570679 time/batch=0.62s
21444/10943 (epoch 176.358) train_loss=495.70455933 time/batch=1.23s
21445/10943 (epoch 176.366) train_loss=335.47277832 time/batch=0.86s
21446/10943 (epoch 176.374) train_loss=242.17196655 time/batch=0.63s
21447/10943 (epoch 176.382) train_loss=406.03698730 time/batch=0.93s
21448/10943 (epoch 176.391) train_loss=205.78695679 time/batch=0.57s
21449/10943 (epoch 176.399) train_loss=274.12713623 time/batch=0.64s
21450/10943 (epoch 176.407) train_loss=273.27111816 time/batch=0.68s
21451/10943 (epoch 176.415) train_loss=171.42926025 time/batch=0.47s
21452/10943 (epoch 176.424) train_loss=388.57598877 time/batch=0.85s
21453/10943 (epoch 176.432) train_loss=226.04183960 time/batch=0.61s
21454/10943 (epoch 176.440) train_loss=182.77426147 time/batch=0.47s
21455/10943 (epoch 176.448) train_loss=265.32058716 time/batch=0.64s
21456/10943 (epoch 176.456) train_loss=205.65386963 time/batch=0.55s
21457/10943 (epoch 176.465) train_loss=117.59710693 time/batch=0.33s
21458/10943 (epoch 176.473) train_loss=359.29321289 time/batch=0.88s
21459/10943 (epoch 176.481) train_loss=283.61453247 time/batch=0.73s
21460/10943 (epoch 176.489) train_loss=147.22901917 time/batch=0.38s
21461/10943 (epoch 176.498) train_loss=310.59033203 time/batch=0.75s
21462/10943 (epoch 176.506) train_loss=295.13342285 time/batch=0.72s
21463/10943 (epoch 176.514) train_loss=320.52569580 time/batch=0.80s
21464/10943 (epoch 176.522) train_loss=365.51995850 time/batch=0.89s
21465/10943 (epoch 176.530) train_loss=226.21987915 time/batch=0.58s
21466/10943 (epoch 176.539) train_loss=249.92413330 time/batch=0.60s
21467/10943 (epoch 176.547) train_loss=207.59680176 time/batch=0.51s
21468/10943 (epoch 176.555) train_loss=146.74923706 time/batch=0.39s
21469/10943 (epoch 176.563) train_loss=220.15640259 time/batch=0.54s
21470/10943 (epoch 176.572) train_loss=231.55123901 time/batch=0.57s
21471/10943 (epoch 176.580) train_loss=133.55160522 time/batch=0.34s
21472/10943 (epoch 176.588) train_loss=124.00881195 time/batch=0.35s
21473/10943 (epoch 176.596) train_loss=244.88160706 time/batch=0.59s
21474/10943 (epoch 176.604) train_loss=125.29025269 time/batch=0.38s
21475/10943 (epoch 176.613) train_loss=204.72633362 time/batch=0.50s
21476/10943 (epoch 176.621) train_loss=377.38571167 time/batch=0.96s
21477/10943 (epoch 176.629) train_loss=168.25619507 time/batch=0.46s
21478/10943 (epoch 176.637) train_loss=236.45339966 time/batch=0.56s
21479/10943 (epoch 176.646) train_loss=247.65617371 time/batch=0.60s
21480/10943 (epoch 176.654) train_loss=351.83905029 time/batch=0.81s
21481/10943 (epoch 176.662) train_loss=169.98130798 time/batch=0.45s
21482/10943 (epoch 176.670) train_loss=308.77447510 time/batch=0.73s
21483/10943 (epoch 176.678) train_loss=294.75897217 time/batch=0.75s
21484/10943 (epoch 176.687) train_loss=244.11274719 time/batch=0.64s
21485/10943 (epoch 176.695) train_loss=372.01129150 time/batch=0.92s
21486/10943 (epoch 176.703) train_loss=223.29496765 time/batch=0.59s
21487/10943 (epoch 176.711) train_loss=330.11248779 time/batch=0.81s
21488/10943 (epoch 176.720) train_loss=239.83834839 time/batch=0.64s
21489/10943 (epoch 176.728) train_loss=243.38482666 time/batch=0.63s
21490/10943 (epoch 176.736) train_loss=155.76026917 time/batch=0.39s
21491/10943 (epoch 176.744) train_loss=311.86105347 time/batch=0.74s
21492/10943 (epoch 176.753) train_loss=354.61407471 time/batch=0.85s
21493/10943 (epoch 176.761) train_loss=351.85348511 time/batch=0.89s
21494/10943 (epoch 176.769) train_loss=301.67883301 time/batch=0.76s
21495/10943 (epoch 176.777) train_loss=158.21359253 time/batch=0.47s
21496/10943 (epoch 176.785) train_loss=292.01470947 time/batch=0.73s
21497/10943 (epoch 176.794) train_loss=319.87591553 time/batch=0.83s
21498/10943 (epoch 176.802) train_loss=315.94400024 time/batch=0.81s
21499/10943 (epoch 176.810) train_loss=350.89300537 time/batch=0.84s
21500/10943 (epoch 176.818) train_loss=285.11529541 time/batch=0.72s
21501/10943 (epoch 176.827) train_loss=234.46853638 time/batch=0.59s
21502/10943 (epoch 176.835) train_loss=267.08911133 time/batch=0.68s
21503/10943 (epoch 176.843) train_loss=227.33151245 time/batch=0.70s
21504/10943 (epoch 176.851) train_loss=234.81318665 time/batch=0.71s
21505/10943 (epoch 176.859) train_loss=311.44961548 time/batch=0.80s
21506/10943 (epoch 176.868) train_loss=349.78152466 time/batch=0.86s
21507/10943 (epoch 176.876) train_loss=295.96002197 time/batch=0.84s
setting learning rate to 0.0007390
21508/10943 (epoch 176.884) train_loss=181.28070068 time/batch=0.48s
21509/10943 (epoch 176.892) train_loss=336.22332764 time/batch=0.81s
21510/10943 (epoch 176.901) train_loss=382.57156372 time/batch=0.90s
21511/10943 (epoch 176.909) train_loss=137.75601196 time/batch=0.38s
21512/10943 (epoch 176.917) train_loss=490.79409790 time/batch=1.05s
21513/10943 (epoch 176.925) train_loss=349.49951172 time/batch=0.90s
21514/10943 (epoch 176.933) train_loss=537.74572754 time/batch=1.26s
21515/10943 (epoch 176.942) train_loss=1046.20202637 time/batch=3.16s
21516/10943 (epoch 176.950) train_loss=219.76075745 time/batch=0.81s
21517/10943 (epoch 176.958) train_loss=313.46902466 time/batch=0.72s
21518/10943 (epoch 176.966) train_loss=182.71136475 time/batch=0.48s
21519/10943 (epoch 176.975) train_loss=461.25119019 time/batch=1.11s
21520/10943 (epoch 176.983) train_loss=209.21231079 time/batch=0.58s
21521/10943 (epoch 176.991) train_loss=652.52941895 time/batch=1.53s
21522/10943 (epoch 176.999) train_loss=247.66625977 time/batch=0.69s
21523/10943 (epoch 177.007) train_loss=304.24481201 time/batch=0.73s
21524/10943 (epoch 177.016) train_loss=310.93200684 time/batch=0.77s
21525/10943 (epoch 177.024) train_loss=561.80438232 time/batch=1.38s
21526/10943 (epoch 177.032) train_loss=300.59674072 time/batch=0.84s
21527/10943 (epoch 177.040) train_loss=582.80090332 time/batch=1.31s
21528/10943 (epoch 177.049) train_loss=238.01728821 time/batch=0.72s
21529/10943 (epoch 177.057) train_loss=278.23889160 time/batch=0.66s
21530/10943 (epoch 177.065) train_loss=445.41973877 time/batch=1.09s
21531/10943 (epoch 177.073) train_loss=442.15209961 time/batch=1.05s
21532/10943 (epoch 177.081) train_loss=271.26898193 time/batch=0.73s
21533/10943 (epoch 177.090) train_loss=122.75120544 time/batch=0.33s
21534/10943 (epoch 177.098) train_loss=267.03347778 time/batch=0.66s
21535/10943 (epoch 177.106) train_loss=424.09622192 time/batch=1.05s
21536/10943 (epoch 177.114) train_loss=293.00909424 time/batch=0.76s
21537/10943 (epoch 177.123) train_loss=147.36814880 time/batch=0.40s
21538/10943 (epoch 177.131) train_loss=225.81579590 time/batch=0.55s
21539/10943 (epoch 177.139) train_loss=143.84742737 time/batch=0.38s
21540/10943 (epoch 177.147) train_loss=257.25909424 time/batch=0.62s
21541/10943 (epoch 177.155) train_loss=255.42301941 time/batch=0.65s
21542/10943 (epoch 177.164) train_loss=349.29583740 time/batch=0.84s
21543/10943 (epoch 177.172) train_loss=382.84582520 time/batch=0.92s
21544/10943 (epoch 177.180) train_loss=128.14840698 time/batch=0.36s
21545/10943 (epoch 177.188) train_loss=358.96658325 time/batch=0.82s
21546/10943 (epoch 177.197) train_loss=616.85400391 time/batch=1.62s
21547/10943 (epoch 177.205) train_loss=150.10568237 time/batch=0.49s
21548/10943 (epoch 177.213) train_loss=204.33041382 time/batch=0.51s
21549/10943 (epoch 177.221) train_loss=449.99432373 time/batch=1.08s
21550/10943 (epoch 177.230) train_loss=377.31439209 time/batch=0.97s
21551/10943 (epoch 177.238) train_loss=112.84503937 time/batch=0.37s
21552/10943 (epoch 177.246) train_loss=371.68444824 time/batch=0.88s
21553/10943 (epoch 177.254) train_loss=209.47537231 time/batch=0.57s
21554/10943 (epoch 177.262) train_loss=160.77120972 time/batch=0.41s
21555/10943 (epoch 177.271) train_loss=179.73928833 time/batch=0.44s
21556/10943 (epoch 177.279) train_loss=404.85064697 time/batch=0.97s
21557/10943 (epoch 177.287) train_loss=293.47842407 time/batch=0.77s
21558/10943 (epoch 177.295) train_loss=370.07440186 time/batch=0.89s
21559/10943 (epoch 177.304) train_loss=362.84063721 time/batch=0.90s
21560/10943 (epoch 177.312) train_loss=226.83674622 time/batch=0.60s
21561/10943 (epoch 177.320) train_loss=323.95742798 time/batch=0.75s
21562/10943 (epoch 177.328) train_loss=111.08245850 time/batch=0.36s
21563/10943 (epoch 177.336) train_loss=400.85449219 time/batch=0.93s
21564/10943 (epoch 177.345) train_loss=204.80407715 time/batch=0.56s
21565/10943 (epoch 177.353) train_loss=137.76290894 time/batch=0.34s
21566/10943 (epoch 177.361) train_loss=398.18829346 time/batch=0.93s
21567/10943 (epoch 177.369) train_loss=548.07769775 time/batch=1.29s
21568/10943 (epoch 177.378) train_loss=229.22332764 time/batch=0.64s
21569/10943 (epoch 177.386) train_loss=450.71929932 time/batch=1.01s
21570/10943 (epoch 177.394) train_loss=321.46011353 time/batch=0.85s
21571/10943 (epoch 177.402) train_loss=353.66857910 time/batch=0.85s
21572/10943 (epoch 177.410) train_loss=270.34930420 time/batch=0.71s
21573/10943 (epoch 177.419) train_loss=469.50909424 time/batch=1.15s
21574/10943 (epoch 177.427) train_loss=321.32458496 time/batch=0.87s
21575/10943 (epoch 177.435) train_loss=219.99746704 time/batch=0.57s
21576/10943 (epoch 177.443) train_loss=309.13189697 time/batch=0.79s
21577/10943 (epoch 177.452) train_loss=458.69198608 time/batch=1.18s
21578/10943 (epoch 177.460) train_loss=247.31510925 time/batch=0.69s
21579/10943 (epoch 177.468) train_loss=315.68325806 time/batch=0.77s
21580/10943 (epoch 177.476) train_loss=138.24612427 time/batch=0.40s
21581/10943 (epoch 177.484) train_loss=338.51126099 time/batch=0.80s
21582/10943 (epoch 177.493) train_loss=635.25537109 time/batch=1.67s
21583/10943 (epoch 177.501) train_loss=337.09197998 time/batch=0.91s
21584/10943 (epoch 177.509) train_loss=273.48214722 time/batch=0.68s
21585/10943 (epoch 177.517) train_loss=214.38339233 time/batch=0.55s
21586/10943 (epoch 177.526) train_loss=336.03430176 time/batch=0.85s
21587/10943 (epoch 177.534) train_loss=381.19262695 time/batch=0.94s
21588/10943 (epoch 177.542) train_loss=207.83999634 time/batch=0.58s
21589/10943 (epoch 177.550) train_loss=142.83721924 time/batch=0.40s
21590/10943 (epoch 177.558) train_loss=160.90835571 time/batch=0.39s
21591/10943 (epoch 177.567) train_loss=289.03643799 time/batch=0.72s
21592/10943 (epoch 177.575) train_loss=402.92419434 time/batch=0.96s
21593/10943 (epoch 177.583) train_loss=229.64199829 time/batch=0.61s
21594/10943 (epoch 177.591) train_loss=255.27554321 time/batch=0.63s
21595/10943 (epoch 177.600) train_loss=234.18907166 time/batch=0.59s
21596/10943 (epoch 177.608) train_loss=242.25959778 time/batch=0.61s
21597/10943 (epoch 177.616) train_loss=120.78509521 time/batch=0.39s
21598/10943 (epoch 177.624) train_loss=229.12478638 time/batch=0.56s
21599/10943 (epoch 177.632) train_loss=195.31079102 time/batch=0.49s
21600/10943 (epoch 177.641) train_loss=243.90945435 time/batch=0.61s
21601/10943 (epoch 177.649) train_loss=159.62533569 time/batch=0.42s
21602/10943 (epoch 177.657) train_loss=267.32861328 time/batch=0.68s
21603/10943 (epoch 177.665) train_loss=315.75482178 time/batch=0.79s
21604/10943 (epoch 177.674) train_loss=243.20912170 time/batch=0.64s
21605/10943 (epoch 177.682) train_loss=223.94909668 time/batch=0.59s
21606/10943 (epoch 177.690) train_loss=188.04455566 time/batch=0.47s
21607/10943 (epoch 177.698) train_loss=236.09089661 time/batch=0.58s
21608/10943 (epoch 177.707) train_loss=154.12808228 time/batch=0.43s
21609/10943 (epoch 177.715) train_loss=163.66969299 time/batch=0.43s
21610/10943 (epoch 177.723) train_loss=189.26153564 time/batch=0.47s
21611/10943 (epoch 177.731) train_loss=407.97753906 time/batch=1.14s
21612/10943 (epoch 177.739) train_loss=226.26480103 time/batch=0.67s
21613/10943 (epoch 177.748) train_loss=336.27606201 time/batch=0.91s
21614/10943 (epoch 177.756) train_loss=319.32592773 time/batch=0.80s
21615/10943 (epoch 177.764) train_loss=279.40600586 time/batch=0.72s
21616/10943 (epoch 177.772) train_loss=279.76211548 time/batch=0.68s
21617/10943 (epoch 177.781) train_loss=341.26553345 time/batch=1.67s
21618/10943 (epoch 177.789) train_loss=242.25659180 time/batch=0.72s
21619/10943 (epoch 177.797) train_loss=226.82014465 time/batch=0.60s
21620/10943 (epoch 177.805) train_loss=310.90570068 time/batch=0.77s
21621/10943 (epoch 177.813) train_loss=292.42150879 time/batch=0.73s
21622/10943 (epoch 177.822) train_loss=193.06173706 time/batch=0.52s
21623/10943 (epoch 177.830) train_loss=264.04797363 time/batch=0.64s
21624/10943 (epoch 177.838) train_loss=283.89413452 time/batch=0.70s
21625/10943 (epoch 177.846) train_loss=189.71533203 time/batch=0.64s
21626/10943 (epoch 177.855) train_loss=264.53857422 time/batch=0.67s
21627/10943 (epoch 177.863) train_loss=317.66406250 time/batch=0.78s
21628/10943 (epoch 177.871) train_loss=284.14941406 time/batch=0.72s
setting learning rate to 0.0007168
21629/10943 (epoch 177.879) train_loss=323.13241577 time/batch=0.81s
21630/10943 (epoch 177.887) train_loss=607.06860352 time/batch=1.37s
21631/10943 (epoch 177.896) train_loss=378.81976318 time/batch=0.90s
21632/10943 (epoch 177.904) train_loss=476.83709717 time/batch=1.13s
21633/10943 (epoch 177.912) train_loss=623.77886963 time/batch=1.54s
21634/10943 (epoch 177.920) train_loss=445.60137939 time/batch=1.14s
21635/10943 (epoch 177.929) train_loss=274.81164551 time/batch=0.73s
21636/10943 (epoch 177.937) train_loss=533.78479004 time/batch=1.24s
21637/10943 (epoch 177.945) train_loss=445.03231812 time/batch=1.12s
21638/10943 (epoch 177.953) train_loss=470.18771362 time/batch=1.10s
21639/10943 (epoch 177.961) train_loss=182.72007751 time/batch=0.51s
21640/10943 (epoch 177.970) train_loss=519.47778320 time/batch=1.23s
21641/10943 (epoch 177.978) train_loss=162.85852051 time/batch=0.49s
21642/10943 (epoch 177.986) train_loss=567.37774658 time/batch=1.34s
21643/10943 (epoch 177.994) train_loss=785.67565918 time/batch=2.04s
21644/10943 (epoch 178.003) train_loss=482.48181152 time/batch=1.26s
21645/10943 (epoch 178.011) train_loss=226.74043274 time/batch=0.62s
21646/10943 (epoch 178.019) train_loss=352.38702393 time/batch=0.86s
21647/10943 (epoch 178.027) train_loss=308.24319458 time/batch=0.78s
21648/10943 (epoch 178.035) train_loss=124.13291931 time/batch=0.35s
21649/10943 (epoch 178.044) train_loss=186.32357788 time/batch=0.45s
21650/10943 (epoch 178.052) train_loss=168.65600586 time/batch=0.43s
21651/10943 (epoch 178.060) train_loss=434.62854004 time/batch=0.97s
21652/10943 (epoch 178.068) train_loss=267.69012451 time/batch=0.71s
21653/10943 (epoch 178.077) train_loss=437.03982544 time/batch=1.08s
21654/10943 (epoch 178.085) train_loss=548.39978027 time/batch=1.55s
21655/10943 (epoch 178.093) train_loss=414.06048584 time/batch=1.05s
21656/10943 (epoch 178.101) train_loss=704.49060059 time/batch=2.11s
21657/10943 (epoch 178.109) train_loss=103.85860443 time/batch=0.45s
21658/10943 (epoch 178.118) train_loss=117.96423340 time/batch=0.29s
21659/10943 (epoch 178.126) train_loss=313.87161255 time/batch=0.75s
21660/10943 (epoch 178.134) train_loss=232.42608643 time/batch=0.62s
21661/10943 (epoch 178.142) train_loss=350.74511719 time/batch=0.85s
21662/10943 (epoch 178.151) train_loss=215.37277222 time/batch=0.59s
21663/10943 (epoch 178.159) train_loss=361.52761841 time/batch=0.91s
21664/10943 (epoch 178.167) train_loss=119.64886475 time/batch=0.36s
21665/10943 (epoch 178.175) train_loss=472.96984863 time/batch=1.12s
21666/10943 (epoch 178.184) train_loss=247.78778076 time/batch=0.69s
21667/10943 (epoch 178.192) train_loss=171.70596313 time/batch=0.46s
21668/10943 (epoch 178.200) train_loss=339.54147339 time/batch=0.83s
21669/10943 (epoch 178.208) train_loss=137.89602661 time/batch=0.39s
21670/10943 (epoch 178.216) train_loss=200.10290527 time/batch=0.51s
21671/10943 (epoch 178.225) train_loss=362.80596924 time/batch=0.86s
21672/10943 (epoch 178.233) train_loss=274.70056152 time/batch=0.74s
21673/10943 (epoch 178.241) train_loss=390.36047363 time/batch=0.99s
21674/10943 (epoch 178.249) train_loss=516.93548584 time/batch=2.19s
21675/10943 (epoch 178.258) train_loss=282.31985474 time/batch=0.88s
21676/10943 (epoch 178.266) train_loss=290.91787720 time/batch=0.74s
21677/10943 (epoch 178.274) train_loss=245.24304199 time/batch=0.64s
21678/10943 (epoch 178.282) train_loss=310.03857422 time/batch=0.79s
21679/10943 (epoch 178.290) train_loss=148.89250183 time/batch=0.41s
21680/10943 (epoch 178.299) train_loss=190.37701416 time/batch=0.47s
21681/10943 (epoch 178.307) train_loss=297.87030029 time/batch=0.70s
21682/10943 (epoch 178.315) train_loss=219.64584351 time/batch=0.56s
21683/10943 (epoch 178.323) train_loss=254.73803711 time/batch=0.64s
21684/10943 (epoch 178.332) train_loss=116.02326965 time/batch=0.34s
21685/10943 (epoch 178.340) train_loss=405.29693604 time/batch=0.93s
21686/10943 (epoch 178.348) train_loss=152.51252747 time/batch=0.46s
21687/10943 (epoch 178.356) train_loss=271.78649902 time/batch=0.64s
21688/10943 (epoch 178.364) train_loss=267.95071411 time/batch=0.68s
21689/10943 (epoch 178.373) train_loss=222.15782166 time/batch=0.58s
21690/10943 (epoch 178.381) train_loss=158.08151245 time/batch=0.42s
21691/10943 (epoch 178.389) train_loss=268.79675293 time/batch=0.66s
21692/10943 (epoch 178.397) train_loss=354.00759888 time/batch=0.84s
21693/10943 (epoch 178.406) train_loss=403.53060913 time/batch=0.98s
21694/10943 (epoch 178.414) train_loss=413.13119507 time/batch=1.03s
21695/10943 (epoch 178.422) train_loss=249.47749329 time/batch=0.66s
21696/10943 (epoch 178.430) train_loss=260.39678955 time/batch=0.65s
21697/10943 (epoch 178.438) train_loss=133.89202881 time/batch=0.37s
21698/10943 (epoch 178.447) train_loss=181.56153870 time/batch=0.46s
21699/10943 (epoch 178.455) train_loss=309.32098389 time/batch=0.78s
21700/10943 (epoch 178.463) train_loss=300.37402344 time/batch=0.82s
21701/10943 (epoch 178.471) train_loss=310.03167725 time/batch=0.80s
21702/10943 (epoch 178.480) train_loss=256.43682861 time/batch=0.67s
21703/10943 (epoch 178.488) train_loss=366.95916748 time/batch=0.91s
21704/10943 (epoch 178.496) train_loss=205.96844482 time/batch=0.55s
21705/10943 (epoch 178.504) train_loss=606.28381348 time/batch=3.05s
21706/10943 (epoch 178.512) train_loss=274.30230713 time/batch=0.97s
21707/10943 (epoch 178.521) train_loss=331.05285645 time/batch=0.83s
21708/10943 (epoch 178.529) train_loss=296.68518066 time/batch=0.75s
21709/10943 (epoch 178.537) train_loss=132.48254395 time/batch=0.38s
21710/10943 (epoch 178.545) train_loss=200.61236572 time/batch=0.51s
21711/10943 (epoch 178.554) train_loss=309.61437988 time/batch=0.80s
21712/10943 (epoch 178.562) train_loss=157.94235229 time/batch=0.45s
21713/10943 (epoch 178.570) train_loss=349.01940918 time/batch=0.84s
21714/10943 (epoch 178.578) train_loss=314.13427734 time/batch=0.82s
21715/10943 (epoch 178.586) train_loss=243.12730408 time/batch=0.64s
21716/10943 (epoch 178.595) train_loss=217.19628906 time/batch=0.55s
21717/10943 (epoch 178.603) train_loss=147.99740601 time/batch=0.42s
21718/10943 (epoch 178.611) train_loss=227.30366516 time/batch=0.57s
21719/10943 (epoch 178.619) train_loss=173.42358398 time/batch=0.47s
21720/10943 (epoch 178.628) train_loss=324.26275635 time/batch=0.82s
21721/10943 (epoch 178.636) train_loss=329.45022583 time/batch=0.86s
21722/10943 (epoch 178.644) train_loss=377.98071289 time/batch=0.95s
21723/10943 (epoch 178.652) train_loss=212.25321960 time/batch=0.57s
21724/10943 (epoch 178.660) train_loss=327.33737183 time/batch=0.86s
21725/10943 (epoch 178.669) train_loss=239.72535706 time/batch=0.66s
21726/10943 (epoch 178.677) train_loss=157.19766235 time/batch=0.43s
21727/10943 (epoch 178.685) train_loss=241.39932251 time/batch=0.62s
21728/10943 (epoch 178.693) train_loss=201.09513855 time/batch=0.56s
21729/10943 (epoch 178.702) train_loss=264.26495361 time/batch=0.67s
21730/10943 (epoch 178.710) train_loss=196.00994873 time/batch=0.51s
21731/10943 (epoch 178.718) train_loss=182.18515015 time/batch=0.48s
21732/10943 (epoch 178.726) train_loss=301.30053711 time/batch=0.75s
21733/10943 (epoch 178.735) train_loss=193.47973633 time/batch=0.52s
21734/10943 (epoch 178.743) train_loss=161.92219543 time/batch=0.47s
21735/10943 (epoch 178.751) train_loss=236.15907288 time/batch=0.60s
21736/10943 (epoch 178.759) train_loss=241.40617371 time/batch=0.59s
21737/10943 (epoch 178.767) train_loss=232.45376587 time/batch=0.59s
21738/10943 (epoch 178.776) train_loss=236.56845093 time/batch=0.63s
21739/10943 (epoch 178.784) train_loss=305.77072144 time/batch=0.73s
21740/10943 (epoch 178.792) train_loss=303.24041748 time/batch=0.77s
21741/10943 (epoch 178.800) train_loss=263.63659668 time/batch=0.68s
21742/10943 (epoch 178.809) train_loss=295.72891235 time/batch=0.70s
21743/10943 (epoch 178.817) train_loss=289.73870850 time/batch=0.73s
21744/10943 (epoch 178.825) train_loss=344.20721436 time/batch=0.93s
21745/10943 (epoch 178.833) train_loss=317.83972168 time/batch=0.82s
21746/10943 (epoch 178.841) train_loss=229.49890137 time/batch=0.60s
21747/10943 (epoch 178.850) train_loss=213.91165161 time/batch=0.59s
21748/10943 (epoch 178.858) train_loss=287.28845215 time/batch=0.71s
21749/10943 (epoch 178.866) train_loss=199.79345703 time/batch=0.70s
setting learning rate to 0.0006953
21750/10943 (epoch 178.874) train_loss=567.18121338 time/batch=1.43s
21751/10943 (epoch 178.883) train_loss=177.39602661 time/batch=0.52s
21752/10943 (epoch 178.891) train_loss=117.37873840 time/batch=0.31s
21753/10943 (epoch 178.899) train_loss=425.17285156 time/batch=1.01s
21754/10943 (epoch 178.907) train_loss=608.63159180 time/batch=1.52s
21755/10943 (epoch 178.915) train_loss=309.38137817 time/batch=0.86s
21756/10943 (epoch 178.924) train_loss=216.19512939 time/batch=0.57s
21757/10943 (epoch 178.932) train_loss=199.21365356 time/batch=0.52s
21758/10943 (epoch 178.940) train_loss=271.15487671 time/batch=0.68s
21759/10943 (epoch 178.948) train_loss=325.83090210 time/batch=0.86s
21760/10943 (epoch 178.957) train_loss=507.13021851 time/batch=1.20s
21761/10943 (epoch 178.965) train_loss=634.89373779 time/batch=1.57s
21762/10943 (epoch 178.973) train_loss=1020.66241455 time/batch=3.18s
21763/10943 (epoch 178.981) train_loss=399.92028809 time/batch=1.20s
21764/10943 (epoch 178.989) train_loss=326.89303589 time/batch=0.84s
21765/10943 (epoch 178.998) train_loss=354.46679688 time/batch=0.89s
21766/10943 (epoch 179.006) train_loss=462.39627075 time/batch=1.16s
21767/10943 (epoch 179.014) train_loss=505.30737305 time/batch=1.27s
21768/10943 (epoch 179.022) train_loss=274.32470703 time/batch=0.74s
21769/10943 (epoch 179.031) train_loss=719.27014160 time/batch=1.68s
21770/10943 (epoch 179.039) train_loss=441.98818970 time/batch=1.14s
21771/10943 (epoch 179.047) train_loss=150.96191406 time/batch=0.46s
21772/10943 (epoch 179.055) train_loss=431.50631714 time/batch=1.00s
21773/10943 (epoch 179.063) train_loss=175.82437134 time/batch=0.50s
21774/10943 (epoch 179.072) train_loss=406.96673584 time/batch=0.93s
21775/10943 (epoch 179.080) train_loss=443.98703003 time/batch=1.09s
21776/10943 (epoch 179.088) train_loss=261.34515381 time/batch=0.70s
21777/10943 (epoch 179.096) train_loss=363.36505127 time/batch=0.88s
21778/10943 (epoch 179.105) train_loss=282.33502197 time/batch=0.75s
21779/10943 (epoch 179.113) train_loss=157.22227478 time/batch=0.45s
21780/10943 (epoch 179.121) train_loss=92.99942017 time/batch=0.27s
21781/10943 (epoch 179.129) train_loss=184.26614380 time/batch=0.46s
21782/10943 (epoch 179.137) train_loss=175.02673340 time/batch=0.44s
21783/10943 (epoch 179.146) train_loss=444.10699463 time/batch=1.07s
21784/10943 (epoch 179.154) train_loss=556.89050293 time/batch=1.32s
21785/10943 (epoch 179.162) train_loss=495.00738525 time/batch=1.29s
21786/10943 (epoch 179.170) train_loss=194.85229492 time/batch=0.56s
21787/10943 (epoch 179.179) train_loss=467.38989258 time/batch=1.07s
21788/10943 (epoch 179.187) train_loss=362.11239624 time/batch=0.96s
21789/10943 (epoch 179.195) train_loss=255.05691528 time/batch=0.69s
21790/10943 (epoch 179.203) train_loss=118.05574036 time/batch=0.32s
21791/10943 (epoch 179.212) train_loss=332.90670776 time/batch=0.79s
21792/10943 (epoch 179.220) train_loss=382.19793701 time/batch=0.96s
21793/10943 (epoch 179.228) train_loss=114.07929993 time/batch=0.37s
21794/10943 (epoch 179.236) train_loss=385.62438965 time/batch=0.92s
21795/10943 (epoch 179.244) train_loss=278.35681152 time/batch=0.71s
21796/10943 (epoch 179.253) train_loss=229.30033875 time/batch=0.59s
21797/10943 (epoch 179.261) train_loss=289.16442871 time/batch=0.71s
21798/10943 (epoch 179.269) train_loss=163.71560669 time/batch=0.46s
21799/10943 (epoch 179.277) train_loss=128.51846313 time/batch=0.34s
21800/10943 (epoch 179.286) train_loss=473.01736450 time/batch=1.50s
21801/10943 (epoch 179.294) train_loss=298.69464111 time/batch=0.86s
21802/10943 (epoch 179.302) train_loss=293.96090698 time/batch=0.72s
21803/10943 (epoch 179.310) train_loss=270.61071777 time/batch=0.68s
21804/10943 (epoch 179.318) train_loss=143.36587524 time/batch=0.37s
21805/10943 (epoch 179.327) train_loss=122.45750427 time/batch=0.32s
21806/10943 (epoch 179.335) train_loss=268.51702881 time/batch=0.67s
21807/10943 (epoch 179.343) train_loss=347.44940186 time/batch=0.89s
21808/10943 (epoch 179.351) train_loss=355.52883911 time/batch=0.88s
21809/10943 (epoch 179.360) train_loss=390.98181152 time/batch=0.99s
21810/10943 (epoch 179.368) train_loss=244.24124146 time/batch=0.67s
21811/10943 (epoch 179.376) train_loss=387.62695312 time/batch=0.96s
21812/10943 (epoch 179.384) train_loss=308.95211792 time/batch=0.82s
21813/10943 (epoch 179.392) train_loss=338.03341675 time/batch=0.90s
21814/10943 (epoch 179.401) train_loss=242.01814270 time/batch=0.64s
21815/10943 (epoch 179.409) train_loss=314.24536133 time/batch=0.78s
21816/10943 (epoch 179.417) train_loss=369.01690674 time/batch=0.91s
21817/10943 (epoch 179.425) train_loss=265.19421387 time/batch=0.73s
21818/10943 (epoch 179.434) train_loss=198.03060913 time/batch=0.51s
21819/10943 (epoch 179.442) train_loss=315.17971802 time/batch=0.76s
21820/10943 (epoch 179.450) train_loss=219.42141724 time/batch=0.58s
21821/10943 (epoch 179.458) train_loss=190.26536560 time/batch=0.50s
21822/10943 (epoch 179.466) train_loss=239.21249390 time/batch=0.60s
21823/10943 (epoch 179.475) train_loss=297.77026367 time/batch=0.75s
21824/10943 (epoch 179.483) train_loss=185.36990356 time/batch=0.50s
21825/10943 (epoch 179.491) train_loss=224.08181763 time/batch=0.56s
21826/10943 (epoch 179.499) train_loss=298.27313232 time/batch=0.79s
21827/10943 (epoch 179.508) train_loss=223.37068176 time/batch=0.61s
21828/10943 (epoch 179.516) train_loss=187.64471436 time/batch=0.48s
21829/10943 (epoch 179.524) train_loss=241.13732910 time/batch=0.60s
21830/10943 (epoch 179.532) train_loss=266.14538574 time/batch=0.68s
21831/10943 (epoch 179.540) train_loss=303.65167236 time/batch=0.81s
21832/10943 (epoch 179.549) train_loss=236.74604797 time/batch=0.62s
21833/10943 (epoch 179.557) train_loss=230.16435242 time/batch=0.59s
21834/10943 (epoch 179.565) train_loss=243.75273132 time/batch=0.62s
21835/10943 (epoch 179.573) train_loss=202.12966919 time/batch=0.54s
21836/10943 (epoch 179.582) train_loss=431.26538086 time/batch=0.97s
21837/10943 (epoch 179.590) train_loss=222.46083069 time/batch=0.60s
21838/10943 (epoch 179.598) train_loss=162.98828125 time/batch=0.44s
21839/10943 (epoch 179.606) train_loss=200.47018433 time/batch=0.51s
21840/10943 (epoch 179.614) train_loss=357.06207275 time/batch=0.97s
21841/10943 (epoch 179.623) train_loss=281.22186279 time/batch=0.75s
21842/10943 (epoch 179.631) train_loss=214.39395142 time/batch=0.56s
21843/10943 (epoch 179.639) train_loss=257.34152222 time/batch=0.65s
21844/10943 (epoch 179.647) train_loss=226.46272278 time/batch=0.61s
21845/10943 (epoch 179.656) train_loss=230.67306519 time/batch=0.63s
21846/10943 (epoch 179.664) train_loss=137.77659607 time/batch=0.37s
21847/10943 (epoch 179.672) train_loss=310.34020996 time/batch=0.76s
21848/10943 (epoch 179.680) train_loss=244.92266846 time/batch=0.65s
21849/10943 (epoch 179.689) train_loss=157.87484741 time/batch=0.40s
21850/10943 (epoch 179.697) train_loss=306.27713013 time/batch=0.74s
21851/10943 (epoch 179.705) train_loss=144.68853760 time/batch=0.42s
21852/10943 (epoch 179.713) train_loss=291.21936035 time/batch=0.73s
21853/10943 (epoch 179.721) train_loss=138.55200195 time/batch=0.39s
21854/10943 (epoch 179.730) train_loss=296.29187012 time/batch=0.69s
21855/10943 (epoch 179.738) train_loss=151.73689270 time/batch=0.47s
21856/10943 (epoch 179.746) train_loss=213.14672852 time/batch=0.55s
21857/10943 (epoch 179.754) train_loss=302.68054199 time/batch=0.76s
21858/10943 (epoch 179.763) train_loss=350.24060059 time/batch=0.85s
21859/10943 (epoch 179.771) train_loss=203.58406067 time/batch=0.54s
21860/10943 (epoch 179.779) train_loss=347.89398193 time/batch=0.81s
21861/10943 (epoch 179.787) train_loss=316.49002075 time/batch=0.82s
21862/10943 (epoch 179.795) train_loss=329.35931396 time/batch=0.83s
21863/10943 (epoch 179.804) train_loss=294.65472412 time/batch=0.79s
21864/10943 (epoch 179.812) train_loss=313.22717285 time/batch=0.84s
21865/10943 (epoch 179.820) train_loss=162.04544067 time/batch=0.49s
21866/10943 (epoch 179.828) train_loss=203.76708984 time/batch=0.50s
21867/10943 (epoch 179.837) train_loss=239.43566895 time/batch=0.58s
21868/10943 (epoch 179.845) train_loss=267.02203369 time/batch=0.70s
21869/10943 (epoch 179.853) train_loss=225.35714722 time/batch=0.65s
21870/10943 (epoch 179.861) train_loss=266.12344360 time/batch=0.66s
setting learning rate to 0.0006744
  saved to metadata/gru_no_dropout-9_nov_folkwiki-20181115-214759_epoch69.pkl
21871/10943 (epoch 179.869) train_loss=684.14355469 time/batch=1.66s
21872/10943 (epoch 179.878) train_loss=200.03164673 time/batch=0.63s
21873/10943 (epoch 179.886) train_loss=302.86508179 time/batch=0.77s
21874/10943 (epoch 179.894) train_loss=494.45263672 time/batch=1.19s
21875/10943 (epoch 179.902) train_loss=159.22836304 time/batch=0.47s
21876/10943 (epoch 179.911) train_loss=578.27124023 time/batch=1.27s
21877/10943 (epoch 179.919) train_loss=465.76800537 time/batch=1.18s
21878/10943 (epoch 179.927) train_loss=297.85070801 time/batch=0.79s
21879/10943 (epoch 179.935) train_loss=371.77490234 time/batch=0.93s
21880/10943 (epoch 179.943) train_loss=354.75729370 time/batch=0.89s
21881/10943 (epoch 179.952) train_loss=445.61889648 time/batch=1.11s
21882/10943 (epoch 179.960) train_loss=194.95777893 time/batch=0.57s
21883/10943 (epoch 179.968) train_loss=333.68188477 time/batch=0.81s
21884/10943 (epoch 179.976) train_loss=296.31707764 time/batch=0.73s
21885/10943 (epoch 179.985) train_loss=460.43081665 time/batch=1.10s
21886/10943 (epoch 179.993) train_loss=143.89929199 time/batch=0.42s
21887/10943 (epoch 180.001) train_loss=651.99243164 time/batch=1.59s
21888/10943 (epoch 180.009) train_loss=249.13684082 time/batch=0.74s
21889/10943 (epoch 180.017) train_loss=347.45611572 time/batch=0.83s
21890/10943 (epoch 180.026) train_loss=138.88082886 time/batch=0.40s
21891/10943 (epoch 180.034) train_loss=261.51181030 time/batch=0.64s
21892/10943 (epoch 180.042) train_loss=259.79595947 time/batch=0.67s
21893/10943 (epoch 180.050) train_loss=252.86201477 time/batch=0.65s
21894/10943 (epoch 180.059) train_loss=145.90240479 time/batch=0.40s
21895/10943 (epoch 180.067) train_loss=420.95486450 time/batch=1.01s
21896/10943 (epoch 180.075) train_loss=565.99255371 time/batch=1.40s
21897/10943 (epoch 180.083) train_loss=436.03082275 time/batch=1.04s
21898/10943 (epoch 180.091) train_loss=476.68386841 time/batch=1.19s
21899/10943 (epoch 180.100) train_loss=316.95214844 time/batch=0.84s
21900/10943 (epoch 180.108) train_loss=937.17028809 time/batch=3.11s
21901/10943 (epoch 180.116) train_loss=158.10403442 time/batch=0.72s
21902/10943 (epoch 180.124) train_loss=182.99423218 time/batch=0.43s
21903/10943 (epoch 180.133) train_loss=366.76995850 time/batch=0.85s
21904/10943 (epoch 180.141) train_loss=395.25027466 time/batch=1.02s
21905/10943 (epoch 180.149) train_loss=310.96948242 time/batch=0.80s
21906/10943 (epoch 180.157) train_loss=424.89941406 time/batch=1.16s
21907/10943 (epoch 180.166) train_loss=275.16632080 time/batch=0.73s
21908/10943 (epoch 180.174) train_loss=522.18005371 time/batch=1.35s
21909/10943 (epoch 180.182) train_loss=109.59098053 time/batch=0.39s
21910/10943 (epoch 180.190) train_loss=173.60366821 time/batch=0.44s
21911/10943 (epoch 180.198) train_loss=239.83569336 time/batch=0.59s
21912/10943 (epoch 180.207) train_loss=430.32180786 time/batch=1.00s
21913/10943 (epoch 180.215) train_loss=321.09628296 time/batch=0.83s
21914/10943 (epoch 180.223) train_loss=307.53054810 time/batch=0.82s
21915/10943 (epoch 180.231) train_loss=376.18426514 time/batch=0.97s
21916/10943 (epoch 180.240) train_loss=125.51101685 time/batch=0.38s
21917/10943 (epoch 180.248) train_loss=182.84313965 time/batch=0.44s
21918/10943 (epoch 180.256) train_loss=367.72265625 time/batch=0.86s
21919/10943 (epoch 180.264) train_loss=313.84686279 time/batch=0.85s
21920/10943 (epoch 180.272) train_loss=263.61425781 time/batch=0.71s
21921/10943 (epoch 180.281) train_loss=258.88647461 time/batch=0.66s
21922/10943 (epoch 180.289) train_loss=186.60098267 time/batch=0.50s
21923/10943 (epoch 180.297) train_loss=229.43737793 time/batch=0.56s
21924/10943 (epoch 180.305) train_loss=238.57890320 time/batch=0.62s
21925/10943 (epoch 180.314) train_loss=197.14614868 time/batch=0.54s
21926/10943 (epoch 180.322) train_loss=360.07385254 time/batch=0.89s
21927/10943 (epoch 180.330) train_loss=152.67175293 time/batch=0.45s
21928/10943 (epoch 180.338) train_loss=264.03759766 time/batch=0.65s
21929/10943 (epoch 180.346) train_loss=133.82278442 time/batch=0.38s
21930/10943 (epoch 180.355) train_loss=156.47146606 time/batch=0.39s
21931/10943 (epoch 180.363) train_loss=294.75360107 time/batch=0.79s
21932/10943 (epoch 180.371) train_loss=290.64312744 time/batch=0.76s
21933/10943 (epoch 180.379) train_loss=287.16821289 time/batch=0.75s
21934/10943 (epoch 180.388) train_loss=265.46408081 time/batch=0.67s
21935/10943 (epoch 180.396) train_loss=171.11941528 time/batch=0.46s
21936/10943 (epoch 180.404) train_loss=286.57894897 time/batch=0.72s
21937/10943 (epoch 180.412) train_loss=336.03149414 time/batch=0.88s
21938/10943 (epoch 180.420) train_loss=217.63198853 time/batch=0.60s
21939/10943 (epoch 180.429) train_loss=527.21704102 time/batch=1.61s
21940/10943 (epoch 180.437) train_loss=256.32647705 time/batch=0.72s
21941/10943 (epoch 180.445) train_loss=288.97958374 time/batch=0.72s
21942/10943 (epoch 180.453) train_loss=234.23008728 time/batch=0.61s
21943/10943 (epoch 180.462) train_loss=384.49725342 time/batch=0.96s
21944/10943 (epoch 180.470) train_loss=300.49621582 time/batch=0.79s
21945/10943 (epoch 180.478) train_loss=241.38191223 time/batch=0.64s
21946/10943 (epoch 180.486) train_loss=348.15356445 time/batch=0.90s
21947/10943 (epoch 180.494) train_loss=412.02783203 time/batch=1.01s
21948/10943 (epoch 180.503) train_loss=99.20167542 time/batch=0.36s
21949/10943 (epoch 180.511) train_loss=308.30487061 time/batch=0.76s
21950/10943 (epoch 180.519) train_loss=519.18353271 time/batch=1.67s
21951/10943 (epoch 180.527) train_loss=425.43154907 time/batch=1.10s
21952/10943 (epoch 180.536) train_loss=294.09130859 time/batch=0.75s
21953/10943 (epoch 180.544) train_loss=158.89646912 time/batch=0.44s
21954/10943 (epoch 180.552) train_loss=240.06105042 time/batch=0.60s
21955/10943 (epoch 180.560) train_loss=159.31271362 time/batch=0.44s
21956/10943 (epoch 180.568) train_loss=332.21472168 time/batch=0.89s
21957/10943 (epoch 180.577) train_loss=123.85354614 time/batch=0.37s
21958/10943 (epoch 180.585) train_loss=128.35964966 time/batch=0.35s
21959/10943 (epoch 180.593) train_loss=299.09768677 time/batch=0.72s
21960/10943 (epoch 180.601) train_loss=228.45210266 time/batch=0.61s
21961/10943 (epoch 180.610) train_loss=184.89204407 time/batch=0.48s
21962/10943 (epoch 180.618) train_loss=197.76750183 time/batch=0.52s
21963/10943 (epoch 180.626) train_loss=268.67974854 time/batch=0.67s
21964/10943 (epoch 180.634) train_loss=218.80111694 time/batch=0.57s
21965/10943 (epoch 180.643) train_loss=211.47908020 time/batch=0.54s
21966/10943 (epoch 180.651) train_loss=176.91578674 time/batch=0.47s
21967/10943 (epoch 180.659) train_loss=207.28024292 time/batch=0.53s
21968/10943 (epoch 180.667) train_loss=304.93963623 time/batch=0.77s
21969/10943 (epoch 180.675) train_loss=346.57745361 time/batch=0.84s
21970/10943 (epoch 180.684) train_loss=278.34509277 time/batch=0.72s
21971/10943 (epoch 180.692) train_loss=306.60046387 time/batch=0.81s
21972/10943 (epoch 180.700) train_loss=254.21934509 time/batch=0.70s
21973/10943 (epoch 180.708) train_loss=207.17819214 time/batch=0.56s
21974/10943 (epoch 180.717) train_loss=299.93725586 time/batch=0.75s
21975/10943 (epoch 180.725) train_loss=193.88406372 time/batch=0.52s
21976/10943 (epoch 180.733) train_loss=303.13189697 time/batch=0.78s
21977/10943 (epoch 180.741) train_loss=199.38119507 time/batch=0.55s
21978/10943 (epoch 180.749) train_loss=254.95767212 time/batch=0.68s
21979/10943 (epoch 180.758) train_loss=264.28320312 time/batch=0.70s
21980/10943 (epoch 180.766) train_loss=212.13154602 time/batch=0.56s
21981/10943 (epoch 180.774) train_loss=329.87847900 time/batch=0.81s
21982/10943 (epoch 180.782) train_loss=237.55139160 time/batch=0.61s
21983/10943 (epoch 180.791) train_loss=412.32095337 time/batch=0.99s
21984/10943 (epoch 180.799) train_loss=211.66564941 time/batch=0.64s
21985/10943 (epoch 180.807) train_loss=233.97128296 time/batch=0.63s
21986/10943 (epoch 180.815) train_loss=114.70764923 time/batch=0.33s
21987/10943 (epoch 180.823) train_loss=332.93869019 time/batch=0.89s
21988/10943 (epoch 180.832) train_loss=303.24154663 time/batch=0.87s
21989/10943 (epoch 180.840) train_loss=170.96051025 time/batch=0.62s
21990/10943 (epoch 180.848) train_loss=242.40997314 time/batch=0.69s
21991/10943 (epoch 180.856) train_loss=229.14837646 time/batch=0.62s
setting learning rate to 0.0006542
21992/10943 (epoch 180.865) train_loss=228.88891602 time/batch=0.59s
21993/10943 (epoch 180.873) train_loss=147.78656006 time/batch=0.40s
21994/10943 (epoch 180.881) train_loss=439.82775879 time/batch=0.98s
21995/10943 (epoch 180.889) train_loss=472.02868652 time/batch=1.19s
21996/10943 (epoch 180.897) train_loss=325.57412720 time/batch=0.84s
21997/10943 (epoch 180.906) train_loss=93.65914917 time/batch=0.30s
21998/10943 (epoch 180.914) train_loss=467.49533081 time/batch=1.05s
21999/10943 (epoch 180.922) train_loss=562.08282471 time/batch=1.47s
Validating
    loss:	319.203974

22000/10943 (epoch 180.930) train_loss=127.31591797 time/batch=2.11s
22001/10943 (epoch 180.939) train_loss=394.68249512 time/batch=0.93s
22002/10943 (epoch 180.947) train_loss=758.63476562 time/batch=1.79s
22003/10943 (epoch 180.955) train_loss=721.97363281 time/batch=1.67s
22004/10943 (epoch 180.963) train_loss=613.94775391 time/batch=1.39s
22005/10943 (epoch 180.971) train_loss=501.21170044 time/batch=1.25s
22006/10943 (epoch 180.980) train_loss=440.90182495 time/batch=1.17s
22007/10943 (epoch 180.988) train_loss=441.31838989 time/batch=1.17s
22008/10943 (epoch 180.996) train_loss=390.32150269 time/batch=1.01s
22009/10943 (epoch 181.004) train_loss=354.73541260 time/batch=0.96s
22010/10943 (epoch 181.013) train_loss=873.84399414 time/batch=3.10s
22011/10943 (epoch 181.021) train_loss=444.97842407 time/batch=1.42s
22012/10943 (epoch 181.029) train_loss=150.10168457 time/batch=0.45s
22013/10943 (epoch 181.037) train_loss=257.60086060 time/batch=0.66s
22014/10943 (epoch 181.045) train_loss=160.95806885 time/batch=0.47s
22015/10943 (epoch 181.054) train_loss=189.21199036 time/batch=0.47s
22016/10943 (epoch 181.062) train_loss=322.52136230 time/batch=0.84s
22017/10943 (epoch 181.070) train_loss=132.50189209 time/batch=0.38s
22018/10943 (epoch 181.078) train_loss=174.39419556 time/batch=0.43s
22019/10943 (epoch 181.087) train_loss=265.86810303 time/batch=0.68s
22020/10943 (epoch 181.095) train_loss=266.08361816 time/batch=0.68s
22021/10943 (epoch 181.103) train_loss=296.81494141 time/batch=0.80s
22022/10943 (epoch 181.111) train_loss=359.98107910 time/batch=0.93s
22023/10943 (epoch 181.120) train_loss=230.95280457 time/batch=0.64s
22024/10943 (epoch 181.128) train_loss=291.91308594 time/batch=0.75s
22025/10943 (epoch 181.136) train_loss=155.70202637 time/batch=0.46s
22026/10943 (epoch 181.144) train_loss=429.96630859 time/batch=1.15s
22027/10943 (epoch 181.152) train_loss=236.25610352 time/batch=0.68s
22028/10943 (epoch 181.161) train_loss=110.59372711 time/batch=0.31s
22029/10943 (epoch 181.169) train_loss=308.55364990 time/batch=0.78s
22030/10943 (epoch 181.177) train_loss=210.94909668 time/batch=0.57s
22031/10943 (epoch 181.185) train_loss=390.40869141 time/batch=0.95s
22032/10943 (epoch 181.194) train_loss=176.44219971 time/batch=0.49s
22033/10943 (epoch 181.202) train_loss=265.47662354 time/batch=0.66s
22034/10943 (epoch 181.210) train_loss=553.13214111 time/batch=1.33s
22035/10943 (epoch 181.218) train_loss=273.63842773 time/batch=0.77s
22036/10943 (epoch 181.226) train_loss=390.88967896 time/batch=0.94s
22037/10943 (epoch 181.235) train_loss=319.54650879 time/batch=0.85s
22038/10943 (epoch 181.243) train_loss=430.37976074 time/batch=1.03s
22039/10943 (epoch 181.251) train_loss=372.49639893 time/batch=0.98s
22040/10943 (epoch 181.259) train_loss=118.31427002 time/batch=0.37s
22041/10943 (epoch 181.268) train_loss=151.06971741 time/batch=0.39s
22042/10943 (epoch 181.276) train_loss=503.00601196 time/batch=1.31s
22043/10943 (epoch 181.284) train_loss=337.55108643 time/batch=0.89s
22044/10943 (epoch 181.292) train_loss=293.53442383 time/batch=0.77s
22045/10943 (epoch 181.300) train_loss=365.27679443 time/batch=0.89s
22046/10943 (epoch 181.309) train_loss=273.01318359 time/batch=0.70s
22047/10943 (epoch 181.317) train_loss=173.13137817 time/batch=0.47s
22048/10943 (epoch 181.325) train_loss=212.46984863 time/batch=0.53s
22049/10943 (epoch 181.333) train_loss=177.98522949 time/batch=0.47s
22050/10943 (epoch 181.342) train_loss=145.37048340 time/batch=0.36s
22051/10943 (epoch 181.350) train_loss=276.06884766 time/batch=0.69s
22052/10943 (epoch 181.358) train_loss=300.37207031 time/batch=0.75s
22053/10943 (epoch 181.366) train_loss=201.88845825 time/batch=0.56s
22054/10943 (epoch 181.374) train_loss=356.47741699 time/batch=0.88s
22055/10943 (epoch 181.383) train_loss=358.35540771 time/batch=0.91s
22056/10943 (epoch 181.391) train_loss=215.57382202 time/batch=0.60s
22057/10943 (epoch 181.399) train_loss=277.54272461 time/batch=0.70s
22058/10943 (epoch 181.407) train_loss=216.26406860 time/batch=0.59s
22059/10943 (epoch 181.416) train_loss=254.09043884 time/batch=0.65s
22060/10943 (epoch 181.424) train_loss=280.08215332 time/batch=0.71s
22061/10943 (epoch 181.432) train_loss=216.93716431 time/batch=0.58s
22062/10943 (epoch 181.440) train_loss=263.73260498 time/batch=0.66s
22063/10943 (epoch 181.448) train_loss=258.21450806 time/batch=0.65s
22064/10943 (epoch 181.457) train_loss=186.80844116 time/batch=0.50s
22065/10943 (epoch 181.465) train_loss=291.11993408 time/batch=0.70s
22066/10943 (epoch 181.473) train_loss=304.91900635 time/batch=0.76s
22067/10943 (epoch 181.481) train_loss=320.38385010 time/batch=0.84s
22068/10943 (epoch 181.490) train_loss=216.66995239 time/batch=0.60s
22069/10943 (epoch 181.498) train_loss=170.30508423 time/batch=0.48s
22070/10943 (epoch 181.506) train_loss=195.24082947 time/batch=0.51s
22071/10943 (epoch 181.514) train_loss=288.56427002 time/batch=0.74s
22072/10943 (epoch 181.522) train_loss=114.47145844 time/batch=0.35s
22073/10943 (epoch 181.531) train_loss=295.78515625 time/batch=0.71s
22074/10943 (epoch 181.539) train_loss=403.09478760 time/batch=1.01s
22075/10943 (epoch 181.547) train_loss=136.00134277 time/batch=0.41s
22076/10943 (epoch 181.555) train_loss=167.60324097 time/batch=0.46s
22077/10943 (epoch 181.564) train_loss=433.20153809 time/batch=0.99s
22078/10943 (epoch 181.572) train_loss=283.02191162 time/batch=0.75s
22079/10943 (epoch 181.580) train_loss=234.06848145 time/batch=0.61s
22080/10943 (epoch 181.588) train_loss=304.60382080 time/batch=0.77s
22081/10943 (epoch 181.597) train_loss=180.67794800 time/batch=0.51s
22082/10943 (epoch 181.605) train_loss=396.96600342 time/batch=1.17s
22083/10943 (epoch 181.613) train_loss=230.47209167 time/batch=0.70s
22084/10943 (epoch 181.621) train_loss=278.08798218 time/batch=0.74s
22085/10943 (epoch 181.629) train_loss=349.68572998 time/batch=0.85s
22086/10943 (epoch 181.638) train_loss=136.97994995 time/batch=0.40s
22087/10943 (epoch 181.646) train_loss=242.50253296 time/batch=0.61s
22088/10943 (epoch 181.654) train_loss=377.41345215 time/batch=1.19s
22089/10943 (epoch 181.662) train_loss=179.04341125 time/batch=0.57s
22090/10943 (epoch 181.671) train_loss=227.23504639 time/batch=0.59s
22091/10943 (epoch 181.679) train_loss=230.44624329 time/batch=0.62s
22092/10943 (epoch 181.687) train_loss=208.26098633 time/batch=0.52s
22093/10943 (epoch 181.695) train_loss=174.38983154 time/batch=0.50s
22094/10943 (epoch 181.703) train_loss=291.76135254 time/batch=0.76s
22095/10943 (epoch 181.712) train_loss=245.48268127 time/batch=0.65s
22096/10943 (epoch 181.720) train_loss=306.68292236 time/batch=0.78s
22097/10943 (epoch 181.728) train_loss=314.33044434 time/batch=0.83s
22098/10943 (epoch 181.736) train_loss=280.71011353 time/batch=0.79s
22099/10943 (epoch 181.745) train_loss=341.29727173 time/batch=0.85s
22100/10943 (epoch 181.753) train_loss=200.03945923 time/batch=0.57s
22101/10943 (epoch 181.761) train_loss=327.65328979 time/batch=0.84s
22102/10943 (epoch 181.769) train_loss=199.53192139 time/batch=0.56s
22103/10943 (epoch 181.777) train_loss=316.80072021 time/batch=0.81s
22104/10943 (epoch 181.786) train_loss=141.46954346 time/batch=0.40s
22105/10943 (epoch 181.794) train_loss=241.37673950 time/batch=0.59s
22106/10943 (epoch 181.802) train_loss=233.28494263 time/batch=0.58s
22107/10943 (epoch 181.810) train_loss=304.92019653 time/batch=0.79s
22108/10943 (epoch 181.819) train_loss=239.47801208 time/batch=0.66s
22109/10943 (epoch 181.827) train_loss=228.70861816 time/batch=0.59s
22110/10943 (epoch 181.835) train_loss=216.95886230 time/batch=0.63s
22111/10943 (epoch 181.843) train_loss=270.43817139 time/batch=0.80s
22112/10943 (epoch 181.851) train_loss=251.08361816 time/batch=0.66s
setting learning rate to 0.0006346
22113/10943 (epoch 181.860) train_loss=551.71166992 time/batch=1.26s
22114/10943 (epoch 181.868) train_loss=984.72753906 time/batch=3.16s
22115/10943 (epoch 181.876) train_loss=492.42019653 time/batch=1.31s
22116/10943 (epoch 181.884) train_loss=130.88328552 time/batch=0.40s
22117/10943 (epoch 181.893) train_loss=211.71343994 time/batch=0.52s
22118/10943 (epoch 181.901) train_loss=337.02685547 time/batch=0.82s
22119/10943 (epoch 181.909) train_loss=400.63537598 time/batch=1.02s
22120/10943 (epoch 181.917) train_loss=482.12197876 time/batch=1.19s
22121/10943 (epoch 181.925) train_loss=111.99166107 time/batch=0.36s
22122/10943 (epoch 181.934) train_loss=418.80139160 time/batch=0.91s
22123/10943 (epoch 181.942) train_loss=159.36225891 time/batch=0.47s
22124/10943 (epoch 181.950) train_loss=364.24798584 time/batch=0.89s
22125/10943 (epoch 181.958) train_loss=294.83905029 time/batch=0.79s
22126/10943 (epoch 181.967) train_loss=466.46640015 time/batch=1.11s
22127/10943 (epoch 181.975) train_loss=301.42266846 time/batch=0.82s
22128/10943 (epoch 181.983) train_loss=226.88713074 time/batch=0.62s
22129/10943 (epoch 181.991) train_loss=266.35403442 time/batch=0.68s
22130/10943 (epoch 181.999) train_loss=363.86706543 time/batch=0.89s
22131/10943 (epoch 182.008) train_loss=160.55606079 time/batch=0.46s
22132/10943 (epoch 182.016) train_loss=510.78457642 time/batch=1.17s
22133/10943 (epoch 182.024) train_loss=559.97485352 time/batch=1.44s
22134/10943 (epoch 182.032) train_loss=257.30712891 time/batch=0.72s
22135/10943 (epoch 182.041) train_loss=345.05572510 time/batch=0.83s
22136/10943 (epoch 182.049) train_loss=732.94921875 time/batch=1.69s
22137/10943 (epoch 182.057) train_loss=196.21653748 time/batch=0.62s
22138/10943 (epoch 182.065) train_loss=639.74157715 time/batch=1.51s
22139/10943 (epoch 182.074) train_loss=532.86828613 time/batch=1.38s
22140/10943 (epoch 182.082) train_loss=256.72344971 time/batch=0.72s
22141/10943 (epoch 182.090) train_loss=228.64628601 time/batch=0.59s
22142/10943 (epoch 182.098) train_loss=171.22735596 time/batch=0.44s
22143/10943 (epoch 182.106) train_loss=494.22601318 time/batch=1.27s
22144/10943 (epoch 182.115) train_loss=241.57046509 time/batch=0.71s
22145/10943 (epoch 182.123) train_loss=515.66394043 time/batch=1.42s
22146/10943 (epoch 182.131) train_loss=424.81604004 time/batch=1.14s
22147/10943 (epoch 182.139) train_loss=207.53459167 time/batch=0.57s
22148/10943 (epoch 182.148) train_loss=445.27124023 time/batch=1.10s
22149/10943 (epoch 182.156) train_loss=303.12744141 time/batch=0.85s
22150/10943 (epoch 182.164) train_loss=164.99386597 time/batch=0.47s
22151/10943 (epoch 182.172) train_loss=356.13720703 time/batch=0.87s
22152/10943 (epoch 182.180) train_loss=229.93612671 time/batch=0.63s
22153/10943 (epoch 182.189) train_loss=465.15490723 time/batch=1.05s
22154/10943 (epoch 182.197) train_loss=208.32929993 time/batch=0.57s
22155/10943 (epoch 182.205) train_loss=428.55236816 time/batch=0.99s
22156/10943 (epoch 182.213) train_loss=125.20863342 time/batch=0.38s
22157/10943 (epoch 182.222) train_loss=305.75988770 time/batch=0.74s
22158/10943 (epoch 182.230) train_loss=136.84017944 time/batch=0.38s
22159/10943 (epoch 182.238) train_loss=443.90112305 time/batch=1.04s
22160/10943 (epoch 182.246) train_loss=314.22314453 time/batch=0.85s
22161/10943 (epoch 182.254) train_loss=388.02020264 time/batch=0.97s
22162/10943 (epoch 182.263) train_loss=325.42108154 time/batch=0.85s
22163/10943 (epoch 182.271) train_loss=294.66101074 time/batch=0.77s
22164/10943 (epoch 182.279) train_loss=245.83845520 time/batch=0.62s
22165/10943 (epoch 182.287) train_loss=267.54962158 time/batch=0.67s
22166/10943 (epoch 182.296) train_loss=221.10375977 time/batch=0.57s
22167/10943 (epoch 182.304) train_loss=206.24073792 time/batch=0.54s
22168/10943 (epoch 182.312) train_loss=218.50300598 time/batch=0.57s
22169/10943 (epoch 182.320) train_loss=291.09909058 time/batch=0.71s
22170/10943 (epoch 182.328) train_loss=285.27441406 time/batch=0.72s
22171/10943 (epoch 182.337) train_loss=148.60726929 time/batch=0.40s
22172/10943 (epoch 182.345) train_loss=266.19665527 time/batch=0.67s
22173/10943 (epoch 182.353) train_loss=312.30914307 time/batch=0.78s
22174/10943 (epoch 182.361) train_loss=331.67846680 time/batch=0.86s
22175/10943 (epoch 182.370) train_loss=376.22204590 time/batch=0.95s
22176/10943 (epoch 182.378) train_loss=207.39132690 time/batch=0.57s
22177/10943 (epoch 182.386) train_loss=377.22106934 time/batch=0.91s
22178/10943 (epoch 182.394) train_loss=111.74266052 time/batch=0.35s
22179/10943 (epoch 182.402) train_loss=138.50671387 time/batch=0.34s
22180/10943 (epoch 182.411) train_loss=162.10363770 time/batch=0.43s
22181/10943 (epoch 182.419) train_loss=298.50808716 time/batch=0.76s
22182/10943 (epoch 182.427) train_loss=239.21966553 time/batch=0.63s
22183/10943 (epoch 182.435) train_loss=391.05328369 time/batch=0.98s
22184/10943 (epoch 182.444) train_loss=127.68267822 time/batch=0.37s
22185/10943 (epoch 182.452) train_loss=295.10766602 time/batch=0.72s
22186/10943 (epoch 182.460) train_loss=194.79858398 time/batch=0.55s
22187/10943 (epoch 182.468) train_loss=355.57138062 time/batch=0.94s
22188/10943 (epoch 182.476) train_loss=209.33644104 time/batch=0.61s
22189/10943 (epoch 182.485) train_loss=282.49725342 time/batch=0.72s
22190/10943 (epoch 182.493) train_loss=237.39440918 time/batch=0.66s
22191/10943 (epoch 182.501) train_loss=307.68908691 time/batch=0.79s
22192/10943 (epoch 182.509) train_loss=380.62292480 time/batch=0.98s
22193/10943 (epoch 182.518) train_loss=280.81491089 time/batch=0.72s
22194/10943 (epoch 182.526) train_loss=274.04760742 time/batch=0.67s
22195/10943 (epoch 182.534) train_loss=263.87426758 time/batch=0.67s
22196/10943 (epoch 182.542) train_loss=174.58621216 time/batch=0.48s
22197/10943 (epoch 182.551) train_loss=190.13421631 time/batch=0.49s
22198/10943 (epoch 182.559) train_loss=142.79730225 time/batch=0.36s
22199/10943 (epoch 182.567) train_loss=326.10507202 time/batch=0.82s
22200/10943 (epoch 182.575) train_loss=125.32992554 time/batch=0.41s
22201/10943 (epoch 182.583) train_loss=179.89831543 time/batch=0.47s
22202/10943 (epoch 182.592) train_loss=252.89889526 time/batch=0.64s
22203/10943 (epoch 182.600) train_loss=220.15733337 time/batch=0.62s
22204/10943 (epoch 182.608) train_loss=303.65969849 time/batch=0.79s
22205/10943 (epoch 182.616) train_loss=225.58262634 time/batch=0.61s
22206/10943 (epoch 182.625) train_loss=215.08779907 time/batch=0.57s
22207/10943 (epoch 182.633) train_loss=342.75521851 time/batch=0.86s
22208/10943 (epoch 182.641) train_loss=265.44885254 time/batch=0.72s
22209/10943 (epoch 182.649) train_loss=350.23760986 time/batch=0.86s
22210/10943 (epoch 182.657) train_loss=198.73171997 time/batch=0.53s
22211/10943 (epoch 182.666) train_loss=112.44596863 time/batch=0.36s
22212/10943 (epoch 182.674) train_loss=336.18563843 time/batch=0.86s
22213/10943 (epoch 182.682) train_loss=316.76043701 time/batch=0.85s
22214/10943 (epoch 182.690) train_loss=297.46911621 time/batch=0.75s
22215/10943 (epoch 182.699) train_loss=235.60960388 time/batch=0.65s
22216/10943 (epoch 182.707) train_loss=259.01083374 time/batch=0.65s
22217/10943 (epoch 182.715) train_loss=241.45715332 time/batch=0.62s
22218/10943 (epoch 182.723) train_loss=220.02435303 time/batch=0.61s
22219/10943 (epoch 182.731) train_loss=183.74862671 time/batch=0.50s
22220/10943 (epoch 182.740) train_loss=257.12847900 time/batch=0.66s
22221/10943 (epoch 182.748) train_loss=153.24369812 time/batch=0.40s
22222/10943 (epoch 182.756) train_loss=301.25115967 time/batch=0.79s
22223/10943 (epoch 182.764) train_loss=196.19793701 time/batch=0.60s
22224/10943 (epoch 182.773) train_loss=281.98046875 time/batch=0.74s
22225/10943 (epoch 182.781) train_loss=179.49670410 time/batch=0.60s
22226/10943 (epoch 182.789) train_loss=309.08642578 time/batch=0.81s
22227/10943 (epoch 182.797) train_loss=311.50549316 time/batch=0.84s
22228/10943 (epoch 182.805) train_loss=149.29978943 time/batch=0.44s
22229/10943 (epoch 182.814) train_loss=294.81365967 time/batch=0.69s
22230/10943 (epoch 182.822) train_loss=161.87974548 time/batch=0.59s
22231/10943 (epoch 182.830) train_loss=253.61550903 time/batch=0.67s
22232/10943 (epoch 182.838) train_loss=231.06990051 time/batch=0.59s
22233/10943 (epoch 182.847) train_loss=249.67980957 time/batch=0.69s
setting learning rate to 0.0006155
22234/10943 (epoch 182.855) train_loss=349.47277832 time/batch=0.92s
22235/10943 (epoch 182.863) train_loss=466.43725586 time/batch=1.12s
22236/10943 (epoch 182.871) train_loss=809.54351807 time/batch=1.95s
22237/10943 (epoch 182.879) train_loss=332.69299316 time/batch=0.92s
22238/10943 (epoch 182.888) train_loss=373.08868408 time/batch=0.91s
22239/10943 (epoch 182.896) train_loss=518.99578857 time/batch=1.27s
22240/10943 (epoch 182.904) train_loss=570.95837402 time/batch=1.40s
22241/10943 (epoch 182.912) train_loss=479.61431885 time/batch=1.26s
22242/10943 (epoch 182.921) train_loss=539.20965576 time/batch=1.42s
22243/10943 (epoch 182.929) train_loss=308.43371582 time/batch=0.87s
22244/10943 (epoch 182.937) train_loss=106.55947876 time/batch=0.32s
22245/10943 (epoch 182.945) train_loss=427.78442383 time/batch=1.02s
22246/10943 (epoch 182.953) train_loss=455.49591064 time/batch=1.19s
22247/10943 (epoch 182.962) train_loss=585.25329590 time/batch=1.55s
22248/10943 (epoch 182.970) train_loss=407.62179565 time/batch=1.09s
22249/10943 (epoch 182.978) train_loss=508.88980103 time/batch=1.25s
22250/10943 (epoch 182.986) train_loss=272.84326172 time/batch=0.74s
22251/10943 (epoch 182.995) train_loss=154.05578613 time/batch=0.44s
22252/10943 (epoch 183.003) train_loss=145.53324890 time/batch=0.38s
22253/10943 (epoch 183.011) train_loss=263.87899780 time/batch=0.64s
22254/10943 (epoch 183.019) train_loss=863.79992676 time/batch=3.10s
22255/10943 (epoch 183.027) train_loss=140.79145813 time/batch=0.65s
22256/10943 (epoch 183.036) train_loss=286.98355103 time/batch=0.67s
22257/10943 (epoch 183.044) train_loss=141.02233887 time/batch=0.38s
22258/10943 (epoch 183.052) train_loss=378.57662964 time/batch=0.92s
22259/10943 (epoch 183.060) train_loss=187.87435913 time/batch=0.54s
22260/10943 (epoch 183.069) train_loss=250.85675049 time/batch=0.65s
22261/10943 (epoch 183.077) train_loss=258.65698242 time/batch=0.68s
22262/10943 (epoch 183.085) train_loss=542.68463135 time/batch=1.53s
22263/10943 (epoch 183.093) train_loss=392.53228760 time/batch=1.07s
22264/10943 (epoch 183.102) train_loss=346.32696533 time/batch=0.90s
22265/10943 (epoch 183.110) train_loss=260.97454834 time/batch=0.70s
22266/10943 (epoch 183.118) train_loss=280.91772461 time/batch=0.73s
22267/10943 (epoch 183.126) train_loss=221.30102539 time/batch=0.59s
22268/10943 (epoch 183.134) train_loss=271.39904785 time/batch=0.71s
22269/10943 (epoch 183.143) train_loss=434.16201782 time/batch=1.11s
22270/10943 (epoch 183.151) train_loss=348.39080811 time/batch=0.91s
22271/10943 (epoch 183.159) train_loss=231.10787964 time/batch=0.64s
22272/10943 (epoch 183.167) train_loss=259.78344727 time/batch=0.68s
22273/10943 (epoch 183.176) train_loss=194.45025635 time/batch=0.51s
22274/10943 (epoch 183.184) train_loss=118.36457062 time/batch=0.31s
22275/10943 (epoch 183.192) train_loss=166.10180664 time/batch=0.42s
22276/10943 (epoch 183.200) train_loss=290.00292969 time/batch=0.73s
22277/10943 (epoch 183.208) train_loss=439.08450317 time/batch=1.12s
22278/10943 (epoch 183.217) train_loss=203.10955811 time/batch=0.59s
22279/10943 (epoch 183.225) train_loss=183.02346802 time/batch=0.49s
22280/10943 (epoch 183.233) train_loss=158.99194336 time/batch=0.43s
22281/10943 (epoch 183.241) train_loss=263.79656982 time/batch=0.67s
22282/10943 (epoch 183.250) train_loss=228.20829773 time/batch=0.60s
22283/10943 (epoch 183.258) train_loss=169.89270020 time/batch=0.45s
22284/10943 (epoch 183.266) train_loss=229.34237671 time/batch=0.57s
22285/10943 (epoch 183.274) train_loss=381.23785400 time/batch=0.93s
22286/10943 (epoch 183.282) train_loss=422.07449341 time/batch=1.03s
22287/10943 (epoch 183.291) train_loss=274.16009521 time/batch=0.74s
22288/10943 (epoch 183.299) train_loss=430.95349121 time/batch=1.02s
22289/10943 (epoch 183.307) train_loss=220.11705017 time/batch=0.63s
22290/10943 (epoch 183.315) train_loss=199.56718445 time/batch=0.54s
22291/10943 (epoch 183.324) train_loss=296.48541260 time/batch=0.76s
22292/10943 (epoch 183.332) train_loss=175.66177368 time/batch=0.49s
22293/10943 (epoch 183.340) train_loss=299.63815308 time/batch=0.79s
22294/10943 (epoch 183.348) train_loss=107.86062622 time/batch=0.34s
22295/10943 (epoch 183.356) train_loss=295.80920410 time/batch=0.75s
22296/10943 (epoch 183.365) train_loss=296.67245483 time/batch=0.76s
22297/10943 (epoch 183.373) train_loss=328.16424561 time/batch=0.84s
22298/10943 (epoch 183.381) train_loss=317.52761841 time/batch=0.79s
22299/10943 (epoch 183.389) train_loss=119.32064819 time/batch=0.35s
22300/10943 (epoch 183.398) train_loss=411.35675049 time/batch=0.98s
22301/10943 (epoch 183.406) train_loss=187.61059570 time/batch=0.54s
22302/10943 (epoch 183.414) train_loss=405.92968750 time/batch=1.01s
22303/10943 (epoch 183.422) train_loss=320.36566162 time/batch=0.86s
22304/10943 (epoch 183.430) train_loss=288.46759033 time/batch=0.74s
22305/10943 (epoch 183.439) train_loss=140.95721436 time/batch=0.38s
22306/10943 (epoch 183.447) train_loss=105.68562317 time/batch=0.32s
22307/10943 (epoch 183.455) train_loss=195.81759644 time/batch=0.49s
22308/10943 (epoch 183.463) train_loss=215.96340942 time/batch=0.59s
22309/10943 (epoch 183.472) train_loss=361.32748413 time/batch=0.92s
22310/10943 (epoch 183.480) train_loss=228.49722290 time/batch=0.62s
22311/10943 (epoch 183.488) train_loss=376.47317505 time/batch=0.94s
22312/10943 (epoch 183.496) train_loss=267.23275757 time/batch=0.72s
22313/10943 (epoch 183.504) train_loss=262.29537964 time/batch=0.68s
22314/10943 (epoch 183.513) train_loss=132.49450684 time/batch=0.38s
22315/10943 (epoch 183.521) train_loss=178.36581421 time/batch=0.45s
22316/10943 (epoch 183.529) train_loss=169.66633606 time/batch=0.43s
22317/10943 (epoch 183.537) train_loss=263.72479248 time/batch=0.68s
22318/10943 (epoch 183.546) train_loss=128.34310913 time/batch=0.38s
22319/10943 (epoch 183.554) train_loss=238.32353210 time/batch=0.59s
22320/10943 (epoch 183.562) train_loss=365.20208740 time/batch=0.88s
22321/10943 (epoch 183.570) train_loss=237.13238525 time/batch=0.66s
22322/10943 (epoch 183.579) train_loss=277.22485352 time/batch=0.75s
22323/10943 (epoch 183.587) train_loss=174.64334106 time/batch=0.50s
22324/10943 (epoch 183.595) train_loss=252.42945862 time/batch=0.62s
22325/10943 (epoch 183.603) train_loss=223.29434204 time/batch=0.62s
22326/10943 (epoch 183.611) train_loss=171.00692749 time/batch=0.49s
22327/10943 (epoch 183.620) train_loss=345.63128662 time/batch=0.86s
22328/10943 (epoch 183.628) train_loss=204.05294800 time/batch=0.56s
22329/10943 (epoch 183.636) train_loss=288.89263916 time/batch=0.71s
22330/10943 (epoch 183.644) train_loss=234.45733643 time/batch=0.63s
22331/10943 (epoch 183.653) train_loss=287.93591309 time/batch=0.72s
22332/10943 (epoch 183.661) train_loss=234.41542053 time/batch=0.62s
22333/10943 (epoch 183.669) train_loss=194.31576538 time/batch=0.53s
22334/10943 (epoch 183.677) train_loss=301.04403687 time/batch=0.78s
22335/10943 (epoch 183.685) train_loss=253.01651001 time/batch=0.68s
22336/10943 (epoch 183.694) train_loss=213.85295105 time/batch=0.56s
22337/10943 (epoch 183.702) train_loss=292.42251587 time/batch=0.78s
22338/10943 (epoch 183.710) train_loss=215.15397644 time/batch=0.59s
22339/10943 (epoch 183.718) train_loss=141.88281250 time/batch=0.40s
22340/10943 (epoch 183.727) train_loss=333.50030518 time/batch=0.82s
22341/10943 (epoch 183.735) train_loss=214.46423340 time/batch=0.60s
22342/10943 (epoch 183.743) train_loss=307.58529663 time/batch=0.79s
22343/10943 (epoch 183.751) train_loss=232.89097595 time/batch=0.63s
22344/10943 (epoch 183.759) train_loss=339.98126221 time/batch=0.89s
22345/10943 (epoch 183.768) train_loss=312.46749878 time/batch=0.84s
22346/10943 (epoch 183.776) train_loss=156.85205078 time/batch=0.43s
22347/10943 (epoch 183.784) train_loss=163.80133057 time/batch=0.53s
22348/10943 (epoch 183.792) train_loss=325.22064209 time/batch=0.81s
22349/10943 (epoch 183.801) train_loss=329.47650146 time/batch=0.87s
22350/10943 (epoch 183.809) train_loss=306.19412231 time/batch=0.84s
22351/10943 (epoch 183.817) train_loss=332.04235840 time/batch=0.88s
22352/10943 (epoch 183.825) train_loss=207.22993469 time/batch=0.63s
22353/10943 (epoch 183.833) train_loss=231.28976440 time/batch=0.61s
22354/10943 (epoch 183.842) train_loss=244.02226257 time/batch=0.64s
setting learning rate to 0.0005971
22355/10943 (epoch 183.850) train_loss=156.64494324 time/batch=0.42s
22356/10943 (epoch 183.858) train_loss=334.48712158 time/batch=0.81s
22357/10943 (epoch 183.866) train_loss=560.19476318 time/batch=1.35s
22358/10943 (epoch 183.875) train_loss=984.39672852 time/batch=3.17s
22359/10943 (epoch 183.883) train_loss=662.97534180 time/batch=1.75s
22360/10943 (epoch 183.891) train_loss=444.09185791 time/batch=1.09s
22361/10943 (epoch 183.899) train_loss=121.61134338 time/batch=0.37s
22362/10943 (epoch 183.907) train_loss=497.28961182 time/batch=1.19s
22363/10943 (epoch 183.916) train_loss=539.40637207 time/batch=1.55s
22364/10943 (epoch 183.924) train_loss=175.24319458 time/batch=0.58s
22365/10943 (epoch 183.932) train_loss=424.85675049 time/batch=1.01s
22366/10943 (epoch 183.940) train_loss=95.89268494 time/batch=0.33s
22367/10943 (epoch 183.949) train_loss=497.83624268 time/batch=1.15s
22368/10943 (epoch 183.957) train_loss=355.17211914 time/batch=0.95s
22369/10943 (epoch 183.965) train_loss=459.43212891 time/batch=1.17s
22370/10943 (epoch 183.973) train_loss=148.97029114 time/batch=0.46s
22371/10943 (epoch 183.981) train_loss=161.38957214 time/batch=0.43s
22372/10943 (epoch 183.990) train_loss=410.24475098 time/batch=0.99s
22373/10943 (epoch 183.998) train_loss=273.16387939 time/batch=0.76s
22374/10943 (epoch 184.006) train_loss=694.73870850 time/batch=1.69s
22375/10943 (epoch 184.014) train_loss=275.17559814 time/batch=0.82s
22376/10943 (epoch 184.023) train_loss=123.66757202 time/batch=0.35s
22377/10943 (epoch 184.031) train_loss=214.57273865 time/batch=0.54s
22378/10943 (epoch 184.039) train_loss=347.21896362 time/batch=0.87s
22379/10943 (epoch 184.047) train_loss=186.23620605 time/batch=0.53s
22380/10943 (epoch 184.056) train_loss=256.73098755 time/batch=0.67s
22381/10943 (epoch 184.064) train_loss=376.34893799 time/batch=0.95s
22382/10943 (epoch 184.072) train_loss=381.51638794 time/batch=1.00s
22383/10943 (epoch 184.080) train_loss=106.52360535 time/batch=0.35s
22384/10943 (epoch 184.088) train_loss=444.32867432 time/batch=1.07s
22385/10943 (epoch 184.097) train_loss=284.57983398 time/batch=0.77s
22386/10943 (epoch 184.105) train_loss=198.03437805 time/batch=0.55s
22387/10943 (epoch 184.113) train_loss=356.35754395 time/batch=0.89s
22388/10943 (epoch 184.121) train_loss=383.38287354 time/batch=1.01s
22389/10943 (epoch 184.130) train_loss=201.35287476 time/batch=0.60s
22390/10943 (epoch 184.138) train_loss=445.78729248 time/batch=1.09s
22391/10943 (epoch 184.146) train_loss=303.24246216 time/batch=0.82s
22392/10943 (epoch 184.154) train_loss=601.20489502 time/batch=1.55s
22393/10943 (epoch 184.162) train_loss=462.28900146 time/batch=1.22s
22394/10943 (epoch 184.171) train_loss=302.14685059 time/batch=0.79s
22395/10943 (epoch 184.179) train_loss=193.17697144 time/batch=0.55s
22396/10943 (epoch 184.187) train_loss=204.81234741 time/batch=0.55s
22397/10943 (epoch 184.195) train_loss=427.62185669 time/batch=1.14s
22398/10943 (epoch 184.204) train_loss=157.57623291 time/batch=0.50s
22399/10943 (epoch 184.212) train_loss=291.98638916 time/batch=0.77s
22400/10943 (epoch 184.220) train_loss=258.31930542 time/batch=0.68s
22401/10943 (epoch 184.228) train_loss=114.74808502 time/batch=0.34s
22402/10943 (epoch 184.236) train_loss=219.27447510 time/batch=0.56s
22403/10943 (epoch 184.245) train_loss=316.30187988 time/batch=0.82s
22404/10943 (epoch 184.253) train_loss=309.76254272 time/batch=0.84s
22405/10943 (epoch 184.261) train_loss=352.11724854 time/batch=0.91s
22406/10943 (epoch 184.269) train_loss=333.18444824 time/batch=0.87s
22407/10943 (epoch 184.278) train_loss=306.47244263 time/batch=0.78s
22408/10943 (epoch 184.286) train_loss=297.24163818 time/batch=0.81s
22409/10943 (epoch 184.294) train_loss=155.77420044 time/batch=0.45s
22410/10943 (epoch 184.302) train_loss=296.07287598 time/batch=0.78s
22411/10943 (epoch 184.310) train_loss=120.67565918 time/batch=0.37s
22412/10943 (epoch 184.319) train_loss=234.20346069 time/batch=0.59s
22413/10943 (epoch 184.327) train_loss=177.07400513 time/batch=0.49s
22414/10943 (epoch 184.335) train_loss=234.59332275 time/batch=0.62s
22415/10943 (epoch 184.343) train_loss=220.49453735 time/batch=0.59s
22416/10943 (epoch 184.352) train_loss=181.74905396 time/batch=0.50s
22417/10943 (epoch 184.360) train_loss=300.56756592 time/batch=0.77s
22418/10943 (epoch 184.368) train_loss=318.49078369 time/batch=0.85s
22419/10943 (epoch 184.376) train_loss=146.11962891 time/batch=0.42s
22420/10943 (epoch 184.384) train_loss=193.33197021 time/batch=0.48s
22421/10943 (epoch 184.393) train_loss=260.26394653 time/batch=0.66s
22422/10943 (epoch 184.401) train_loss=145.77578735 time/batch=0.41s
22423/10943 (epoch 184.409) train_loss=298.05853271 time/batch=0.75s
22424/10943 (epoch 184.417) train_loss=363.42871094 time/batch=0.95s
22425/10943 (epoch 184.426) train_loss=450.92605591 time/batch=1.05s
22426/10943 (epoch 184.434) train_loss=409.91357422 time/batch=1.05s
22427/10943 (epoch 184.442) train_loss=298.36340332 time/batch=0.80s
22428/10943 (epoch 184.450) train_loss=442.58239746 time/batch=1.19s
22429/10943 (epoch 184.458) train_loss=395.57293701 time/batch=1.28s
22430/10943 (epoch 184.467) train_loss=304.90460205 time/batch=0.85s
22431/10943 (epoch 184.475) train_loss=300.08621216 time/batch=0.80s
22432/10943 (epoch 184.483) train_loss=224.72994995 time/batch=0.64s
22433/10943 (epoch 184.491) train_loss=172.55926514 time/batch=0.46s
22434/10943 (epoch 184.500) train_loss=188.69267273 time/batch=0.47s
22435/10943 (epoch 184.508) train_loss=136.61972046 time/batch=0.35s
22436/10943 (epoch 184.516) train_loss=271.55987549 time/batch=0.64s
22437/10943 (epoch 184.524) train_loss=239.74090576 time/batch=0.64s
22438/10943 (epoch 184.533) train_loss=251.63168335 time/batch=0.65s
22439/10943 (epoch 184.541) train_loss=299.77130127 time/batch=0.81s
22440/10943 (epoch 184.549) train_loss=267.92669678 time/batch=0.71s
22441/10943 (epoch 184.557) train_loss=290.22747803 time/batch=0.73s
22442/10943 (epoch 184.565) train_loss=179.31761169 time/batch=0.52s
22443/10943 (epoch 184.574) train_loss=331.17416382 time/batch=0.82s
22444/10943 (epoch 184.582) train_loss=131.18394470 time/batch=0.38s
22445/10943 (epoch 184.590) train_loss=213.30828857 time/batch=0.53s
22446/10943 (epoch 184.598) train_loss=242.43072510 time/batch=0.63s
22447/10943 (epoch 184.607) train_loss=201.59980774 time/batch=0.56s
22448/10943 (epoch 184.615) train_loss=201.90582275 time/batch=0.54s
22449/10943 (epoch 184.623) train_loss=355.35003662 time/batch=0.89s
22450/10943 (epoch 184.631) train_loss=186.32690430 time/batch=0.55s
22451/10943 (epoch 184.639) train_loss=332.44577026 time/batch=0.85s
22452/10943 (epoch 184.648) train_loss=236.31695557 time/batch=0.64s
22453/10943 (epoch 184.656) train_loss=142.40429688 time/batch=0.37s
22454/10943 (epoch 184.664) train_loss=255.60136414 time/batch=0.62s
22455/10943 (epoch 184.672) train_loss=322.37152100 time/batch=0.86s
22456/10943 (epoch 184.681) train_loss=201.75607300 time/batch=0.55s
22457/10943 (epoch 184.689) train_loss=284.07263184 time/batch=0.70s
22458/10943 (epoch 184.697) train_loss=280.79156494 time/batch=0.78s
22459/10943 (epoch 184.705) train_loss=224.06051636 time/batch=0.61s
22460/10943 (epoch 184.713) train_loss=283.55270386 time/batch=0.70s
22461/10943 (epoch 184.722) train_loss=204.10375977 time/batch=0.58s
22462/10943 (epoch 184.730) train_loss=221.36270142 time/batch=0.60s
22463/10943 (epoch 184.738) train_loss=296.08496094 time/batch=0.79s
22464/10943 (epoch 184.746) train_loss=247.97772217 time/batch=0.72s
22465/10943 (epoch 184.755) train_loss=288.53283691 time/batch=0.75s
22466/10943 (epoch 184.763) train_loss=255.71665955 time/batch=0.69s
22467/10943 (epoch 184.771) train_loss=266.41622925 time/batch=0.73s
22468/10943 (epoch 184.779) train_loss=287.28897095 time/batch=0.87s
22469/10943 (epoch 184.787) train_loss=226.79022217 time/batch=0.61s
22470/10943 (epoch 184.796) train_loss=151.29730225 time/batch=0.57s
22471/10943 (epoch 184.804) train_loss=243.29560852 time/batch=0.66s
22472/10943 (epoch 184.812) train_loss=223.23316956 time/batch=0.59s
22473/10943 (epoch 184.820) train_loss=226.79605103 time/batch=0.59s
22474/10943 (epoch 184.829) train_loss=172.12506104 time/batch=0.60s
22475/10943 (epoch 184.837) train_loss=233.46650696 time/batch=0.61s
setting learning rate to 0.0005792
  saved to metadata/gru_no_dropout-9_nov_folkwiki-20181115-214759_epoch74.pkl
22476/10943 (epoch 184.845) train_loss=161.58595276 time/batch=0.54s
22477/10943 (epoch 184.853) train_loss=131.86291504 time/batch=0.34s
22478/10943 (epoch 184.861) train_loss=321.59283447 time/batch=0.79s
22479/10943 (epoch 184.870) train_loss=422.35467529 time/batch=1.05s
22480/10943 (epoch 184.878) train_loss=303.56384277 time/batch=0.81s
22481/10943 (epoch 184.886) train_loss=350.36193848 time/batch=0.88s
22482/10943 (epoch 184.894) train_loss=292.99890137 time/batch=0.74s
22483/10943 (epoch 184.903) train_loss=167.47958374 time/batch=0.45s
22484/10943 (epoch 184.911) train_loss=939.48657227 time/batch=3.05s
22485/10943 (epoch 184.919) train_loss=696.55938721 time/batch=1.86s
22486/10943 (epoch 184.927) train_loss=162.12564087 time/batch=0.51s
22487/10943 (epoch 184.935) train_loss=368.12448120 time/batch=0.90s
22488/10943 (epoch 184.944) train_loss=140.58322144 time/batch=0.41s
22489/10943 (epoch 184.952) train_loss=517.88903809 time/batch=1.23s
22490/10943 (epoch 184.960) train_loss=432.67813110 time/batch=1.14s
22491/10943 (epoch 184.968) train_loss=632.15093994 time/batch=1.66s
22492/10943 (epoch 184.977) train_loss=327.08990479 time/batch=0.97s
22493/10943 (epoch 184.985) train_loss=349.41015625 time/batch=0.94s
22494/10943 (epoch 184.993) train_loss=157.49526978 time/batch=0.46s
22495/10943 (epoch 185.001) train_loss=282.30352783 time/batch=0.69s
22496/10943 (epoch 185.010) train_loss=443.58007812 time/batch=1.12s
22497/10943 (epoch 185.018) train_loss=121.30725861 time/batch=0.39s
22498/10943 (epoch 185.026) train_loss=364.07626343 time/batch=0.84s
22499/10943 (epoch 185.034) train_loss=298.82208252 time/batch=0.84s
22500/10943 (epoch 185.042) train_loss=388.31939697 time/batch=1.02s
22501/10943 (epoch 185.051) train_loss=576.42456055 time/batch=1.70s
22502/10943 (epoch 185.059) train_loss=240.94900513 time/batch=0.72s
22503/10943 (epoch 185.067) train_loss=96.28278351 time/batch=0.28s
22504/10943 (epoch 185.075) train_loss=138.18395996 time/batch=0.38s
22505/10943 (epoch 185.084) train_loss=232.00445557 time/batch=0.60s
22506/10943 (epoch 185.092) train_loss=215.53315735 time/batch=0.58s
22507/10943 (epoch 185.100) train_loss=106.47541809 time/batch=0.31s
22508/10943 (epoch 185.108) train_loss=330.16674805 time/batch=0.80s
22509/10943 (epoch 185.116) train_loss=456.55426025 time/batch=1.16s
22510/10943 (epoch 185.125) train_loss=388.87451172 time/batch=1.02s
22511/10943 (epoch 185.133) train_loss=186.84036255 time/batch=0.52s
22512/10943 (epoch 185.141) train_loss=378.79788208 time/batch=0.94s
22513/10943 (epoch 185.149) train_loss=439.46554565 time/batch=1.20s
22514/10943 (epoch 185.158) train_loss=131.04296875 time/batch=0.41s
22515/10943 (epoch 185.166) train_loss=151.25311279 time/batch=0.40s
22516/10943 (epoch 185.174) train_loss=250.60098267 time/batch=0.66s
22517/10943 (epoch 185.182) train_loss=221.95495605 time/batch=0.59s
22518/10943 (epoch 185.190) train_loss=309.22082520 time/batch=0.76s
22519/10943 (epoch 185.199) train_loss=358.39233398 time/batch=0.91s
22520/10943 (epoch 185.207) train_loss=201.11592102 time/batch=0.59s
22521/10943 (epoch 185.215) train_loss=435.53039551 time/batch=1.06s
22522/10943 (epoch 185.223) train_loss=202.01765442 time/batch=0.59s
22523/10943 (epoch 185.232) train_loss=204.00506592 time/batch=0.54s
22524/10943 (epoch 185.240) train_loss=297.97390747 time/batch=0.76s
22525/10943 (epoch 185.248) train_loss=295.26623535 time/batch=0.81s
22526/10943 (epoch 185.256) train_loss=540.82965088 time/batch=1.30s
22527/10943 (epoch 185.264) train_loss=566.98962402 time/batch=1.40s
22528/10943 (epoch 185.273) train_loss=321.69506836 time/batch=0.90s
22529/10943 (epoch 185.281) train_loss=299.81549072 time/batch=0.80s
22530/10943 (epoch 185.289) train_loss=295.60986328 time/batch=0.78s
22531/10943 (epoch 185.297) train_loss=291.59170532 time/batch=0.84s
22532/10943 (epoch 185.306) train_loss=192.70254517 time/batch=0.53s
22533/10943 (epoch 185.314) train_loss=432.75195312 time/batch=0.98s
22534/10943 (epoch 185.322) train_loss=232.49777222 time/batch=0.65s
22535/10943 (epoch 185.330) train_loss=501.72052002 time/batch=1.18s
22536/10943 (epoch 185.338) train_loss=164.61851501 time/batch=0.52s
22537/10943 (epoch 185.347) train_loss=164.74621582 time/batch=0.44s
22538/10943 (epoch 185.355) train_loss=289.87353516 time/batch=0.76s
22539/10943 (epoch 185.363) train_loss=440.63085938 time/batch=1.21s
22540/10943 (epoch 185.371) train_loss=266.35479736 time/batch=0.75s
22541/10943 (epoch 185.380) train_loss=391.82955933 time/batch=0.95s
22542/10943 (epoch 185.388) train_loss=147.85455322 time/batch=0.42s
22543/10943 (epoch 185.396) train_loss=261.96075439 time/batch=0.64s
22544/10943 (epoch 185.404) train_loss=236.16647339 time/batch=0.63s
22545/10943 (epoch 185.412) train_loss=266.03417969 time/batch=0.72s
22546/10943 (epoch 185.421) train_loss=339.28900146 time/batch=0.85s
22547/10943 (epoch 185.429) train_loss=230.29231262 time/batch=0.65s
22548/10943 (epoch 185.437) train_loss=328.31774902 time/batch=0.84s
22549/10943 (epoch 185.445) train_loss=282.24505615 time/batch=0.75s
22550/10943 (epoch 185.454) train_loss=287.56060791 time/batch=0.73s
22551/10943 (epoch 185.462) train_loss=238.38565063 time/batch=0.63s
22552/10943 (epoch 185.470) train_loss=281.98748779 time/batch=0.78s
22553/10943 (epoch 185.478) train_loss=242.97990417 time/batch=0.66s
22554/10943 (epoch 185.487) train_loss=119.39956665 time/batch=0.35s
22555/10943 (epoch 185.495) train_loss=114.58409119 time/batch=0.35s
22556/10943 (epoch 185.503) train_loss=122.43060303 time/batch=0.35s
22557/10943 (epoch 185.511) train_loss=351.38668823 time/batch=0.85s
22558/10943 (epoch 185.519) train_loss=185.43858337 time/batch=0.55s
22559/10943 (epoch 185.528) train_loss=291.27972412 time/batch=0.71s
22560/10943 (epoch 185.536) train_loss=297.32553101 time/batch=0.81s
22561/10943 (epoch 185.544) train_loss=154.58392334 time/batch=0.46s
22562/10943 (epoch 185.552) train_loss=209.54928589 time/batch=0.53s
22563/10943 (epoch 185.561) train_loss=208.06828308 time/batch=0.55s
22564/10943 (epoch 185.569) train_loss=174.71145630 time/batch=0.46s
22565/10943 (epoch 185.577) train_loss=226.82275391 time/batch=0.59s
22566/10943 (epoch 185.585) train_loss=331.75436401 time/batch=0.86s
22567/10943 (epoch 185.593) train_loss=257.21102905 time/batch=0.69s
22568/10943 (epoch 185.602) train_loss=263.85272217 time/batch=0.65s
22569/10943 (epoch 185.610) train_loss=328.07458496 time/batch=0.86s
22570/10943 (epoch 185.618) train_loss=188.44737244 time/batch=0.50s
22571/10943 (epoch 185.626) train_loss=211.96180725 time/batch=0.55s
22572/10943 (epoch 185.635) train_loss=325.54809570 time/batch=0.90s
22573/10943 (epoch 185.643) train_loss=205.54373169 time/batch=0.61s
22574/10943 (epoch 185.651) train_loss=175.93090820 time/batch=0.48s
22575/10943 (epoch 185.659) train_loss=197.38534546 time/batch=0.50s
22576/10943 (epoch 185.667) train_loss=176.79196167 time/batch=0.48s
22577/10943 (epoch 185.676) train_loss=245.81384277 time/batch=0.63s
22578/10943 (epoch 185.684) train_loss=386.69610596 time/batch=1.01s
22579/10943 (epoch 185.692) train_loss=292.73535156 time/batch=0.78s
22580/10943 (epoch 185.700) train_loss=273.82171631 time/batch=0.71s
22581/10943 (epoch 185.709) train_loss=227.84008789 time/batch=0.60s
22582/10943 (epoch 185.717) train_loss=220.84481812 time/batch=0.59s
22583/10943 (epoch 185.725) train_loss=167.13507080 time/batch=0.49s
22584/10943 (epoch 185.733) train_loss=257.18466187 time/batch=0.65s
22585/10943 (epoch 185.741) train_loss=277.61920166 time/batch=0.75s
22586/10943 (epoch 185.750) train_loss=307.57241821 time/batch=0.91s
22587/10943 (epoch 185.758) train_loss=221.65916443 time/batch=0.65s
22588/10943 (epoch 185.766) train_loss=255.50964355 time/batch=0.73s
22589/10943 (epoch 185.774) train_loss=236.97293091 time/batch=0.68s
22590/10943 (epoch 185.783) train_loss=335.23303223 time/batch=1.00s
22591/10943 (epoch 185.791) train_loss=227.18498230 time/batch=0.64s
22592/10943 (epoch 185.799) train_loss=192.71064758 time/batch=0.52s
22593/10943 (epoch 185.807) train_loss=400.55081177 time/batch=1.00s
22594/10943 (epoch 185.815) train_loss=219.23336792 time/batch=0.64s
22595/10943 (epoch 185.824) train_loss=262.98126221 time/batch=0.66s
22596/10943 (epoch 185.832) train_loss=257.14611816 time/batch=0.68s
setting learning rate to 0.0005618
22597/10943 (epoch 185.840) train_loss=637.89001465 time/batch=1.59s
22598/10943 (epoch 185.848) train_loss=241.27124023 time/batch=0.72s
22599/10943 (epoch 185.857) train_loss=540.66516113 time/batch=1.28s
22600/10943 (epoch 185.865) train_loss=635.38305664 time/batch=1.67s
22601/10943 (epoch 185.873) train_loss=126.35244751 time/batch=0.46s
22602/10943 (epoch 185.881) train_loss=98.63351440 time/batch=0.26s
22603/10943 (epoch 185.889) train_loss=391.62368774 time/batch=0.96s
22604/10943 (epoch 185.898) train_loss=540.58776855 time/batch=1.40s
22605/10943 (epoch 185.906) train_loss=437.60687256 time/batch=1.08s
22606/10943 (epoch 185.914) train_loss=341.38476562 time/batch=0.90s
22607/10943 (epoch 185.922) train_loss=157.13052368 time/batch=0.46s
22608/10943 (epoch 185.931) train_loss=234.63540649 time/batch=0.59s
22609/10943 (epoch 185.939) train_loss=917.34765625 time/batch=3.08s
22610/10943 (epoch 185.947) train_loss=313.82000732 time/batch=1.03s
22611/10943 (epoch 185.955) train_loss=326.88229370 time/batch=0.84s
22612/10943 (epoch 185.964) train_loss=137.38676453 time/batch=0.38s
22613/10943 (epoch 185.972) train_loss=128.00137329 time/batch=0.34s
22614/10943 (epoch 185.980) train_loss=212.21252441 time/batch=0.54s
22615/10943 (epoch 185.988) train_loss=385.36621094 time/batch=0.96s
22616/10943 (epoch 185.996) train_loss=109.26088715 time/batch=0.36s
22617/10943 (epoch 186.005) train_loss=330.42691040 time/batch=0.80s
22618/10943 (epoch 186.013) train_loss=121.00888824 time/batch=0.35s
22619/10943 (epoch 186.021) train_loss=223.04101562 time/batch=0.55s
22620/10943 (epoch 186.029) train_loss=346.05831909 time/batch=0.91s
22621/10943 (epoch 186.038) train_loss=244.51779175 time/batch=0.68s
22622/10943 (epoch 186.046) train_loss=465.66717529 time/batch=1.16s
22623/10943 (epoch 186.054) train_loss=280.74987793 time/batch=0.80s
22624/10943 (epoch 186.062) train_loss=379.86303711 time/batch=0.95s
22625/10943 (epoch 186.070) train_loss=224.32345581 time/batch=0.64s
22626/10943 (epoch 186.079) train_loss=321.43240356 time/batch=0.81s
22627/10943 (epoch 186.087) train_loss=447.45385742 time/batch=1.16s
22628/10943 (epoch 186.095) train_loss=189.39183044 time/batch=0.54s
22629/10943 (epoch 186.103) train_loss=429.57150269 time/batch=1.05s
22630/10943 (epoch 186.112) train_loss=140.54890442 time/batch=0.44s
22631/10943 (epoch 186.120) train_loss=260.39544678 time/batch=0.67s
22632/10943 (epoch 186.128) train_loss=146.45831299 time/batch=0.40s
22633/10943 (epoch 186.136) train_loss=193.41313171 time/batch=0.51s
22634/10943 (epoch 186.144) train_loss=425.79064941 time/batch=1.08s
22635/10943 (epoch 186.153) train_loss=527.89532471 time/batch=1.42s
22636/10943 (epoch 186.161) train_loss=269.75949097 time/batch=0.79s
22637/10943 (epoch 186.169) train_loss=213.07070923 time/batch=0.56s
22638/10943 (epoch 186.177) train_loss=227.00534058 time/batch=0.61s
22639/10943 (epoch 186.186) train_loss=322.50094604 time/batch=0.83s
22640/10943 (epoch 186.194) train_loss=261.40240479 time/batch=0.72s
22641/10943 (epoch 186.202) train_loss=150.23376465 time/batch=0.42s
22642/10943 (epoch 186.210) train_loss=107.83347321 time/batch=0.32s
22643/10943 (epoch 186.218) train_loss=291.16979980 time/batch=0.74s
22644/10943 (epoch 186.227) train_loss=232.95695496 time/batch=0.65s
22645/10943 (epoch 186.235) train_loss=137.07638550 time/batch=0.41s
22646/10943 (epoch 186.243) train_loss=240.85623169 time/batch=0.62s
22647/10943 (epoch 186.251) train_loss=209.29852295 time/batch=0.55s
22648/10943 (epoch 186.260) train_loss=361.43417358 time/batch=0.86s
22649/10943 (epoch 186.268) train_loss=184.79162598 time/batch=0.53s
22650/10943 (epoch 186.276) train_loss=254.11254883 time/batch=0.67s
22651/10943 (epoch 186.284) train_loss=353.06069946 time/batch=0.89s
22652/10943 (epoch 186.292) train_loss=562.60961914 time/batch=1.70s
22653/10943 (epoch 186.301) train_loss=314.13589478 time/batch=0.92s
22654/10943 (epoch 186.309) train_loss=400.55557251 time/batch=1.03s
22655/10943 (epoch 186.317) train_loss=162.90080261 time/batch=0.50s
22656/10943 (epoch 186.325) train_loss=230.42309570 time/batch=0.61s
22657/10943 (epoch 186.334) train_loss=289.42456055 time/batch=0.76s
22658/10943 (epoch 186.342) train_loss=423.39263916 time/batch=1.06s
22659/10943 (epoch 186.350) train_loss=261.01522827 time/batch=0.72s
22660/10943 (epoch 186.358) train_loss=277.90338135 time/batch=0.76s
22661/10943 (epoch 186.366) train_loss=210.60343933 time/batch=0.60s
22662/10943 (epoch 186.375) train_loss=188.64286804 time/batch=0.53s
22663/10943 (epoch 186.383) train_loss=156.48449707 time/batch=0.41s
22664/10943 (epoch 186.391) train_loss=269.51519775 time/batch=0.69s
22665/10943 (epoch 186.399) train_loss=133.33346558 time/batch=0.37s
22666/10943 (epoch 186.408) train_loss=152.26609802 time/batch=0.41s
22667/10943 (epoch 186.416) train_loss=166.39837646 time/batch=0.43s
22668/10943 (epoch 186.424) train_loss=292.18814087 time/batch=0.74s
22669/10943 (epoch 186.432) train_loss=198.00946045 time/batch=0.57s
22670/10943 (epoch 186.441) train_loss=184.09835815 time/batch=0.51s
22671/10943 (epoch 186.449) train_loss=137.04762268 time/batch=0.36s
22672/10943 (epoch 186.457) train_loss=164.86285400 time/batch=0.43s
22673/10943 (epoch 186.465) train_loss=314.83496094 time/batch=0.82s
22674/10943 (epoch 186.473) train_loss=332.91973877 time/batch=0.88s
22675/10943 (epoch 186.482) train_loss=314.49328613 time/batch=0.80s
22676/10943 (epoch 186.490) train_loss=300.88958740 time/batch=0.80s
22677/10943 (epoch 186.498) train_loss=424.63519287 time/batch=1.04s
22678/10943 (epoch 186.506) train_loss=486.43792725 time/batch=1.23s
22679/10943 (epoch 186.515) train_loss=197.25201416 time/batch=0.60s
22680/10943 (epoch 186.523) train_loss=395.77197266 time/batch=1.01s
22681/10943 (epoch 186.531) train_loss=399.96508789 time/batch=1.12s
22682/10943 (epoch 186.539) train_loss=237.52175903 time/batch=0.63s
22683/10943 (epoch 186.547) train_loss=231.55813599 time/batch=0.61s
22684/10943 (epoch 186.556) train_loss=168.12921143 time/batch=0.47s
22685/10943 (epoch 186.564) train_loss=378.00189209 time/batch=0.93s
22686/10943 (epoch 186.572) train_loss=270.83319092 time/batch=0.70s
22687/10943 (epoch 186.580) train_loss=270.35681152 time/batch=0.71s
22688/10943 (epoch 186.589) train_loss=226.09756470 time/batch=0.60s
22689/10943 (epoch 186.597) train_loss=314.70501709 time/batch=0.86s
22690/10943 (epoch 186.605) train_loss=244.70205688 time/batch=0.67s
22691/10943 (epoch 186.613) train_loss=262.64245605 time/batch=0.66s
22692/10943 (epoch 186.621) train_loss=336.28448486 time/batch=0.88s
22693/10943 (epoch 186.630) train_loss=412.90783691 time/batch=1.12s
22694/10943 (epoch 186.638) train_loss=414.51586914 time/batch=1.24s
22695/10943 (epoch 186.646) train_loss=314.44296265 time/batch=0.88s
22696/10943 (epoch 186.654) train_loss=245.52188110 time/batch=0.65s
22697/10943 (epoch 186.663) train_loss=175.75785828 time/batch=0.48s
22698/10943 (epoch 186.671) train_loss=194.67790222 time/batch=0.49s
22699/10943 (epoch 186.679) train_loss=303.36102295 time/batch=0.72s
22700/10943 (epoch 186.687) train_loss=259.10607910 time/batch=0.67s
22701/10943 (epoch 186.695) train_loss=210.76968384 time/batch=0.56s
22702/10943 (epoch 186.704) train_loss=270.38507080 time/batch=0.70s
22703/10943 (epoch 186.712) train_loss=187.17309570 time/batch=0.51s
22704/10943 (epoch 186.720) train_loss=205.88143921 time/batch=0.51s
22705/10943 (epoch 186.728) train_loss=264.31777954 time/batch=0.70s
22706/10943 (epoch 186.737) train_loss=172.22232056 time/batch=0.57s
22707/10943 (epoch 186.745) train_loss=287.49566650 time/batch=0.70s
22708/10943 (epoch 186.753) train_loss=220.45204163 time/batch=0.61s
22709/10943 (epoch 186.761) train_loss=351.19287109 time/batch=0.88s
22710/10943 (epoch 186.769) train_loss=275.21450806 time/batch=0.74s
22711/10943 (epoch 186.778) train_loss=252.63984680 time/batch=0.66s
22712/10943 (epoch 186.786) train_loss=301.75830078 time/batch=0.80s
22713/10943 (epoch 186.794) train_loss=297.53387451 time/batch=0.91s
22714/10943 (epoch 186.802) train_loss=296.39987183 time/batch=0.83s
22715/10943 (epoch 186.811) train_loss=280.17727661 time/batch=0.77s
22716/10943 (epoch 186.819) train_loss=298.87280273 time/batch=0.81s
22717/10943 (epoch 186.827) train_loss=227.17199707 time/batch=0.76s
setting learning rate to 0.0005449
22718/10943 (epoch 186.835) train_loss=415.88107300 time/batch=1.02s
22719/10943 (epoch 186.843) train_loss=376.23529053 time/batch=0.98s
22720/10943 (epoch 186.852) train_loss=911.02758789 time/batch=3.12s
22721/10943 (epoch 186.860) train_loss=208.93392944 time/batch=0.80s
22722/10943 (epoch 186.868) train_loss=296.00097656 time/batch=0.74s
22723/10943 (epoch 186.876) train_loss=211.73323059 time/batch=0.58s
22724/10943 (epoch 186.885) train_loss=440.46142578 time/batch=1.10s
22725/10943 (epoch 186.893) train_loss=549.88684082 time/batch=1.41s
22726/10943 (epoch 186.901) train_loss=470.08245850 time/batch=1.17s
22727/10943 (epoch 186.909) train_loss=390.37982178 time/batch=1.02s
22728/10943 (epoch 186.918) train_loss=223.02511597 time/batch=0.61s
22729/10943 (epoch 186.926) train_loss=333.88116455 time/batch=0.84s
22730/10943 (epoch 186.934) train_loss=282.75042725 time/batch=0.73s
22731/10943 (epoch 186.942) train_loss=288.88229370 time/batch=0.80s
22732/10943 (epoch 186.950) train_loss=355.50866699 time/batch=0.91s
22733/10943 (epoch 186.959) train_loss=292.88098145 time/batch=0.79s
22734/10943 (epoch 186.967) train_loss=372.40005493 time/batch=0.98s
22735/10943 (epoch 186.975) train_loss=179.62612915 time/batch=0.53s
22736/10943 (epoch 186.983) train_loss=279.28936768 time/batch=0.74s
22737/10943 (epoch 186.992) train_loss=597.68048096 time/batch=1.52s
22738/10943 (epoch 187.000) train_loss=229.42556763 time/batch=0.72s
22739/10943 (epoch 187.008) train_loss=275.14739990 time/batch=0.71s
22740/10943 (epoch 187.016) train_loss=289.31280518 time/batch=0.83s
22741/10943 (epoch 187.024) train_loss=205.68254089 time/batch=0.59s
22742/10943 (epoch 187.033) train_loss=451.44415283 time/batch=1.13s
22743/10943 (epoch 187.041) train_loss=220.89089966 time/batch=0.65s
22744/10943 (epoch 187.049) train_loss=397.16763306 time/batch=0.98s
22745/10943 (epoch 187.057) train_loss=253.23052979 time/batch=0.73s
22746/10943 (epoch 187.066) train_loss=256.04122925 time/batch=0.66s
22747/10943 (epoch 187.074) train_loss=154.28244019 time/batch=0.44s
22748/10943 (epoch 187.082) train_loss=400.06353760 time/batch=0.96s
22749/10943 (epoch 187.090) train_loss=502.35980225 time/batch=1.24s
22750/10943 (epoch 187.098) train_loss=348.05807495 time/batch=0.90s
22751/10943 (epoch 187.107) train_loss=403.34164429 time/batch=1.02s
22752/10943 (epoch 187.115) train_loss=212.77229309 time/batch=0.62s
22753/10943 (epoch 187.123) train_loss=209.70619202 time/batch=0.54s
22754/10943 (epoch 187.131) train_loss=105.85795593 time/batch=0.30s
22755/10943 (epoch 187.140) train_loss=217.77125549 time/batch=0.58s
22756/10943 (epoch 187.148) train_loss=318.63330078 time/batch=0.84s
22757/10943 (epoch 187.156) train_loss=406.63916016 time/batch=1.07s
22758/10943 (epoch 187.164) train_loss=93.34828949 time/batch=0.33s
22759/10943 (epoch 187.172) train_loss=154.90896606 time/batch=0.40s
22760/10943 (epoch 187.181) train_loss=228.08432007 time/batch=0.58s
22761/10943 (epoch 187.189) train_loss=123.86521912 time/batch=0.35s
22762/10943 (epoch 187.197) train_loss=440.00585938 time/batch=1.11s
22763/10943 (epoch 187.205) train_loss=274.88256836 time/batch=0.73s
22764/10943 (epoch 187.214) train_loss=118.63204193 time/batch=0.33s
22765/10943 (epoch 187.222) train_loss=609.67993164 time/batch=1.56s
22766/10943 (epoch 187.230) train_loss=251.31393433 time/batch=0.73s
22767/10943 (epoch 187.238) train_loss=348.14978027 time/batch=0.90s
22768/10943 (epoch 187.246) train_loss=118.93663788 time/batch=0.37s
22769/10943 (epoch 187.255) train_loss=303.87701416 time/batch=0.78s
22770/10943 (epoch 187.263) train_loss=543.42883301 time/batch=1.29s
22771/10943 (epoch 187.271) train_loss=362.11267090 time/batch=0.95s
22772/10943 (epoch 187.279) train_loss=166.72123718 time/batch=0.49s
22773/10943 (epoch 187.288) train_loss=142.47651672 time/batch=0.36s
22774/10943 (epoch 187.296) train_loss=184.58871460 time/batch=0.48s
22775/10943 (epoch 187.304) train_loss=185.57583618 time/batch=0.50s
22776/10943 (epoch 187.312) train_loss=229.21475220 time/batch=0.62s
22777/10943 (epoch 187.320) train_loss=627.71728516 time/batch=1.66s
22778/10943 (epoch 187.329) train_loss=172.91415405 time/batch=0.59s
22779/10943 (epoch 187.337) train_loss=485.04370117 time/batch=1.21s
22780/10943 (epoch 187.345) train_loss=365.47216797 time/batch=1.01s
22781/10943 (epoch 187.353) train_loss=299.77636719 time/batch=0.82s
22782/10943 (epoch 187.362) train_loss=281.50909424 time/batch=0.74s
22783/10943 (epoch 187.370) train_loss=351.29333496 time/batch=0.89s
22784/10943 (epoch 187.378) train_loss=306.42431641 time/batch=0.80s
22785/10943 (epoch 187.386) train_loss=169.30001831 time/batch=0.48s
22786/10943 (epoch 187.395) train_loss=257.60662842 time/batch=0.65s
22787/10943 (epoch 187.403) train_loss=258.81228638 time/batch=0.70s
22788/10943 (epoch 187.411) train_loss=437.60772705 time/batch=1.17s
22789/10943 (epoch 187.419) train_loss=378.97467041 time/batch=1.05s
22790/10943 (epoch 187.427) train_loss=425.89001465 time/batch=1.10s
22791/10943 (epoch 187.436) train_loss=209.02618408 time/batch=0.57s
22792/10943 (epoch 187.444) train_loss=221.61126709 time/batch=0.57s
22793/10943 (epoch 187.452) train_loss=332.90209961 time/batch=0.86s
22794/10943 (epoch 187.460) train_loss=299.50421143 time/batch=0.76s
22795/10943 (epoch 187.469) train_loss=190.41729736 time/batch=0.54s
22796/10943 (epoch 187.477) train_loss=288.90789795 time/batch=0.77s
22797/10943 (epoch 187.485) train_loss=326.87045288 time/batch=0.88s
22798/10943 (epoch 187.493) train_loss=237.29275513 time/batch=0.62s
22799/10943 (epoch 187.501) train_loss=230.08969116 time/batch=0.61s
22800/10943 (epoch 187.510) train_loss=137.39286804 time/batch=0.39s
22801/10943 (epoch 187.518) train_loss=293.90518188 time/batch=0.78s
22802/10943 (epoch 187.526) train_loss=248.22250366 time/batch=0.66s
22803/10943 (epoch 187.534) train_loss=114.18112946 time/batch=0.34s
22804/10943 (epoch 187.543) train_loss=278.34814453 time/batch=0.71s
22805/10943 (epoch 187.551) train_loss=254.44348145 time/batch=0.66s
22806/10943 (epoch 187.559) train_loss=212.25534058 time/batch=0.58s
22807/10943 (epoch 187.567) train_loss=283.68560791 time/batch=0.77s
22808/10943 (epoch 187.575) train_loss=323.53308105 time/batch=0.85s
22809/10943 (epoch 187.584) train_loss=193.16137695 time/batch=0.49s
22810/10943 (epoch 187.592) train_loss=314.85556030 time/batch=0.82s
22811/10943 (epoch 187.600) train_loss=193.58285522 time/batch=0.56s
22812/10943 (epoch 187.608) train_loss=135.29919434 time/batch=0.35s
22813/10943 (epoch 187.617) train_loss=274.31671143 time/batch=0.71s
22814/10943 (epoch 187.625) train_loss=229.67001343 time/batch=0.64s
22815/10943 (epoch 187.633) train_loss=138.88949585 time/batch=0.41s
22816/10943 (epoch 187.641) train_loss=148.80206299 time/batch=0.39s
22817/10943 (epoch 187.649) train_loss=192.34033203 time/batch=0.51s
22818/10943 (epoch 187.658) train_loss=260.34878540 time/batch=0.68s
22819/10943 (epoch 187.666) train_loss=257.49682617 time/batch=0.69s
22820/10943 (epoch 187.674) train_loss=306.47161865 time/batch=0.80s
22821/10943 (epoch 187.682) train_loss=230.69850159 time/batch=0.65s
22822/10943 (epoch 187.691) train_loss=254.76502991 time/batch=0.65s
22823/10943 (epoch 187.699) train_loss=256.97137451 time/batch=0.68s
22824/10943 (epoch 187.707) train_loss=137.80752563 time/batch=0.38s
22825/10943 (epoch 187.715) train_loss=135.41899109 time/batch=0.37s
22826/10943 (epoch 187.723) train_loss=220.60095215 time/batch=0.57s
22827/10943 (epoch 187.732) train_loss=151.04371643 time/batch=0.43s
22828/10943 (epoch 187.740) train_loss=320.55258179 time/batch=0.80s
22829/10943 (epoch 187.748) train_loss=268.94973755 time/batch=0.71s
22830/10943 (epoch 187.756) train_loss=172.05514526 time/batch=0.48s
22831/10943 (epoch 187.765) train_loss=331.83416748 time/batch=0.99s
22832/10943 (epoch 187.773) train_loss=205.27130127 time/batch=0.64s
22833/10943 (epoch 187.781) train_loss=273.73959351 time/batch=0.71s
22834/10943 (epoch 187.789) train_loss=238.52813721 time/batch=0.65s
22835/10943 (epoch 187.797) train_loss=294.69537354 time/batch=0.81s
22836/10943 (epoch 187.806) train_loss=188.43997192 time/batch=0.66s
22837/10943 (epoch 187.814) train_loss=160.01795959 time/batch=0.44s
22838/10943 (epoch 187.822) train_loss=229.32299805 time/batch=0.67s
setting learning rate to 0.0005286
22839/10943 (epoch 187.830) train_loss=134.41540527 time/batch=0.37s
22840/10943 (epoch 187.839) train_loss=436.69354248 time/batch=1.09s
22841/10943 (epoch 187.847) train_loss=124.84619141 time/batch=0.39s
22842/10943 (epoch 187.855) train_loss=421.34411621 time/batch=1.03s
22843/10943 (epoch 187.863) train_loss=226.20675659 time/batch=0.65s
22844/10943 (epoch 187.871) train_loss=229.97279358 time/batch=0.61s
22845/10943 (epoch 187.880) train_loss=547.28137207 time/batch=1.42s
22846/10943 (epoch 187.888) train_loss=323.16436768 time/batch=0.91s
22847/10943 (epoch 187.896) train_loss=391.58789062 time/batch=0.98s
22848/10943 (epoch 187.904) train_loss=371.40692139 time/batch=1.00s
22849/10943 (epoch 187.913) train_loss=447.45971680 time/batch=1.18s
22850/10943 (epoch 187.921) train_loss=240.68753052 time/batch=0.70s
22851/10943 (epoch 187.929) train_loss=481.90405273 time/batch=1.19s
22852/10943 (epoch 187.937) train_loss=529.69897461 time/batch=1.36s
22853/10943 (epoch 187.946) train_loss=593.66748047 time/batch=1.60s
22854/10943 (epoch 187.954) train_loss=392.39233398 time/batch=1.08s
22855/10943 (epoch 187.962) train_loss=402.51171875 time/batch=1.08s
22856/10943 (epoch 187.970) train_loss=563.93389893 time/batch=1.60s
22857/10943 (epoch 187.978) train_loss=109.69961548 time/batch=0.42s
22858/10943 (epoch 187.987) train_loss=731.84667969 time/batch=1.87s
22859/10943 (epoch 187.995) train_loss=143.07608032 time/batch=0.55s
22860/10943 (epoch 188.003) train_loss=258.24377441 time/batch=0.66s
22861/10943 (epoch 188.011) train_loss=167.81321716 time/batch=0.47s
22862/10943 (epoch 188.020) train_loss=836.10333252 time/batch=3.06s
22863/10943 (epoch 188.028) train_loss=303.52984619 time/batch=1.01s
22864/10943 (epoch 188.036) train_loss=210.42041016 time/batch=0.58s
22865/10943 (epoch 188.044) train_loss=272.20800781 time/batch=0.69s
22866/10943 (epoch 188.052) train_loss=289.95220947 time/batch=0.79s
22867/10943 (epoch 188.061) train_loss=377.38323975 time/batch=1.01s
22868/10943 (epoch 188.069) train_loss=132.15637207 time/batch=0.42s
22869/10943 (epoch 188.077) train_loss=291.96951294 time/batch=0.74s
22870/10943 (epoch 188.085) train_loss=146.86996460 time/batch=0.44s
22871/10943 (epoch 188.094) train_loss=283.47546387 time/batch=0.71s
22872/10943 (epoch 188.102) train_loss=192.16046143 time/batch=0.55s
22873/10943 (epoch 188.110) train_loss=140.26989746 time/batch=0.38s
22874/10943 (epoch 188.118) train_loss=243.31030273 time/batch=0.63s
22875/10943 (epoch 188.126) train_loss=206.43043518 time/batch=0.55s
22876/10943 (epoch 188.135) train_loss=96.80464172 time/batch=0.31s
22877/10943 (epoch 188.143) train_loss=350.30551147 time/batch=0.86s
22878/10943 (epoch 188.151) train_loss=422.80450439 time/batch=1.01s
22879/10943 (epoch 188.159) train_loss=171.70478821 time/batch=0.51s
22880/10943 (epoch 188.168) train_loss=215.89807129 time/batch=0.58s
22881/10943 (epoch 188.176) train_loss=167.09683228 time/batch=0.47s
22882/10943 (epoch 188.184) train_loss=144.07945251 time/batch=0.37s
22883/10943 (epoch 188.192) train_loss=445.53106689 time/batch=1.06s
22884/10943 (epoch 188.200) train_loss=157.15866089 time/batch=0.49s
22885/10943 (epoch 188.209) train_loss=213.72485352 time/batch=0.55s
22886/10943 (epoch 188.217) train_loss=226.77778625 time/batch=0.63s
22887/10943 (epoch 188.225) train_loss=133.44360352 time/batch=0.37s
22888/10943 (epoch 188.233) train_loss=476.79534912 time/batch=1.18s
22889/10943 (epoch 188.242) train_loss=327.45147705 time/batch=0.89s
22890/10943 (epoch 188.250) train_loss=326.25964355 time/batch=0.86s
22891/10943 (epoch 188.258) train_loss=209.56890869 time/batch=0.59s
22892/10943 (epoch 188.266) train_loss=108.95698547 time/batch=0.31s
22893/10943 (epoch 188.274) train_loss=337.68801880 time/batch=0.83s
22894/10943 (epoch 188.283) train_loss=319.90841675 time/batch=0.86s
22895/10943 (epoch 188.291) train_loss=178.73596191 time/batch=0.50s
22896/10943 (epoch 188.299) train_loss=334.92572021 time/batch=0.82s
22897/10943 (epoch 188.307) train_loss=397.78491211 time/batch=1.03s
22898/10943 (epoch 188.316) train_loss=269.52764893 time/batch=0.74s
22899/10943 (epoch 188.324) train_loss=460.05822754 time/batch=1.24s
22900/10943 (epoch 188.332) train_loss=270.79235840 time/batch=0.75s
22901/10943 (epoch 188.340) train_loss=214.78295898 time/batch=0.58s
22902/10943 (epoch 188.348) train_loss=295.20495605 time/batch=0.82s
22903/10943 (epoch 188.357) train_loss=424.03775024 time/batch=1.10s
22904/10943 (epoch 188.365) train_loss=206.69119263 time/batch=0.61s
22905/10943 (epoch 188.373) train_loss=336.28430176 time/batch=0.86s
22906/10943 (epoch 188.381) train_loss=182.38110352 time/batch=0.53s
22907/10943 (epoch 188.390) train_loss=295.41992188 time/batch=0.78s
22908/10943 (epoch 188.398) train_loss=383.51791382 time/batch=1.03s
22909/10943 (epoch 188.406) train_loss=228.62677002 time/batch=0.64s
22910/10943 (epoch 188.414) train_loss=250.05920410 time/batch=0.66s
22911/10943 (epoch 188.423) train_loss=154.80575562 time/batch=0.45s
22912/10943 (epoch 188.431) train_loss=193.31719971 time/batch=0.50s
22913/10943 (epoch 188.439) train_loss=347.96505737 time/batch=0.90s
22914/10943 (epoch 188.447) train_loss=185.41320801 time/batch=0.54s
22915/10943 (epoch 188.455) train_loss=312.92489624 time/batch=0.81s
22916/10943 (epoch 188.464) train_loss=294.11666870 time/batch=0.78s
22917/10943 (epoch 188.472) train_loss=117.94734955 time/batch=0.35s
22918/10943 (epoch 188.480) train_loss=188.77618408 time/batch=0.49s
22919/10943 (epoch 188.488) train_loss=142.61633301 time/batch=0.40s
22920/10943 (epoch 188.497) train_loss=282.14224243 time/batch=0.73s
22921/10943 (epoch 188.505) train_loss=191.06753540 time/batch=0.52s
22922/10943 (epoch 188.513) train_loss=219.55853271 time/batch=0.59s
22923/10943 (epoch 188.521) train_loss=267.41241455 time/batch=0.72s
22924/10943 (epoch 188.529) train_loss=243.52536011 time/batch=0.65s
22925/10943 (epoch 188.538) train_loss=251.19213867 time/batch=0.65s
22926/10943 (epoch 188.546) train_loss=253.20431519 time/batch=0.67s
22927/10943 (epoch 188.554) train_loss=189.17080688 time/batch=0.58s
22928/10943 (epoch 188.562) train_loss=188.68954468 time/batch=0.50s
22929/10943 (epoch 188.571) train_loss=272.17034912 time/batch=0.70s
22930/10943 (epoch 188.579) train_loss=402.83972168 time/batch=1.02s
22931/10943 (epoch 188.587) train_loss=309.04934692 time/batch=0.83s
22932/10943 (epoch 188.595) train_loss=270.74868774 time/batch=0.72s
22933/10943 (epoch 188.603) train_loss=298.12084961 time/batch=0.78s
22934/10943 (epoch 188.612) train_loss=228.99696350 time/batch=0.65s
22935/10943 (epoch 188.620) train_loss=173.68141174 time/batch=0.48s
22936/10943 (epoch 188.628) train_loss=348.98626709 time/batch=0.86s
22937/10943 (epoch 188.636) train_loss=330.51641846 time/batch=0.88s
22938/10943 (epoch 188.645) train_loss=247.25486755 time/batch=0.72s
22939/10943 (epoch 188.653) train_loss=284.86215210 time/batch=0.75s
22940/10943 (epoch 188.661) train_loss=342.82720947 time/batch=0.93s
22941/10943 (epoch 188.669) train_loss=358.46063232 time/batch=0.91s
22942/10943 (epoch 188.677) train_loss=186.92878723 time/batch=0.52s
22943/10943 (epoch 188.686) train_loss=231.35455322 time/batch=0.58s
22944/10943 (epoch 188.694) train_loss=232.21681213 time/batch=0.61s
22945/10943 (epoch 188.702) train_loss=197.63217163 time/batch=0.58s
22946/10943 (epoch 188.710) train_loss=159.67607117 time/batch=0.47s
22947/10943 (epoch 188.719) train_loss=301.56213379 time/batch=0.84s
22948/10943 (epoch 188.727) train_loss=227.02792358 time/batch=0.67s
22949/10943 (epoch 188.735) train_loss=117.27416229 time/batch=0.35s
22950/10943 (epoch 188.743) train_loss=282.29180908 time/batch=0.70s
22951/10943 (epoch 188.751) train_loss=257.80453491 time/batch=0.70s
22952/10943 (epoch 188.760) train_loss=211.57257080 time/batch=0.62s
22953/10943 (epoch 188.768) train_loss=273.45898438 time/batch=0.72s
22954/10943 (epoch 188.776) train_loss=303.55963135 time/batch=0.80s
22955/10943 (epoch 188.784) train_loss=260.44598389 time/batch=0.70s
22956/10943 (epoch 188.793) train_loss=288.13159180 time/batch=0.77s
22957/10943 (epoch 188.801) train_loss=298.74453735 time/batch=0.83s
22958/10943 (epoch 188.809) train_loss=244.46334839 time/batch=0.74s
22959/10943 (epoch 188.817) train_loss=284.51092529 time/batch=0.82s
setting learning rate to 0.0005127
22960/10943 (epoch 188.825) train_loss=510.22387695 time/batch=1.27s
22961/10943 (epoch 188.834) train_loss=651.04931641 time/batch=1.62s
22962/10943 (epoch 188.842) train_loss=312.31433105 time/batch=0.88s
22963/10943 (epoch 188.850) train_loss=328.16149902 time/batch=0.84s
22964/10943 (epoch 188.858) train_loss=96.49450684 time/batch=0.32s
22965/10943 (epoch 188.867) train_loss=484.74575806 time/batch=1.23s
22966/10943 (epoch 188.875) train_loss=465.19635010 time/batch=1.24s
22967/10943 (epoch 188.883) train_loss=354.58786011 time/batch=0.96s
22968/10943 (epoch 188.891) train_loss=706.54010010 time/batch=1.78s
22969/10943 (epoch 188.900) train_loss=908.75952148 time/batch=3.22s
22970/10943 (epoch 188.908) train_loss=202.06343079 time/batch=0.81s
22971/10943 (epoch 188.916) train_loss=545.27044678 time/batch=1.28s
22972/10943 (epoch 188.924) train_loss=218.30136108 time/batch=0.68s
22973/10943 (epoch 188.932) train_loss=113.63362122 time/batch=0.34s
22974/10943 (epoch 188.941) train_loss=525.23864746 time/batch=1.38s
22975/10943 (epoch 188.949) train_loss=149.10453796 time/batch=0.49s
22976/10943 (epoch 188.957) train_loss=352.85052490 time/batch=0.91s
22977/10943 (epoch 188.965) train_loss=403.59271240 time/batch=1.04s
22978/10943 (epoch 188.974) train_loss=209.52664185 time/batch=0.59s
22979/10943 (epoch 188.982) train_loss=142.00128174 time/batch=0.36s
22980/10943 (epoch 188.990) train_loss=105.78037262 time/batch=0.29s
22981/10943 (epoch 188.998) train_loss=191.92480469 time/batch=0.49s
22982/10943 (epoch 189.006) train_loss=344.26690674 time/batch=0.90s
22983/10943 (epoch 189.015) train_loss=156.79666138 time/batch=0.45s
22984/10943 (epoch 189.023) train_loss=284.57861328 time/batch=0.73s
22985/10943 (epoch 189.031) train_loss=400.28009033 time/batch=0.99s
22986/10943 (epoch 189.039) train_loss=182.74618530 time/batch=0.54s
22987/10943 (epoch 189.048) train_loss=383.95153809 time/batch=0.96s
22988/10943 (epoch 189.056) train_loss=374.42559814 time/batch=1.01s
22989/10943 (epoch 189.064) train_loss=161.51644897 time/batch=0.51s
22990/10943 (epoch 189.072) train_loss=194.07431030 time/batch=0.55s
22991/10943 (epoch 189.080) train_loss=498.47668457 time/batch=1.33s
22992/10943 (epoch 189.089) train_loss=218.43472290 time/batch=0.65s
22993/10943 (epoch 189.097) train_loss=380.91467285 time/batch=0.94s
22994/10943 (epoch 189.105) train_loss=288.78384399 time/batch=0.77s
22995/10943 (epoch 189.113) train_loss=433.11163330 time/batch=1.11s
22996/10943 (epoch 189.122) train_loss=445.90478516 time/batch=1.18s
22997/10943 (epoch 189.130) train_loss=475.65097046 time/batch=1.20s
22998/10943 (epoch 189.138) train_loss=224.96716309 time/batch=0.65s
22999/10943 (epoch 189.146) train_loss=282.42678833 time/batch=0.75s
Validating
    loss:	303.211100

23000/10943 (epoch 189.154) train_loss=416.33505249 time/batch=2.92s
23001/10943 (epoch 189.163) train_loss=318.88580322 time/batch=0.87s
23002/10943 (epoch 189.171) train_loss=335.27224731 time/batch=0.88s
23003/10943 (epoch 189.179) train_loss=351.25717163 time/batch=0.95s
23004/10943 (epoch 189.187) train_loss=421.03637695 time/batch=1.10s
23005/10943 (epoch 189.196) train_loss=202.62176514 time/batch=0.57s
23006/10943 (epoch 189.204) train_loss=110.24845886 time/batch=0.32s
23007/10943 (epoch 189.212) train_loss=250.00674438 time/batch=0.62s
23008/10943 (epoch 189.220) train_loss=288.76361084 time/batch=0.79s
23009/10943 (epoch 189.228) train_loss=396.00753784 time/batch=1.05s
23010/10943 (epoch 189.237) train_loss=358.70477295 time/batch=0.99s
23011/10943 (epoch 189.245) train_loss=157.98091125 time/batch=0.47s
23012/10943 (epoch 189.253) train_loss=273.18774414 time/batch=0.72s
23013/10943 (epoch 189.261) train_loss=230.44726562 time/batch=0.64s
23014/10943 (epoch 189.270) train_loss=259.65917969 time/batch=0.69s
23015/10943 (epoch 189.278) train_loss=312.51345825 time/batch=0.86s
23016/10943 (epoch 189.286) train_loss=288.73001099 time/batch=0.78s
23017/10943 (epoch 189.294) train_loss=221.59890747 time/batch=0.61s
23018/10943 (epoch 189.302) train_loss=321.44381714 time/batch=0.85s
23019/10943 (epoch 189.311) train_loss=141.42073059 time/batch=0.44s
23020/10943 (epoch 189.319) train_loss=160.73733521 time/batch=0.44s
23021/10943 (epoch 189.327) train_loss=172.00346375 time/batch=0.45s
23022/10943 (epoch 189.335) train_loss=292.01785278 time/batch=0.77s
23023/10943 (epoch 189.344) train_loss=148.54907227 time/batch=0.45s
23024/10943 (epoch 189.352) train_loss=254.17565918 time/batch=0.66s
23025/10943 (epoch 189.360) train_loss=427.57830811 time/batch=1.08s
23026/10943 (epoch 189.368) train_loss=275.44812012 time/batch=0.77s
23027/10943 (epoch 189.377) train_loss=299.11047363 time/batch=0.82s
23028/10943 (epoch 189.385) train_loss=198.86305237 time/batch=0.57s
23029/10943 (epoch 189.393) train_loss=123.80554962 time/batch=0.33s
23030/10943 (epoch 189.401) train_loss=281.82275391 time/batch=0.73s
23031/10943 (epoch 189.409) train_loss=213.13352966 time/batch=0.58s
23032/10943 (epoch 189.418) train_loss=117.15711975 time/batch=0.33s
23033/10943 (epoch 189.426) train_loss=294.12832642 time/batch=0.75s
23034/10943 (epoch 189.434) train_loss=137.41418457 time/batch=0.39s
23035/10943 (epoch 189.442) train_loss=227.72839355 time/batch=0.60s
23036/10943 (epoch 189.451) train_loss=186.13916016 time/batch=0.51s
23037/10943 (epoch 189.459) train_loss=178.58178711 time/batch=0.48s
23038/10943 (epoch 189.467) train_loss=335.63671875 time/batch=0.85s
23039/10943 (epoch 189.475) train_loss=230.65106201 time/batch=0.64s
23040/10943 (epoch 189.483) train_loss=252.77285767 time/batch=0.67s
23041/10943 (epoch 189.492) train_loss=290.26837158 time/batch=0.80s
23042/10943 (epoch 189.500) train_loss=295.01394653 time/batch=0.79s
23043/10943 (epoch 189.508) train_loss=187.98324585 time/batch=0.52s
23044/10943 (epoch 189.516) train_loss=355.73617554 time/batch=0.97s
23045/10943 (epoch 189.525) train_loss=225.75706482 time/batch=0.68s
23046/10943 (epoch 189.533) train_loss=274.26800537 time/batch=0.72s
23047/10943 (epoch 189.541) train_loss=268.41546631 time/batch=0.71s
23048/10943 (epoch 189.549) train_loss=247.98118591 time/batch=0.66s
23049/10943 (epoch 189.557) train_loss=202.97161865 time/batch=0.58s
23050/10943 (epoch 189.566) train_loss=282.79455566 time/batch=0.78s
23051/10943 (epoch 189.574) train_loss=134.74038696 time/batch=0.40s
23052/10943 (epoch 189.582) train_loss=123.16781616 time/batch=0.34s
23053/10943 (epoch 189.590) train_loss=145.74459839 time/batch=0.40s
23054/10943 (epoch 189.599) train_loss=354.28372192 time/batch=0.86s
23055/10943 (epoch 189.607) train_loss=322.63525391 time/batch=0.85s
23056/10943 (epoch 189.615) train_loss=227.27606201 time/batch=0.62s
23057/10943 (epoch 189.623) train_loss=163.65785217 time/batch=0.46s
23058/10943 (epoch 189.631) train_loss=255.39933777 time/batch=0.66s
23059/10943 (epoch 189.640) train_loss=229.97570801 time/batch=0.63s
23060/10943 (epoch 189.648) train_loss=155.80763245 time/batch=0.47s
23061/10943 (epoch 189.656) train_loss=214.22024536 time/batch=0.59s
23062/10943 (epoch 189.664) train_loss=239.79357910 time/batch=0.64s
23063/10943 (epoch 189.673) train_loss=243.41647339 time/batch=0.64s
23064/10943 (epoch 189.681) train_loss=190.14880371 time/batch=0.53s
23065/10943 (epoch 189.689) train_loss=233.91491699 time/batch=0.62s
23066/10943 (epoch 189.697) train_loss=257.24981689 time/batch=0.67s
23067/10943 (epoch 189.705) train_loss=179.58546448 time/batch=0.51s
23068/10943 (epoch 189.714) train_loss=288.26214600 time/batch=0.78s
23069/10943 (epoch 189.722) train_loss=263.63049316 time/batch=0.70s
23070/10943 (epoch 189.730) train_loss=296.74960327 time/batch=0.80s
23071/10943 (epoch 189.738) train_loss=262.50579834 time/batch=0.71s
23072/10943 (epoch 189.747) train_loss=198.02796936 time/batch=0.58s
23073/10943 (epoch 189.755) train_loss=297.92138672 time/batch=0.80s
23074/10943 (epoch 189.763) train_loss=247.40185547 time/batch=0.70s
23075/10943 (epoch 189.771) train_loss=282.60711670 time/batch=0.83s
23076/10943 (epoch 189.779) train_loss=312.91906738 time/batch=0.85s
23077/10943 (epoch 189.788) train_loss=224.80181885 time/batch=0.64s
23078/10943 (epoch 189.796) train_loss=240.29278564 time/batch=0.67s
23079/10943 (epoch 189.804) train_loss=262.17358398 time/batch=0.70s
23080/10943 (epoch 189.812) train_loss=253.98454285 time/batch=0.72s
setting learning rate to 0.0004973
  saved to metadata/gru_no_dropout-9_nov_folkwiki-20181115-214759_epoch79.pkl
23081/10943 (epoch 189.821) train_loss=187.79528809 time/batch=0.59s
23082/10943 (epoch 189.829) train_loss=324.53979492 time/batch=0.83s
23083/10943 (epoch 189.837) train_loss=350.55096436 time/batch=0.92s
23084/10943 (epoch 189.845) train_loss=783.52593994 time/batch=2.09s
23085/10943 (epoch 189.854) train_loss=163.83294678 time/batch=0.61s
23086/10943 (epoch 189.862) train_loss=107.84997559 time/batch=0.29s
23087/10943 (epoch 189.870) train_loss=535.48577881 time/batch=1.24s
23088/10943 (epoch 189.878) train_loss=137.32496643 time/batch=0.45s
23089/10943 (epoch 189.886) train_loss=368.53515625 time/batch=0.91s
23090/10943 (epoch 189.895) train_loss=250.66053772 time/batch=0.71s
23091/10943 (epoch 189.903) train_loss=144.31451416 time/batch=0.41s
23092/10943 (epoch 189.911) train_loss=411.05703735 time/batch=1.04s
23093/10943 (epoch 189.919) train_loss=557.52795410 time/batch=1.52s
23094/10943 (epoch 189.928) train_loss=283.01037598 time/batch=0.82s
23095/10943 (epoch 189.936) train_loss=427.68151855 time/batch=1.13s
23096/10943 (epoch 189.944) train_loss=504.79412842 time/batch=1.33s
23097/10943 (epoch 189.952) train_loss=419.86151123 time/batch=1.10s
23098/10943 (epoch 189.960) train_loss=220.24026489 time/batch=0.62s
23099/10943 (epoch 189.969) train_loss=284.42822266 time/batch=0.81s
23100/10943 (epoch 189.977) train_loss=272.21908569 time/batch=0.78s
23101/10943 (epoch 189.985) train_loss=336.79895020 time/batch=0.90s
23102/10943 (epoch 189.993) train_loss=428.41046143 time/batch=1.12s
23103/10943 (epoch 190.002) train_loss=190.56921387 time/batch=0.58s
23104/10943 (epoch 190.010) train_loss=601.50317383 time/batch=1.55s
23105/10943 (epoch 190.018) train_loss=307.63092041 time/batch=0.92s
23106/10943 (epoch 190.026) train_loss=426.96984863 time/batch=1.11s
23107/10943 (epoch 190.034) train_loss=142.72991943 time/batch=0.46s
23108/10943 (epoch 190.043) train_loss=296.76184082 time/batch=0.73s
23109/10943 (epoch 190.051) train_loss=246.42089844 time/batch=0.67s
23110/10943 (epoch 190.059) train_loss=259.13931274 time/batch=0.69s
23111/10943 (epoch 190.067) train_loss=283.51864624 time/batch=0.74s
23112/10943 (epoch 190.076) train_loss=285.99429321 time/batch=0.79s
23113/10943 (epoch 190.084) train_loss=115.17915344 time/batch=0.34s
23114/10943 (epoch 190.092) train_loss=270.84121704 time/batch=0.70s
23115/10943 (epoch 190.100) train_loss=276.99694824 time/batch=0.76s
23116/10943 (epoch 190.108) train_loss=331.54785156 time/batch=0.88s
23117/10943 (epoch 190.117) train_loss=206.10754395 time/batch=0.60s
23118/10943 (epoch 190.125) train_loss=157.37872314 time/batch=0.44s
23119/10943 (epoch 190.133) train_loss=511.74520874 time/batch=1.32s
23120/10943 (epoch 190.141) train_loss=429.71319580 time/batch=1.21s
23121/10943 (epoch 190.150) train_loss=447.07797241 time/batch=1.21s
23122/10943 (epoch 190.158) train_loss=173.03366089 time/batch=0.51s
23123/10943 (epoch 190.166) train_loss=478.77648926 time/batch=1.16s
23124/10943 (epoch 190.174) train_loss=117.37873840 time/batch=0.41s
23125/10943 (epoch 190.182) train_loss=193.81214905 time/batch=0.49s
23126/10943 (epoch 190.191) train_loss=370.79321289 time/batch=0.94s
23127/10943 (epoch 190.199) train_loss=224.77687073 time/batch=0.67s
23128/10943 (epoch 190.207) train_loss=231.75732422 time/batch=0.62s
23129/10943 (epoch 190.215) train_loss=295.28521729 time/batch=0.76s
23130/10943 (epoch 190.224) train_loss=412.91732788 time/batch=1.03s
23131/10943 (epoch 190.232) train_loss=395.70483398 time/batch=1.03s
23132/10943 (epoch 190.240) train_loss=222.60824585 time/batch=0.64s
23133/10943 (epoch 190.248) train_loss=189.51782227 time/batch=0.53s
23134/10943 (epoch 190.256) train_loss=153.22018433 time/batch=0.44s
23135/10943 (epoch 190.265) train_loss=326.38958740 time/batch=0.82s
23136/10943 (epoch 190.273) train_loss=209.60464478 time/batch=0.60s
23137/10943 (epoch 190.281) train_loss=183.74563599 time/batch=0.49s
23138/10943 (epoch 190.289) train_loss=786.09326172 time/batch=3.07s
23139/10943 (epoch 190.298) train_loss=277.94824219 time/batch=0.96s
23140/10943 (epoch 190.306) train_loss=319.23809814 time/batch=0.85s
23141/10943 (epoch 190.314) train_loss=218.68225098 time/batch=0.63s
23142/10943 (epoch 190.322) train_loss=372.17251587 time/batch=0.96s
23143/10943 (epoch 190.331) train_loss=144.04876709 time/batch=0.42s
23144/10943 (epoch 190.339) train_loss=455.53112793 time/batch=1.16s
23145/10943 (epoch 190.347) train_loss=258.44229126 time/batch=0.73s
23146/10943 (epoch 190.355) train_loss=348.40670776 time/batch=0.92s
23147/10943 (epoch 190.363) train_loss=197.81654358 time/batch=0.57s
23148/10943 (epoch 190.372) train_loss=322.65710449 time/batch=0.84s
23149/10943 (epoch 190.380) train_loss=225.27214050 time/batch=0.65s
23150/10943 (epoch 190.388) train_loss=260.77429199 time/batch=0.72s
23151/10943 (epoch 190.396) train_loss=311.05273438 time/batch=0.87s
23152/10943 (epoch 190.405) train_loss=153.82650757 time/batch=0.44s
23153/10943 (epoch 190.413) train_loss=218.02456665 time/batch=0.58s
23154/10943 (epoch 190.421) train_loss=90.41748047 time/batch=0.28s
23155/10943 (epoch 190.429) train_loss=284.41436768 time/batch=0.76s
23156/10943 (epoch 190.437) train_loss=256.76837158 time/batch=0.70s
23157/10943 (epoch 190.446) train_loss=357.26641846 time/batch=0.91s
23158/10943 (epoch 190.454) train_loss=173.87835693 time/batch=0.50s
23159/10943 (epoch 190.462) train_loss=197.85009766 time/batch=0.54s
23160/10943 (epoch 190.470) train_loss=171.69479370 time/batch=0.49s
23161/10943 (epoch 190.479) train_loss=248.11590576 time/batch=0.68s
23162/10943 (epoch 190.487) train_loss=250.65719604 time/batch=0.70s
23163/10943 (epoch 190.495) train_loss=380.19024658 time/batch=0.95s
23164/10943 (epoch 190.503) train_loss=293.97918701 time/batch=0.78s
23165/10943 (epoch 190.511) train_loss=337.99484253 time/batch=0.93s
23166/10943 (epoch 190.520) train_loss=301.75146484 time/batch=0.83s
23167/10943 (epoch 190.528) train_loss=254.97225952 time/batch=0.72s
23168/10943 (epoch 190.536) train_loss=241.32804871 time/batch=0.65s
23169/10943 (epoch 190.544) train_loss=241.30752563 time/batch=0.64s
23170/10943 (epoch 190.553) train_loss=116.68164062 time/batch=0.34s
23171/10943 (epoch 190.561) train_loss=257.14807129 time/batch=0.64s
23172/10943 (epoch 190.569) train_loss=293.58728027 time/batch=0.80s
23173/10943 (epoch 190.577) train_loss=137.84664917 time/batch=0.41s
23174/10943 (epoch 190.585) train_loss=220.88381958 time/batch=0.60s
23175/10943 (epoch 190.594) train_loss=217.37805176 time/batch=0.60s
23176/10943 (epoch 190.602) train_loss=203.09083557 time/batch=0.55s
23177/10943 (epoch 190.610) train_loss=149.15890503 time/batch=0.44s
23178/10943 (epoch 190.618) train_loss=244.79306030 time/batch=0.67s
23179/10943 (epoch 190.627) train_loss=226.74389648 time/batch=0.64s
23180/10943 (epoch 190.635) train_loss=175.43722534 time/batch=0.49s
23181/10943 (epoch 190.643) train_loss=117.76213074 time/batch=0.34s
23182/10943 (epoch 190.651) train_loss=193.78616333 time/batch=0.51s
23183/10943 (epoch 190.659) train_loss=224.01472473 time/batch=0.57s
23184/10943 (epoch 190.668) train_loss=186.25112915 time/batch=0.50s
23185/10943 (epoch 190.676) train_loss=311.38208008 time/batch=0.80s
23186/10943 (epoch 190.684) train_loss=196.42358398 time/batch=0.57s
23187/10943 (epoch 190.692) train_loss=352.66006470 time/batch=0.95s
23188/10943 (epoch 190.701) train_loss=296.13641357 time/batch=0.82s
23189/10943 (epoch 190.709) train_loss=328.57360840 time/batch=0.84s
23190/10943 (epoch 190.717) train_loss=244.06683350 time/batch=0.66s
23191/10943 (epoch 190.725) train_loss=163.71231079 time/batch=0.48s
23192/10943 (epoch 190.733) train_loss=285.30383301 time/batch=0.79s
23193/10943 (epoch 190.742) train_loss=279.48645020 time/batch=0.72s
23194/10943 (epoch 190.750) train_loss=194.71591187 time/batch=0.58s
23195/10943 (epoch 190.758) train_loss=298.17770386 time/batch=0.79s
23196/10943 (epoch 190.766) train_loss=278.06079102 time/batch=0.73s
23197/10943 (epoch 190.775) train_loss=219.46356201 time/batch=0.61s
23198/10943 (epoch 190.783) train_loss=135.02394104 time/batch=0.38s
23199/10943 (epoch 190.791) train_loss=153.60382080 time/batch=0.58s
23200/10943 (epoch 190.799) train_loss=244.73400879 time/batch=0.71s
23201/10943 (epoch 190.808) train_loss=256.30438232 time/batch=0.81s
setting learning rate to 0.0004824
23202/10943 (epoch 190.816) train_loss=522.64434814 time/batch=1.31s
23203/10943 (epoch 190.824) train_loss=369.12310791 time/batch=1.00s
23204/10943 (epoch 190.832) train_loss=380.23767090 time/batch=0.96s
23205/10943 (epoch 190.840) train_loss=535.93475342 time/batch=1.40s
23206/10943 (epoch 190.849) train_loss=301.27252197 time/batch=0.87s
23207/10943 (epoch 190.857) train_loss=332.11572266 time/batch=0.94s
23208/10943 (epoch 190.865) train_loss=599.19189453 time/batch=1.57s
23209/10943 (epoch 190.873) train_loss=416.43371582 time/batch=1.17s
23210/10943 (epoch 190.882) train_loss=199.10308838 time/batch=0.61s
23211/10943 (epoch 190.890) train_loss=188.39178467 time/batch=0.52s
23212/10943 (epoch 190.898) train_loss=450.04067993 time/batch=1.15s
23213/10943 (epoch 190.906) train_loss=147.01376343 time/batch=0.46s
23214/10943 (epoch 190.914) train_loss=219.39544678 time/batch=0.60s
23215/10943 (epoch 190.923) train_loss=296.81445312 time/batch=0.76s
23216/10943 (epoch 190.931) train_loss=224.92025757 time/batch=0.64s
23217/10943 (epoch 190.939) train_loss=370.37750244 time/batch=0.95s
23218/10943 (epoch 190.947) train_loss=103.23096466 time/batch=0.33s
23219/10943 (epoch 190.956) train_loss=798.69293213 time/batch=2.16s
23220/10943 (epoch 190.964) train_loss=292.20065308 time/batch=0.91s
23221/10943 (epoch 190.972) train_loss=774.15332031 time/batch=3.10s
23222/10943 (epoch 190.980) train_loss=468.87097168 time/batch=1.48s
23223/10943 (epoch 190.988) train_loss=330.53808594 time/batch=0.91s
23224/10943 (epoch 190.997) train_loss=477.16723633 time/batch=1.22s
23225/10943 (epoch 191.005) train_loss=407.18096924 time/batch=1.08s
23226/10943 (epoch 191.013) train_loss=523.30126953 time/batch=1.43s
23227/10943 (epoch 191.021) train_loss=216.82717896 time/batch=0.67s
23228/10943 (epoch 191.030) train_loss=429.74325562 time/batch=1.08s
23229/10943 (epoch 191.038) train_loss=198.32788086 time/batch=0.61s
23230/10943 (epoch 191.046) train_loss=405.57464600 time/batch=0.98s
23231/10943 (epoch 191.054) train_loss=152.74157715 time/batch=0.47s
23232/10943 (epoch 191.062) train_loss=417.11062622 time/batch=1.09s
23233/10943 (epoch 191.071) train_loss=414.17889404 time/batch=1.07s
23234/10943 (epoch 191.079) train_loss=215.61904907 time/batch=0.64s
23235/10943 (epoch 191.087) train_loss=260.78573608 time/batch=0.66s
23236/10943 (epoch 191.095) train_loss=271.96813965 time/batch=0.71s
23237/10943 (epoch 191.104) train_loss=134.53091431 time/batch=0.41s
23238/10943 (epoch 191.112) train_loss=94.41007233 time/batch=0.29s
23239/10943 (epoch 191.120) train_loss=328.04266357 time/batch=0.82s
23240/10943 (epoch 191.128) train_loss=308.62246704 time/batch=0.84s
23241/10943 (epoch 191.136) train_loss=314.15359497 time/batch=0.88s
23242/10943 (epoch 191.145) train_loss=475.81234741 time/batch=1.44s
23243/10943 (epoch 191.153) train_loss=251.08235168 time/batch=0.75s
23244/10943 (epoch 191.161) train_loss=114.91763306 time/batch=0.34s
23245/10943 (epoch 191.169) train_loss=249.70339966 time/batch=0.61s
23246/10943 (epoch 191.178) train_loss=432.81420898 time/batch=1.11s
23247/10943 (epoch 191.186) train_loss=118.92160034 time/batch=0.39s
23248/10943 (epoch 191.194) train_loss=319.06591797 time/batch=0.80s
23249/10943 (epoch 191.202) train_loss=211.33163452 time/batch=0.60s
23250/10943 (epoch 191.210) train_loss=181.09631348 time/batch=0.49s
23251/10943 (epoch 191.219) train_loss=165.30960083 time/batch=0.43s
23252/10943 (epoch 191.227) train_loss=214.54173279 time/batch=0.57s
23253/10943 (epoch 191.235) train_loss=367.72137451 time/batch=1.02s
23254/10943 (epoch 191.243) train_loss=367.68231201 time/batch=1.01s
23255/10943 (epoch 191.252) train_loss=258.97741699 time/batch=0.70s
23256/10943 (epoch 191.260) train_loss=114.00718689 time/batch=0.32s
23257/10943 (epoch 191.268) train_loss=138.59744263 time/batch=0.35s
23258/10943 (epoch 191.276) train_loss=344.61035156 time/batch=0.85s
23259/10943 (epoch 191.285) train_loss=352.76986694 time/batch=0.92s
23260/10943 (epoch 191.293) train_loss=294.30584717 time/batch=0.79s
23261/10943 (epoch 191.301) train_loss=355.60946655 time/batch=0.91s
23262/10943 (epoch 191.309) train_loss=198.72253418 time/batch=0.55s
23263/10943 (epoch 191.317) train_loss=138.65280151 time/batch=0.40s
23264/10943 (epoch 191.326) train_loss=165.89561462 time/batch=0.44s
23265/10943 (epoch 191.334) train_loss=380.88775635 time/batch=0.93s
23266/10943 (epoch 191.342) train_loss=321.34765625 time/batch=0.86s
23267/10943 (epoch 191.350) train_loss=333.35269165 time/batch=0.89s
23268/10943 (epoch 191.359) train_loss=244.94569397 time/batch=0.66s
23269/10943 (epoch 191.367) train_loss=370.47869873 time/batch=1.03s
23270/10943 (epoch 191.375) train_loss=276.91076660 time/batch=0.78s
23271/10943 (epoch 191.383) train_loss=126.78859711 time/batch=0.36s
23272/10943 (epoch 191.391) train_loss=257.24725342 time/batch=0.67s
23273/10943 (epoch 191.400) train_loss=151.38778687 time/batch=0.44s
23274/10943 (epoch 191.408) train_loss=193.61270142 time/batch=0.52s
23275/10943 (epoch 191.416) train_loss=220.71047974 time/batch=0.59s
23276/10943 (epoch 191.424) train_loss=201.19201660 time/batch=0.55s
23277/10943 (epoch 191.433) train_loss=288.81884766 time/batch=0.79s
23278/10943 (epoch 191.441) train_loss=153.67602539 time/batch=0.46s
23279/10943 (epoch 191.449) train_loss=150.13984680 time/batch=0.42s
23280/10943 (epoch 191.457) train_loss=272.70117188 time/batch=0.72s
23281/10943 (epoch 191.465) train_loss=284.58410645 time/batch=0.75s
23282/10943 (epoch 191.474) train_loss=291.81506348 time/batch=0.82s
23283/10943 (epoch 191.482) train_loss=224.61111450 time/batch=0.63s
23284/10943 (epoch 191.490) train_loss=215.87133789 time/batch=0.59s
23285/10943 (epoch 191.498) train_loss=239.89628601 time/batch=0.65s
23286/10943 (epoch 191.507) train_loss=296.75155640 time/batch=0.78s
23287/10943 (epoch 191.515) train_loss=159.44015503 time/batch=0.47s
23288/10943 (epoch 191.523) train_loss=311.73757935 time/batch=0.84s
23289/10943 (epoch 191.531) train_loss=287.11584473 time/batch=0.79s
23290/10943 (epoch 191.539) train_loss=301.85778809 time/batch=0.84s
23291/10943 (epoch 191.548) train_loss=182.64167786 time/batch=0.51s
23292/10943 (epoch 191.556) train_loss=294.17367554 time/batch=0.81s
23293/10943 (epoch 191.564) train_loss=230.87390137 time/batch=0.67s
23294/10943 (epoch 191.572) train_loss=229.64904785 time/batch=0.58s
23295/10943 (epoch 191.581) train_loss=293.91400146 time/batch=0.79s
23296/10943 (epoch 191.589) train_loss=250.74795532 time/batch=0.71s
23297/10943 (epoch 191.597) train_loss=165.81898499 time/batch=0.48s
23298/10943 (epoch 191.605) train_loss=142.49258423 time/batch=0.43s
23299/10943 (epoch 191.613) train_loss=199.15510559 time/batch=0.53s
23300/10943 (epoch 191.622) train_loss=179.95288086 time/batch=0.49s
23301/10943 (epoch 191.630) train_loss=214.51136780 time/batch=0.59s
23302/10943 (epoch 191.638) train_loss=287.24273682 time/batch=0.79s
23303/10943 (epoch 191.646) train_loss=266.51562500 time/batch=0.69s
23304/10943 (epoch 191.655) train_loss=268.69668579 time/batch=0.71s
23305/10943 (epoch 191.663) train_loss=181.08633423 time/batch=0.51s
23306/10943 (epoch 191.671) train_loss=228.21865845 time/batch=0.60s
23307/10943 (epoch 191.679) train_loss=258.68597412 time/batch=0.70s
23308/10943 (epoch 191.687) train_loss=291.08477783 time/batch=0.79s
23309/10943 (epoch 191.696) train_loss=289.59497070 time/batch=0.80s
23310/10943 (epoch 191.704) train_loss=195.43504333 time/batch=0.58s
23311/10943 (epoch 191.712) train_loss=263.46215820 time/batch=0.71s
23312/10943 (epoch 191.720) train_loss=188.29673767 time/batch=0.52s
23313/10943 (epoch 191.729) train_loss=120.27714539 time/batch=0.34s
23314/10943 (epoch 191.737) train_loss=211.64480591 time/batch=0.57s
23315/10943 (epoch 191.745) train_loss=245.35296631 time/batch=0.67s
23316/10943 (epoch 191.753) train_loss=276.58843994 time/batch=0.74s
23317/10943 (epoch 191.762) train_loss=141.26660156 time/batch=0.47s
23318/10943 (epoch 191.770) train_loss=244.76904297 time/batch=0.66s
23319/10943 (epoch 191.778) train_loss=243.65046692 time/batch=0.69s
23320/10943 (epoch 191.786) train_loss=266.89270020 time/batch=0.79s
23321/10943 (epoch 191.794) train_loss=194.34388733 time/batch=0.64s
23322/10943 (epoch 191.803) train_loss=230.08967590 time/batch=0.62s
setting learning rate to 0.0004679
23323/10943 (epoch 191.811) train_loss=629.71954346 time/batch=1.58s
23324/10943 (epoch 191.819) train_loss=151.53598022 time/batch=0.50s
23325/10943 (epoch 191.827) train_loss=256.14379883 time/batch=0.67s
23326/10943 (epoch 191.836) train_loss=213.15611267 time/batch=0.59s
23327/10943 (epoch 191.844) train_loss=104.40885925 time/batch=0.31s
23328/10943 (epoch 191.852) train_loss=180.74974060 time/batch=0.47s
23329/10943 (epoch 191.860) train_loss=345.06719971 time/batch=0.89s
23330/10943 (epoch 191.868) train_loss=463.38189697 time/batch=1.20s
23331/10943 (epoch 191.877) train_loss=222.72021484 time/batch=0.66s
23332/10943 (epoch 191.885) train_loss=526.08862305 time/batch=1.38s
23333/10943 (epoch 191.893) train_loss=344.99487305 time/batch=1.01s
23334/10943 (epoch 191.901) train_loss=443.32595825 time/batch=1.13s
23335/10943 (epoch 191.910) train_loss=314.28240967 time/batch=0.90s
23336/10943 (epoch 191.918) train_loss=427.18395996 time/batch=1.13s
23337/10943 (epoch 191.926) train_loss=503.51336670 time/batch=1.31s
23338/10943 (epoch 191.934) train_loss=129.25152588 time/batch=0.42s
23339/10943 (epoch 191.942) train_loss=319.57330322 time/batch=0.82s
23340/10943 (epoch 191.951) train_loss=246.92846680 time/batch=0.69s
23341/10943 (epoch 191.959) train_loss=273.35723877 time/batch=0.75s
23342/10943 (epoch 191.967) train_loss=373.19808960 time/batch=0.98s
23343/10943 (epoch 191.975) train_loss=415.30944824 time/batch=1.16s
23344/10943 (epoch 191.984) train_loss=287.82092285 time/batch=0.84s
23345/10943 (epoch 191.992) train_loss=248.02142334 time/batch=0.67s
23346/10943 (epoch 192.000) train_loss=242.76348877 time/batch=0.65s
23347/10943 (epoch 192.008) train_loss=401.00173950 time/batch=1.04s
23348/10943 (epoch 192.016) train_loss=166.60322571 time/batch=0.53s
23349/10943 (epoch 192.025) train_loss=453.24597168 time/batch=1.17s
23350/10943 (epoch 192.033) train_loss=420.33413696 time/batch=1.19s
23351/10943 (epoch 192.041) train_loss=154.32225037 time/batch=0.49s
23352/10943 (epoch 192.049) train_loss=137.44282532 time/batch=0.39s
23353/10943 (epoch 192.058) train_loss=532.23510742 time/batch=1.29s
23354/10943 (epoch 192.066) train_loss=191.50677490 time/batch=0.60s
23355/10943 (epoch 192.074) train_loss=328.00778198 time/batch=0.85s
23356/10943 (epoch 192.082) train_loss=155.21406555 time/batch=0.49s
23357/10943 (epoch 192.090) train_loss=217.20832825 time/batch=0.59s
23358/10943 (epoch 192.099) train_loss=370.07183838 time/batch=0.93s
23359/10943 (epoch 192.107) train_loss=401.19946289 time/batch=1.09s
23360/10943 (epoch 192.115) train_loss=630.24780273 time/batch=1.67s
23361/10943 (epoch 192.123) train_loss=306.52294922 time/batch=0.92s
23362/10943 (epoch 192.132) train_loss=343.54623413 time/batch=0.91s
23363/10943 (epoch 192.140) train_loss=748.89916992 time/batch=2.11s
23364/10943 (epoch 192.148) train_loss=156.97143555 time/batch=0.59s
23365/10943 (epoch 192.156) train_loss=284.95648193 time/batch=0.68s
23366/10943 (epoch 192.164) train_loss=288.77642822 time/batch=0.81s
23367/10943 (epoch 192.173) train_loss=225.99383545 time/batch=0.64s
23368/10943 (epoch 192.181) train_loss=350.24087524 time/batch=0.87s
23369/10943 (epoch 192.189) train_loss=311.20312500 time/batch=0.85s
23370/10943 (epoch 192.197) train_loss=196.06013489 time/batch=0.55s
23371/10943 (epoch 192.206) train_loss=188.98156738 time/batch=0.52s
23372/10943 (epoch 192.214) train_loss=254.20960999 time/batch=0.65s
23373/10943 (epoch 192.222) train_loss=346.79919434 time/batch=0.92s
23374/10943 (epoch 192.230) train_loss=104.68054199 time/batch=0.37s
23375/10943 (epoch 192.238) train_loss=405.68377686 time/batch=1.01s
23376/10943 (epoch 192.247) train_loss=194.84454346 time/batch=0.61s
23377/10943 (epoch 192.255) train_loss=429.28942871 time/batch=1.18s
23378/10943 (epoch 192.263) train_loss=322.07659912 time/batch=0.93s
23379/10943 (epoch 192.271) train_loss=118.32154846 time/batch=0.37s
23380/10943 (epoch 192.280) train_loss=268.84014893 time/batch=0.69s
23381/10943 (epoch 192.288) train_loss=400.43554688 time/batch=0.99s
23382/10943 (epoch 192.296) train_loss=141.07821655 time/batch=0.43s
23383/10943 (epoch 192.304) train_loss=184.29489136 time/batch=0.51s
23384/10943 (epoch 192.313) train_loss=178.99909973 time/batch=0.47s
23385/10943 (epoch 192.321) train_loss=216.99586487 time/batch=0.58s
23386/10943 (epoch 192.329) train_loss=377.96368408 time/batch=0.95s
23387/10943 (epoch 192.337) train_loss=180.43179321 time/batch=0.54s
23388/10943 (epoch 192.345) train_loss=326.92669678 time/batch=0.83s
23389/10943 (epoch 192.354) train_loss=363.83489990 time/batch=1.00s
23390/10943 (epoch 192.362) train_loss=147.99449158 time/batch=0.47s
23391/10943 (epoch 192.370) train_loss=211.41534424 time/batch=0.53s
23392/10943 (epoch 192.378) train_loss=119.24324036 time/batch=0.35s
23393/10943 (epoch 192.387) train_loss=549.89111328 time/batch=2.26s
23394/10943 (epoch 192.395) train_loss=160.51402283 time/batch=0.63s
23395/10943 (epoch 192.403) train_loss=282.10156250 time/batch=0.72s
23396/10943 (epoch 192.411) train_loss=225.54940796 time/batch=0.60s
23397/10943 (epoch 192.419) train_loss=339.43826294 time/batch=0.96s
23398/10943 (epoch 192.428) train_loss=258.62426758 time/batch=0.71s
23399/10943 (epoch 192.436) train_loss=258.50082397 time/batch=0.67s
23400/10943 (epoch 192.444) train_loss=107.24864197 time/batch=0.33s
23401/10943 (epoch 192.452) train_loss=248.35650635 time/batch=0.64s
23402/10943 (epoch 192.461) train_loss=297.77230835 time/batch=0.78s
23403/10943 (epoch 192.469) train_loss=255.05700684 time/batch=0.72s
23404/10943 (epoch 192.477) train_loss=206.14482117 time/batch=0.58s
23405/10943 (epoch 192.485) train_loss=224.73397827 time/batch=0.61s
23406/10943 (epoch 192.493) train_loss=111.42567444 time/batch=0.34s
23407/10943 (epoch 192.502) train_loss=281.21389771 time/batch=0.73s
23408/10943 (epoch 192.510) train_loss=249.34413147 time/batch=0.70s
23409/10943 (epoch 192.518) train_loss=171.23049927 time/batch=0.49s
23410/10943 (epoch 192.526) train_loss=191.39160156 time/batch=0.50s
23411/10943 (epoch 192.535) train_loss=264.01654053 time/batch=0.70s
23412/10943 (epoch 192.543) train_loss=223.68110657 time/batch=0.64s
23413/10943 (epoch 192.551) train_loss=142.68777466 time/batch=0.43s
23414/10943 (epoch 192.559) train_loss=269.66635132 time/batch=0.69s
23415/10943 (epoch 192.567) train_loss=195.16432190 time/batch=0.57s
23416/10943 (epoch 192.576) train_loss=219.81652832 time/batch=0.60s
23417/10943 (epoch 192.584) train_loss=230.11276245 time/batch=0.64s
23418/10943 (epoch 192.592) train_loss=125.41618347 time/batch=0.37s
23419/10943 (epoch 192.600) train_loss=182.69648743 time/batch=0.48s
23420/10943 (epoch 192.609) train_loss=283.96075439 time/batch=0.79s
23421/10943 (epoch 192.617) train_loss=170.58953857 time/batch=0.47s
23422/10943 (epoch 192.625) train_loss=189.46130371 time/batch=0.53s
23423/10943 (epoch 192.633) train_loss=233.18365479 time/batch=0.64s
23424/10943 (epoch 192.641) train_loss=250.47521973 time/batch=0.69s
23425/10943 (epoch 192.650) train_loss=465.22888184 time/batch=3.09s
23426/10943 (epoch 192.658) train_loss=295.29217529 time/batch=1.01s
23427/10943 (epoch 192.666) train_loss=306.59780884 time/batch=0.82s
23428/10943 (epoch 192.674) train_loss=153.28402710 time/batch=0.49s
23429/10943 (epoch 192.683) train_loss=282.78808594 time/batch=0.71s
23430/10943 (epoch 192.691) train_loss=298.89489746 time/batch=0.77s
23431/10943 (epoch 192.699) train_loss=294.01589966 time/batch=0.79s
23432/10943 (epoch 192.707) train_loss=204.03048706 time/batch=0.58s
23433/10943 (epoch 192.715) train_loss=256.89318848 time/batch=0.68s
23434/10943 (epoch 192.724) train_loss=278.34063721 time/batch=0.80s
23435/10943 (epoch 192.732) train_loss=309.09332275 time/batch=0.85s
23436/10943 (epoch 192.740) train_loss=260.18316650 time/batch=0.76s
23437/10943 (epoch 192.748) train_loss=306.61779785 time/batch=0.83s
23438/10943 (epoch 192.757) train_loss=271.87808228 time/batch=0.79s
23439/10943 (epoch 192.765) train_loss=222.76434326 time/batch=0.63s
23440/10943 (epoch 192.773) train_loss=244.06091309 time/batch=0.76s
23441/10943 (epoch 192.781) train_loss=183.68374634 time/batch=0.59s
23442/10943 (epoch 192.790) train_loss=223.64175415 time/batch=0.61s
23443/10943 (epoch 192.798) train_loss=262.49505615 time/batch=0.79s
setting learning rate to 0.0004539
23444/10943 (epoch 192.806) train_loss=181.01034546 time/batch=0.52s
23445/10943 (epoch 192.814) train_loss=628.29425049 time/batch=1.57s
23446/10943 (epoch 192.822) train_loss=909.38476562 time/batch=3.18s
23447/10943 (epoch 192.831) train_loss=111.69259644 time/batch=0.60s
23448/10943 (epoch 192.839) train_loss=137.55773926 time/batch=0.35s
23449/10943 (epoch 192.847) train_loss=345.46618652 time/batch=0.88s
23450/10943 (epoch 192.855) train_loss=587.51147461 time/batch=1.63s
23451/10943 (epoch 192.864) train_loss=353.23474121 time/batch=1.00s
23452/10943 (epoch 192.872) train_loss=257.74255371 time/batch=0.70s
23453/10943 (epoch 192.880) train_loss=357.74578857 time/batch=0.96s
23454/10943 (epoch 192.888) train_loss=195.29052734 time/batch=0.56s
23455/10943 (epoch 192.896) train_loss=109.62860107 time/batch=0.31s
23456/10943 (epoch 192.905) train_loss=375.83593750 time/batch=0.97s
23457/10943 (epoch 192.913) train_loss=495.02441406 time/batch=1.28s
23458/10943 (epoch 192.921) train_loss=350.54064941 time/batch=0.95s
23459/10943 (epoch 192.929) train_loss=521.02673340 time/batch=1.40s
23460/10943 (epoch 192.938) train_loss=229.78742981 time/batch=0.70s
23461/10943 (epoch 192.946) train_loss=190.82418823 time/batch=0.53s
23462/10943 (epoch 192.954) train_loss=280.92022705 time/batch=0.78s
23463/10943 (epoch 192.962) train_loss=413.85742188 time/batch=1.09s
23464/10943 (epoch 192.970) train_loss=276.25131226 time/batch=0.80s
23465/10943 (epoch 192.979) train_loss=212.97750854 time/batch=0.59s
23466/10943 (epoch 192.987) train_loss=94.77218628 time/batch=0.32s
23467/10943 (epoch 192.995) train_loss=159.18183899 time/batch=0.42s
23468/10943 (epoch 193.003) train_loss=282.59313965 time/batch=0.75s
23469/10943 (epoch 193.012) train_loss=152.91946411 time/batch=0.44s
23470/10943 (epoch 193.020) train_loss=522.57672119 time/batch=1.26s
23471/10943 (epoch 193.028) train_loss=293.70526123 time/batch=0.82s
23472/10943 (epoch 193.036) train_loss=141.22636414 time/batch=0.40s
23473/10943 (epoch 193.044) train_loss=307.59912109 time/batch=0.79s
23474/10943 (epoch 193.053) train_loss=410.80517578 time/batch=1.09s
23475/10943 (epoch 193.061) train_loss=510.91897583 time/batch=1.69s
23476/10943 (epoch 193.069) train_loss=349.65435791 time/batch=0.97s
23477/10943 (epoch 193.077) train_loss=251.94726562 time/batch=0.72s
23478/10943 (epoch 193.086) train_loss=323.96475220 time/batch=0.88s
23479/10943 (epoch 193.094) train_loss=256.96743774 time/batch=0.69s
23480/10943 (epoch 193.102) train_loss=127.78903198 time/batch=0.36s
23481/10943 (epoch 193.110) train_loss=311.16320801 time/batch=0.81s
23482/10943 (epoch 193.118) train_loss=249.92364502 time/batch=0.71s
23483/10943 (epoch 193.127) train_loss=436.96810913 time/batch=1.10s
23484/10943 (epoch 193.135) train_loss=146.86145020 time/batch=0.44s
23485/10943 (epoch 193.143) train_loss=421.58312988 time/batch=1.08s
23486/10943 (epoch 193.151) train_loss=287.98400879 time/batch=0.76s
23487/10943 (epoch 193.160) train_loss=153.34449768 time/batch=0.44s
23488/10943 (epoch 193.168) train_loss=176.84439087 time/batch=0.47s
23489/10943 (epoch 193.176) train_loss=409.26718140 time/batch=0.95s
23490/10943 (epoch 193.184) train_loss=190.98318481 time/batch=0.59s
23491/10943 (epoch 193.192) train_loss=226.14364624 time/batch=0.61s
23492/10943 (epoch 193.201) train_loss=162.96276855 time/batch=0.46s
23493/10943 (epoch 193.209) train_loss=451.34844971 time/batch=1.15s
23494/10943 (epoch 193.217) train_loss=471.41320801 time/batch=1.24s
23495/10943 (epoch 193.225) train_loss=207.17005920 time/batch=0.62s
23496/10943 (epoch 193.234) train_loss=271.79196167 time/batch=0.70s
23497/10943 (epoch 193.242) train_loss=215.08724976 time/batch=0.60s
23498/10943 (epoch 193.250) train_loss=261.15234375 time/batch=0.70s
23499/10943 (epoch 193.258) train_loss=413.09417725 time/batch=1.02s
23500/10943 (epoch 193.267) train_loss=246.55267334 time/batch=0.69s
23501/10943 (epoch 193.275) train_loss=156.67243958 time/batch=0.47s
23502/10943 (epoch 193.283) train_loss=108.98950958 time/batch=0.32s
23503/10943 (epoch 193.291) train_loss=211.53894043 time/batch=0.56s
23504/10943 (epoch 193.299) train_loss=383.51928711 time/batch=0.96s
23505/10943 (epoch 193.308) train_loss=494.66894531 time/batch=1.71s
23506/10943 (epoch 193.316) train_loss=194.25073242 time/batch=0.64s
23507/10943 (epoch 193.324) train_loss=190.91601562 time/batch=0.51s
23508/10943 (epoch 193.332) train_loss=259.87573242 time/batch=0.71s
23509/10943 (epoch 193.341) train_loss=113.31671143 time/batch=0.35s
23510/10943 (epoch 193.349) train_loss=321.00009155 time/batch=0.80s
23511/10943 (epoch 193.357) train_loss=178.29891968 time/batch=0.52s
23512/10943 (epoch 193.365) train_loss=272.98309326 time/batch=0.72s
23513/10943 (epoch 193.373) train_loss=136.30599976 time/batch=0.43s
23514/10943 (epoch 193.382) train_loss=145.62545776 time/batch=0.39s
23515/10943 (epoch 193.390) train_loss=388.53466797 time/batch=1.09s
23516/10943 (epoch 193.398) train_loss=330.95471191 time/batch=0.92s
23517/10943 (epoch 193.406) train_loss=184.51429749 time/batch=0.53s
23518/10943 (epoch 193.415) train_loss=278.12152100 time/batch=0.74s
23519/10943 (epoch 193.423) train_loss=223.29359436 time/batch=0.62s
23520/10943 (epoch 193.431) train_loss=337.48083496 time/batch=0.89s
23521/10943 (epoch 193.439) train_loss=260.66937256 time/batch=0.74s
23522/10943 (epoch 193.447) train_loss=338.90200806 time/batch=0.91s
23523/10943 (epoch 193.456) train_loss=172.13259888 time/batch=0.49s
23524/10943 (epoch 193.464) train_loss=122.28775024 time/batch=0.33s
23525/10943 (epoch 193.472) train_loss=258.79257202 time/batch=0.70s
23526/10943 (epoch 193.480) train_loss=288.27178955 time/batch=0.78s
23527/10943 (epoch 193.489) train_loss=330.15631104 time/batch=0.93s
23528/10943 (epoch 193.497) train_loss=133.14630127 time/batch=0.42s
23529/10943 (epoch 193.505) train_loss=144.31866455 time/batch=0.41s
23530/10943 (epoch 193.513) train_loss=385.71490479 time/batch=0.98s
23531/10943 (epoch 193.521) train_loss=318.48428345 time/batch=0.87s
23532/10943 (epoch 193.530) train_loss=197.70234680 time/batch=0.58s
23533/10943 (epoch 193.538) train_loss=284.95648193 time/batch=0.77s
23534/10943 (epoch 193.546) train_loss=205.18772888 time/batch=0.58s
23535/10943 (epoch 193.554) train_loss=279.36041260 time/batch=0.75s
23536/10943 (epoch 193.563) train_loss=175.79493713 time/batch=0.53s
23537/10943 (epoch 193.571) train_loss=217.44754028 time/batch=0.58s
23538/10943 (epoch 193.579) train_loss=363.00390625 time/batch=0.96s
23539/10943 (epoch 193.587) train_loss=224.93083191 time/batch=0.62s
23540/10943 (epoch 193.595) train_loss=291.63037109 time/batch=0.78s
23541/10943 (epoch 193.604) train_loss=253.33309937 time/batch=0.70s
23542/10943 (epoch 193.612) train_loss=345.55444336 time/batch=0.94s
23543/10943 (epoch 193.620) train_loss=178.74983215 time/batch=0.56s
23544/10943 (epoch 193.628) train_loss=191.30712891 time/batch=0.53s
23545/10943 (epoch 193.637) train_loss=241.76431274 time/batch=0.65s
23546/10943 (epoch 193.645) train_loss=285.97839355 time/batch=0.81s
23547/10943 (epoch 193.653) train_loss=243.93972778 time/batch=0.68s
23548/10943 (epoch 193.661) train_loss=239.79112244 time/batch=0.64s
23549/10943 (epoch 193.669) train_loss=255.44052124 time/batch=0.74s
23550/10943 (epoch 193.678) train_loss=277.22009277 time/batch=0.75s
23551/10943 (epoch 193.686) train_loss=211.31173706 time/batch=0.63s
23552/10943 (epoch 193.694) train_loss=230.11599731 time/batch=0.63s
23553/10943 (epoch 193.702) train_loss=224.53378296 time/batch=0.63s
23554/10943 (epoch 193.711) train_loss=234.73435974 time/batch=0.66s
23555/10943 (epoch 193.719) train_loss=280.86688232 time/batch=0.80s
23556/10943 (epoch 193.727) train_loss=227.37246704 time/batch=0.64s
23557/10943 (epoch 193.735) train_loss=230.74609375 time/batch=0.61s
23558/10943 (epoch 193.744) train_loss=294.64376831 time/batch=0.81s
23559/10943 (epoch 193.752) train_loss=210.72061157 time/batch=0.60s
23560/10943 (epoch 193.760) train_loss=285.56231689 time/batch=0.76s
23561/10943 (epoch 193.768) train_loss=220.25698853 time/batch=0.69s
23562/10943 (epoch 193.776) train_loss=306.27670288 time/batch=0.81s
23563/10943 (epoch 193.785) train_loss=282.17272949 time/batch=0.83s
23564/10943 (epoch 193.793) train_loss=236.56588745 time/batch=0.71s
setting learning rate to 0.0004403
23565/10943 (epoch 193.801) train_loss=469.15628052 time/batch=1.21s
23566/10943 (epoch 193.809) train_loss=146.43144226 time/batch=0.44s
23567/10943 (epoch 193.818) train_loss=149.20278931 time/batch=0.40s
23568/10943 (epoch 193.826) train_loss=615.05682373 time/batch=1.57s
23569/10943 (epoch 193.834) train_loss=349.49630737 time/batch=1.04s
23570/10943 (epoch 193.842) train_loss=518.37170410 time/batch=1.32s
23571/10943 (epoch 193.850) train_loss=390.97192383 time/batch=1.02s
23572/10943 (epoch 193.859) train_loss=189.84103394 time/batch=0.51s
23573/10943 (epoch 193.867) train_loss=526.07897949 time/batch=1.33s
23574/10943 (epoch 193.875) train_loss=490.41619873 time/batch=1.42s
23575/10943 (epoch 193.883) train_loss=414.70596313 time/batch=1.09s
23576/10943 (epoch 193.892) train_loss=314.99475098 time/batch=0.87s
23577/10943 (epoch 193.900) train_loss=104.07880402 time/batch=0.33s
23578/10943 (epoch 193.908) train_loss=442.64471436 time/batch=1.32s
23579/10943 (epoch 193.916) train_loss=200.13916016 time/batch=0.63s
23580/10943 (epoch 193.924) train_loss=340.82354736 time/batch=0.87s
23581/10943 (epoch 193.933) train_loss=518.20935059 time/batch=1.45s
23582/10943 (epoch 193.941) train_loss=232.46894836 time/batch=0.71s
23583/10943 (epoch 193.949) train_loss=230.15484619 time/batch=0.61s
23584/10943 (epoch 193.957) train_loss=692.05969238 time/batch=1.85s
23585/10943 (epoch 193.966) train_loss=329.64175415 time/batch=1.00s
23586/10943 (epoch 193.974) train_loss=298.60256958 time/batch=0.84s
23587/10943 (epoch 193.982) train_loss=204.23797607 time/batch=0.57s
23588/10943 (epoch 193.990) train_loss=127.51386261 time/batch=0.35s
23589/10943 (epoch 193.998) train_loss=178.34811401 time/batch=0.47s
23590/10943 (epoch 194.007) train_loss=229.14852905 time/batch=0.62s
23591/10943 (epoch 194.015) train_loss=166.29254150 time/batch=0.45s
23592/10943 (epoch 194.023) train_loss=349.48892212 time/batch=0.85s
23593/10943 (epoch 194.031) train_loss=151.29975891 time/batch=0.48s
23594/10943 (epoch 194.040) train_loss=814.20910645 time/batch=3.06s
23595/10943 (epoch 194.048) train_loss=333.96948242 time/batch=1.14s
23596/10943 (epoch 194.056) train_loss=279.48571777 time/batch=0.74s
23597/10943 (epoch 194.064) train_loss=253.43399048 time/batch=0.70s
23598/10943 (epoch 194.072) train_loss=279.02804565 time/batch=0.71s
23599/10943 (epoch 194.081) train_loss=189.27574158 time/batch=0.55s
23600/10943 (epoch 194.089) train_loss=243.64958191 time/batch=0.67s
23601/10943 (epoch 194.097) train_loss=247.14068604 time/batch=0.66s
23602/10943 (epoch 194.105) train_loss=284.02026367 time/batch=0.77s
23603/10943 (epoch 194.114) train_loss=395.81768799 time/batch=1.03s
23604/10943 (epoch 194.122) train_loss=99.59956360 time/batch=0.35s
23605/10943 (epoch 194.130) train_loss=285.22290039 time/batch=0.76s
23606/10943 (epoch 194.138) train_loss=178.11149597 time/batch=0.51s
23607/10943 (epoch 194.146) train_loss=254.04887390 time/batch=0.67s
23608/10943 (epoch 194.155) train_loss=165.10571289 time/batch=0.48s
23609/10943 (epoch 194.163) train_loss=281.41815186 time/batch=0.75s
23610/10943 (epoch 194.171) train_loss=195.32014465 time/batch=0.54s
23611/10943 (epoch 194.179) train_loss=232.51150513 time/batch=0.62s
23612/10943 (epoch 194.188) train_loss=294.43365479 time/batch=0.77s
23613/10943 (epoch 194.196) train_loss=251.75233459 time/batch=0.69s
23614/10943 (epoch 194.204) train_loss=202.61102295 time/batch=0.56s
23615/10943 (epoch 194.212) train_loss=275.16271973 time/batch=0.72s
23616/10943 (epoch 194.221) train_loss=414.31402588 time/batch=1.05s
23617/10943 (epoch 194.229) train_loss=442.39529419 time/batch=1.12s
23618/10943 (epoch 194.237) train_loss=180.43725586 time/batch=0.54s
23619/10943 (epoch 194.245) train_loss=291.24707031 time/batch=0.78s
23620/10943 (epoch 194.253) train_loss=426.79968262 time/batch=1.13s
23621/10943 (epoch 194.262) train_loss=411.62670898 time/batch=1.03s
23622/10943 (epoch 194.270) train_loss=220.45880127 time/batch=0.65s
23623/10943 (epoch 194.278) train_loss=152.99392700 time/batch=0.43s
23624/10943 (epoch 194.286) train_loss=217.99404907 time/batch=0.58s
23625/10943 (epoch 194.295) train_loss=195.68478394 time/batch=0.51s
23626/10943 (epoch 194.303) train_loss=362.28765869 time/batch=0.94s
23627/10943 (epoch 194.311) train_loss=366.09588623 time/batch=1.01s
23628/10943 (epoch 194.319) train_loss=192.13043213 time/batch=0.61s
23629/10943 (epoch 194.327) train_loss=348.07012939 time/batch=0.92s
23630/10943 (epoch 194.336) train_loss=220.36982727 time/batch=0.66s
23631/10943 (epoch 194.344) train_loss=174.23428345 time/batch=0.49s
23632/10943 (epoch 194.352) train_loss=199.10221863 time/batch=0.55s
23633/10943 (epoch 194.360) train_loss=205.95318604 time/batch=0.57s
23634/10943 (epoch 194.369) train_loss=275.92407227 time/batch=0.74s
23635/10943 (epoch 194.377) train_loss=263.45959473 time/batch=0.73s
23636/10943 (epoch 194.385) train_loss=152.25611877 time/batch=0.46s
23637/10943 (epoch 194.393) train_loss=331.26470947 time/batch=0.83s
23638/10943 (epoch 194.401) train_loss=213.44827271 time/batch=0.61s
23639/10943 (epoch 194.410) train_loss=250.75860596 time/batch=0.66s
23640/10943 (epoch 194.418) train_loss=422.69430542 time/batch=1.09s
23641/10943 (epoch 194.426) train_loss=421.97546387 time/batch=1.17s
23642/10943 (epoch 194.434) train_loss=151.15286255 time/batch=0.47s
23643/10943 (epoch 194.443) train_loss=318.31756592 time/batch=0.87s
23644/10943 (epoch 194.451) train_loss=181.21823120 time/batch=0.56s
23645/10943 (epoch 194.459) train_loss=137.61752319 time/batch=0.37s
23646/10943 (epoch 194.467) train_loss=110.20361328 time/batch=0.32s
23647/10943 (epoch 194.475) train_loss=278.08367920 time/batch=0.76s
23648/10943 (epoch 194.484) train_loss=374.89129639 time/batch=1.00s
23649/10943 (epoch 194.492) train_loss=384.81066895 time/batch=1.07s
23650/10943 (epoch 194.500) train_loss=333.14889526 time/batch=0.95s
23651/10943 (epoch 194.508) train_loss=283.32092285 time/batch=0.76s
23652/10943 (epoch 194.517) train_loss=216.79031372 time/batch=0.60s
23653/10943 (epoch 194.525) train_loss=286.75747681 time/batch=0.78s
23654/10943 (epoch 194.533) train_loss=274.12646484 time/batch=0.76s
23655/10943 (epoch 194.541) train_loss=275.15252686 time/batch=0.78s
23656/10943 (epoch 194.549) train_loss=261.27563477 time/batch=0.75s
23657/10943 (epoch 194.558) train_loss=136.82736206 time/batch=0.41s
23658/10943 (epoch 194.566) train_loss=250.58792114 time/batch=0.66s
23659/10943 (epoch 194.574) train_loss=213.55105591 time/batch=0.63s
23660/10943 (epoch 194.582) train_loss=229.80110168 time/batch=0.64s
23661/10943 (epoch 194.591) train_loss=248.65829468 time/batch=0.71s
23662/10943 (epoch 194.599) train_loss=359.63018799 time/batch=1.14s
23663/10943 (epoch 194.607) train_loss=298.75451660 time/batch=0.87s
23664/10943 (epoch 194.615) train_loss=233.52012634 time/batch=0.62s
23665/10943 (epoch 194.623) train_loss=130.27619934 time/batch=0.38s
23666/10943 (epoch 194.632) train_loss=214.83142090 time/batch=0.59s
23667/10943 (epoch 194.640) train_loss=237.27954102 time/batch=0.64s
23668/10943 (epoch 194.648) train_loss=107.16636658 time/batch=0.32s
23669/10943 (epoch 194.656) train_loss=310.70739746 time/batch=0.80s
23670/10943 (epoch 194.665) train_loss=255.17236328 time/batch=0.70s
23671/10943 (epoch 194.673) train_loss=213.92428589 time/batch=0.60s
23672/10943 (epoch 194.681) train_loss=315.77542114 time/batch=0.82s
23673/10943 (epoch 194.689) train_loss=299.26437378 time/batch=0.83s
23674/10943 (epoch 194.698) train_loss=284.11553955 time/batch=0.81s
23675/10943 (epoch 194.706) train_loss=313.14334106 time/batch=0.84s
23676/10943 (epoch 194.714) train_loss=252.92810059 time/batch=0.73s
23677/10943 (epoch 194.722) train_loss=330.22448730 time/batch=1.15s
23678/10943 (epoch 194.730) train_loss=243.12052917 time/batch=0.72s
23679/10943 (epoch 194.739) train_loss=124.60525513 time/batch=0.35s
23680/10943 (epoch 194.747) train_loss=172.70944214 time/batch=0.48s
23681/10943 (epoch 194.755) train_loss=184.04951477 time/batch=0.50s
23682/10943 (epoch 194.763) train_loss=115.27491760 time/batch=0.38s
23683/10943 (epoch 194.772) train_loss=140.89004517 time/batch=0.50s
23684/10943 (epoch 194.780) train_loss=149.51289368 time/batch=0.53s
23685/10943 (epoch 194.788) train_loss=253.48271179 time/batch=0.72s
setting learning rate to 0.0004271
  saved to metadata/gru_no_dropout-9_nov_folkwiki-20181115-214759_epoch84.pkl
23686/10943 (epoch 194.796) train_loss=173.44662476 time/batch=0.57s
23687/10943 (epoch 194.804) train_loss=443.97094727 time/batch=1.13s
23688/10943 (epoch 194.813) train_loss=157.09230042 time/batch=0.50s
23689/10943 (epoch 194.821) train_loss=280.73104858 time/batch=0.73s
23690/10943 (epoch 194.829) train_loss=215.40139771 time/batch=0.62s
23691/10943 (epoch 194.837) train_loss=275.54647827 time/batch=0.73s
23692/10943 (epoch 194.846) train_loss=279.67620850 time/batch=0.75s
23693/10943 (epoch 194.854) train_loss=655.03259277 time/batch=1.67s
23694/10943 (epoch 194.862) train_loss=549.93157959 time/batch=1.47s
23695/10943 (epoch 194.870) train_loss=115.19143677 time/batch=0.39s
23696/10943 (epoch 194.878) train_loss=425.10977173 time/batch=0.97s
23697/10943 (epoch 194.887) train_loss=256.64807129 time/batch=0.70s
23698/10943 (epoch 194.895) train_loss=444.81506348 time/batch=1.09s
23699/10943 (epoch 194.903) train_loss=419.35614014 time/batch=1.11s
23700/10943 (epoch 194.911) train_loss=377.05639648 time/batch=1.01s
23701/10943 (epoch 194.920) train_loss=531.48193359 time/batch=1.41s
23702/10943 (epoch 194.928) train_loss=411.20208740 time/batch=1.17s
23703/10943 (epoch 194.936) train_loss=875.40979004 time/batch=3.14s
23704/10943 (epoch 194.944) train_loss=267.16275024 time/batch=0.96s
23705/10943 (epoch 194.952) train_loss=582.12744141 time/batch=1.66s
23706/10943 (epoch 194.961) train_loss=400.94308472 time/batch=1.16s
23707/10943 (epoch 194.969) train_loss=166.72003174 time/batch=0.50s
23708/10943 (epoch 194.977) train_loss=476.82843018 time/batch=1.20s
23709/10943 (epoch 194.985) train_loss=511.42614746 time/batch=1.72s
23710/10943 (epoch 194.994) train_loss=358.38146973 time/batch=1.09s
23711/10943 (epoch 195.002) train_loss=475.27886963 time/batch=1.22s
23712/10943 (epoch 195.010) train_loss=293.63964844 time/batch=0.82s
23713/10943 (epoch 195.018) train_loss=137.03814697 time/batch=0.42s
23714/10943 (epoch 195.026) train_loss=262.02148438 time/batch=0.68s
23715/10943 (epoch 195.035) train_loss=278.51062012 time/batch=0.80s
23716/10943 (epoch 195.043) train_loss=340.08111572 time/batch=0.90s
23717/10943 (epoch 195.051) train_loss=224.76007080 time/batch=0.61s
23718/10943 (epoch 195.059) train_loss=419.11694336 time/batch=1.15s
23719/10943 (epoch 195.068) train_loss=226.85356140 time/batch=0.69s
23720/10943 (epoch 195.076) train_loss=144.17288208 time/batch=0.40s
23721/10943 (epoch 195.084) train_loss=415.80291748 time/batch=1.14s
23722/10943 (epoch 195.092) train_loss=279.08767700 time/batch=0.81s
23723/10943 (epoch 195.100) train_loss=306.38461304 time/batch=0.83s
23724/10943 (epoch 195.109) train_loss=267.42614746 time/batch=0.77s
23725/10943 (epoch 195.117) train_loss=252.27697754 time/batch=0.72s
23726/10943 (epoch 195.125) train_loss=178.73095703 time/batch=0.50s
23727/10943 (epoch 195.133) train_loss=89.33274841 time/batch=0.30s
23728/10943 (epoch 195.142) train_loss=337.39321899 time/batch=0.84s
23729/10943 (epoch 195.150) train_loss=381.62176514 time/batch=1.02s
23730/10943 (epoch 195.158) train_loss=284.60864258 time/batch=0.83s
23731/10943 (epoch 195.166) train_loss=109.26768494 time/batch=0.35s
23732/10943 (epoch 195.175) train_loss=115.65868378 time/batch=0.30s
23733/10943 (epoch 195.183) train_loss=135.40077209 time/batch=0.36s
23734/10943 (epoch 195.191) train_loss=135.65280151 time/batch=0.35s
23735/10943 (epoch 195.199) train_loss=235.02267456 time/batch=0.61s
23736/10943 (epoch 195.207) train_loss=174.93997192 time/batch=0.48s
23737/10943 (epoch 195.216) train_loss=277.84008789 time/batch=0.68s
23738/10943 (epoch 195.224) train_loss=274.43045044 time/batch=0.72s
23739/10943 (epoch 195.232) train_loss=228.62265015 time/batch=0.63s
23740/10943 (epoch 195.240) train_loss=123.10569763 time/batch=0.34s
23741/10943 (epoch 195.249) train_loss=166.77853394 time/batch=0.47s
23742/10943 (epoch 195.257) train_loss=264.01184082 time/batch=0.72s
23743/10943 (epoch 195.265) train_loss=153.94921875 time/batch=0.44s
23744/10943 (epoch 195.273) train_loss=250.08676147 time/batch=0.64s
23745/10943 (epoch 195.281) train_loss=221.17337036 time/batch=0.63s
23746/10943 (epoch 195.290) train_loss=328.13787842 time/batch=0.86s
23747/10943 (epoch 195.298) train_loss=368.98028564 time/batch=0.96s
23748/10943 (epoch 195.306) train_loss=210.90542603 time/batch=0.59s
23749/10943 (epoch 195.314) train_loss=219.14529419 time/batch=0.62s
23750/10943 (epoch 195.323) train_loss=290.49392700 time/batch=0.80s
23751/10943 (epoch 195.331) train_loss=162.55120850 time/batch=0.48s
23752/10943 (epoch 195.339) train_loss=302.55606079 time/batch=0.83s
23753/10943 (epoch 195.347) train_loss=194.48229980 time/batch=0.56s
23754/10943 (epoch 195.355) train_loss=192.07449341 time/batch=0.51s
23755/10943 (epoch 195.364) train_loss=321.63555908 time/batch=0.81s
23756/10943 (epoch 195.372) train_loss=322.33386230 time/batch=0.86s
23757/10943 (epoch 195.380) train_loss=211.88175964 time/batch=0.62s
23758/10943 (epoch 195.388) train_loss=246.76486206 time/batch=0.66s
23759/10943 (epoch 195.397) train_loss=274.24835205 time/batch=0.75s
23760/10943 (epoch 195.405) train_loss=331.09375000 time/batch=0.90s
23761/10943 (epoch 195.413) train_loss=150.21386719 time/batch=0.47s
23762/10943 (epoch 195.421) train_loss=198.83424377 time/batch=0.53s
23763/10943 (epoch 195.429) train_loss=109.90936279 time/batch=0.33s
23764/10943 (epoch 195.438) train_loss=245.71255493 time/batch=0.67s
23765/10943 (epoch 195.446) train_loss=175.44429016 time/batch=0.51s
23766/10943 (epoch 195.454) train_loss=221.51675415 time/batch=0.61s
23767/10943 (epoch 195.462) train_loss=259.28704834 time/batch=0.75s
23768/10943 (epoch 195.471) train_loss=345.87710571 time/batch=0.92s
23769/10943 (epoch 195.479) train_loss=245.52398682 time/batch=0.68s
23770/10943 (epoch 195.487) train_loss=420.05621338 time/batch=1.19s
23771/10943 (epoch 195.495) train_loss=151.11389160 time/batch=0.52s
23772/10943 (epoch 195.503) train_loss=221.03785706 time/batch=0.58s
23773/10943 (epoch 195.512) train_loss=191.30371094 time/batch=0.52s
23774/10943 (epoch 195.520) train_loss=184.65234375 time/batch=0.52s
23775/10943 (epoch 195.528) train_loss=290.16461182 time/batch=0.77s
23776/10943 (epoch 195.536) train_loss=286.91711426 time/batch=0.82s
23777/10943 (epoch 195.545) train_loss=335.87271118 time/batch=0.93s
23778/10943 (epoch 195.553) train_loss=218.42216492 time/batch=0.63s
23779/10943 (epoch 195.561) train_loss=203.56858826 time/batch=0.57s
23780/10943 (epoch 195.569) train_loss=123.69496155 time/batch=0.36s
23781/10943 (epoch 195.577) train_loss=129.99325562 time/batch=0.34s
23782/10943 (epoch 195.586) train_loss=235.85906982 time/batch=0.62s
23783/10943 (epoch 195.594) train_loss=212.05865479 time/batch=0.60s
23784/10943 (epoch 195.602) train_loss=204.76788330 time/batch=0.57s
23785/10943 (epoch 195.610) train_loss=157.73452759 time/batch=0.50s
23786/10943 (epoch 195.619) train_loss=310.85675049 time/batch=0.89s
23787/10943 (epoch 195.627) train_loss=216.71249390 time/batch=0.64s
23788/10943 (epoch 195.635) train_loss=198.64617920 time/batch=0.55s
23789/10943 (epoch 195.643) train_loss=370.14239502 time/batch=0.93s
23790/10943 (epoch 195.652) train_loss=152.99459839 time/batch=0.54s
23791/10943 (epoch 195.660) train_loss=250.61145020 time/batch=0.66s
23792/10943 (epoch 195.668) train_loss=251.60144043 time/batch=0.68s
23793/10943 (epoch 195.676) train_loss=285.30078125 time/batch=0.81s
23794/10943 (epoch 195.684) train_loss=307.92376709 time/batch=0.85s
23795/10943 (epoch 195.693) train_loss=301.90957642 time/batch=0.79s
23796/10943 (epoch 195.701) train_loss=280.48779297 time/batch=0.80s
23797/10943 (epoch 195.709) train_loss=323.32879639 time/batch=0.93s
23798/10943 (epoch 195.717) train_loss=250.66824341 time/batch=0.72s
23799/10943 (epoch 195.726) train_loss=370.48687744 time/batch=0.98s
23800/10943 (epoch 195.734) train_loss=283.74157715 time/batch=0.86s
23801/10943 (epoch 195.742) train_loss=269.26721191 time/batch=0.84s
23802/10943 (epoch 195.750) train_loss=326.42114258 time/batch=0.94s
23803/10943 (epoch 195.758) train_loss=190.07127380 time/batch=0.55s
23804/10943 (epoch 195.767) train_loss=186.71862793 time/batch=0.52s
23805/10943 (epoch 195.775) train_loss=229.56988525 time/batch=0.66s
23806/10943 (epoch 195.783) train_loss=182.96243286 time/batch=0.58s
setting learning rate to 0.0004143
23807/10943 (epoch 195.791) train_loss=285.71301270 time/batch=0.80s
23808/10943 (epoch 195.800) train_loss=286.71890259 time/batch=0.82s
23809/10943 (epoch 195.808) train_loss=339.04199219 time/batch=0.94s
23810/10943 (epoch 195.816) train_loss=310.66452026 time/batch=0.89s
23811/10943 (epoch 195.824) train_loss=419.43988037 time/batch=1.04s
23812/10943 (epoch 195.832) train_loss=833.46990967 time/batch=2.42s
23813/10943 (epoch 195.841) train_loss=187.95230103 time/batch=0.71s
23814/10943 (epoch 195.849) train_loss=220.28353882 time/batch=0.58s
23815/10943 (epoch 195.857) train_loss=372.24981689 time/batch=0.95s
23816/10943 (epoch 195.865) train_loss=275.37683105 time/batch=0.78s
23817/10943 (epoch 195.874) train_loss=220.25000000 time/batch=0.65s
23818/10943 (epoch 195.882) train_loss=242.63647461 time/batch=0.70s
23819/10943 (epoch 195.890) train_loss=401.88543701 time/batch=1.02s
23820/10943 (epoch 195.898) train_loss=363.04162598 time/batch=1.07s
23821/10943 (epoch 195.906) train_loss=342.83062744 time/batch=0.93s
23822/10943 (epoch 195.915) train_loss=322.14910889 time/batch=0.90s
23823/10943 (epoch 195.923) train_loss=526.91119385 time/batch=1.35s
23824/10943 (epoch 195.931) train_loss=414.41467285 time/batch=1.15s
23825/10943 (epoch 195.939) train_loss=493.47177124 time/batch=1.30s
23826/10943 (epoch 195.948) train_loss=238.43859863 time/batch=0.73s
23827/10943 (epoch 195.956) train_loss=88.00865936 time/batch=0.28s
23828/10943 (epoch 195.964) train_loss=422.59167480 time/batch=1.08s
23829/10943 (epoch 195.972) train_loss=304.16809082 time/batch=0.88s
23830/10943 (epoch 195.980) train_loss=362.66674805 time/batch=1.00s
23831/10943 (epoch 195.989) train_loss=223.21343994 time/batch=0.64s
23832/10943 (epoch 195.997) train_loss=553.17553711 time/batch=1.48s
23833/10943 (epoch 196.005) train_loss=298.99722290 time/batch=0.88s
23834/10943 (epoch 196.013) train_loss=244.29682922 time/batch=0.71s
23835/10943 (epoch 196.022) train_loss=212.64041138 time/batch=0.60s
23836/10943 (epoch 196.030) train_loss=293.07833862 time/batch=0.80s
23837/10943 (epoch 196.038) train_loss=464.77883911 time/batch=1.19s
23838/10943 (epoch 196.046) train_loss=175.44558716 time/batch=0.54s
23839/10943 (epoch 196.054) train_loss=115.73239899 time/batch=0.31s
23840/10943 (epoch 196.063) train_loss=126.95741272 time/batch=0.33s
23841/10943 (epoch 196.071) train_loss=147.46609497 time/batch=0.41s
23842/10943 (epoch 196.079) train_loss=196.56311035 time/batch=0.52s
23843/10943 (epoch 196.087) train_loss=316.29156494 time/batch=0.84s
23844/10943 (epoch 196.096) train_loss=141.85806274 time/batch=0.41s
23845/10943 (epoch 196.104) train_loss=200.73519897 time/batch=0.52s
23846/10943 (epoch 196.112) train_loss=123.40969849 time/batch=0.36s
23847/10943 (epoch 196.120) train_loss=143.46261597 time/batch=0.37s
23848/10943 (epoch 196.129) train_loss=400.39428711 time/batch=0.96s
23849/10943 (epoch 196.137) train_loss=258.85986328 time/batch=0.74s
23850/10943 (epoch 196.145) train_loss=436.21673584 time/batch=1.14s
23851/10943 (epoch 196.153) train_loss=362.17169189 time/batch=0.99s
23852/10943 (epoch 196.161) train_loss=378.88769531 time/batch=1.07s
23853/10943 (epoch 196.170) train_loss=367.64511108 time/batch=1.00s
23854/10943 (epoch 196.178) train_loss=277.74496460 time/batch=0.78s
23855/10943 (epoch 196.186) train_loss=167.44172668 time/batch=0.50s
23856/10943 (epoch 196.194) train_loss=153.01615906 time/batch=0.44s
23857/10943 (epoch 196.203) train_loss=103.16559601 time/batch=0.29s
23858/10943 (epoch 196.211) train_loss=207.24452209 time/batch=0.55s
23859/10943 (epoch 196.219) train_loss=242.66058350 time/batch=0.68s
23860/10943 (epoch 196.227) train_loss=505.28033447 time/batch=1.37s
23861/10943 (epoch 196.235) train_loss=157.34353638 time/batch=0.52s
23862/10943 (epoch 196.244) train_loss=250.80218506 time/batch=0.65s
23863/10943 (epoch 196.252) train_loss=731.74877930 time/batch=3.09s
23864/10943 (epoch 196.260) train_loss=196.29553223 time/batch=0.83s
23865/10943 (epoch 196.268) train_loss=290.22402954 time/batch=0.75s
23866/10943 (epoch 196.277) train_loss=166.70257568 time/batch=0.50s
23867/10943 (epoch 196.285) train_loss=343.77206421 time/batch=0.87s
23868/10943 (epoch 196.293) train_loss=141.63949585 time/batch=0.40s
23869/10943 (epoch 196.301) train_loss=293.02127075 time/batch=0.76s
23870/10943 (epoch 196.309) train_loss=488.53131104 time/batch=1.39s
23871/10943 (epoch 196.318) train_loss=134.50585938 time/batch=0.47s
23872/10943 (epoch 196.326) train_loss=492.57598877 time/batch=1.51s
23873/10943 (epoch 196.334) train_loss=452.20703125 time/batch=1.19s
23874/10943 (epoch 196.342) train_loss=228.06011963 time/batch=0.66s
23875/10943 (epoch 196.351) train_loss=251.71791077 time/batch=0.67s
23876/10943 (epoch 196.359) train_loss=213.45178223 time/batch=0.61s
23877/10943 (epoch 196.367) train_loss=231.48867798 time/batch=0.63s
23878/10943 (epoch 196.375) train_loss=137.50372314 time/batch=0.41s
23879/10943 (epoch 196.383) train_loss=192.72100830 time/batch=0.53s
23880/10943 (epoch 196.392) train_loss=412.61578369 time/batch=1.07s
23881/10943 (epoch 196.400) train_loss=211.84597778 time/batch=0.63s
23882/10943 (epoch 196.408) train_loss=181.08093262 time/batch=0.49s
23883/10943 (epoch 196.416) train_loss=327.30914307 time/batch=0.87s
23884/10943 (epoch 196.425) train_loss=259.17089844 time/batch=0.68s
23885/10943 (epoch 196.433) train_loss=185.85472107 time/batch=0.53s
23886/10943 (epoch 196.441) train_loss=270.87414551 time/batch=0.70s
23887/10943 (epoch 196.449) train_loss=272.20098877 time/batch=0.75s
23888/10943 (epoch 196.457) train_loss=112.93716431 time/batch=0.35s
23889/10943 (epoch 196.466) train_loss=253.55264282 time/batch=0.66s
23890/10943 (epoch 196.474) train_loss=139.13647461 time/batch=0.42s
23891/10943 (epoch 196.482) train_loss=268.23004150 time/batch=0.72s
23892/10943 (epoch 196.490) train_loss=355.15045166 time/batch=1.04s
23893/10943 (epoch 196.499) train_loss=330.15783691 time/batch=0.94s
23894/10943 (epoch 196.507) train_loss=282.86975098 time/batch=0.79s
23895/10943 (epoch 196.515) train_loss=210.40476990 time/batch=0.61s
23896/10943 (epoch 196.523) train_loss=280.20019531 time/batch=0.77s
23897/10943 (epoch 196.531) train_loss=197.73928833 time/batch=0.56s
23898/10943 (epoch 196.540) train_loss=110.15075684 time/batch=0.33s
23899/10943 (epoch 196.548) train_loss=277.34417725 time/batch=0.68s
23900/10943 (epoch 196.556) train_loss=287.98358154 time/batch=0.77s
23901/10943 (epoch 196.564) train_loss=226.05610657 time/batch=0.64s
23902/10943 (epoch 196.573) train_loss=219.42547607 time/batch=0.59s
23903/10943 (epoch 196.581) train_loss=252.99176025 time/batch=0.66s
23904/10943 (epoch 196.589) train_loss=182.31759644 time/batch=0.51s
23905/10943 (epoch 196.597) train_loss=279.54406738 time/batch=0.78s
23906/10943 (epoch 196.605) train_loss=178.58740234 time/batch=0.53s
23907/10943 (epoch 196.614) train_loss=178.92825317 time/batch=0.49s
23908/10943 (epoch 196.622) train_loss=247.96768188 time/batch=0.65s
23909/10943 (epoch 196.630) train_loss=269.52282715 time/batch=0.72s
23910/10943 (epoch 196.638) train_loss=163.39065552 time/batch=0.45s
23911/10943 (epoch 196.647) train_loss=281.13998413 time/batch=0.76s
23912/10943 (epoch 196.655) train_loss=192.61968994 time/batch=0.53s
23913/10943 (epoch 196.663) train_loss=237.25079346 time/batch=0.63s
23914/10943 (epoch 196.671) train_loss=281.18518066 time/batch=0.82s
23915/10943 (epoch 196.680) train_loss=313.58062744 time/batch=0.88s
23916/10943 (epoch 196.688) train_loss=227.40928650 time/batch=0.64s
23917/10943 (epoch 196.696) train_loss=266.41119385 time/batch=0.72s
23918/10943 (epoch 196.704) train_loss=211.33636475 time/batch=0.62s
23919/10943 (epoch 196.712) train_loss=210.64346313 time/batch=0.59s
23920/10943 (epoch 196.721) train_loss=319.15853882 time/batch=0.83s
23921/10943 (epoch 196.729) train_loss=136.61956787 time/batch=0.46s
23922/10943 (epoch 196.737) train_loss=321.17150879 time/batch=0.80s
23923/10943 (epoch 196.745) train_loss=183.83380127 time/batch=0.55s
23924/10943 (epoch 196.754) train_loss=282.18023682 time/batch=0.77s
23925/10943 (epoch 196.762) train_loss=194.69766235 time/batch=0.64s
23926/10943 (epoch 196.770) train_loss=222.53665161 time/batch=0.65s
23927/10943 (epoch 196.778) train_loss=251.07667542 time/batch=0.71s
setting learning rate to 0.0004018
23928/10943 (epoch 196.786) train_loss=356.63049316 time/batch=0.97s
23929/10943 (epoch 196.795) train_loss=218.68544006 time/batch=0.65s
23930/10943 (epoch 196.803) train_loss=251.98393250 time/batch=0.66s
23931/10943 (epoch 196.811) train_loss=474.06298828 time/batch=1.19s
23932/10943 (epoch 196.819) train_loss=444.32919312 time/batch=1.14s
23933/10943 (epoch 196.828) train_loss=405.69299316 time/batch=1.14s
23934/10943 (epoch 196.836) train_loss=246.78259277 time/batch=0.70s
23935/10943 (epoch 196.844) train_loss=406.24401855 time/batch=1.06s
23936/10943 (epoch 196.852) train_loss=177.39648438 time/batch=0.53s
23937/10943 (epoch 196.860) train_loss=148.95248413 time/batch=0.41s
23938/10943 (epoch 196.869) train_loss=445.41714478 time/batch=1.14s
23939/10943 (epoch 196.877) train_loss=517.19122314 time/batch=1.40s
23940/10943 (epoch 196.885) train_loss=138.83926392 time/batch=0.47s
23941/10943 (epoch 196.893) train_loss=549.43249512 time/batch=1.44s
23942/10943 (epoch 196.902) train_loss=379.99719238 time/batch=1.07s
23943/10943 (epoch 196.910) train_loss=141.92602539 time/batch=0.43s
23944/10943 (epoch 196.918) train_loss=274.02426147 time/batch=0.71s
23945/10943 (epoch 196.926) train_loss=605.46441650 time/batch=1.59s
23946/10943 (epoch 196.934) train_loss=223.69293213 time/batch=0.73s
23947/10943 (epoch 196.943) train_loss=383.41928101 time/batch=0.98s
23948/10943 (epoch 196.951) train_loss=119.86772156 time/batch=0.38s
23949/10943 (epoch 196.959) train_loss=865.40197754 time/batch=3.02s
23950/10943 (epoch 196.967) train_loss=109.15586853 time/batch=0.58s
23951/10943 (epoch 196.976) train_loss=480.74511719 time/batch=1.19s
23952/10943 (epoch 196.984) train_loss=618.99951172 time/batch=1.73s
23953/10943 (epoch 196.992) train_loss=333.12402344 time/batch=0.99s
23954/10943 (epoch 197.000) train_loss=283.53186035 time/batch=0.82s
23955/10943 (epoch 197.008) train_loss=176.35598755 time/batch=0.51s
23956/10943 (epoch 197.017) train_loss=224.93241882 time/batch=0.57s
23957/10943 (epoch 197.025) train_loss=274.56616211 time/batch=0.73s
23958/10943 (epoch 197.033) train_loss=252.50054932 time/batch=0.68s
23959/10943 (epoch 197.041) train_loss=375.03390503 time/batch=1.00s
23960/10943 (epoch 197.050) train_loss=276.91424561 time/batch=0.76s
23961/10943 (epoch 197.058) train_loss=142.79866028 time/batch=0.41s
23962/10943 (epoch 197.066) train_loss=287.37832642 time/batch=0.75s
23963/10943 (epoch 197.074) train_loss=317.24957275 time/batch=0.86s
23964/10943 (epoch 197.082) train_loss=183.73123169 time/batch=0.55s
23965/10943 (epoch 197.091) train_loss=342.66906738 time/batch=0.86s
23966/10943 (epoch 197.099) train_loss=510.96972656 time/batch=1.31s
23967/10943 (epoch 197.107) train_loss=207.81539917 time/batch=0.66s
23968/10943 (epoch 197.115) train_loss=427.97421265 time/batch=1.26s
23969/10943 (epoch 197.124) train_loss=391.85269165 time/batch=1.13s
23970/10943 (epoch 197.132) train_loss=271.75717163 time/batch=0.79s
23971/10943 (epoch 197.140) train_loss=265.53384399 time/batch=0.75s
23972/10943 (epoch 197.148) train_loss=419.67745972 time/batch=1.12s
23973/10943 (epoch 197.157) train_loss=284.13192749 time/batch=0.84s
23974/10943 (epoch 197.165) train_loss=159.44750977 time/batch=0.48s
23975/10943 (epoch 197.173) train_loss=183.83041382 time/batch=0.52s
23976/10943 (epoch 197.181) train_loss=332.48394775 time/batch=0.88s
23977/10943 (epoch 197.189) train_loss=190.73089600 time/batch=0.55s
23978/10943 (epoch 197.198) train_loss=143.72865295 time/batch=0.40s
23979/10943 (epoch 197.206) train_loss=354.74127197 time/batch=0.92s
23980/10943 (epoch 197.214) train_loss=276.91766357 time/batch=0.79s
23981/10943 (epoch 197.222) train_loss=213.07095337 time/batch=0.64s
23982/10943 (epoch 197.231) train_loss=342.87078857 time/batch=0.93s
23983/10943 (epoch 197.239) train_loss=267.39471436 time/batch=0.75s
23984/10943 (epoch 197.247) train_loss=147.83068848 time/batch=0.45s
23985/10943 (epoch 197.255) train_loss=224.05703735 time/batch=0.61s
23986/10943 (epoch 197.263) train_loss=330.71426392 time/batch=0.91s
23987/10943 (epoch 197.272) train_loss=242.69027710 time/batch=0.70s
23988/10943 (epoch 197.280) train_loss=246.96499634 time/batch=0.67s
23989/10943 (epoch 197.288) train_loss=218.68928528 time/batch=0.62s
23990/10943 (epoch 197.296) train_loss=202.55233765 time/batch=0.55s
23991/10943 (epoch 197.305) train_loss=105.44397736 time/batch=0.33s
23992/10943 (epoch 197.313) train_loss=263.70581055 time/batch=0.68s
23993/10943 (epoch 197.321) train_loss=369.47048950 time/batch=1.00s
23994/10943 (epoch 197.329) train_loss=167.61190796 time/batch=0.52s
23995/10943 (epoch 197.337) train_loss=235.93692017 time/batch=0.62s
23996/10943 (epoch 197.346) train_loss=386.56610107 time/batch=1.00s
23997/10943 (epoch 197.354) train_loss=269.13006592 time/batch=0.76s
23998/10943 (epoch 197.362) train_loss=245.64089966 time/batch=0.68s
23999/10943 (epoch 197.370) train_loss=190.11035156 time/batch=0.53s
Validating
    loss:	292.487829

24000/10943 (epoch 197.379) train_loss=333.80453491 time/batch=2.90s
24001/10943 (epoch 197.387) train_loss=256.07321167 time/batch=0.74s
24002/10943 (epoch 197.395) train_loss=228.80383301 time/batch=0.64s
24003/10943 (epoch 197.403) train_loss=276.09457397 time/batch=0.77s
24004/10943 (epoch 197.411) train_loss=122.99025726 time/batch=0.37s
24005/10943 (epoch 197.420) train_loss=123.97399902 time/batch=0.34s
24006/10943 (epoch 197.428) train_loss=139.87210083 time/batch=0.37s
24007/10943 (epoch 197.436) train_loss=285.90414429 time/batch=0.74s
24008/10943 (epoch 197.444) train_loss=140.61622620 time/batch=0.43s
24009/10943 (epoch 197.453) train_loss=305.88400269 time/batch=0.81s
24010/10943 (epoch 197.461) train_loss=189.80793762 time/batch=0.58s
24011/10943 (epoch 197.469) train_loss=129.80604553 time/batch=0.35s
24012/10943 (epoch 197.477) train_loss=278.34454346 time/batch=0.73s
24013/10943 (epoch 197.485) train_loss=95.09516144 time/batch=0.36s
24014/10943 (epoch 197.494) train_loss=308.55773926 time/batch=0.79s
24015/10943 (epoch 197.502) train_loss=284.66961670 time/batch=0.84s
24016/10943 (epoch 197.510) train_loss=297.01361084 time/batch=0.81s
24017/10943 (epoch 197.518) train_loss=389.59375000 time/batch=1.03s
24018/10943 (epoch 197.527) train_loss=180.98562622 time/batch=0.54s
24019/10943 (epoch 197.535) train_loss=215.12121582 time/batch=0.59s
24020/10943 (epoch 197.543) train_loss=119.43209839 time/batch=0.41s
24021/10943 (epoch 197.551) train_loss=211.25816345 time/batch=0.57s
24022/10943 (epoch 197.559) train_loss=195.52447510 time/batch=0.56s
24023/10943 (epoch 197.568) train_loss=201.52670288 time/batch=0.57s
24024/10943 (epoch 197.576) train_loss=154.61213684 time/batch=0.44s
24025/10943 (epoch 197.584) train_loss=314.41741943 time/batch=0.80s
24026/10943 (epoch 197.592) train_loss=138.39190674 time/batch=0.47s
24027/10943 (epoch 197.601) train_loss=283.76440430 time/batch=0.79s
24028/10943 (epoch 197.609) train_loss=277.97314453 time/batch=0.81s
24029/10943 (epoch 197.617) train_loss=196.73788452 time/batch=0.57s
24030/10943 (epoch 197.625) train_loss=302.31735229 time/batch=0.83s
24031/10943 (epoch 197.634) train_loss=181.98568726 time/batch=0.53s
24032/10943 (epoch 197.642) train_loss=247.91128540 time/batch=0.67s
24033/10943 (epoch 197.650) train_loss=209.57968140 time/batch=0.59s
24034/10943 (epoch 197.658) train_loss=297.46612549 time/batch=0.83s
24035/10943 (epoch 197.666) train_loss=188.68576050 time/batch=0.56s
24036/10943 (epoch 197.675) train_loss=317.78390503 time/batch=0.84s
24037/10943 (epoch 197.683) train_loss=167.95703125 time/batch=0.53s
24038/10943 (epoch 197.691) train_loss=240.11004639 time/batch=0.66s
24039/10943 (epoch 197.699) train_loss=250.37222290 time/batch=0.69s
24040/10943 (epoch 197.708) train_loss=234.87051392 time/batch=0.68s
24041/10943 (epoch 197.716) train_loss=300.95690918 time/batch=0.83s
24042/10943 (epoch 197.724) train_loss=243.66494751 time/batch=0.82s
24043/10943 (epoch 197.732) train_loss=186.79147339 time/batch=0.59s
24044/10943 (epoch 197.740) train_loss=240.74975586 time/batch=0.67s
24045/10943 (epoch 197.749) train_loss=212.29049683 time/batch=0.62s
24046/10943 (epoch 197.757) train_loss=287.06661987 time/batch=0.85s
24047/10943 (epoch 197.765) train_loss=227.58662415 time/batch=0.65s
24048/10943 (epoch 197.773) train_loss=208.94726562 time/batch=0.61s
setting learning rate to 0.0003898
24049/10943 (epoch 197.782) train_loss=143.53321838 time/batch=0.40s
24050/10943 (epoch 197.790) train_loss=386.45016479 time/batch=1.00s
24051/10943 (epoch 197.798) train_loss=302.19348145 time/batch=0.89s
24052/10943 (epoch 197.806) train_loss=103.18872833 time/batch=0.34s
24053/10943 (epoch 197.814) train_loss=356.37445068 time/batch=0.90s
24054/10943 (epoch 197.823) train_loss=523.14843750 time/batch=1.34s
24055/10943 (epoch 197.831) train_loss=221.33657837 time/batch=0.68s
24056/10943 (epoch 197.839) train_loss=242.52743530 time/batch=0.67s
24057/10943 (epoch 197.847) train_loss=407.45874023 time/batch=1.08s
24058/10943 (epoch 197.856) train_loss=206.43695068 time/batch=0.62s
24059/10943 (epoch 197.864) train_loss=185.20391846 time/batch=0.50s
24060/10943 (epoch 197.872) train_loss=272.47012329 time/batch=0.74s
24061/10943 (epoch 197.880) train_loss=859.24743652 time/batch=3.10s
24062/10943 (epoch 197.888) train_loss=446.90142822 time/batch=1.36s
24063/10943 (epoch 197.897) train_loss=254.85032654 time/batch=0.75s
24064/10943 (epoch 197.905) train_loss=273.42077637 time/batch=0.74s
24065/10943 (epoch 197.913) train_loss=150.93347168 time/batch=0.44s
24066/10943 (epoch 197.921) train_loss=99.34115601 time/batch=0.30s
24067/10943 (epoch 197.930) train_loss=238.63552856 time/batch=0.62s
24068/10943 (epoch 197.938) train_loss=655.24291992 time/batch=1.67s
24069/10943 (epoch 197.946) train_loss=106.74649048 time/batch=0.45s
24070/10943 (epoch 197.954) train_loss=484.33035278 time/batch=1.21s
24071/10943 (epoch 197.962) train_loss=201.09967041 time/batch=0.63s
24072/10943 (epoch 197.971) train_loss=267.24291992 time/batch=0.72s
24073/10943 (epoch 197.979) train_loss=423.67767334 time/batch=1.14s
24074/10943 (epoch 197.987) train_loss=294.86676025 time/batch=0.82s
24075/10943 (epoch 197.995) train_loss=219.54112244 time/batch=0.64s
24076/10943 (epoch 198.004) train_loss=139.83981323 time/batch=0.41s
24077/10943 (epoch 198.012) train_loss=573.11932373 time/batch=1.51s
24078/10943 (epoch 198.020) train_loss=490.12744141 time/batch=1.42s
24079/10943 (epoch 198.028) train_loss=413.82589722 time/batch=1.18s
24080/10943 (epoch 198.036) train_loss=155.97630310 time/batch=0.51s
24081/10943 (epoch 198.045) train_loss=268.30026245 time/batch=0.73s
24082/10943 (epoch 198.053) train_loss=171.55639648 time/batch=0.49s
24083/10943 (epoch 198.061) train_loss=459.82797241 time/batch=1.17s
24084/10943 (epoch 198.069) train_loss=450.18713379 time/batch=1.40s
24085/10943 (epoch 198.078) train_loss=280.06069946 time/batch=0.88s
24086/10943 (epoch 198.086) train_loss=355.71282959 time/batch=0.98s
24087/10943 (epoch 198.094) train_loss=174.20645142 time/batch=0.53s
24088/10943 (epoch 198.102) train_loss=188.63528442 time/batch=0.50s
24089/10943 (epoch 198.111) train_loss=118.65133667 time/batch=0.34s
24090/10943 (epoch 198.119) train_loss=316.50772095 time/batch=0.83s
24091/10943 (epoch 198.127) train_loss=360.33624268 time/batch=0.98s
24092/10943 (epoch 198.135) train_loss=182.39978027 time/batch=0.59s
24093/10943 (epoch 198.143) train_loss=275.06024170 time/batch=0.77s
24094/10943 (epoch 198.152) train_loss=378.36291504 time/batch=0.99s
24095/10943 (epoch 198.160) train_loss=315.85391235 time/batch=0.91s
24096/10943 (epoch 198.168) train_loss=504.18780518 time/batch=1.44s
24097/10943 (epoch 198.176) train_loss=141.06044006 time/batch=0.46s
24098/10943 (epoch 198.185) train_loss=212.95034790 time/batch=0.57s
24099/10943 (epoch 198.193) train_loss=263.16235352 time/batch=0.72s
24100/10943 (epoch 198.201) train_loss=403.68969727 time/batch=1.09s
24101/10943 (epoch 198.209) train_loss=163.05151367 time/batch=0.52s
24102/10943 (epoch 198.217) train_loss=275.34869385 time/batch=0.71s
24103/10943 (epoch 198.226) train_loss=303.25091553 time/batch=0.83s
24104/10943 (epoch 198.234) train_loss=176.46408081 time/batch=0.54s
24105/10943 (epoch 198.242) train_loss=295.69696045 time/batch=0.82s
24106/10943 (epoch 198.250) train_loss=248.91390991 time/batch=0.72s
24107/10943 (epoch 198.259) train_loss=389.52297974 time/batch=0.99s
24108/10943 (epoch 198.267) train_loss=213.77349854 time/batch=0.62s
24109/10943 (epoch 198.275) train_loss=346.67053223 time/batch=0.88s
24110/10943 (epoch 198.283) train_loss=291.83056641 time/batch=0.82s
24111/10943 (epoch 198.291) train_loss=342.79980469 time/batch=0.95s
24112/10943 (epoch 198.300) train_loss=416.01553345 time/batch=1.14s
24113/10943 (epoch 198.308) train_loss=154.09094238 time/batch=0.49s
24114/10943 (epoch 198.316) train_loss=187.27279663 time/batch=0.50s
24115/10943 (epoch 198.324) train_loss=277.37194824 time/batch=0.78s
24116/10943 (epoch 198.333) train_loss=109.15115356 time/batch=0.35s
24117/10943 (epoch 198.341) train_loss=230.49868774 time/batch=0.61s
24118/10943 (epoch 198.349) train_loss=143.72232056 time/batch=0.43s
24119/10943 (epoch 198.357) train_loss=244.73074341 time/batch=0.63s
24120/10943 (epoch 198.365) train_loss=342.40042114 time/batch=0.88s
24121/10943 (epoch 198.374) train_loss=243.93542480 time/batch=0.72s
24122/10943 (epoch 198.382) train_loss=274.28527832 time/batch=0.77s
24123/10943 (epoch 198.390) train_loss=174.52568054 time/batch=0.51s
24124/10943 (epoch 198.398) train_loss=267.73266602 time/batch=0.72s
24125/10943 (epoch 198.407) train_loss=211.40553284 time/batch=0.60s
24126/10943 (epoch 198.415) train_loss=360.27233887 time/batch=0.99s
24127/10943 (epoch 198.423) train_loss=134.41201782 time/batch=0.42s
24128/10943 (epoch 198.431) train_loss=335.89813232 time/batch=0.89s
24129/10943 (epoch 198.439) train_loss=211.47064209 time/batch=0.63s
24130/10943 (epoch 198.448) train_loss=267.22991943 time/batch=0.72s
24131/10943 (epoch 198.456) train_loss=239.83186340 time/batch=0.66s
24132/10943 (epoch 198.464) train_loss=197.02038574 time/batch=0.55s
24133/10943 (epoch 198.472) train_loss=312.27691650 time/batch=0.84s
24134/10943 (epoch 198.481) train_loss=178.30981445 time/batch=0.54s
24135/10943 (epoch 198.489) train_loss=363.19082642 time/batch=0.99s
24136/10943 (epoch 198.497) train_loss=247.10195923 time/batch=0.69s
24137/10943 (epoch 198.505) train_loss=314.95214844 time/batch=0.84s
24138/10943 (epoch 198.513) train_loss=245.55267334 time/batch=0.73s
24139/10943 (epoch 198.522) train_loss=193.09295654 time/batch=0.54s
24140/10943 (epoch 198.530) train_loss=128.36985779 time/batch=0.36s
24141/10943 (epoch 198.538) train_loss=220.63259888 time/batch=0.59s
24142/10943 (epoch 198.546) train_loss=286.13763428 time/batch=0.81s
24143/10943 (epoch 198.555) train_loss=279.46466064 time/batch=0.74s
24144/10943 (epoch 198.563) train_loss=216.00665283 time/batch=0.60s
24145/10943 (epoch 198.571) train_loss=160.33285522 time/batch=0.45s
24146/10943 (epoch 198.579) train_loss=181.65872192 time/batch=0.52s
24147/10943 (epoch 198.588) train_loss=161.68414307 time/batch=0.46s
24148/10943 (epoch 198.596) train_loss=223.40655518 time/batch=0.62s
24149/10943 (epoch 198.604) train_loss=218.33473206 time/batch=0.62s
24150/10943 (epoch 198.612) train_loss=254.14537048 time/batch=0.66s
24151/10943 (epoch 198.620) train_loss=228.09637451 time/batch=0.67s
24152/10943 (epoch 198.629) train_loss=128.95317078 time/batch=0.38s
24153/10943 (epoch 198.637) train_loss=321.90963745 time/batch=0.80s
24154/10943 (epoch 198.645) train_loss=230.15554810 time/batch=0.65s
24155/10943 (epoch 198.653) train_loss=141.62945557 time/batch=0.40s
24156/10943 (epoch 198.662) train_loss=327.35919189 time/batch=0.86s
24157/10943 (epoch 198.670) train_loss=201.16340637 time/batch=0.59s
24158/10943 (epoch 198.678) train_loss=261.58666992 time/batch=0.70s
24159/10943 (epoch 198.686) train_loss=286.12512207 time/batch=0.78s
24160/10943 (epoch 198.694) train_loss=284.41772461 time/batch=0.83s
24161/10943 (epoch 198.703) train_loss=223.72308350 time/batch=0.61s
24162/10943 (epoch 198.711) train_loss=278.06750488 time/batch=0.80s
24163/10943 (epoch 198.719) train_loss=253.71322632 time/batch=0.69s
24164/10943 (epoch 198.727) train_loss=207.00198364 time/batch=0.63s
24165/10943 (epoch 198.736) train_loss=211.82168579 time/batch=0.63s
24166/10943 (epoch 198.744) train_loss=292.06854248 time/batch=0.81s
24167/10943 (epoch 198.752) train_loss=253.73889160 time/batch=0.76s
24168/10943 (epoch 198.760) train_loss=119.71622467 time/batch=0.38s
24169/10943 (epoch 198.768) train_loss=169.81114197 time/batch=0.59s
setting learning rate to 0.0003781
24170/10943 (epoch 198.777) train_loss=99.53200531 time/batch=0.31s
24171/10943 (epoch 198.785) train_loss=358.49584961 time/batch=0.90s
24172/10943 (epoch 198.793) train_loss=323.85537720 time/batch=0.91s
24173/10943 (epoch 198.801) train_loss=216.44216919 time/batch=0.61s
24174/10943 (epoch 198.810) train_loss=432.70779419 time/batch=1.14s
24175/10943 (epoch 198.818) train_loss=97.83847046 time/batch=0.35s
24176/10943 (epoch 198.826) train_loss=142.71502686 time/batch=0.39s
24177/10943 (epoch 198.834) train_loss=865.22863770 time/batch=3.06s
24178/10943 (epoch 198.842) train_loss=431.62670898 time/batch=1.39s
24179/10943 (epoch 198.851) train_loss=154.57414246 time/batch=0.48s
24180/10943 (epoch 198.859) train_loss=173.59179688 time/batch=0.46s
24181/10943 (epoch 198.867) train_loss=283.56671143 time/batch=0.74s
24182/10943 (epoch 198.875) train_loss=496.25732422 time/batch=1.40s
24183/10943 (epoch 198.884) train_loss=340.35156250 time/batch=0.98s
24184/10943 (epoch 198.892) train_loss=520.10839844 time/batch=1.34s
24185/10943 (epoch 198.900) train_loss=281.85314941 time/batch=0.82s
24186/10943 (epoch 198.908) train_loss=402.03594971 time/batch=1.00s
24187/10943 (epoch 198.916) train_loss=213.08419800 time/batch=0.68s
24188/10943 (epoch 198.925) train_loss=345.01980591 time/batch=0.99s
24189/10943 (epoch 198.933) train_loss=279.97485352 time/batch=0.82s
24190/10943 (epoch 198.941) train_loss=459.89807129 time/batch=1.22s
24191/10943 (epoch 198.949) train_loss=433.12124634 time/batch=1.18s
24192/10943 (epoch 198.958) train_loss=220.86499023 time/batch=0.66s
24193/10943 (epoch 198.966) train_loss=564.83715820 time/batch=1.51s
24194/10943 (epoch 198.974) train_loss=442.94345093 time/batch=1.27s
24195/10943 (epoch 198.982) train_loss=283.04199219 time/batch=0.84s
24196/10943 (epoch 198.990) train_loss=291.94488525 time/batch=0.79s
24197/10943 (epoch 198.999) train_loss=184.77615356 time/batch=0.54s
24198/10943 (epoch 199.007) train_loss=634.59497070 time/batch=1.61s
24199/10943 (epoch 199.015) train_loss=184.20666504 time/batch=0.62s
24200/10943 (epoch 199.023) train_loss=452.49816895 time/batch=1.17s
24201/10943 (epoch 199.032) train_loss=268.40197754 time/batch=0.79s
24202/10943 (epoch 199.040) train_loss=133.06127930 time/batch=0.40s
24203/10943 (epoch 199.048) train_loss=127.54541016 time/batch=0.34s
24204/10943 (epoch 199.056) train_loss=321.40087891 time/batch=0.86s
24205/10943 (epoch 199.065) train_loss=241.77981567 time/batch=0.68s
24206/10943 (epoch 199.073) train_loss=417.72433472 time/batch=1.24s
24207/10943 (epoch 199.081) train_loss=223.28865051 time/batch=0.65s
24208/10943 (epoch 199.089) train_loss=172.65844727 time/batch=0.50s
24209/10943 (epoch 199.097) train_loss=389.25494385 time/batch=0.99s
24210/10943 (epoch 199.106) train_loss=185.13220215 time/batch=0.54s
24211/10943 (epoch 199.114) train_loss=209.73712158 time/batch=0.59s
24212/10943 (epoch 199.122) train_loss=376.42663574 time/batch=0.95s
24213/10943 (epoch 199.130) train_loss=117.22099304 time/batch=0.36s
24214/10943 (epoch 199.139) train_loss=421.41372681 time/batch=1.20s
24215/10943 (epoch 199.147) train_loss=107.52674103 time/batch=0.42s
24216/10943 (epoch 199.155) train_loss=150.75057983 time/batch=0.40s
24217/10943 (epoch 199.163) train_loss=246.01254272 time/batch=0.66s
24218/10943 (epoch 199.171) train_loss=248.22592163 time/batch=0.67s
24219/10943 (epoch 199.180) train_loss=418.74987793 time/batch=1.27s
24220/10943 (epoch 199.188) train_loss=135.15753174 time/batch=0.46s
24221/10943 (epoch 199.196) train_loss=189.93170166 time/batch=0.51s
24222/10943 (epoch 199.204) train_loss=245.93041992 time/batch=0.67s
24223/10943 (epoch 199.213) train_loss=246.07334900 time/batch=0.72s
24224/10943 (epoch 199.221) train_loss=187.29965210 time/batch=0.54s
24225/10943 (epoch 199.229) train_loss=203.96121216 time/batch=0.58s
24226/10943 (epoch 199.237) train_loss=278.88452148 time/batch=0.77s
24227/10943 (epoch 199.245) train_loss=328.08593750 time/batch=0.89s
24228/10943 (epoch 199.254) train_loss=142.56150818 time/batch=0.44s
24229/10943 (epoch 199.262) train_loss=279.12762451 time/batch=0.79s
24230/10943 (epoch 199.270) train_loss=398.48852539 time/batch=1.03s
24231/10943 (epoch 199.278) train_loss=251.91683960 time/batch=0.75s
24232/10943 (epoch 199.287) train_loss=240.44604492 time/batch=0.66s
24233/10943 (epoch 199.295) train_loss=116.42503357 time/batch=0.34s
24234/10943 (epoch 199.303) train_loss=300.85400391 time/batch=0.82s
24235/10943 (epoch 199.311) train_loss=126.47596741 time/batch=0.40s
24236/10943 (epoch 199.319) train_loss=298.45504761 time/batch=0.82s
24237/10943 (epoch 199.328) train_loss=156.69519043 time/batch=0.49s
24238/10943 (epoch 199.336) train_loss=328.53375244 time/batch=0.86s
24239/10943 (epoch 199.344) train_loss=494.05987549 time/batch=1.70s
24240/10943 (epoch 199.352) train_loss=273.25427246 time/batch=0.86s
24241/10943 (epoch 199.361) train_loss=226.15875244 time/batch=0.64s
24242/10943 (epoch 199.369) train_loss=229.37075806 time/batch=0.64s
24243/10943 (epoch 199.377) train_loss=138.79658508 time/batch=0.44s
24244/10943 (epoch 199.385) train_loss=360.96496582 time/batch=0.96s
24245/10943 (epoch 199.393) train_loss=272.16436768 time/batch=0.78s
24246/10943 (epoch 199.402) train_loss=146.89492798 time/batch=0.45s
24247/10943 (epoch 199.410) train_loss=300.81799316 time/batch=0.80s
24248/10943 (epoch 199.418) train_loss=223.57910156 time/batch=0.66s
24249/10943 (epoch 199.426) train_loss=328.94613647 time/batch=0.93s
24250/10943 (epoch 199.435) train_loss=346.96066284 time/batch=0.94s
24251/10943 (epoch 199.443) train_loss=232.45831299 time/batch=0.67s
24252/10943 (epoch 199.451) train_loss=212.85900879 time/batch=0.60s
24253/10943 (epoch 199.459) train_loss=256.82196045 time/batch=0.70s
24254/10943 (epoch 199.467) train_loss=279.88372803 time/batch=0.80s
24255/10943 (epoch 199.476) train_loss=223.30017090 time/batch=0.63s
24256/10943 (epoch 199.484) train_loss=205.33514404 time/batch=0.59s
24257/10943 (epoch 199.492) train_loss=149.28942871 time/batch=0.43s
24258/10943 (epoch 199.500) train_loss=274.49713135 time/batch=0.74s
24259/10943 (epoch 199.509) train_loss=338.92327881 time/batch=0.97s
24260/10943 (epoch 199.517) train_loss=268.42080688 time/batch=0.77s
24261/10943 (epoch 199.525) train_loss=310.40078735 time/batch=0.92s
24262/10943 (epoch 199.533) train_loss=157.95613098 time/batch=0.50s
24263/10943 (epoch 199.542) train_loss=200.36244202 time/batch=0.58s
24264/10943 (epoch 199.550) train_loss=241.81420898 time/batch=0.67s
24265/10943 (epoch 199.558) train_loss=199.73739624 time/batch=0.54s
24266/10943 (epoch 199.566) train_loss=192.96148682 time/batch=0.55s
24267/10943 (epoch 199.574) train_loss=160.50341797 time/batch=0.45s
24268/10943 (epoch 199.583) train_loss=229.38128662 time/batch=0.62s
24269/10943 (epoch 199.591) train_loss=142.35079956 time/batch=0.45s
24270/10943 (epoch 199.599) train_loss=198.93827820 time/batch=0.54s
24271/10943 (epoch 199.607) train_loss=194.84588623 time/batch=0.56s
24272/10943 (epoch 199.616) train_loss=221.96362305 time/batch=0.60s
24273/10943 (epoch 199.624) train_loss=138.34442139 time/batch=0.47s
24274/10943 (epoch 199.632) train_loss=275.98028564 time/batch=0.68s
24275/10943 (epoch 199.640) train_loss=275.89935303 time/batch=0.80s
24276/10943 (epoch 199.648) train_loss=318.96817017 time/batch=0.85s
24277/10943 (epoch 199.657) train_loss=296.96032715 time/batch=0.81s
24278/10943 (epoch 199.665) train_loss=178.56161499 time/batch=0.53s
24279/10943 (epoch 199.673) train_loss=265.45300293 time/batch=0.73s
24280/10943 (epoch 199.681) train_loss=235.21347046 time/batch=0.67s
24281/10943 (epoch 199.690) train_loss=241.88922119 time/batch=0.71s
24282/10943 (epoch 199.698) train_loss=185.46914673 time/batch=0.55s
24283/10943 (epoch 199.706) train_loss=263.84695435 time/batch=0.79s
24284/10943 (epoch 199.714) train_loss=287.81198120 time/batch=0.83s
24285/10943 (epoch 199.722) train_loss=186.62265015 time/batch=0.53s
24286/10943 (epoch 199.731) train_loss=205.08148193 time/batch=0.60s
24287/10943 (epoch 199.739) train_loss=263.30566406 time/batch=0.74s
24288/10943 (epoch 199.747) train_loss=310.08612061 time/batch=0.85s
24289/10943 (epoch 199.755) train_loss=258.23010254 time/batch=0.69s
24290/10943 (epoch 199.764) train_loss=275.48117065 time/batch=0.80s
setting learning rate to 0.0003668
  saved to metadata/gru_no_dropout-9_nov_folkwiki-20181115-214759_epoch89.pkl
