vocabulary size: 226
n tunes: 4083
n train tunes: 3891.0
n validation tunes: 192.0
min, max length 55 822
Building the model
  number of parameters: 10384102
  layer output shapes:               #params:   output shape:
    InputLayer                       0          (32, None)
    EmbeddingLayer                   51076      (32, None, 226)
    InputLayer                       0          (32, None)
    GRULayer                         2465600    (32, None, 800)
    DropoutLayer                     0          (32, None, 800)
    GRULayer                         3843200    (32, None, 800)
    DropoutLayer                     0          (32, None, 800)
    GRULayer                         3843200    (32, None, 800)
    DropoutLayer                     0          (32, None, 800)
    ReshapeLayer                     0          (None, 800)
    DenseLayer                       181026     (None, 226)
Train model
Load metadata for resuming
setting learning rate to 0.0012402
19451/10943 (epoch 159.967) train_loss=686.69018555 time/batch=1.23s
19452/10943 (epoch 159.975) train_loss=613.91003418 time/batch=0.82s
19453/10943 (epoch 159.984) train_loss=1377.27368164 time/batch=1.67s
19454/10943 (epoch 159.992) train_loss=935.05316162 time/batch=1.47s
19455/10943 (epoch 160.000) train_loss=236.45858765 time/batch=0.49s
19456/10943 (epoch 160.008) train_loss=357.39266968 time/batch=0.55s
19457/10943 (epoch 160.016) train_loss=510.78723145 time/batch=0.83s
19458/10943 (epoch 160.025) train_loss=145.30642700 time/batch=0.31s
19459/10943 (epoch 160.033) train_loss=558.08563232 time/batch=0.87s
19460/10943 (epoch 160.041) train_loss=1106.49072266 time/batch=1.95s
19461/10943 (epoch 160.049) train_loss=1321.13476562 time/batch=3.21s
19462/10943 (epoch 160.058) train_loss=484.99710083 time/batch=0.97s
19463/10943 (epoch 160.066) train_loss=420.05389404 time/batch=0.67s
19464/10943 (epoch 160.074) train_loss=331.30136108 time/batch=0.57s
19465/10943 (epoch 160.082) train_loss=468.74664307 time/batch=0.74s
19466/10943 (epoch 160.090) train_loss=647.81597900 time/batch=1.04s
19467/10943 (epoch 160.099) train_loss=563.34942627 time/batch=0.93s
19468/10943 (epoch 160.107) train_loss=259.34851074 time/batch=0.48s
19469/10943 (epoch 160.115) train_loss=205.38543701 time/batch=0.35s
19470/10943 (epoch 160.123) train_loss=278.59820557 time/batch=0.45s
19471/10943 (epoch 160.132) train_loss=454.64489746 time/batch=0.75s
19472/10943 (epoch 160.140) train_loss=598.29522705 time/batch=0.96s
19473/10943 (epoch 160.148) train_loss=238.87890625 time/batch=0.45s
19474/10943 (epoch 160.156) train_loss=656.27490234 time/batch=0.95s
19475/10943 (epoch 160.164) train_loss=333.38195801 time/batch=0.60s
19476/10943 (epoch 160.173) train_loss=280.16369629 time/batch=0.48s
19477/10943 (epoch 160.181) train_loss=597.28674316 time/batch=0.94s
19478/10943 (epoch 160.189) train_loss=576.58398438 time/batch=0.94s
19479/10943 (epoch 160.197) train_loss=894.07067871 time/batch=1.32s
19480/10943 (epoch 160.206) train_loss=760.19995117 time/batch=1.19s
19481/10943 (epoch 160.214) train_loss=245.56320190 time/batch=0.47s
19482/10943 (epoch 160.222) train_loss=457.27142334 time/batch=0.73s
19483/10943 (epoch 160.230) train_loss=676.45373535 time/batch=1.06s
19484/10943 (epoch 160.238) train_loss=374.82400513 time/batch=0.67s
19485/10943 (epoch 160.247) train_loss=166.14685059 time/batch=0.31s
19486/10943 (epoch 160.255) train_loss=816.72003174 time/batch=1.21s
19487/10943 (epoch 160.263) train_loss=536.39849854 time/batch=0.92s
19488/10943 (epoch 160.271) train_loss=728.31750488 time/batch=1.19s
19489/10943 (epoch 160.280) train_loss=500.52828979 time/batch=0.87s
19490/10943 (epoch 160.288) train_loss=420.08532715 time/batch=0.68s
19491/10943 (epoch 160.296) train_loss=793.44647217 time/batch=1.31s
19492/10943 (epoch 160.304) train_loss=647.46728516 time/batch=1.07s
19493/10943 (epoch 160.313) train_loss=313.69375610 time/batch=0.59s
19494/10943 (epoch 160.321) train_loss=416.61187744 time/batch=0.69s
19495/10943 (epoch 160.329) train_loss=584.75109863 time/batch=0.94s
19496/10943 (epoch 160.337) train_loss=755.08203125 time/batch=1.21s
19497/10943 (epoch 160.345) train_loss=221.15975952 time/batch=0.45s
19498/10943 (epoch 160.354) train_loss=482.23516846 time/batch=0.76s
19499/10943 (epoch 160.362) train_loss=595.72320557 time/batch=0.98s
19500/10943 (epoch 160.370) train_loss=702.84643555 time/batch=1.13s
19501/10943 (epoch 160.378) train_loss=220.20959473 time/batch=0.43s
19502/10943 (epoch 160.387) train_loss=500.68801880 time/batch=0.79s
19503/10943 (epoch 160.395) train_loss=230.35021973 time/batch=0.42s
19504/10943 (epoch 160.403) train_loss=431.93511963 time/batch=0.70s
19505/10943 (epoch 160.411) train_loss=274.94607544 time/batch=0.47s
19506/10943 (epoch 160.419) train_loss=505.63891602 time/batch=0.80s
19507/10943 (epoch 160.428) train_loss=587.85528564 time/batch=0.99s
19508/10943 (epoch 160.436) train_loss=500.10888672 time/batch=0.84s
19509/10943 (epoch 160.444) train_loss=359.93371582 time/batch=0.60s
19510/10943 (epoch 160.452) train_loss=333.21295166 time/batch=0.56s
19511/10943 (epoch 160.461) train_loss=174.90695190 time/batch=0.32s
19512/10943 (epoch 160.469) train_loss=341.09957886 time/batch=0.55s
19513/10943 (epoch 160.477) train_loss=203.17959595 time/batch=0.37s
19514/10943 (epoch 160.485) train_loss=238.28961182 time/batch=0.40s
19515/10943 (epoch 160.493) train_loss=358.47570801 time/batch=0.59s
19516/10943 (epoch 160.502) train_loss=685.55163574 time/batch=1.11s
19517/10943 (epoch 160.510) train_loss=316.79486084 time/batch=0.59s
19518/10943 (epoch 160.518) train_loss=491.51879883 time/batch=0.82s
19519/10943 (epoch 160.526) train_loss=301.20513916 time/batch=0.53s
19520/10943 (epoch 160.535) train_loss=428.27490234 time/batch=0.68s
19521/10943 (epoch 160.543) train_loss=478.60424805 time/batch=0.80s
19522/10943 (epoch 160.551) train_loss=478.36022949 time/batch=0.80s
19523/10943 (epoch 160.559) train_loss=508.88827515 time/batch=0.85s
19524/10943 (epoch 160.567) train_loss=372.21307373 time/batch=0.66s
19525/10943 (epoch 160.576) train_loss=177.36247253 time/batch=0.33s
19526/10943 (epoch 160.584) train_loss=395.27661133 time/batch=0.62s
19527/10943 (epoch 160.592) train_loss=502.25857544 time/batch=0.83s
19528/10943 (epoch 160.600) train_loss=579.63995361 time/batch=1.02s
19529/10943 (epoch 160.609) train_loss=290.47390747 time/batch=0.53s
19530/10943 (epoch 160.617) train_loss=471.98211670 time/batch=0.75s
19531/10943 (epoch 160.625) train_loss=540.35546875 time/batch=0.87s
19532/10943 (epoch 160.633) train_loss=454.99255371 time/batch=0.75s
19533/10943 (epoch 160.641) train_loss=717.56433105 time/batch=1.42s
19534/10943 (epoch 160.650) train_loss=323.83551025 time/batch=0.60s
19535/10943 (epoch 160.658) train_loss=399.08569336 time/batch=0.63s
19536/10943 (epoch 160.666) train_loss=535.05651855 time/batch=0.86s
19537/10943 (epoch 160.674) train_loss=253.13827515 time/batch=0.48s
19538/10943 (epoch 160.683) train_loss=413.71343994 time/batch=0.65s
19539/10943 (epoch 160.691) train_loss=379.38696289 time/batch=0.63s
19540/10943 (epoch 160.699) train_loss=345.75616455 time/batch=0.59s
19541/10943 (epoch 160.707) train_loss=352.26269531 time/batch=0.60s
19542/10943 (epoch 160.715) train_loss=392.30319214 time/batch=0.65s
19543/10943 (epoch 160.724) train_loss=236.66311646 time/batch=0.46s
19544/10943 (epoch 160.732) train_loss=258.35159302 time/batch=0.45s
19545/10943 (epoch 160.740) train_loss=215.48942566 time/batch=0.45s
19546/10943 (epoch 160.748) train_loss=367.08532715 time/batch=0.61s
19547/10943 (epoch 160.757) train_loss=436.74316406 time/batch=0.71s
19548/10943 (epoch 160.765) train_loss=304.95428467 time/batch=0.56s
19549/10943 (epoch 160.773) train_loss=293.58312988 time/batch=0.49s
19550/10943 (epoch 160.781) train_loss=301.14242554 time/batch=0.50s
19551/10943 (epoch 160.790) train_loss=449.01434326 time/batch=0.73s
19552/10943 (epoch 160.798) train_loss=184.65646362 time/batch=0.35s
19553/10943 (epoch 160.806) train_loss=521.03125000 time/batch=0.84s
19554/10943 (epoch 160.814) train_loss=352.09082031 time/batch=0.62s
19555/10943 (epoch 160.822) train_loss=258.11614990 time/batch=0.52s
19556/10943 (epoch 160.831) train_loss=355.91870117 time/batch=0.60s
19557/10943 (epoch 160.839) train_loss=312.43756104 time/batch=0.54s
19558/10943 (epoch 160.847) train_loss=411.47964478 time/batch=0.66s
19559/10943 (epoch 160.855) train_loss=253.85806274 time/batch=0.57s
19560/10943 (epoch 160.864) train_loss=463.92742920 time/batch=0.71s
19561/10943 (epoch 160.872) train_loss=400.55496216 time/batch=0.68s
19562/10943 (epoch 160.880) train_loss=417.42431641 time/batch=0.68s
19563/10943 (epoch 160.888) train_loss=552.67211914 time/batch=1.01s
19564/10943 (epoch 160.896) train_loss=367.75314331 time/batch=0.65s
19565/10943 (epoch 160.905) train_loss=485.49169922 time/batch=0.86s
19566/10943 (epoch 160.913) train_loss=379.02386475 time/batch=0.71s
19567/10943 (epoch 160.921) train_loss=440.68829346 time/batch=0.73s
19568/10943 (epoch 160.929) train_loss=455.14141846 time/batch=0.88s
19569/10943 (epoch 160.938) train_loss=400.32296753 time/batch=0.70s
19570/10943 (epoch 160.946) train_loss=437.28778076 time/batch=0.71s
19571/10943 (epoch 160.954) train_loss=420.97500610 time/batch=0.73s
setting learning rate to 0.0012030
19572/10943 (epoch 160.962) train_loss=241.44487000 time/batch=0.45s
19573/10943 (epoch 160.970) train_loss=406.66082764 time/batch=0.64s
19574/10943 (epoch 160.979) train_loss=634.93035889 time/batch=1.03s
19575/10943 (epoch 160.987) train_loss=769.42614746 time/batch=1.27s
19576/10943 (epoch 160.995) train_loss=1509.29736328 time/batch=3.15s
19577/10943 (epoch 161.003) train_loss=978.74902344 time/batch=1.62s
19578/10943 (epoch 161.012) train_loss=497.69030762 time/batch=0.89s
19579/10943 (epoch 161.020) train_loss=639.84924316 time/batch=1.04s
19580/10943 (epoch 161.028) train_loss=455.54159546 time/batch=0.82s
19581/10943 (epoch 161.036) train_loss=482.65167236 time/batch=0.85s
19582/10943 (epoch 161.044) train_loss=297.43585205 time/batch=0.55s
19583/10943 (epoch 161.053) train_loss=1058.49450684 time/batch=1.65s
19584/10943 (epoch 161.061) train_loss=425.98986816 time/batch=0.85s
19585/10943 (epoch 161.069) train_loss=671.83660889 time/batch=1.11s
19586/10943 (epoch 161.077) train_loss=139.79127502 time/batch=0.34s
19587/10943 (epoch 161.086) train_loss=491.65795898 time/batch=0.80s
19588/10943 (epoch 161.094) train_loss=939.03417969 time/batch=1.55s
19589/10943 (epoch 161.102) train_loss=364.66354370 time/batch=0.69s
19590/10943 (epoch 161.110) train_loss=468.46350098 time/batch=0.77s
19591/10943 (epoch 161.118) train_loss=834.98895264 time/batch=1.38s
19592/10943 (epoch 161.127) train_loss=204.76486206 time/batch=0.46s
19593/10943 (epoch 161.135) train_loss=268.43200684 time/batch=0.45s
19594/10943 (epoch 161.143) train_loss=355.49200439 time/batch=0.61s
19595/10943 (epoch 161.151) train_loss=648.64953613 time/batch=1.05s
19596/10943 (epoch 161.160) train_loss=258.90820312 time/batch=0.50s
19597/10943 (epoch 161.168) train_loss=416.62997437 time/batch=0.67s
19598/10943 (epoch 161.176) train_loss=180.61190796 time/batch=0.35s
19599/10943 (epoch 161.184) train_loss=568.43054199 time/batch=0.92s
19600/10943 (epoch 161.192) train_loss=524.35382080 time/batch=0.89s
19601/10943 (epoch 161.201) train_loss=720.48870850 time/batch=1.17s
19602/10943 (epoch 161.209) train_loss=497.79174805 time/batch=0.84s
19603/10943 (epoch 161.217) train_loss=344.32070923 time/batch=0.61s
19604/10943 (epoch 161.225) train_loss=276.88586426 time/batch=0.49s
19605/10943 (epoch 161.234) train_loss=387.31854248 time/batch=0.63s
19606/10943 (epoch 161.242) train_loss=292.97378540 time/batch=0.52s
19607/10943 (epoch 161.250) train_loss=443.68902588 time/batch=0.71s
19608/10943 (epoch 161.258) train_loss=527.72991943 time/batch=0.91s
19609/10943 (epoch 161.267) train_loss=173.53375244 time/batch=0.36s
19610/10943 (epoch 161.275) train_loss=495.92684937 time/batch=0.81s
19611/10943 (epoch 161.283) train_loss=740.13940430 time/batch=1.20s
19612/10943 (epoch 161.291) train_loss=659.01745605 time/batch=1.04s
19613/10943 (epoch 161.299) train_loss=184.07104492 time/batch=0.38s
19614/10943 (epoch 161.308) train_loss=479.88067627 time/batch=0.76s
19615/10943 (epoch 161.316) train_loss=545.79882812 time/batch=0.90s
19616/10943 (epoch 161.324) train_loss=200.55155945 time/batch=0.40s
19617/10943 (epoch 161.332) train_loss=465.99743652 time/batch=0.78s
19618/10943 (epoch 161.341) train_loss=271.61508179 time/batch=0.48s
19619/10943 (epoch 161.349) train_loss=552.91625977 time/batch=0.88s
19620/10943 (epoch 161.357) train_loss=535.18127441 time/batch=0.89s
19621/10943 (epoch 161.365) train_loss=194.22460938 time/batch=0.40s
19622/10943 (epoch 161.373) train_loss=678.24353027 time/batch=1.05s
19623/10943 (epoch 161.382) train_loss=434.14147949 time/batch=0.75s
19624/10943 (epoch 161.390) train_loss=228.15013123 time/batch=0.42s
19625/10943 (epoch 161.398) train_loss=435.25500488 time/batch=0.69s
19626/10943 (epoch 161.406) train_loss=399.11853027 time/batch=0.69s
19627/10943 (epoch 161.415) train_loss=157.88435364 time/batch=0.31s
19628/10943 (epoch 161.423) train_loss=662.78112793 time/batch=1.05s
19629/10943 (epoch 161.431) train_loss=651.15167236 time/batch=1.17s
19630/10943 (epoch 161.439) train_loss=219.85229492 time/batch=0.44s
19631/10943 (epoch 161.447) train_loss=552.30657959 time/batch=0.89s
19632/10943 (epoch 161.456) train_loss=473.84844971 time/batch=0.79s
19633/10943 (epoch 161.464) train_loss=357.79235840 time/batch=0.62s
19634/10943 (epoch 161.472) train_loss=248.48739624 time/batch=0.44s
19635/10943 (epoch 161.480) train_loss=839.14337158 time/batch=1.39s
19636/10943 (epoch 161.489) train_loss=337.64065552 time/batch=0.65s
19637/10943 (epoch 161.497) train_loss=711.41632080 time/batch=1.20s
19638/10943 (epoch 161.505) train_loss=355.63488770 time/batch=0.66s
19639/10943 (epoch 161.513) train_loss=410.10644531 time/batch=0.67s
19640/10943 (epoch 161.521) train_loss=194.40492249 time/batch=0.39s
19641/10943 (epoch 161.530) train_loss=324.32250977 time/batch=0.54s
19642/10943 (epoch 161.538) train_loss=378.65554810 time/batch=0.63s
19643/10943 (epoch 161.546) train_loss=226.28839111 time/batch=0.41s
19644/10943 (epoch 161.554) train_loss=279.72943115 time/batch=0.49s
19645/10943 (epoch 161.563) train_loss=437.90728760 time/batch=0.74s
19646/10943 (epoch 161.571) train_loss=420.34497070 time/batch=0.70s
19647/10943 (epoch 161.579) train_loss=342.95776367 time/batch=0.62s
19648/10943 (epoch 161.587) train_loss=321.85443115 time/batch=0.56s
19649/10943 (epoch 161.595) train_loss=432.96484375 time/batch=0.70s
19650/10943 (epoch 161.604) train_loss=528.63781738 time/batch=0.88s
19651/10943 (epoch 161.612) train_loss=301.27383423 time/batch=0.57s
19652/10943 (epoch 161.620) train_loss=430.92584229 time/batch=0.70s
19653/10943 (epoch 161.628) train_loss=302.43359375 time/batch=0.54s
19654/10943 (epoch 161.637) train_loss=290.70471191 time/batch=0.51s
19655/10943 (epoch 161.645) train_loss=433.12023926 time/batch=0.73s
19656/10943 (epoch 161.653) train_loss=356.12442017 time/batch=0.63s
19657/10943 (epoch 161.661) train_loss=573.08270264 time/batch=0.92s
19658/10943 (epoch 161.669) train_loss=281.15429688 time/batch=0.52s
19659/10943 (epoch 161.678) train_loss=360.36923218 time/batch=0.61s
19660/10943 (epoch 161.686) train_loss=374.76422119 time/batch=0.63s
19661/10943 (epoch 161.694) train_loss=286.11370850 time/batch=0.49s
19662/10943 (epoch 161.702) train_loss=588.50183105 time/batch=0.96s
19663/10943 (epoch 161.711) train_loss=477.99951172 time/batch=0.83s
19664/10943 (epoch 161.719) train_loss=464.09478760 time/batch=0.80s
19665/10943 (epoch 161.727) train_loss=243.17398071 time/batch=0.49s
19666/10943 (epoch 161.735) train_loss=378.07720947 time/batch=0.63s
19667/10943 (epoch 161.744) train_loss=269.55593872 time/batch=0.49s
19668/10943 (epoch 161.752) train_loss=195.02351379 time/batch=0.38s
19669/10943 (epoch 161.760) train_loss=401.52008057 time/batch=0.64s
19670/10943 (epoch 161.768) train_loss=354.26898193 time/batch=0.64s
19671/10943 (epoch 161.776) train_loss=576.27819824 time/batch=0.98s
19672/10943 (epoch 161.785) train_loss=223.89402771 time/batch=0.44s
19673/10943 (epoch 161.793) train_loss=332.30490112 time/batch=0.57s
19674/10943 (epoch 161.801) train_loss=307.32177734 time/batch=0.53s
19675/10943 (epoch 161.809) train_loss=261.93164062 time/batch=0.54s
19676/10943 (epoch 161.818) train_loss=393.43646240 time/batch=0.67s
19677/10943 (epoch 161.826) train_loss=289.54620361 time/batch=0.56s
19678/10943 (epoch 161.834) train_loss=397.42663574 time/batch=0.65s
19679/10943 (epoch 161.842) train_loss=409.13442993 time/batch=0.67s
19680/10943 (epoch 161.850) train_loss=440.76184082 time/batch=0.73s
19681/10943 (epoch 161.859) train_loss=289.55914307 time/batch=0.61s
19682/10943 (epoch 161.867) train_loss=349.29983521 time/batch=0.63s
19683/10943 (epoch 161.875) train_loss=571.61682129 time/batch=0.94s
19684/10943 (epoch 161.883) train_loss=492.10009766 time/batch=0.83s
19685/10943 (epoch 161.892) train_loss=478.64114380 time/batch=0.78s
19686/10943 (epoch 161.900) train_loss=514.10687256 time/batch=0.85s
19687/10943 (epoch 161.908) train_loss=420.88973999 time/batch=0.77s
19688/10943 (epoch 161.916) train_loss=501.91052246 time/batch=0.83s
19689/10943 (epoch 161.924) train_loss=336.73315430 time/batch=0.64s
19690/10943 (epoch 161.933) train_loss=522.06481934 time/batch=0.93s
19691/10943 (epoch 161.941) train_loss=488.10455322 time/batch=0.85s
19692/10943 (epoch 161.949) train_loss=432.20233154 time/batch=0.83s
setting learning rate to 0.0011669
19693/10943 (epoch 161.957) train_loss=461.14730835 time/batch=0.81s
19694/10943 (epoch 161.966) train_loss=459.27536011 time/batch=0.82s
19695/10943 (epoch 161.974) train_loss=1072.14599609 time/batch=1.77s
19696/10943 (epoch 161.982) train_loss=283.12145996 time/batch=0.59s
19697/10943 (epoch 161.990) train_loss=298.56948853 time/batch=0.52s
19698/10943 (epoch 161.998) train_loss=320.56793213 time/batch=0.55s
19699/10943 (epoch 162.007) train_loss=627.84777832 time/batch=0.97s
19700/10943 (epoch 162.015) train_loss=344.36877441 time/batch=0.64s
19701/10943 (epoch 162.023) train_loss=695.40301514 time/batch=1.12s
19702/10943 (epoch 162.031) train_loss=289.72558594 time/batch=0.56s
19703/10943 (epoch 162.040) train_loss=1338.24841309 time/batch=3.07s
19704/10943 (epoch 162.048) train_loss=683.62829590 time/batch=1.28s
19705/10943 (epoch 162.056) train_loss=686.30670166 time/batch=1.06s
19706/10943 (epoch 162.064) train_loss=402.74246216 time/batch=0.69s
19707/10943 (epoch 162.072) train_loss=837.51477051 time/batch=1.35s
19708/10943 (epoch 162.081) train_loss=656.22271729 time/batch=1.15s
19709/10943 (epoch 162.089) train_loss=887.42736816 time/batch=1.52s
19710/10943 (epoch 162.097) train_loss=306.43933105 time/batch=0.60s
19711/10943 (epoch 162.105) train_loss=232.93930054 time/batch=0.40s
19712/10943 (epoch 162.114) train_loss=816.63360596 time/batch=1.24s
19713/10943 (epoch 162.122) train_loss=460.97015381 time/batch=0.83s
19714/10943 (epoch 162.130) train_loss=740.61370850 time/batch=1.29s
19715/10943 (epoch 162.138) train_loss=527.52770996 time/batch=0.93s
19716/10943 (epoch 162.146) train_loss=256.41140747 time/batch=0.47s
19717/10943 (epoch 162.155) train_loss=557.66772461 time/batch=0.91s
19718/10943 (epoch 162.163) train_loss=351.95251465 time/batch=0.65s
19719/10943 (epoch 162.171) train_loss=461.24145508 time/batch=0.80s
19720/10943 (epoch 162.179) train_loss=227.68182373 time/batch=0.44s
19721/10943 (epoch 162.188) train_loss=896.89849854 time/batch=1.51s
19722/10943 (epoch 162.196) train_loss=354.98956299 time/batch=0.67s
19723/10943 (epoch 162.204) train_loss=474.44540405 time/batch=0.80s
19724/10943 (epoch 162.212) train_loss=708.55029297 time/batch=1.18s
19725/10943 (epoch 162.221) train_loss=679.91760254 time/batch=1.16s
19726/10943 (epoch 162.229) train_loss=615.49377441 time/batch=1.03s
19727/10943 (epoch 162.237) train_loss=587.81665039 time/batch=0.97s
19728/10943 (epoch 162.245) train_loss=392.56286621 time/batch=0.68s
19729/10943 (epoch 162.253) train_loss=438.43768311 time/batch=0.74s
19730/10943 (epoch 162.262) train_loss=215.18289185 time/batch=0.41s
19731/10943 (epoch 162.270) train_loss=203.30285645 time/batch=0.36s
19732/10943 (epoch 162.278) train_loss=753.41931152 time/batch=1.16s
19733/10943 (epoch 162.286) train_loss=341.77584839 time/batch=0.66s
19734/10943 (epoch 162.295) train_loss=211.04542542 time/batch=0.39s
19735/10943 (epoch 162.303) train_loss=401.11517334 time/batch=0.65s
19736/10943 (epoch 162.311) train_loss=176.17372131 time/batch=0.33s
19737/10943 (epoch 162.319) train_loss=159.91046143 time/batch=0.29s
19738/10943 (epoch 162.327) train_loss=333.82983398 time/batch=0.56s
19739/10943 (epoch 162.336) train_loss=423.77392578 time/batch=0.72s
19740/10943 (epoch 162.344) train_loss=415.05096436 time/batch=0.68s
19741/10943 (epoch 162.352) train_loss=444.99069214 time/batch=0.74s
19742/10943 (epoch 162.360) train_loss=188.22372437 time/batch=0.37s
19743/10943 (epoch 162.369) train_loss=137.12646484 time/batch=0.27s
19744/10943 (epoch 162.377) train_loss=297.87789917 time/batch=0.52s
19745/10943 (epoch 162.385) train_loss=666.77947998 time/batch=1.05s
19746/10943 (epoch 162.393) train_loss=167.29949951 time/batch=0.37s
19747/10943 (epoch 162.401) train_loss=406.15972900 time/batch=0.64s
19748/10943 (epoch 162.410) train_loss=673.36895752 time/batch=1.09s
19749/10943 (epoch 162.418) train_loss=450.85717773 time/batch=0.76s
19750/10943 (epoch 162.426) train_loss=462.00109863 time/batch=0.76s
19751/10943 (epoch 162.434) train_loss=292.73596191 time/batch=0.52s
19752/10943 (epoch 162.443) train_loss=595.76940918 time/batch=0.98s
19753/10943 (epoch 162.451) train_loss=436.82458496 time/batch=0.81s
19754/10943 (epoch 162.459) train_loss=300.66027832 time/batch=0.55s
19755/10943 (epoch 162.467) train_loss=188.23147583 time/batch=0.34s
19756/10943 (epoch 162.475) train_loss=359.35845947 time/batch=0.60s
19757/10943 (epoch 162.484) train_loss=395.97198486 time/batch=0.69s
19758/10943 (epoch 162.492) train_loss=505.35369873 time/batch=0.85s
19759/10943 (epoch 162.500) train_loss=316.68469238 time/batch=0.59s
19760/10943 (epoch 162.508) train_loss=237.07083130 time/batch=0.42s
19761/10943 (epoch 162.517) train_loss=295.59106445 time/batch=0.49s
19762/10943 (epoch 162.525) train_loss=460.56185913 time/batch=0.76s
19763/10943 (epoch 162.533) train_loss=562.35980225 time/batch=0.93s
19764/10943 (epoch 162.541) train_loss=229.77713013 time/batch=0.47s
19765/10943 (epoch 162.549) train_loss=175.95768738 time/batch=0.32s
19766/10943 (epoch 162.558) train_loss=339.09637451 time/batch=0.55s
19767/10943 (epoch 162.566) train_loss=532.58380127 time/batch=0.88s
19768/10943 (epoch 162.574) train_loss=224.80201721 time/batch=0.47s
19769/10943 (epoch 162.582) train_loss=573.99536133 time/batch=0.91s
19770/10943 (epoch 162.591) train_loss=293.15338135 time/batch=0.56s
19771/10943 (epoch 162.599) train_loss=432.08059692 time/batch=0.68s
19772/10943 (epoch 162.607) train_loss=282.56005859 time/batch=0.48s
19773/10943 (epoch 162.615) train_loss=318.07443237 time/batch=0.56s
19774/10943 (epoch 162.623) train_loss=496.91802979 time/batch=0.82s
19775/10943 (epoch 162.632) train_loss=361.77996826 time/batch=0.63s
19776/10943 (epoch 162.640) train_loss=262.79888916 time/batch=0.46s
19777/10943 (epoch 162.648) train_loss=286.10507202 time/batch=0.50s
19778/10943 (epoch 162.656) train_loss=471.67663574 time/batch=0.80s
19779/10943 (epoch 162.665) train_loss=509.15789795 time/batch=0.88s
19780/10943 (epoch 162.673) train_loss=658.94677734 time/batch=1.14s
19781/10943 (epoch 162.681) train_loss=488.22537231 time/batch=0.82s
19782/10943 (epoch 162.689) train_loss=195.54156494 time/batch=0.38s
19783/10943 (epoch 162.698) train_loss=437.37701416 time/batch=0.70s
19784/10943 (epoch 162.706) train_loss=262.92761230 time/batch=0.49s
19785/10943 (epoch 162.714) train_loss=301.12310791 time/batch=0.53s
19786/10943 (epoch 162.722) train_loss=470.80377197 time/batch=0.80s
19787/10943 (epoch 162.730) train_loss=270.86444092 time/batch=0.50s
19788/10943 (epoch 162.739) train_loss=228.60568237 time/batch=0.56s
19789/10943 (epoch 162.747) train_loss=419.45837402 time/batch=0.71s
19790/10943 (epoch 162.755) train_loss=380.13018799 time/batch=0.67s
19791/10943 (epoch 162.763) train_loss=337.86862183 time/batch=0.59s
19792/10943 (epoch 162.772) train_loss=509.15042114 time/batch=0.85s
19793/10943 (epoch 162.780) train_loss=393.31738281 time/batch=0.67s
19794/10943 (epoch 162.788) train_loss=549.75921631 time/batch=0.94s
19795/10943 (epoch 162.796) train_loss=368.96667480 time/batch=0.67s
19796/10943 (epoch 162.804) train_loss=432.56976318 time/batch=0.70s
19797/10943 (epoch 162.813) train_loss=539.10876465 time/batch=0.90s
19798/10943 (epoch 162.821) train_loss=505.03787231 time/batch=0.86s
19799/10943 (epoch 162.829) train_loss=369.02493286 time/batch=0.64s
19800/10943 (epoch 162.837) train_loss=314.64514160 time/batch=0.59s
19801/10943 (epoch 162.846) train_loss=472.86291504 time/batch=0.81s
19802/10943 (epoch 162.854) train_loss=364.56045532 time/batch=0.63s
19803/10943 (epoch 162.862) train_loss=356.49371338 time/batch=0.63s
19804/10943 (epoch 162.870) train_loss=377.06027222 time/batch=0.64s
19805/10943 (epoch 162.878) train_loss=481.52758789 time/batch=0.83s
19806/10943 (epoch 162.887) train_loss=525.03417969 time/batch=0.90s
19807/10943 (epoch 162.895) train_loss=403.97894287 time/batch=0.73s
19808/10943 (epoch 162.903) train_loss=356.47247314 time/batch=0.69s
19809/10943 (epoch 162.911) train_loss=522.17028809 time/batch=0.89s
19810/10943 (epoch 162.920) train_loss=451.48333740 time/batch=0.79s
19811/10943 (epoch 162.928) train_loss=415.46563721 time/batch=0.72s
19812/10943 (epoch 162.936) train_loss=445.72113037 time/batch=0.79s
19813/10943 (epoch 162.944) train_loss=402.45449829 time/batch=0.74s
setting learning rate to 0.0011319
19814/10943 (epoch 162.952) train_loss=560.09057617 time/batch=0.96s
19815/10943 (epoch 162.961) train_loss=1016.88372803 time/batch=1.65s
19816/10943 (epoch 162.969) train_loss=327.50909424 time/batch=0.66s
19817/10943 (epoch 162.977) train_loss=558.29180908 time/batch=0.92s
19818/10943 (epoch 162.985) train_loss=849.19860840 time/batch=1.39s
19819/10943 (epoch 162.994) train_loss=511.93145752 time/batch=0.90s
19820/10943 (epoch 163.002) train_loss=580.89392090 time/batch=0.99s
19821/10943 (epoch 163.010) train_loss=679.08361816 time/batch=1.14s
19822/10943 (epoch 163.018) train_loss=860.45495605 time/batch=1.48s
19823/10943 (epoch 163.026) train_loss=754.93237305 time/batch=1.27s
19824/10943 (epoch 163.035) train_loss=932.56622314 time/batch=1.72s
19825/10943 (epoch 163.043) train_loss=695.58190918 time/batch=1.19s
19826/10943 (epoch 163.051) train_loss=582.91644287 time/batch=1.00s
19827/10943 (epoch 163.059) train_loss=1342.93664551 time/batch=3.11s
19828/10943 (epoch 163.068) train_loss=868.66906738 time/batch=1.93s
19829/10943 (epoch 163.076) train_loss=306.28134155 time/batch=0.65s
19830/10943 (epoch 163.084) train_loss=488.76135254 time/batch=0.82s
19831/10943 (epoch 163.092) train_loss=619.75677490 time/batch=1.05s
19832/10943 (epoch 163.100) train_loss=185.63339233 time/batch=0.39s
19833/10943 (epoch 163.109) train_loss=290.47009277 time/batch=0.50s
19834/10943 (epoch 163.117) train_loss=216.99612427 time/batch=0.38s
19835/10943 (epoch 163.125) train_loss=620.23754883 time/batch=0.95s
19836/10943 (epoch 163.133) train_loss=434.21673584 time/batch=0.78s
19837/10943 (epoch 163.142) train_loss=426.14978027 time/batch=0.75s
19838/10943 (epoch 163.150) train_loss=295.50039673 time/batch=0.54s
19839/10943 (epoch 163.158) train_loss=730.05725098 time/batch=1.18s
19840/10943 (epoch 163.166) train_loss=410.14282227 time/batch=0.74s
19841/10943 (epoch 163.175) train_loss=228.84747314 time/batch=0.43s
19842/10943 (epoch 163.183) train_loss=462.18145752 time/batch=0.75s
19843/10943 (epoch 163.191) train_loss=164.75637817 time/batch=0.34s
19844/10943 (epoch 163.199) train_loss=292.37954712 time/batch=0.50s
19845/10943 (epoch 163.207) train_loss=209.22848511 time/batch=0.39s
19846/10943 (epoch 163.216) train_loss=715.28265381 time/batch=1.20s
19847/10943 (epoch 163.224) train_loss=648.42120361 time/batch=1.15s
19848/10943 (epoch 163.232) train_loss=139.81579590 time/batch=0.34s
19849/10943 (epoch 163.240) train_loss=654.59820557 time/batch=1.00s
19850/10943 (epoch 163.249) train_loss=540.20672607 time/batch=0.93s
19851/10943 (epoch 163.257) train_loss=540.68096924 time/batch=0.94s
19852/10943 (epoch 163.265) train_loss=674.52343750 time/batch=1.17s
19853/10943 (epoch 163.273) train_loss=243.96041870 time/batch=0.50s
19854/10943 (epoch 163.281) train_loss=316.89627075 time/batch=0.54s
19855/10943 (epoch 163.290) train_loss=198.76516724 time/batch=0.37s
19856/10943 (epoch 163.298) train_loss=263.26284790 time/batch=0.46s
19857/10943 (epoch 163.306) train_loss=322.54107666 time/batch=0.56s
19858/10943 (epoch 163.314) train_loss=311.86846924 time/batch=0.58s
19859/10943 (epoch 163.323) train_loss=247.82296753 time/batch=0.43s
19860/10943 (epoch 163.331) train_loss=642.01300049 time/batch=1.06s
19861/10943 (epoch 163.339) train_loss=511.12402344 time/batch=0.90s
19862/10943 (epoch 163.347) train_loss=446.46374512 time/batch=0.79s
19863/10943 (epoch 163.355) train_loss=409.22216797 time/batch=0.72s
19864/10943 (epoch 163.364) train_loss=218.20651245 time/batch=0.42s
19865/10943 (epoch 163.372) train_loss=325.53894043 time/batch=0.56s
19866/10943 (epoch 163.380) train_loss=586.39013672 time/batch=0.99s
19867/10943 (epoch 163.388) train_loss=248.79730225 time/batch=0.50s
19868/10943 (epoch 163.397) train_loss=454.21121216 time/batch=0.75s
19869/10943 (epoch 163.405) train_loss=332.32476807 time/batch=0.62s
19870/10943 (epoch 163.413) train_loss=189.57038879 time/batch=0.35s
19871/10943 (epoch 163.421) train_loss=595.96026611 time/batch=0.96s
19872/10943 (epoch 163.429) train_loss=306.26882935 time/batch=0.60s
19873/10943 (epoch 163.438) train_loss=529.17034912 time/batch=0.87s
19874/10943 (epoch 163.446) train_loss=532.06817627 time/batch=0.90s
19875/10943 (epoch 163.454) train_loss=174.24252319 time/batch=0.36s
19876/10943 (epoch 163.462) train_loss=295.68939209 time/batch=0.53s
19877/10943 (epoch 163.471) train_loss=415.26092529 time/batch=0.69s
19878/10943 (epoch 163.479) train_loss=471.72772217 time/batch=0.82s
19879/10943 (epoch 163.487) train_loss=207.92098999 time/batch=0.39s
19880/10943 (epoch 163.495) train_loss=414.75592041 time/batch=0.69s
19881/10943 (epoch 163.503) train_loss=173.34654236 time/batch=0.36s
19882/10943 (epoch 163.512) train_loss=490.86386108 time/batch=0.78s
19883/10943 (epoch 163.520) train_loss=403.27191162 time/batch=0.70s
19884/10943 (epoch 163.528) train_loss=481.34173584 time/batch=0.83s
19885/10943 (epoch 163.536) train_loss=281.24902344 time/batch=0.51s
19886/10943 (epoch 163.545) train_loss=395.75799561 time/batch=0.65s
19887/10943 (epoch 163.553) train_loss=388.72094727 time/batch=0.67s
19888/10943 (epoch 163.561) train_loss=446.95397949 time/batch=0.78s
19889/10943 (epoch 163.569) train_loss=464.60705566 time/batch=0.79s
19890/10943 (epoch 163.577) train_loss=512.58776855 time/batch=0.87s
19891/10943 (epoch 163.586) train_loss=558.66082764 time/batch=0.95s
19892/10943 (epoch 163.594) train_loss=535.79650879 time/batch=0.93s
19893/10943 (epoch 163.602) train_loss=407.68164062 time/batch=0.72s
19894/10943 (epoch 163.610) train_loss=386.22238159 time/batch=0.67s
19895/10943 (epoch 163.619) train_loss=456.43496704 time/batch=0.80s
19896/10943 (epoch 163.627) train_loss=449.38101196 time/batch=0.81s
19897/10943 (epoch 163.635) train_loss=508.96487427 time/batch=0.89s
19898/10943 (epoch 163.643) train_loss=441.31460571 time/batch=0.79s
19899/10943 (epoch 163.652) train_loss=326.90209961 time/batch=0.61s
19900/10943 (epoch 163.660) train_loss=333.47418213 time/batch=0.57s
19901/10943 (epoch 163.668) train_loss=279.72357178 time/batch=0.49s
19902/10943 (epoch 163.676) train_loss=159.35447693 time/batch=0.32s
19903/10943 (epoch 163.684) train_loss=416.64846802 time/batch=0.68s
19904/10943 (epoch 163.693) train_loss=319.04794312 time/batch=0.60s
19905/10943 (epoch 163.701) train_loss=409.19195557 time/batch=0.69s
19906/10943 (epoch 163.709) train_loss=454.29046631 time/batch=0.80s
19907/10943 (epoch 163.717) train_loss=338.67422485 time/batch=0.62s
19908/10943 (epoch 163.726) train_loss=332.63305664 time/batch=0.59s
19909/10943 (epoch 163.734) train_loss=350.30297852 time/batch=0.62s
19910/10943 (epoch 163.742) train_loss=421.66772461 time/batch=0.70s
19911/10943 (epoch 163.750) train_loss=479.13766479 time/batch=0.84s
19912/10943 (epoch 163.758) train_loss=291.58493042 time/batch=0.53s
19913/10943 (epoch 163.767) train_loss=297.58178711 time/batch=0.58s
19914/10943 (epoch 163.775) train_loss=362.54229736 time/batch=0.63s
19915/10943 (epoch 163.783) train_loss=235.74185181 time/batch=0.46s
19916/10943 (epoch 163.791) train_loss=420.97705078 time/batch=0.71s
19917/10943 (epoch 163.800) train_loss=456.17117310 time/batch=0.85s
19918/10943 (epoch 163.808) train_loss=386.30523682 time/batch=0.68s
19919/10943 (epoch 163.816) train_loss=254.85079956 time/batch=0.46s
19920/10943 (epoch 163.824) train_loss=251.61437988 time/batch=0.45s
19921/10943 (epoch 163.832) train_loss=345.56036377 time/batch=0.58s
19922/10943 (epoch 163.841) train_loss=180.22967529 time/batch=0.40s
19923/10943 (epoch 163.849) train_loss=234.82870483 time/batch=0.43s
19924/10943 (epoch 163.857) train_loss=471.99414062 time/batch=0.82s
19925/10943 (epoch 163.865) train_loss=455.65368652 time/batch=0.78s
19926/10943 (epoch 163.874) train_loss=382.30657959 time/batch=0.64s
19927/10943 (epoch 163.882) train_loss=352.87884521 time/batch=0.63s
19928/10943 (epoch 163.890) train_loss=350.61981201 time/batch=0.63s
19929/10943 (epoch 163.898) train_loss=382.94323730 time/batch=0.68s
19930/10943 (epoch 163.906) train_loss=349.55999756 time/batch=0.62s
19931/10943 (epoch 163.915) train_loss=276.91366577 time/batch=0.60s
19932/10943 (epoch 163.923) train_loss=344.78790283 time/batch=0.63s
19933/10943 (epoch 163.931) train_loss=410.38504028 time/batch=0.72s
19934/10943 (epoch 163.939) train_loss=361.54693604 time/batch=0.66s
setting learning rate to 0.0010980
19935/10943 (epoch 163.948) train_loss=602.90228271 time/batch=0.99s
19936/10943 (epoch 163.956) train_loss=848.01599121 time/batch=1.32s
19937/10943 (epoch 163.964) train_loss=337.49008179 time/batch=0.64s
19938/10943 (epoch 163.972) train_loss=144.63882446 time/batch=0.30s
19939/10943 (epoch 163.980) train_loss=1101.87231445 time/batch=1.83s
19940/10943 (epoch 163.989) train_loss=482.55157471 time/batch=0.92s
19941/10943 (epoch 163.997) train_loss=381.45333862 time/batch=0.66s
19942/10943 (epoch 164.005) train_loss=344.34378052 time/batch=0.60s
19943/10943 (epoch 164.013) train_loss=448.30718994 time/batch=0.81s
19944/10943 (epoch 164.022) train_loss=786.34729004 time/batch=1.31s
19945/10943 (epoch 164.030) train_loss=615.45294189 time/batch=1.07s
19946/10943 (epoch 164.038) train_loss=234.01992798 time/batch=0.46s
19947/10943 (epoch 164.046) train_loss=318.97772217 time/batch=0.54s
19948/10943 (epoch 164.054) train_loss=298.03100586 time/batch=0.53s
19949/10943 (epoch 164.063) train_loss=1275.85058594 time/batch=3.07s
19950/10943 (epoch 164.071) train_loss=795.62939453 time/batch=1.48s
19951/10943 (epoch 164.079) train_loss=723.18566895 time/batch=1.24s
19952/10943 (epoch 164.087) train_loss=936.27679443 time/batch=1.60s
19953/10943 (epoch 164.096) train_loss=702.01556396 time/batch=1.18s
19954/10943 (epoch 164.104) train_loss=334.06961060 time/batch=0.65s
19955/10943 (epoch 164.112) train_loss=192.73995972 time/batch=0.36s
19956/10943 (epoch 164.120) train_loss=735.81854248 time/batch=1.29s
19957/10943 (epoch 164.129) train_loss=574.31274414 time/batch=1.00s
19958/10943 (epoch 164.137) train_loss=583.78131104 time/batch=0.98s
19959/10943 (epoch 164.145) train_loss=385.54806519 time/batch=0.69s
19960/10943 (epoch 164.153) train_loss=169.36132812 time/batch=0.33s
19961/10943 (epoch 164.161) train_loss=433.78271484 time/batch=0.73s
19962/10943 (epoch 164.170) train_loss=618.14868164 time/batch=1.04s
19963/10943 (epoch 164.178) train_loss=561.42138672 time/batch=1.01s
19964/10943 (epoch 164.186) train_loss=689.26330566 time/batch=1.37s
19965/10943 (epoch 164.194) train_loss=645.14245605 time/batch=1.10s
19966/10943 (epoch 164.203) train_loss=506.88458252 time/batch=0.90s
19967/10943 (epoch 164.211) train_loss=175.62530518 time/batch=0.37s
19968/10943 (epoch 164.219) train_loss=432.71725464 time/batch=0.72s
19969/10943 (epoch 164.227) train_loss=434.19958496 time/batch=0.77s
19970/10943 (epoch 164.235) train_loss=625.65344238 time/batch=1.08s
19971/10943 (epoch 164.244) train_loss=514.51452637 time/batch=0.92s
19972/10943 (epoch 164.252) train_loss=332.46441650 time/batch=0.61s
19973/10943 (epoch 164.260) train_loss=227.48301697 time/batch=0.43s
19974/10943 (epoch 164.268) train_loss=636.94299316 time/batch=1.06s
19975/10943 (epoch 164.277) train_loss=172.42227173 time/batch=0.40s
19976/10943 (epoch 164.285) train_loss=557.91162109 time/batch=0.93s
19977/10943 (epoch 164.293) train_loss=308.78668213 time/batch=0.59s
19978/10943 (epoch 164.301) train_loss=478.98992920 time/batch=0.80s
19979/10943 (epoch 164.309) train_loss=206.78469849 time/batch=0.40s
19980/10943 (epoch 164.318) train_loss=529.16564941 time/batch=0.89s
19981/10943 (epoch 164.326) train_loss=212.84260559 time/batch=0.42s
19982/10943 (epoch 164.334) train_loss=280.10302734 time/batch=0.48s
19983/10943 (epoch 164.342) train_loss=140.57125854 time/batch=0.29s
19984/10943 (epoch 164.351) train_loss=261.62322998 time/batch=0.45s
19985/10943 (epoch 164.359) train_loss=386.57595825 time/batch=0.66s
19986/10943 (epoch 164.367) train_loss=792.01416016 time/batch=1.38s
19987/10943 (epoch 164.375) train_loss=686.46154785 time/batch=1.18s
19988/10943 (epoch 164.383) train_loss=425.89840698 time/batch=0.73s
19989/10943 (epoch 164.392) train_loss=489.83563232 time/batch=0.85s
19990/10943 (epoch 164.400) train_loss=185.84649658 time/batch=0.37s
19991/10943 (epoch 164.408) train_loss=447.02124023 time/batch=0.76s
19992/10943 (epoch 164.416) train_loss=240.53169250 time/batch=0.48s
19993/10943 (epoch 164.425) train_loss=411.16009521 time/batch=0.66s
19994/10943 (epoch 164.433) train_loss=425.90795898 time/batch=0.73s
19995/10943 (epoch 164.441) train_loss=508.60415649 time/batch=0.88s
19996/10943 (epoch 164.449) train_loss=459.53088379 time/batch=0.83s
19997/10943 (epoch 164.457) train_loss=544.15570068 time/batch=0.92s
19998/10943 (epoch 164.466) train_loss=427.25421143 time/batch=0.73s
19999/10943 (epoch 164.474) train_loss=458.00610352 time/batch=0.80s
Validating
    loss:	410.357226

20000/10943 (epoch 164.482) train_loss=425.49591064 time/batch=2.60s
20001/10943 (epoch 164.490) train_loss=276.14938354 time/batch=0.51s
20002/10943 (epoch 164.499) train_loss=215.41748047 time/batch=0.38s
20003/10943 (epoch 164.507) train_loss=290.20849609 time/batch=0.52s
20004/10943 (epoch 164.515) train_loss=251.13446045 time/batch=0.46s
20005/10943 (epoch 164.523) train_loss=587.00433350 time/batch=1.38s
20006/10943 (epoch 164.531) train_loss=487.79656982 time/batch=0.91s
20007/10943 (epoch 164.540) train_loss=530.62933350 time/batch=0.90s
20008/10943 (epoch 164.548) train_loss=397.95596313 time/batch=0.68s
20009/10943 (epoch 164.556) train_loss=450.09362793 time/batch=0.77s
20010/10943 (epoch 164.564) train_loss=396.77902222 time/batch=0.68s
20011/10943 (epoch 164.573) train_loss=250.39840698 time/batch=0.46s
20012/10943 (epoch 164.581) train_loss=209.44210815 time/batch=0.39s
20013/10943 (epoch 164.589) train_loss=182.60954285 time/batch=0.34s
20014/10943 (epoch 164.597) train_loss=329.87591553 time/batch=0.56s
20015/10943 (epoch 164.605) train_loss=422.06475830 time/batch=0.69s
20016/10943 (epoch 164.614) train_loss=481.25164795 time/batch=0.85s
20017/10943 (epoch 164.622) train_loss=417.42968750 time/batch=0.74s
20018/10943 (epoch 164.630) train_loss=271.12585449 time/batch=0.49s
20019/10943 (epoch 164.638) train_loss=194.35342407 time/batch=0.37s
20020/10943 (epoch 164.647) train_loss=238.98262024 time/batch=0.43s
20021/10943 (epoch 164.655) train_loss=379.80484009 time/batch=0.68s
20022/10943 (epoch 164.663) train_loss=285.60510254 time/batch=0.54s
20023/10943 (epoch 164.671) train_loss=229.80381775 time/batch=0.45s
20024/10943 (epoch 164.680) train_loss=459.47201538 time/batch=0.79s
20025/10943 (epoch 164.688) train_loss=366.54956055 time/batch=0.66s
20026/10943 (epoch 164.696) train_loss=541.39379883 time/batch=0.90s
20027/10943 (epoch 164.704) train_loss=484.19421387 time/batch=0.81s
20028/10943 (epoch 164.712) train_loss=342.56753540 time/batch=0.62s
20029/10943 (epoch 164.721) train_loss=342.70123291 time/batch=0.60s
20030/10943 (epoch 164.729) train_loss=329.72326660 time/batch=0.59s
20031/10943 (epoch 164.737) train_loss=237.10453796 time/batch=0.48s
20032/10943 (epoch 164.745) train_loss=320.05511475 time/batch=0.57s
20033/10943 (epoch 164.754) train_loss=322.35412598 time/batch=0.59s
20034/10943 (epoch 164.762) train_loss=434.53454590 time/batch=0.73s
20035/10943 (epoch 164.770) train_loss=570.45660400 time/batch=1.43s
20036/10943 (epoch 164.778) train_loss=291.29907227 time/batch=0.60s
20037/10943 (epoch 164.786) train_loss=271.12411499 time/batch=0.50s
20038/10943 (epoch 164.795) train_loss=348.96331787 time/batch=0.61s
20039/10943 (epoch 164.803) train_loss=264.85330200 time/batch=0.52s
20040/10943 (epoch 164.811) train_loss=351.27905273 time/batch=0.61s
20041/10943 (epoch 164.819) train_loss=448.20431519 time/batch=0.77s
20042/10943 (epoch 164.828) train_loss=296.90097046 time/batch=0.55s
20043/10943 (epoch 164.836) train_loss=292.32696533 time/batch=0.59s
20044/10943 (epoch 164.844) train_loss=372.45245361 time/batch=0.65s
20045/10943 (epoch 164.852) train_loss=430.90689087 time/batch=0.73s
20046/10943 (epoch 164.860) train_loss=381.61175537 time/batch=0.67s
20047/10943 (epoch 164.869) train_loss=412.78363037 time/batch=0.67s
20048/10943 (epoch 164.877) train_loss=411.43051147 time/batch=0.71s
20049/10943 (epoch 164.885) train_loss=418.63052368 time/batch=0.71s
20050/10943 (epoch 164.893) train_loss=361.26058960 time/batch=0.63s
20051/10943 (epoch 164.902) train_loss=343.30398560 time/batch=0.61s
20052/10943 (epoch 164.910) train_loss=491.78942871 time/batch=0.84s
20053/10943 (epoch 164.918) train_loss=383.83361816 time/batch=0.76s
20054/10943 (epoch 164.926) train_loss=474.76611328 time/batch=0.83s
20055/10943 (epoch 164.934) train_loss=441.39764404 time/batch=0.82s
setting learning rate to 0.0010650
  saved to metadata/gru_dropout-9_nov_folkwiki-20181115-204407_epoch54.pkl
20056/10943 (epoch 164.943) train_loss=687.76855469 time/batch=1.17s
20057/10943 (epoch 164.951) train_loss=717.10253906 time/batch=1.12s
20058/10943 (epoch 164.959) train_loss=310.00567627 time/batch=0.57s
20059/10943 (epoch 164.967) train_loss=805.69433594 time/batch=1.24s
20060/10943 (epoch 164.976) train_loss=905.71807861 time/batch=1.55s
20061/10943 (epoch 164.984) train_loss=555.29870605 time/batch=0.96s
20062/10943 (epoch 164.992) train_loss=539.41918945 time/batch=0.90s
20063/10943 (epoch 165.000) train_loss=303.38317871 time/batch=0.57s
20064/10943 (epoch 165.008) train_loss=615.62341309 time/batch=1.00s
20065/10943 (epoch 165.017) train_loss=710.88427734 time/batch=1.19s
20066/10943 (epoch 165.025) train_loss=516.34985352 time/batch=0.91s
20067/10943 (epoch 165.033) train_loss=209.53845215 time/batch=0.41s
20068/10943 (epoch 165.041) train_loss=1057.13330078 time/batch=1.65s
20069/10943 (epoch 165.050) train_loss=246.20228577 time/batch=0.55s
20070/10943 (epoch 165.058) train_loss=275.42059326 time/batch=0.45s
20071/10943 (epoch 165.066) train_loss=852.52307129 time/batch=1.29s
20072/10943 (epoch 165.074) train_loss=281.94137573 time/batch=0.56s
20073/10943 (epoch 165.082) train_loss=1315.58666992 time/batch=2.36s
20074/10943 (epoch 165.091) train_loss=436.91574097 time/batch=0.88s
20075/10943 (epoch 165.099) train_loss=497.51391602 time/batch=0.83s
20076/10943 (epoch 165.107) train_loss=635.44024658 time/batch=1.00s
20077/10943 (epoch 165.115) train_loss=425.03491211 time/batch=0.72s
20078/10943 (epoch 165.124) train_loss=141.43766785 time/batch=0.29s
20079/10943 (epoch 165.132) train_loss=364.90649414 time/batch=0.58s
20080/10943 (epoch 165.140) train_loss=210.44729614 time/batch=0.38s
20081/10943 (epoch 165.148) train_loss=572.28051758 time/batch=0.90s
20082/10943 (epoch 165.157) train_loss=628.96936035 time/batch=1.07s
20083/10943 (epoch 165.165) train_loss=189.31498718 time/batch=0.41s
20084/10943 (epoch 165.173) train_loss=358.90054321 time/batch=0.60s
20085/10943 (epoch 165.181) train_loss=526.92938232 time/batch=0.89s
20086/10943 (epoch 165.189) train_loss=473.99835205 time/batch=0.82s
20087/10943 (epoch 165.198) train_loss=798.73419189 time/batch=1.35s
20088/10943 (epoch 165.206) train_loss=468.68121338 time/batch=0.77s
20089/10943 (epoch 165.214) train_loss=445.06442261 time/batch=0.75s
20090/10943 (epoch 165.222) train_loss=541.97503662 time/batch=0.90s
20091/10943 (epoch 165.231) train_loss=278.60116577 time/batch=0.53s
20092/10943 (epoch 165.239) train_loss=810.27117920 time/batch=1.34s
20093/10943 (epoch 165.247) train_loss=206.22283936 time/batch=0.47s
20094/10943 (epoch 165.255) train_loss=764.60083008 time/batch=1.46s
20095/10943 (epoch 165.263) train_loss=661.82519531 time/batch=1.14s
20096/10943 (epoch 165.272) train_loss=662.50854492 time/batch=1.08s
20097/10943 (epoch 165.280) train_loss=579.06597900 time/batch=1.01s
20098/10943 (epoch 165.288) train_loss=297.31896973 time/batch=0.56s
20099/10943 (epoch 165.296) train_loss=528.10620117 time/batch=0.86s
20100/10943 (epoch 165.305) train_loss=575.41125488 time/batch=1.00s
20101/10943 (epoch 165.313) train_loss=456.26779175 time/batch=0.81s
20102/10943 (epoch 165.321) train_loss=549.50244141 time/batch=0.92s
20103/10943 (epoch 165.329) train_loss=386.76269531 time/batch=0.67s
20104/10943 (epoch 165.337) train_loss=719.87982178 time/batch=1.50s
20105/10943 (epoch 165.346) train_loss=193.56484985 time/batch=0.46s
20106/10943 (epoch 165.354) train_loss=595.56481934 time/batch=1.02s
20107/10943 (epoch 165.362) train_loss=218.36224365 time/batch=0.46s
20108/10943 (epoch 165.370) train_loss=244.06454468 time/batch=0.43s
20109/10943 (epoch 165.379) train_loss=374.49707031 time/batch=0.63s
20110/10943 (epoch 165.387) train_loss=781.96966553 time/batch=3.09s
20111/10943 (epoch 165.395) train_loss=373.19195557 time/batch=0.91s
20112/10943 (epoch 165.403) train_loss=428.36163330 time/batch=0.72s
20113/10943 (epoch 165.411) train_loss=496.24948120 time/batch=0.82s
20114/10943 (epoch 165.420) train_loss=464.05999756 time/batch=0.83s
20115/10943 (epoch 165.428) train_loss=283.10821533 time/batch=0.52s
20116/10943 (epoch 165.436) train_loss=264.26538086 time/batch=0.48s
20117/10943 (epoch 165.444) train_loss=332.28845215 time/batch=0.58s
20118/10943 (epoch 165.453) train_loss=171.73643494 time/batch=0.33s
20119/10943 (epoch 165.461) train_loss=310.29235840 time/batch=0.53s
20120/10943 (epoch 165.469) train_loss=387.49584961 time/batch=0.67s
20121/10943 (epoch 165.477) train_loss=297.42590332 time/batch=0.55s
20122/10943 (epoch 165.485) train_loss=220.72056580 time/batch=0.38s
20123/10943 (epoch 165.494) train_loss=320.75930786 time/batch=0.54s
20124/10943 (epoch 165.502) train_loss=308.60986328 time/batch=0.54s
20125/10943 (epoch 165.510) train_loss=177.92004395 time/batch=0.33s
20126/10943 (epoch 165.518) train_loss=333.96890259 time/batch=0.55s
20127/10943 (epoch 165.527) train_loss=258.25723267 time/batch=0.49s
20128/10943 (epoch 165.535) train_loss=509.17971802 time/batch=0.84s
20129/10943 (epoch 165.543) train_loss=242.49703979 time/batch=0.46s
20130/10943 (epoch 165.551) train_loss=458.55621338 time/batch=0.76s
20131/10943 (epoch 165.559) train_loss=259.06314087 time/batch=0.48s
20132/10943 (epoch 165.568) train_loss=154.79443359 time/batch=0.29s
20133/10943 (epoch 165.576) train_loss=475.46957397 time/batch=0.75s
20134/10943 (epoch 165.584) train_loss=234.13369751 time/batch=0.47s
20135/10943 (epoch 165.592) train_loss=461.73895264 time/batch=0.78s
20136/10943 (epoch 165.601) train_loss=412.02536011 time/batch=0.72s
20137/10943 (epoch 165.609) train_loss=340.05822754 time/batch=0.59s
20138/10943 (epoch 165.617) train_loss=577.95910645 time/batch=1.05s
20139/10943 (epoch 165.625) train_loss=440.66009521 time/batch=0.75s
20140/10943 (epoch 165.634) train_loss=568.85485840 time/batch=0.95s
20141/10943 (epoch 165.642) train_loss=294.84136963 time/batch=0.54s
20142/10943 (epoch 165.650) train_loss=202.17294312 time/batch=0.38s
20143/10943 (epoch 165.658) train_loss=490.99920654 time/batch=0.82s
20144/10943 (epoch 165.666) train_loss=398.21621704 time/batch=0.68s
20145/10943 (epoch 165.675) train_loss=193.32798767 time/batch=0.43s
20146/10943 (epoch 165.683) train_loss=314.06805420 time/batch=0.54s
20147/10943 (epoch 165.691) train_loss=450.12319946 time/batch=0.75s
20148/10943 (epoch 165.699) train_loss=414.48327637 time/batch=0.72s
20149/10943 (epoch 165.708) train_loss=491.10247803 time/batch=0.89s
20150/10943 (epoch 165.716) train_loss=458.84350586 time/batch=0.78s
20151/10943 (epoch 165.724) train_loss=348.88641357 time/batch=0.62s
20152/10943 (epoch 165.732) train_loss=322.48522949 time/batch=0.58s
20153/10943 (epoch 165.740) train_loss=286.38195801 time/batch=0.53s
20154/10943 (epoch 165.749) train_loss=207.01814270 time/batch=0.49s
20155/10943 (epoch 165.757) train_loss=288.06112671 time/batch=0.51s
20156/10943 (epoch 165.765) train_loss=352.66043091 time/batch=0.61s
20157/10943 (epoch 165.773) train_loss=493.98541260 time/batch=0.81s
20158/10943 (epoch 165.782) train_loss=357.52062988 time/batch=0.63s
20159/10943 (epoch 165.790) train_loss=472.16076660 time/batch=0.77s
20160/10943 (epoch 165.798) train_loss=479.35638428 time/batch=0.83s
20161/10943 (epoch 165.806) train_loss=363.92401123 time/batch=0.64s
20162/10943 (epoch 165.814) train_loss=407.13421631 time/batch=0.67s
20163/10943 (epoch 165.823) train_loss=413.87777710 time/batch=0.72s
20164/10943 (epoch 165.831) train_loss=389.39871216 time/batch=0.68s
20165/10943 (epoch 165.839) train_loss=352.39584351 time/batch=0.59s
20166/10943 (epoch 165.847) train_loss=410.89581299 time/batch=0.66s
20167/10943 (epoch 165.856) train_loss=452.43844604 time/batch=0.75s
20168/10943 (epoch 165.864) train_loss=337.57925415 time/batch=0.64s
20169/10943 (epoch 165.872) train_loss=362.97814941 time/batch=0.66s
20170/10943 (epoch 165.880) train_loss=396.45474243 time/batch=0.68s
20171/10943 (epoch 165.888) train_loss=455.27886963 time/batch=0.80s
20172/10943 (epoch 165.897) train_loss=387.24896240 time/batch=0.70s
20173/10943 (epoch 165.905) train_loss=443.27352905 time/batch=0.75s
20174/10943 (epoch 165.913) train_loss=450.77691650 time/batch=0.80s
20175/10943 (epoch 165.921) train_loss=436.35870361 time/batch=0.73s
20176/10943 (epoch 165.930) train_loss=465.19604492 time/batch=0.83s
setting learning rate to 0.0010331
20177/10943 (epoch 165.938) train_loss=747.54309082 time/batch=1.16s
20178/10943 (epoch 165.946) train_loss=638.79736328 time/batch=0.99s
20179/10943 (epoch 165.954) train_loss=693.88983154 time/batch=1.12s
20180/10943 (epoch 165.962) train_loss=1297.12280273 time/batch=2.33s
20181/10943 (epoch 165.971) train_loss=1084.09411621 time/batch=1.73s
20182/10943 (epoch 165.979) train_loss=1202.76794434 time/batch=3.20s
20183/10943 (epoch 165.987) train_loss=425.97253418 time/batch=0.95s
20184/10943 (epoch 165.995) train_loss=232.20385742 time/batch=0.42s
20185/10943 (epoch 166.004) train_loss=366.60385132 time/batch=0.58s
20186/10943 (epoch 166.012) train_loss=834.76159668 time/batch=1.29s
20187/10943 (epoch 166.020) train_loss=407.61264038 time/batch=0.75s
20188/10943 (epoch 166.028) train_loss=846.00677490 time/batch=1.34s
20189/10943 (epoch 166.036) train_loss=274.74304199 time/batch=0.57s
20190/10943 (epoch 166.045) train_loss=318.42282104 time/batch=0.55s
20191/10943 (epoch 166.053) train_loss=289.22186279 time/batch=0.50s
20192/10943 (epoch 166.061) train_loss=164.01126099 time/batch=0.30s
20193/10943 (epoch 166.069) train_loss=135.11022949 time/batch=0.26s
20194/10943 (epoch 166.078) train_loss=647.92779541 time/batch=0.96s
20195/10943 (epoch 166.086) train_loss=712.53460693 time/batch=1.12s
20196/10943 (epoch 166.094) train_loss=194.84083557 time/batch=0.40s
20197/10943 (epoch 166.102) train_loss=440.73126221 time/batch=0.68s
20198/10943 (epoch 166.111) train_loss=546.51550293 time/batch=0.89s
20199/10943 (epoch 166.119) train_loss=459.62500000 time/batch=0.80s
20200/10943 (epoch 166.127) train_loss=301.69097900 time/batch=0.54s
20201/10943 (epoch 166.135) train_loss=256.57418823 time/batch=0.43s
20202/10943 (epoch 166.143) train_loss=249.13615417 time/batch=0.43s
20203/10943 (epoch 166.152) train_loss=290.02670288 time/batch=0.50s
20204/10943 (epoch 166.160) train_loss=407.40185547 time/batch=0.69s
20205/10943 (epoch 166.168) train_loss=282.46624756 time/batch=0.49s
20206/10943 (epoch 166.176) train_loss=221.28790283 time/batch=0.40s
20207/10943 (epoch 166.185) train_loss=553.12341309 time/batch=0.88s
20208/10943 (epoch 166.193) train_loss=335.68762207 time/batch=0.61s
20209/10943 (epoch 166.201) train_loss=471.04791260 time/batch=0.78s
20210/10943 (epoch 166.209) train_loss=864.26599121 time/batch=1.43s
20211/10943 (epoch 166.217) train_loss=684.40075684 time/batch=1.11s
20212/10943 (epoch 166.226) train_loss=793.25323486 time/batch=1.24s
20213/10943 (epoch 166.234) train_loss=189.63055420 time/batch=0.41s
20214/10943 (epoch 166.242) train_loss=672.83654785 time/batch=1.06s
20215/10943 (epoch 166.250) train_loss=440.68469238 time/batch=0.77s
20216/10943 (epoch 166.259) train_loss=222.71171570 time/batch=0.40s
20217/10943 (epoch 166.267) train_loss=311.15136719 time/batch=0.53s
20218/10943 (epoch 166.275) train_loss=221.43820190 time/batch=0.40s
20219/10943 (epoch 166.283) train_loss=423.71981812 time/batch=0.69s
20220/10943 (epoch 166.291) train_loss=691.22827148 time/batch=1.16s
20221/10943 (epoch 166.300) train_loss=415.50332642 time/batch=0.74s
20222/10943 (epoch 166.308) train_loss=178.45196533 time/batch=0.33s
20223/10943 (epoch 166.316) train_loss=611.14318848 time/batch=0.96s
20224/10943 (epoch 166.324) train_loss=476.34338379 time/batch=0.81s
20225/10943 (epoch 166.333) train_loss=384.56445312 time/batch=0.65s
20226/10943 (epoch 166.341) train_loss=227.62016296 time/batch=0.42s
20227/10943 (epoch 166.349) train_loss=426.79199219 time/batch=0.67s
20228/10943 (epoch 166.357) train_loss=551.00671387 time/batch=0.93s
20229/10943 (epoch 166.365) train_loss=542.42645264 time/batch=0.92s
20230/10943 (epoch 166.374) train_loss=450.57635498 time/batch=0.77s
20231/10943 (epoch 166.382) train_loss=285.80462646 time/batch=0.50s
20232/10943 (epoch 166.390) train_loss=701.95660400 time/batch=1.19s
20233/10943 (epoch 166.398) train_loss=548.87829590 time/batch=1.00s
20234/10943 (epoch 166.407) train_loss=335.15972900 time/batch=0.61s
20235/10943 (epoch 166.415) train_loss=445.77191162 time/batch=0.71s
20236/10943 (epoch 166.423) train_loss=495.41238403 time/batch=0.83s
20237/10943 (epoch 166.431) train_loss=441.59994507 time/batch=0.77s
20238/10943 (epoch 166.439) train_loss=675.61779785 time/batch=1.22s
20239/10943 (epoch 166.448) train_loss=259.91571045 time/batch=0.53s
20240/10943 (epoch 166.456) train_loss=440.55987549 time/batch=0.70s
20241/10943 (epoch 166.464) train_loss=436.70867920 time/batch=0.75s
20242/10943 (epoch 166.472) train_loss=359.74243164 time/batch=0.64s
20243/10943 (epoch 166.481) train_loss=265.27337646 time/batch=0.47s
20244/10943 (epoch 166.489) train_loss=180.45446777 time/batch=0.33s
20245/10943 (epoch 166.497) train_loss=340.63381958 time/batch=0.56s
20246/10943 (epoch 166.505) train_loss=365.49206543 time/batch=0.63s
20247/10943 (epoch 166.513) train_loss=294.36474609 time/batch=0.53s
20248/10943 (epoch 166.522) train_loss=481.87646484 time/batch=0.80s
20249/10943 (epoch 166.530) train_loss=426.27136230 time/batch=0.70s
20250/10943 (epoch 166.538) train_loss=650.88830566 time/batch=1.01s
20251/10943 (epoch 166.546) train_loss=264.81762695 time/batch=0.51s
20252/10943 (epoch 166.555) train_loss=502.61535645 time/batch=0.83s
20253/10943 (epoch 166.563) train_loss=532.98693848 time/batch=0.96s
20254/10943 (epoch 166.571) train_loss=449.93081665 time/batch=0.79s
20255/10943 (epoch 166.579) train_loss=304.80596924 time/batch=0.55s
20256/10943 (epoch 166.588) train_loss=554.75305176 time/batch=0.93s
20257/10943 (epoch 166.596) train_loss=169.56948853 time/batch=0.39s
20258/10943 (epoch 166.604) train_loss=415.37960815 time/batch=0.66s
20259/10943 (epoch 166.612) train_loss=327.11849976 time/batch=0.58s
20260/10943 (epoch 166.620) train_loss=557.89892578 time/batch=0.93s
20261/10943 (epoch 166.629) train_loss=283.43988037 time/batch=0.55s
20262/10943 (epoch 166.637) train_loss=562.98883057 time/batch=0.93s
20263/10943 (epoch 166.645) train_loss=548.39770508 time/batch=1.00s
20264/10943 (epoch 166.653) train_loss=294.46166992 time/batch=0.57s
20265/10943 (epoch 166.662) train_loss=622.43701172 time/batch=1.40s
20266/10943 (epoch 166.670) train_loss=351.99133301 time/batch=0.70s
20267/10943 (epoch 166.678) train_loss=511.86376953 time/batch=0.96s
20268/10943 (epoch 166.686) train_loss=354.37905884 time/batch=0.65s
20269/10943 (epoch 166.694) train_loss=464.57028198 time/batch=0.78s
20270/10943 (epoch 166.703) train_loss=407.08618164 time/batch=0.69s
20271/10943 (epoch 166.711) train_loss=399.20867920 time/batch=0.66s
20272/10943 (epoch 166.719) train_loss=438.00592041 time/batch=0.75s
20273/10943 (epoch 166.727) train_loss=483.99169922 time/batch=0.82s
20274/10943 (epoch 166.736) train_loss=374.49200439 time/batch=0.66s
20275/10943 (epoch 166.744) train_loss=330.03948975 time/batch=0.60s
20276/10943 (epoch 166.752) train_loss=211.23645020 time/batch=0.38s
20277/10943 (epoch 166.760) train_loss=334.28457642 time/batch=0.56s
20278/10943 (epoch 166.768) train_loss=480.45755005 time/batch=0.82s
20279/10943 (epoch 166.777) train_loss=208.30726624 time/batch=0.40s
20280/10943 (epoch 166.785) train_loss=497.61346436 time/batch=0.81s
20281/10943 (epoch 166.793) train_loss=475.59719849 time/batch=0.82s
20282/10943 (epoch 166.801) train_loss=397.74368286 time/batch=0.68s
20283/10943 (epoch 166.810) train_loss=386.92630005 time/batch=0.67s
20284/10943 (epoch 166.818) train_loss=462.58856201 time/batch=0.77s
20285/10943 (epoch 166.826) train_loss=464.41748047 time/batch=0.80s
20286/10943 (epoch 166.834) train_loss=504.60931396 time/batch=1.42s
20287/10943 (epoch 166.842) train_loss=304.79492188 time/batch=0.63s
20288/10943 (epoch 166.851) train_loss=192.74932861 time/batch=0.36s
20289/10943 (epoch 166.859) train_loss=401.76239014 time/batch=0.72s
20290/10943 (epoch 166.867) train_loss=356.32519531 time/batch=0.66s
20291/10943 (epoch 166.875) train_loss=342.72497559 time/batch=0.61s
20292/10943 (epoch 166.884) train_loss=211.77801514 time/batch=0.43s
20293/10943 (epoch 166.892) train_loss=330.70050049 time/batch=0.57s
20294/10943 (epoch 166.900) train_loss=352.54333496 time/batch=0.63s
20295/10943 (epoch 166.908) train_loss=334.31365967 time/batch=0.60s
20296/10943 (epoch 166.916) train_loss=497.06921387 time/batch=0.82s
20297/10943 (epoch 166.925) train_loss=476.90780640 time/batch=0.84s
setting learning rate to 0.0010021
20298/10943 (epoch 166.933) train_loss=815.12377930 time/batch=1.26s
20299/10943 (epoch 166.941) train_loss=539.43933105 time/batch=0.90s
20300/10943 (epoch 166.949) train_loss=227.75430298 time/batch=0.42s
20301/10943 (epoch 166.958) train_loss=355.94686890 time/batch=0.60s
20302/10943 (epoch 166.966) train_loss=539.80035400 time/batch=0.87s
20303/10943 (epoch 166.974) train_loss=862.77087402 time/batch=1.47s
20304/10943 (epoch 166.982) train_loss=907.75109863 time/batch=1.40s
20305/10943 (epoch 166.990) train_loss=312.38830566 time/batch=0.58s
20306/10943 (epoch 166.999) train_loss=169.47830200 time/batch=0.31s
20307/10943 (epoch 167.007) train_loss=366.20422363 time/batch=0.61s
20308/10943 (epoch 167.015) train_loss=937.26416016 time/batch=1.54s
20309/10943 (epoch 167.023) train_loss=244.87571716 time/batch=0.55s
20310/10943 (epoch 167.032) train_loss=527.42871094 time/batch=0.86s
20311/10943 (epoch 167.040) train_loss=200.82656860 time/batch=0.39s
20312/10943 (epoch 167.048) train_loss=248.07969666 time/batch=0.42s
20313/10943 (epoch 167.056) train_loss=238.93536377 time/batch=0.43s
20314/10943 (epoch 167.065) train_loss=183.22393799 time/batch=0.33s
20315/10943 (epoch 167.073) train_loss=368.24816895 time/batch=0.60s
20316/10943 (epoch 167.081) train_loss=779.84808350 time/batch=1.34s
20317/10943 (epoch 167.089) train_loss=1422.17553711 time/batch=3.16s
20318/10943 (epoch 167.097) train_loss=538.87512207 time/batch=1.13s
20319/10943 (epoch 167.106) train_loss=723.04357910 time/batch=1.11s
20320/10943 (epoch 167.114) train_loss=646.49877930 time/batch=1.06s
20321/10943 (epoch 167.122) train_loss=211.91528320 time/batch=0.43s
20322/10943 (epoch 167.130) train_loss=275.61608887 time/batch=0.46s
20323/10943 (epoch 167.139) train_loss=537.80041504 time/batch=0.89s
20324/10943 (epoch 167.147) train_loss=260.65698242 time/batch=0.49s
20325/10943 (epoch 167.155) train_loss=134.20431519 time/batch=0.27s
20326/10943 (epoch 167.163) train_loss=339.81176758 time/batch=0.57s
20327/10943 (epoch 167.171) train_loss=459.12911987 time/batch=0.78s
20328/10943 (epoch 167.180) train_loss=395.98797607 time/batch=0.68s
20329/10943 (epoch 167.188) train_loss=202.11622620 time/batch=0.39s
20330/10943 (epoch 167.196) train_loss=451.66345215 time/batch=0.73s
20331/10943 (epoch 167.204) train_loss=1029.94140625 time/batch=1.69s
20332/10943 (epoch 167.213) train_loss=387.55468750 time/batch=0.75s
20333/10943 (epoch 167.221) train_loss=430.83612061 time/batch=0.68s
20334/10943 (epoch 167.229) train_loss=700.21826172 time/batch=1.15s
20335/10943 (epoch 167.237) train_loss=471.12368774 time/batch=0.83s
20336/10943 (epoch 167.245) train_loss=447.01190186 time/batch=0.75s
20337/10943 (epoch 167.254) train_loss=289.57516479 time/batch=0.52s
20338/10943 (epoch 167.262) train_loss=639.34594727 time/batch=1.05s
20339/10943 (epoch 167.270) train_loss=440.96405029 time/batch=0.79s
20340/10943 (epoch 167.278) train_loss=373.83197021 time/batch=0.66s
20341/10943 (epoch 167.287) train_loss=314.99893188 time/batch=0.56s
20342/10943 (epoch 167.295) train_loss=635.37878418 time/batch=0.97s
20343/10943 (epoch 167.303) train_loss=396.35021973 time/batch=0.73s
20344/10943 (epoch 167.311) train_loss=377.22247314 time/batch=0.67s
20345/10943 (epoch 167.319) train_loss=277.50326538 time/batch=0.51s
20346/10943 (epoch 167.328) train_loss=518.19543457 time/batch=0.87s
20347/10943 (epoch 167.336) train_loss=412.15466309 time/batch=0.71s
20348/10943 (epoch 167.344) train_loss=569.35559082 time/batch=0.95s
20349/10943 (epoch 167.352) train_loss=362.64608765 time/batch=0.66s
20350/10943 (epoch 167.361) train_loss=435.50430298 time/batch=0.71s
20351/10943 (epoch 167.369) train_loss=442.16720581 time/batch=0.78s
20352/10943 (epoch 167.377) train_loss=584.05798340 time/batch=0.98s
20353/10943 (epoch 167.385) train_loss=322.46472168 time/batch=0.60s
20354/10943 (epoch 167.393) train_loss=427.47863770 time/batch=0.70s
20355/10943 (epoch 167.402) train_loss=401.23797607 time/batch=0.71s
20356/10943 (epoch 167.410) train_loss=627.06945801 time/batch=1.05s
20357/10943 (epoch 167.418) train_loss=478.13754272 time/batch=0.84s
20358/10943 (epoch 167.426) train_loss=415.73791504 time/batch=0.74s
20359/10943 (epoch 167.435) train_loss=274.88555908 time/batch=0.50s
20360/10943 (epoch 167.443) train_loss=288.43249512 time/batch=0.50s
20361/10943 (epoch 167.451) train_loss=335.37963867 time/batch=0.56s
20362/10943 (epoch 167.459) train_loss=614.23309326 time/batch=1.01s
20363/10943 (epoch 167.467) train_loss=303.42352295 time/batch=0.59s
20364/10943 (epoch 167.476) train_loss=195.69436646 time/batch=0.36s
20365/10943 (epoch 167.484) train_loss=573.82397461 time/batch=0.96s
20366/10943 (epoch 167.492) train_loss=718.26190186 time/batch=1.21s
20367/10943 (epoch 167.500) train_loss=346.34118652 time/batch=0.64s
20368/10943 (epoch 167.509) train_loss=697.59259033 time/batch=1.17s
20369/10943 (epoch 167.517) train_loss=548.62426758 time/batch=0.95s
20370/10943 (epoch 167.525) train_loss=399.80468750 time/batch=0.69s
20371/10943 (epoch 167.533) train_loss=464.11849976 time/batch=0.78s
20372/10943 (epoch 167.542) train_loss=292.71832275 time/batch=0.57s
20373/10943 (epoch 167.550) train_loss=186.07614136 time/batch=0.38s
20374/10943 (epoch 167.558) train_loss=385.95507812 time/batch=0.64s
20375/10943 (epoch 167.566) train_loss=312.50714111 time/batch=0.55s
20376/10943 (epoch 167.574) train_loss=495.79925537 time/batch=0.82s
20377/10943 (epoch 167.583) train_loss=522.15173340 time/batch=0.89s
20378/10943 (epoch 167.591) train_loss=569.94433594 time/batch=1.05s
20379/10943 (epoch 167.599) train_loss=342.59173584 time/batch=0.63s
20380/10943 (epoch 167.607) train_loss=230.32106018 time/batch=0.41s
20381/10943 (epoch 167.616) train_loss=342.76864624 time/batch=0.60s
20382/10943 (epoch 167.624) train_loss=572.83581543 time/batch=1.00s
20383/10943 (epoch 167.632) train_loss=424.58862305 time/batch=0.78s
20384/10943 (epoch 167.640) train_loss=212.82270813 time/batch=0.43s
20385/10943 (epoch 167.648) train_loss=209.46600342 time/batch=0.39s
20386/10943 (epoch 167.657) train_loss=259.14517212 time/batch=0.49s
20387/10943 (epoch 167.665) train_loss=443.63586426 time/batch=0.75s
20388/10943 (epoch 167.673) train_loss=234.64260864 time/batch=0.47s
20389/10943 (epoch 167.681) train_loss=683.18969727 time/batch=1.17s
20390/10943 (epoch 167.690) train_loss=328.88372803 time/batch=0.65s
20391/10943 (epoch 167.698) train_loss=495.88226318 time/batch=0.88s
20392/10943 (epoch 167.706) train_loss=508.27178955 time/batch=0.93s
20393/10943 (epoch 167.714) train_loss=597.42517090 time/batch=1.07s
20394/10943 (epoch 167.722) train_loss=411.95083618 time/batch=0.73s
20395/10943 (epoch 167.731) train_loss=150.27389526 time/batch=0.31s
20396/10943 (epoch 167.739) train_loss=170.40667725 time/batch=0.30s
20397/10943 (epoch 167.747) train_loss=413.08215332 time/batch=0.68s
20398/10943 (epoch 167.755) train_loss=429.48757935 time/batch=0.75s
20399/10943 (epoch 167.764) train_loss=477.36981201 time/batch=0.85s
20400/10943 (epoch 167.772) train_loss=379.37725830 time/batch=0.66s
20401/10943 (epoch 167.780) train_loss=441.08386230 time/batch=0.79s
20402/10943 (epoch 167.788) train_loss=605.36401367 time/batch=1.11s
20403/10943 (epoch 167.796) train_loss=301.63208008 time/batch=0.62s
20404/10943 (epoch 167.805) train_loss=469.87692261 time/batch=0.80s
20405/10943 (epoch 167.813) train_loss=462.79626465 time/batch=0.82s
20406/10943 (epoch 167.821) train_loss=428.63281250 time/batch=0.76s
20407/10943 (epoch 167.829) train_loss=216.20159912 time/batch=0.49s
20408/10943 (epoch 167.838) train_loss=453.61062622 time/batch=0.79s
20409/10943 (epoch 167.846) train_loss=414.66412354 time/batch=0.76s
20410/10943 (epoch 167.854) train_loss=388.64434814 time/batch=0.70s
20411/10943 (epoch 167.862) train_loss=285.68133545 time/batch=0.59s
20412/10943 (epoch 167.870) train_loss=472.95935059 time/batch=0.83s
20413/10943 (epoch 167.879) train_loss=344.19000244 time/batch=0.63s
20414/10943 (epoch 167.887) train_loss=250.64627075 time/batch=0.47s
20415/10943 (epoch 167.895) train_loss=345.89486694 time/batch=0.78s
20416/10943 (epoch 167.903) train_loss=316.44796753 time/batch=0.61s
20417/10943 (epoch 167.912) train_loss=326.65673828 time/batch=0.59s
20418/10943 (epoch 167.920) train_loss=383.27081299 time/batch=0.80s
setting learning rate to 0.0009720
20419/10943 (epoch 167.928) train_loss=224.17526245 time/batch=0.42s
20420/10943 (epoch 167.936) train_loss=779.26818848 time/batch=1.22s
20421/10943 (epoch 167.944) train_loss=584.89721680 time/batch=1.03s
20422/10943 (epoch 167.953) train_loss=535.24011230 time/batch=0.90s
20423/10943 (epoch 167.961) train_loss=143.16024780 time/batch=0.32s
20424/10943 (epoch 167.969) train_loss=1340.72314453 time/batch=3.05s
20425/10943 (epoch 167.977) train_loss=766.93383789 time/batch=1.42s
20426/10943 (epoch 167.986) train_loss=448.30444336 time/batch=0.79s
20427/10943 (epoch 167.994) train_loss=319.96966553 time/batch=0.59s
20428/10943 (epoch 168.002) train_loss=748.05908203 time/batch=1.19s
20429/10943 (epoch 168.010) train_loss=467.04098511 time/batch=0.83s
20430/10943 (epoch 168.019) train_loss=853.54284668 time/batch=1.49s
20431/10943 (epoch 168.027) train_loss=468.33728027 time/batch=0.89s
20432/10943 (epoch 168.035) train_loss=1012.19958496 time/batch=1.68s
20433/10943 (epoch 168.043) train_loss=513.68157959 time/batch=0.96s
20434/10943 (epoch 168.051) train_loss=876.70788574 time/batch=1.56s
20435/10943 (epoch 168.060) train_loss=293.64837646 time/batch=0.62s
20436/10943 (epoch 168.068) train_loss=464.33816528 time/batch=0.79s
20437/10943 (epoch 168.076) train_loss=421.23773193 time/batch=0.74s
20438/10943 (epoch 168.084) train_loss=482.76632690 time/batch=0.86s
20439/10943 (epoch 168.093) train_loss=153.92047119 time/batch=0.33s
20440/10943 (epoch 168.101) train_loss=396.37689209 time/batch=0.65s
20441/10943 (epoch 168.109) train_loss=582.28063965 time/batch=1.00s
20442/10943 (epoch 168.117) train_loss=437.35394287 time/batch=0.81s
20443/10943 (epoch 168.125) train_loss=164.98004150 time/batch=0.34s
20444/10943 (epoch 168.134) train_loss=480.51147461 time/batch=0.79s
20445/10943 (epoch 168.142) train_loss=392.64697266 time/batch=0.68s
20446/10943 (epoch 168.150) train_loss=673.68902588 time/batch=1.13s
20447/10943 (epoch 168.158) train_loss=423.53338623 time/batch=0.79s
20448/10943 (epoch 168.167) train_loss=788.75164795 time/batch=1.29s
20449/10943 (epoch 168.175) train_loss=648.07733154 time/batch=1.13s
20450/10943 (epoch 168.183) train_loss=204.62020874 time/batch=0.43s
20451/10943 (epoch 168.191) train_loss=618.74230957 time/batch=0.97s
20452/10943 (epoch 168.199) train_loss=369.26766968 time/batch=0.68s
20453/10943 (epoch 168.208) train_loss=793.24353027 time/batch=1.33s
20454/10943 (epoch 168.216) train_loss=589.67633057 time/batch=1.02s
20455/10943 (epoch 168.224) train_loss=295.51538086 time/batch=0.56s
20456/10943 (epoch 168.232) train_loss=683.45159912 time/batch=1.06s
20457/10943 (epoch 168.241) train_loss=693.30194092 time/batch=1.40s
20458/10943 (epoch 168.249) train_loss=192.47344971 time/batch=0.43s
20459/10943 (epoch 168.257) train_loss=643.91027832 time/batch=1.06s
20460/10943 (epoch 168.265) train_loss=573.26483154 time/batch=1.01s
20461/10943 (epoch 168.273) train_loss=570.78942871 time/batch=0.98s
20462/10943 (epoch 168.282) train_loss=314.33264160 time/batch=0.59s
20463/10943 (epoch 168.290) train_loss=450.08654785 time/batch=0.77s
20464/10943 (epoch 168.298) train_loss=306.30886841 time/batch=0.58s
20465/10943 (epoch 168.306) train_loss=169.71017456 time/batch=0.32s
20466/10943 (epoch 168.315) train_loss=622.96380615 time/batch=0.99s
20467/10943 (epoch 168.323) train_loss=405.76654053 time/batch=0.71s
20468/10943 (epoch 168.331) train_loss=286.75183105 time/batch=0.54s
20469/10943 (epoch 168.339) train_loss=555.17156982 time/batch=0.96s
20470/10943 (epoch 168.347) train_loss=441.67858887 time/batch=0.78s
20471/10943 (epoch 168.356) train_loss=587.50988770 time/batch=1.00s
20472/10943 (epoch 168.364) train_loss=299.96575928 time/batch=0.58s
20473/10943 (epoch 168.372) train_loss=264.70068359 time/batch=0.46s
20474/10943 (epoch 168.380) train_loss=226.31250000 time/batch=0.41s
20475/10943 (epoch 168.389) train_loss=459.97128296 time/batch=0.76s
20476/10943 (epoch 168.397) train_loss=232.74508667 time/batch=0.46s
20477/10943 (epoch 168.405) train_loss=517.19543457 time/batch=0.87s
20478/10943 (epoch 168.413) train_loss=387.17260742 time/batch=0.70s
20479/10943 (epoch 168.421) train_loss=244.71583557 time/batch=0.44s
20480/10943 (epoch 168.430) train_loss=249.69120789 time/batch=0.44s
20481/10943 (epoch 168.438) train_loss=198.41477966 time/batch=0.36s
20482/10943 (epoch 168.446) train_loss=428.26754761 time/batch=0.71s
20483/10943 (epoch 168.454) train_loss=175.77127075 time/batch=0.35s
20484/10943 (epoch 168.463) train_loss=277.93261719 time/batch=0.49s
20485/10943 (epoch 168.471) train_loss=528.27374268 time/batch=0.89s
20486/10943 (epoch 168.479) train_loss=518.53771973 time/batch=0.89s
20487/10943 (epoch 168.487) train_loss=368.49810791 time/batch=0.67s
20488/10943 (epoch 168.496) train_loss=379.46209717 time/batch=0.65s
20489/10943 (epoch 168.504) train_loss=400.92065430 time/batch=0.66s
20490/10943 (epoch 168.512) train_loss=245.43402100 time/batch=0.46s
20491/10943 (epoch 168.520) train_loss=394.97702026 time/batch=0.67s
20492/10943 (epoch 168.528) train_loss=346.62634277 time/batch=0.59s
20493/10943 (epoch 168.537) train_loss=502.87695312 time/batch=0.86s
20494/10943 (epoch 168.545) train_loss=201.03413391 time/batch=0.41s
20495/10943 (epoch 168.553) train_loss=613.33776855 time/batch=1.06s
20496/10943 (epoch 168.561) train_loss=341.92163086 time/batch=0.64s
20497/10943 (epoch 168.570) train_loss=539.05407715 time/batch=0.86s
20498/10943 (epoch 168.578) train_loss=342.24664307 time/batch=0.64s
20499/10943 (epoch 168.586) train_loss=280.09573364 time/batch=0.51s
20500/10943 (epoch 168.594) train_loss=216.13331604 time/batch=0.40s
20501/10943 (epoch 168.602) train_loss=518.27172852 time/batch=0.88s
20502/10943 (epoch 168.611) train_loss=430.68640137 time/batch=0.74s
20503/10943 (epoch 168.619) train_loss=330.11694336 time/batch=0.59s
20504/10943 (epoch 168.627) train_loss=428.29354858 time/batch=0.73s
20505/10943 (epoch 168.635) train_loss=445.07040405 time/batch=0.79s
20506/10943 (epoch 168.644) train_loss=453.57165527 time/batch=0.82s
20507/10943 (epoch 168.652) train_loss=387.04699707 time/batch=0.67s
20508/10943 (epoch 168.660) train_loss=313.99142456 time/batch=0.58s
20509/10943 (epoch 168.668) train_loss=198.89662170 time/batch=0.38s
20510/10943 (epoch 168.676) train_loss=406.70169067 time/batch=0.65s
20511/10943 (epoch 168.685) train_loss=408.62969971 time/batch=0.69s
20512/10943 (epoch 168.693) train_loss=462.18969727 time/batch=0.81s
20513/10943 (epoch 168.701) train_loss=453.82623291 time/batch=0.78s
20514/10943 (epoch 168.709) train_loss=466.72952271 time/batch=0.82s
20515/10943 (epoch 168.718) train_loss=362.64303589 time/batch=0.68s
20516/10943 (epoch 168.726) train_loss=217.49693298 time/batch=0.45s
20517/10943 (epoch 168.734) train_loss=227.99591064 time/batch=0.45s
20518/10943 (epoch 168.742) train_loss=176.14381409 time/batch=0.37s
20519/10943 (epoch 168.750) train_loss=269.87524414 time/batch=0.47s
20520/10943 (epoch 168.759) train_loss=341.66552734 time/batch=0.59s
20521/10943 (epoch 168.767) train_loss=429.46978760 time/batch=0.73s
20522/10943 (epoch 168.775) train_loss=436.52508545 time/batch=0.80s
20523/10943 (epoch 168.783) train_loss=284.51727295 time/batch=0.53s
20524/10943 (epoch 168.792) train_loss=473.86239624 time/batch=0.81s
20525/10943 (epoch 168.800) train_loss=333.58831787 time/batch=0.62s
20526/10943 (epoch 168.808) train_loss=350.79953003 time/batch=0.61s
20527/10943 (epoch 168.816) train_loss=263.51495361 time/batch=0.47s
20528/10943 (epoch 168.824) train_loss=338.16503906 time/batch=0.58s
20529/10943 (epoch 168.833) train_loss=315.31341553 time/batch=0.57s
20530/10943 (epoch 168.841) train_loss=294.15637207 time/batch=0.56s
20531/10943 (epoch 168.849) train_loss=255.19586182 time/batch=0.52s
20532/10943 (epoch 168.857) train_loss=352.57714844 time/batch=0.64s
20533/10943 (epoch 168.866) train_loss=496.13223267 time/batch=0.82s
20534/10943 (epoch 168.874) train_loss=489.79339600 time/batch=0.86s
20535/10943 (epoch 168.882) train_loss=432.65179443 time/batch=0.73s
20536/10943 (epoch 168.890) train_loss=324.03573608 time/batch=0.61s
20537/10943 (epoch 168.898) train_loss=351.85797119 time/batch=0.61s
20538/10943 (epoch 168.907) train_loss=385.71560669 time/batch=0.70s
20539/10943 (epoch 168.915) train_loss=346.80126953 time/batch=0.71s
setting learning rate to 0.0009429
20540/10943 (epoch 168.923) train_loss=492.24005127 time/batch=0.85s
20541/10943 (epoch 168.931) train_loss=211.92411804 time/batch=0.41s
20542/10943 (epoch 168.940) train_loss=453.07553101 time/batch=0.75s
20543/10943 (epoch 168.948) train_loss=271.05572510 time/batch=0.50s
20544/10943 (epoch 168.956) train_loss=641.90917969 time/batch=1.05s
20545/10943 (epoch 168.964) train_loss=493.16534424 time/batch=0.87s
20546/10943 (epoch 168.973) train_loss=866.99591064 time/batch=1.32s
20547/10943 (epoch 168.981) train_loss=1311.89306641 time/batch=2.23s
20548/10943 (epoch 168.989) train_loss=775.49841309 time/batch=1.32s
20549/10943 (epoch 168.997) train_loss=767.75555420 time/batch=1.27s
20550/10943 (epoch 169.005) train_loss=845.38098145 time/batch=1.43s
20551/10943 (epoch 169.014) train_loss=1095.55786133 time/batch=2.28s
20552/10943 (epoch 169.022) train_loss=357.05688477 time/batch=0.79s
20553/10943 (epoch 169.030) train_loss=660.31610107 time/batch=1.04s
20554/10943 (epoch 169.038) train_loss=692.07427979 time/batch=1.21s
20555/10943 (epoch 169.047) train_loss=622.39855957 time/batch=1.07s
20556/10943 (epoch 169.055) train_loss=477.06375122 time/batch=0.85s
20557/10943 (epoch 169.063) train_loss=1079.62744141 time/batch=3.11s
20558/10943 (epoch 169.071) train_loss=261.34014893 time/batch=0.71s
20559/10943 (epoch 169.079) train_loss=145.67819214 time/batch=0.27s
20560/10943 (epoch 169.088) train_loss=293.90744019 time/batch=0.49s
20561/10943 (epoch 169.096) train_loss=470.91296387 time/batch=0.76s
20562/10943 (epoch 169.104) train_loss=515.49523926 time/batch=0.87s
20563/10943 (epoch 169.112) train_loss=406.28857422 time/batch=0.69s
20564/10943 (epoch 169.121) train_loss=174.20692444 time/batch=0.34s
20565/10943 (epoch 169.129) train_loss=775.62054443 time/batch=1.20s
20566/10943 (epoch 169.137) train_loss=291.40002441 time/batch=0.57s
20567/10943 (epoch 169.145) train_loss=164.31867981 time/batch=0.29s
20568/10943 (epoch 169.153) train_loss=505.20046997 time/batch=0.81s
20569/10943 (epoch 169.162) train_loss=429.47283936 time/batch=0.76s
20570/10943 (epoch 169.170) train_loss=580.14477539 time/batch=0.94s
20571/10943 (epoch 169.178) train_loss=421.71850586 time/batch=0.72s
20572/10943 (epoch 169.186) train_loss=229.42893982 time/batch=0.42s
20573/10943 (epoch 169.195) train_loss=402.63888550 time/batch=0.64s
20574/10943 (epoch 169.203) train_loss=331.29437256 time/batch=0.60s
20575/10943 (epoch 169.211) train_loss=462.15332031 time/batch=0.78s
20576/10943 (epoch 169.219) train_loss=467.21102905 time/batch=0.80s
20577/10943 (epoch 169.227) train_loss=677.50799561 time/batch=1.10s
20578/10943 (epoch 169.236) train_loss=549.22442627 time/batch=0.91s
20579/10943 (epoch 169.244) train_loss=441.12570190 time/batch=0.78s
20580/10943 (epoch 169.252) train_loss=550.85894775 time/batch=0.92s
20581/10943 (epoch 169.260) train_loss=180.19003296 time/batch=0.37s
20582/10943 (epoch 169.269) train_loss=236.68835449 time/batch=0.41s
20583/10943 (epoch 169.277) train_loss=258.33709717 time/batch=0.45s
20584/10943 (epoch 169.285) train_loss=357.36795044 time/batch=0.61s
20585/10943 (epoch 169.293) train_loss=601.42272949 time/batch=0.97s
20586/10943 (epoch 169.301) train_loss=494.01455688 time/batch=0.87s
20587/10943 (epoch 169.310) train_loss=291.02557373 time/batch=0.54s
20588/10943 (epoch 169.318) train_loss=512.83703613 time/batch=0.85s
20589/10943 (epoch 169.326) train_loss=618.91192627 time/batch=1.04s
20590/10943 (epoch 169.334) train_loss=378.36383057 time/batch=0.68s
20591/10943 (epoch 169.343) train_loss=411.46347046 time/batch=0.67s
20592/10943 (epoch 169.351) train_loss=219.03836060 time/batch=0.40s
20593/10943 (epoch 169.359) train_loss=548.40429688 time/batch=0.88s
20594/10943 (epoch 169.367) train_loss=455.16143799 time/batch=0.81s
20595/10943 (epoch 169.375) train_loss=806.40722656 time/batch=1.44s
20596/10943 (epoch 169.384) train_loss=464.31341553 time/batch=0.82s
20597/10943 (epoch 169.392) train_loss=191.46148682 time/batch=0.36s
20598/10943 (epoch 169.400) train_loss=537.94244385 time/batch=0.85s
20599/10943 (epoch 169.408) train_loss=163.09602356 time/batch=0.36s
20600/10943 (epoch 169.417) train_loss=270.76651001 time/batch=0.46s
20601/10943 (epoch 169.425) train_loss=388.64739990 time/batch=0.63s
20602/10943 (epoch 169.433) train_loss=360.70108032 time/batch=0.62s
20603/10943 (epoch 169.441) train_loss=529.81665039 time/batch=0.88s
20604/10943 (epoch 169.449) train_loss=208.54217529 time/batch=0.40s
20605/10943 (epoch 169.458) train_loss=292.50827026 time/batch=0.52s
20606/10943 (epoch 169.466) train_loss=568.13891602 time/batch=0.94s
20607/10943 (epoch 169.474) train_loss=383.43850708 time/batch=0.69s
20608/10943 (epoch 169.482) train_loss=260.05346680 time/batch=0.48s
20609/10943 (epoch 169.491) train_loss=293.79589844 time/batch=0.50s
20610/10943 (epoch 169.499) train_loss=392.82009888 time/batch=0.69s
20611/10943 (epoch 169.507) train_loss=171.31066895 time/batch=0.37s
20612/10943 (epoch 169.515) train_loss=486.01629639 time/batch=0.79s
20613/10943 (epoch 169.524) train_loss=353.15939331 time/batch=0.64s
20614/10943 (epoch 169.532) train_loss=283.45983887 time/batch=0.51s
20615/10943 (epoch 169.540) train_loss=488.48468018 time/batch=0.80s
20616/10943 (epoch 169.548) train_loss=366.03552246 time/batch=0.64s
20617/10943 (epoch 169.556) train_loss=439.25869751 time/batch=0.73s
20618/10943 (epoch 169.565) train_loss=250.56974792 time/batch=0.46s
20619/10943 (epoch 169.573) train_loss=671.86535645 time/batch=1.13s
20620/10943 (epoch 169.581) train_loss=475.89627075 time/batch=0.82s
20621/10943 (epoch 169.589) train_loss=541.21850586 time/batch=0.89s
20622/10943 (epoch 169.598) train_loss=623.89837646 time/batch=1.00s
20623/10943 (epoch 169.606) train_loss=403.43475342 time/batch=0.72s
20624/10943 (epoch 169.614) train_loss=635.69055176 time/batch=1.08s
20625/10943 (epoch 169.622) train_loss=330.25851440 time/batch=0.63s
20626/10943 (epoch 169.630) train_loss=283.56430054 time/batch=0.51s
20627/10943 (epoch 169.639) train_loss=452.53845215 time/batch=0.88s
20628/10943 (epoch 169.647) train_loss=337.19708252 time/batch=0.62s
20629/10943 (epoch 169.655) train_loss=560.78125000 time/batch=0.94s
20630/10943 (epoch 169.663) train_loss=454.00466919 time/batch=0.79s
20631/10943 (epoch 169.672) train_loss=606.87683105 time/batch=1.03s
20632/10943 (epoch 169.680) train_loss=474.17086792 time/batch=0.85s
20633/10943 (epoch 169.688) train_loss=473.14044189 time/batch=0.82s
20634/10943 (epoch 169.696) train_loss=226.27816772 time/batch=0.44s
20635/10943 (epoch 169.704) train_loss=196.44967651 time/batch=0.35s
20636/10943 (epoch 169.713) train_loss=343.31256104 time/batch=0.55s
20637/10943 (epoch 169.721) train_loss=421.56945801 time/batch=0.69s
20638/10943 (epoch 169.729) train_loss=358.42422485 time/batch=0.64s
20639/10943 (epoch 169.737) train_loss=419.75262451 time/batch=0.70s
20640/10943 (epoch 169.746) train_loss=378.31668091 time/batch=0.66s
20641/10943 (epoch 169.754) train_loss=446.94274902 time/batch=0.79s
20642/10943 (epoch 169.762) train_loss=348.69039917 time/batch=0.61s
20643/10943 (epoch 169.770) train_loss=257.67883301 time/batch=0.49s
20644/10943 (epoch 169.778) train_loss=427.46270752 time/batch=0.72s
20645/10943 (epoch 169.787) train_loss=196.66630554 time/batch=0.39s
20646/10943 (epoch 169.795) train_loss=306.72018433 time/batch=0.53s
20647/10943 (epoch 169.803) train_loss=305.13336182 time/batch=0.56s
20648/10943 (epoch 169.811) train_loss=373.72839355 time/batch=0.63s
20649/10943 (epoch 169.820) train_loss=335.50207520 time/batch=0.59s
20650/10943 (epoch 169.828) train_loss=333.17816162 time/batch=0.59s
20651/10943 (epoch 169.836) train_loss=210.54499817 time/batch=0.42s
20652/10943 (epoch 169.844) train_loss=284.48400879 time/batch=0.50s
20653/10943 (epoch 169.852) train_loss=306.94152832 time/batch=0.55s
20654/10943 (epoch 169.861) train_loss=269.09780884 time/batch=0.55s
20655/10943 (epoch 169.869) train_loss=391.27413940 time/batch=0.68s
20656/10943 (epoch 169.877) train_loss=439.51644897 time/batch=0.71s
20657/10943 (epoch 169.885) train_loss=422.35848999 time/batch=0.71s
20658/10943 (epoch 169.894) train_loss=434.46298218 time/batch=0.72s
20659/10943 (epoch 169.902) train_loss=354.55010986 time/batch=0.64s
20660/10943 (epoch 169.910) train_loss=302.07479858 time/batch=0.62s
setting learning rate to 0.0009146
  saved to metadata/gru_dropout-9_nov_folkwiki-20181115-204407_epoch59.pkl
20661/10943 (epoch 169.918) train_loss=622.19610596 time/batch=0.93s
20662/10943 (epoch 169.926) train_loss=751.62481689 time/batch=1.23s
20663/10943 (epoch 169.935) train_loss=290.46392822 time/batch=0.55s
20664/10943 (epoch 169.943) train_loss=398.03466797 time/batch=0.68s
20665/10943 (epoch 169.951) train_loss=246.40814209 time/batch=0.45s
20666/10943 (epoch 169.959) train_loss=773.81872559 time/batch=1.21s
20667/10943 (epoch 169.968) train_loss=424.02926636 time/batch=0.74s
20668/10943 (epoch 169.976) train_loss=560.01629639 time/batch=0.94s
20669/10943 (epoch 169.984) train_loss=173.97024536 time/batch=0.38s
20670/10943 (epoch 169.992) train_loss=356.67324829 time/batch=0.60s
20671/10943 (epoch 170.001) train_loss=670.56848145 time/batch=1.13s
20672/10943 (epoch 170.009) train_loss=1048.00964355 time/batch=1.72s
20673/10943 (epoch 170.017) train_loss=460.39169312 time/batch=0.84s
20674/10943 (epoch 170.025) train_loss=556.39501953 time/batch=0.91s
20675/10943 (epoch 170.033) train_loss=198.18705750 time/batch=0.40s
20676/10943 (epoch 170.042) train_loss=571.57714844 time/batch=0.92s
20677/10943 (epoch 170.050) train_loss=177.29318237 time/batch=0.38s
20678/10943 (epoch 170.058) train_loss=188.15911865 time/batch=0.34s
20679/10943 (epoch 170.066) train_loss=203.44636536 time/batch=0.35s
20680/10943 (epoch 170.075) train_loss=593.34069824 time/batch=0.96s
20681/10943 (epoch 170.083) train_loss=652.70812988 time/batch=1.10s
20682/10943 (epoch 170.091) train_loss=564.91223145 time/batch=0.97s
20683/10943 (epoch 170.099) train_loss=497.08624268 time/batch=0.88s
20684/10943 (epoch 170.107) train_loss=523.16186523 time/batch=0.87s
20685/10943 (epoch 170.116) train_loss=1133.11669922 time/batch=2.11s
20686/10943 (epoch 170.124) train_loss=235.20214844 time/batch=0.58s
20687/10943 (epoch 170.132) train_loss=135.79870605 time/batch=0.27s
20688/10943 (epoch 170.140) train_loss=443.37933350 time/batch=0.73s
20689/10943 (epoch 170.149) train_loss=814.60351562 time/batch=1.42s
20690/10943 (epoch 170.157) train_loss=316.89617920 time/batch=0.65s
20691/10943 (epoch 170.165) train_loss=346.74807739 time/batch=0.57s
20692/10943 (epoch 170.173) train_loss=176.24952698 time/batch=0.33s
20693/10943 (epoch 170.181) train_loss=1141.59606934 time/batch=3.07s
20694/10943 (epoch 170.190) train_loss=791.52734375 time/batch=1.47s
20695/10943 (epoch 170.198) train_loss=603.14227295 time/batch=1.00s
20696/10943 (epoch 170.206) train_loss=532.50244141 time/batch=0.91s
20697/10943 (epoch 170.214) train_loss=405.98168945 time/batch=0.71s
20698/10943 (epoch 170.223) train_loss=387.21716309 time/batch=0.66s
20699/10943 (epoch 170.231) train_loss=346.71234131 time/batch=0.61s
20700/10943 (epoch 170.239) train_loss=510.00906372 time/batch=0.86s
20701/10943 (epoch 170.247) train_loss=629.05560303 time/batch=1.02s
20702/10943 (epoch 170.255) train_loss=164.26925659 time/batch=0.36s
20703/10943 (epoch 170.264) train_loss=848.68298340 time/batch=1.38s
20704/10943 (epoch 170.272) train_loss=699.07177734 time/batch=1.19s
20705/10943 (epoch 170.280) train_loss=254.33267212 time/batch=0.51s
20706/10943 (epoch 170.288) train_loss=534.25640869 time/batch=0.84s
20707/10943 (epoch 170.297) train_loss=477.01873779 time/batch=0.85s
20708/10943 (epoch 170.305) train_loss=198.18992615 time/batch=0.41s
20709/10943 (epoch 170.313) train_loss=291.07635498 time/batch=0.50s
20710/10943 (epoch 170.321) train_loss=415.64013672 time/batch=0.68s
20711/10943 (epoch 170.329) train_loss=218.50508118 time/batch=0.42s
20712/10943 (epoch 170.338) train_loss=456.20123291 time/batch=0.73s
20713/10943 (epoch 170.346) train_loss=407.01062012 time/batch=0.68s
20714/10943 (epoch 170.354) train_loss=457.42935181 time/batch=0.81s
20715/10943 (epoch 170.362) train_loss=359.03125000 time/batch=0.64s
20716/10943 (epoch 170.371) train_loss=434.41571045 time/batch=0.75s
20717/10943 (epoch 170.379) train_loss=626.24444580 time/batch=1.04s
20718/10943 (epoch 170.387) train_loss=264.62844849 time/batch=0.52s
20719/10943 (epoch 170.395) train_loss=269.63217163 time/batch=0.48s
20720/10943 (epoch 170.403) train_loss=456.04714966 time/batch=0.79s
20721/10943 (epoch 170.412) train_loss=337.32553101 time/batch=0.62s
20722/10943 (epoch 170.420) train_loss=311.59118652 time/batch=0.55s
20723/10943 (epoch 170.428) train_loss=452.54461670 time/batch=0.76s
20724/10943 (epoch 170.436) train_loss=691.47320557 time/batch=1.10s
20725/10943 (epoch 170.445) train_loss=352.63067627 time/batch=0.64s
20726/10943 (epoch 170.453) train_loss=670.78076172 time/batch=1.10s
20727/10943 (epoch 170.461) train_loss=340.70556641 time/batch=0.62s
20728/10943 (epoch 170.469) train_loss=460.21539307 time/batch=0.79s
20729/10943 (epoch 170.478) train_loss=565.87530518 time/batch=0.98s
20730/10943 (epoch 170.486) train_loss=446.69848633 time/batch=0.74s
20731/10943 (epoch 170.494) train_loss=424.43957520 time/batch=0.72s
20732/10943 (epoch 170.502) train_loss=771.47265625 time/batch=1.28s
20733/10943 (epoch 170.510) train_loss=448.77331543 time/batch=0.82s
20734/10943 (epoch 170.519) train_loss=231.68338013 time/batch=0.44s
20735/10943 (epoch 170.527) train_loss=491.00390625 time/batch=0.79s
20736/10943 (epoch 170.535) train_loss=324.52682495 time/batch=0.60s
20737/10943 (epoch 170.543) train_loss=387.35974121 time/batch=0.64s
20738/10943 (epoch 170.552) train_loss=531.67443848 time/batch=0.89s
20739/10943 (epoch 170.560) train_loss=369.19854736 time/batch=0.64s
20740/10943 (epoch 170.568) train_loss=491.70809937 time/batch=0.82s
20741/10943 (epoch 170.576) train_loss=377.61138916 time/batch=0.66s
20742/10943 (epoch 170.584) train_loss=179.26828003 time/batch=0.38s
20743/10943 (epoch 170.593) train_loss=469.03765869 time/batch=0.76s
20744/10943 (epoch 170.601) train_loss=577.88244629 time/batch=0.99s
20745/10943 (epoch 170.609) train_loss=309.03857422 time/batch=0.59s
20746/10943 (epoch 170.617) train_loss=543.54785156 time/batch=0.96s
20747/10943 (epoch 170.626) train_loss=251.59298706 time/batch=0.50s
20748/10943 (epoch 170.634) train_loss=297.99508667 time/batch=0.52s
20749/10943 (epoch 170.642) train_loss=426.03063965 time/batch=0.73s
20750/10943 (epoch 170.650) train_loss=465.22674561 time/batch=0.79s
20751/10943 (epoch 170.658) train_loss=431.89825439 time/batch=0.73s
20752/10943 (epoch 170.667) train_loss=301.94448853 time/batch=0.53s
20753/10943 (epoch 170.675) train_loss=462.01141357 time/batch=0.77s
20754/10943 (epoch 170.683) train_loss=329.31896973 time/batch=0.59s
20755/10943 (epoch 170.691) train_loss=399.52828979 time/batch=0.65s
20756/10943 (epoch 170.700) train_loss=290.31707764 time/batch=0.53s
20757/10943 (epoch 170.708) train_loss=394.65893555 time/batch=0.69s
20758/10943 (epoch 170.716) train_loss=401.84005737 time/batch=0.68s
20759/10943 (epoch 170.724) train_loss=353.73352051 time/batch=0.63s
20760/10943 (epoch 170.732) train_loss=216.77804565 time/batch=0.39s
20761/10943 (epoch 170.741) train_loss=464.15103149 time/batch=0.76s
20762/10943 (epoch 170.749) train_loss=233.22479248 time/batch=0.47s
20763/10943 (epoch 170.757) train_loss=434.39141846 time/batch=0.70s
20764/10943 (epoch 170.765) train_loss=494.69506836 time/batch=0.84s
20765/10943 (epoch 170.774) train_loss=293.58319092 time/batch=0.56s
20766/10943 (epoch 170.782) train_loss=228.60705566 time/batch=0.44s
20767/10943 (epoch 170.790) train_loss=370.07211304 time/batch=0.62s
20768/10943 (epoch 170.798) train_loss=487.01074219 time/batch=0.88s
20769/10943 (epoch 170.806) train_loss=328.01733398 time/batch=0.62s
20770/10943 (epoch 170.815) train_loss=419.74237061 time/batch=0.72s
20771/10943 (epoch 170.823) train_loss=335.14788818 time/batch=0.61s
20772/10943 (epoch 170.831) train_loss=265.18890381 time/batch=0.47s
20773/10943 (epoch 170.839) train_loss=469.35086060 time/batch=0.79s
20774/10943 (epoch 170.848) train_loss=424.71795654 time/batch=0.75s
20775/10943 (epoch 170.856) train_loss=325.69802856 time/batch=0.61s
20776/10943 (epoch 170.864) train_loss=271.59841919 time/batch=0.47s
20777/10943 (epoch 170.872) train_loss=354.52767944 time/batch=0.60s
20778/10943 (epoch 170.880) train_loss=338.61724854 time/batch=0.61s
20779/10943 (epoch 170.889) train_loss=284.81164551 time/batch=0.50s
20780/10943 (epoch 170.897) train_loss=336.21249390 time/batch=0.61s
20781/10943 (epoch 170.905) train_loss=362.61340332 time/batch=0.72s
setting learning rate to 0.0008871
20782/10943 (epoch 170.913) train_loss=544.58978271 time/batch=0.91s
20783/10943 (epoch 170.922) train_loss=542.89068604 time/batch=0.94s
20784/10943 (epoch 170.930) train_loss=465.39257812 time/batch=0.75s
20785/10943 (epoch 170.938) train_loss=872.32312012 time/batch=1.42s
20786/10943 (epoch 170.946) train_loss=1051.45776367 time/batch=1.64s
20787/10943 (epoch 170.955) train_loss=150.33773804 time/batch=0.38s
20788/10943 (epoch 170.963) train_loss=1132.01538086 time/batch=1.72s
20789/10943 (epoch 170.971) train_loss=927.45898438 time/batch=1.89s
20790/10943 (epoch 170.979) train_loss=727.79003906 time/batch=1.28s
20791/10943 (epoch 170.987) train_loss=438.50207520 time/batch=0.77s
20792/10943 (epoch 170.996) train_loss=480.52645874 time/batch=0.85s
20793/10943 (epoch 171.004) train_loss=277.27746582 time/batch=0.51s
20794/10943 (epoch 171.012) train_loss=262.18597412 time/batch=0.46s
20795/10943 (epoch 171.020) train_loss=644.36016846 time/batch=1.04s
20796/10943 (epoch 171.029) train_loss=1297.17211914 time/batch=3.13s
20797/10943 (epoch 171.037) train_loss=844.91442871 time/batch=1.54s
20798/10943 (epoch 171.045) train_loss=511.87200928 time/batch=0.91s
20799/10943 (epoch 171.053) train_loss=291.07455444 time/batch=0.53s
20800/10943 (epoch 171.061) train_loss=287.47167969 time/batch=0.49s
20801/10943 (epoch 171.070) train_loss=157.56718445 time/batch=0.29s
20802/10943 (epoch 171.078) train_loss=255.39723206 time/batch=0.42s
20803/10943 (epoch 171.086) train_loss=586.70434570 time/batch=0.93s
20804/10943 (epoch 171.094) train_loss=253.82592773 time/batch=0.49s
20805/10943 (epoch 171.103) train_loss=228.66557312 time/batch=0.40s
20806/10943 (epoch 171.111) train_loss=319.74893188 time/batch=0.54s
20807/10943 (epoch 171.119) train_loss=630.78906250 time/batch=0.99s
20808/10943 (epoch 171.127) train_loss=598.35211182 time/batch=0.98s
20809/10943 (epoch 171.135) train_loss=410.40551758 time/batch=0.72s
20810/10943 (epoch 171.144) train_loss=199.03204346 time/batch=0.37s
20811/10943 (epoch 171.152) train_loss=163.67449951 time/batch=0.30s
20812/10943 (epoch 171.160) train_loss=626.92736816 time/batch=1.00s
20813/10943 (epoch 171.168) train_loss=434.98217773 time/batch=0.75s
20814/10943 (epoch 171.177) train_loss=451.97222900 time/batch=0.76s
20815/10943 (epoch 171.185) train_loss=295.23022461 time/batch=0.54s
20816/10943 (epoch 171.193) train_loss=664.09008789 time/batch=1.10s
20817/10943 (epoch 171.201) train_loss=308.74465942 time/batch=0.60s
20818/10943 (epoch 171.209) train_loss=440.27267456 time/batch=0.73s
20819/10943 (epoch 171.218) train_loss=696.26153564 time/batch=1.09s
20820/10943 (epoch 171.226) train_loss=191.96896362 time/batch=0.41s
20821/10943 (epoch 171.234) train_loss=245.16937256 time/batch=0.43s
20822/10943 (epoch 171.242) train_loss=540.47485352 time/batch=0.86s
20823/10943 (epoch 171.251) train_loss=243.81221008 time/batch=0.50s
20824/10943 (epoch 171.259) train_loss=593.18273926 time/batch=0.99s
20825/10943 (epoch 171.267) train_loss=793.92712402 time/batch=1.31s
20826/10943 (epoch 171.275) train_loss=322.00531006 time/batch=0.60s
20827/10943 (epoch 171.283) train_loss=339.20159912 time/batch=0.58s
20828/10943 (epoch 171.292) train_loss=470.49942017 time/batch=0.78s
20829/10943 (epoch 171.300) train_loss=333.25274658 time/batch=0.59s
20830/10943 (epoch 171.308) train_loss=295.58563232 time/batch=0.53s
20831/10943 (epoch 171.316) train_loss=396.05780029 time/batch=0.66s
20832/10943 (epoch 171.325) train_loss=435.27136230 time/batch=0.76s
20833/10943 (epoch 171.333) train_loss=295.35760498 time/batch=0.53s
20834/10943 (epoch 171.341) train_loss=396.58673096 time/batch=0.67s
20835/10943 (epoch 171.349) train_loss=575.60943604 time/batch=0.97s
20836/10943 (epoch 171.357) train_loss=473.78625488 time/batch=0.82s
20837/10943 (epoch 171.366) train_loss=268.31494141 time/batch=0.49s
20838/10943 (epoch 171.374) train_loss=325.97949219 time/batch=0.56s
20839/10943 (epoch 171.382) train_loss=351.30902100 time/batch=0.60s
20840/10943 (epoch 171.390) train_loss=472.34634399 time/batch=0.77s
20841/10943 (epoch 171.399) train_loss=515.25140381 time/batch=0.86s
20842/10943 (epoch 171.407) train_loss=678.83819580 time/batch=1.05s
20843/10943 (epoch 171.415) train_loss=273.25659180 time/batch=0.52s
20844/10943 (epoch 171.423) train_loss=234.98725891 time/batch=0.46s
20845/10943 (epoch 171.432) train_loss=380.52752686 time/batch=0.63s
20846/10943 (epoch 171.440) train_loss=745.98559570 time/batch=1.20s
20847/10943 (epoch 171.448) train_loss=717.86273193 time/batch=1.24s
20848/10943 (epoch 171.456) train_loss=380.31118774 time/batch=0.69s
20849/10943 (epoch 171.464) train_loss=204.57217407 time/batch=0.38s
20850/10943 (epoch 171.473) train_loss=557.19012451 time/batch=0.88s
20851/10943 (epoch 171.481) train_loss=436.37689209 time/batch=0.74s
20852/10943 (epoch 171.489) train_loss=176.27799988 time/batch=0.34s
20853/10943 (epoch 171.497) train_loss=665.36828613 time/batch=1.07s
20854/10943 (epoch 171.506) train_loss=309.09136963 time/batch=0.60s
20855/10943 (epoch 171.514) train_loss=219.66662598 time/batch=0.39s
20856/10943 (epoch 171.522) train_loss=430.82617188 time/batch=0.70s
20857/10943 (epoch 171.530) train_loss=445.10998535 time/batch=0.75s
20858/10943 (epoch 171.538) train_loss=340.66622925 time/batch=0.60s
20859/10943 (epoch 171.547) train_loss=456.58081055 time/batch=0.78s
20860/10943 (epoch 171.555) train_loss=455.26110840 time/batch=0.79s
20861/10943 (epoch 171.563) train_loss=357.17446899 time/batch=0.63s
20862/10943 (epoch 171.571) train_loss=517.43817139 time/batch=0.85s
20863/10943 (epoch 171.580) train_loss=389.69940186 time/batch=0.70s
20864/10943 (epoch 171.588) train_loss=218.67636108 time/batch=0.41s
20865/10943 (epoch 171.596) train_loss=484.61566162 time/batch=0.80s
20866/10943 (epoch 171.604) train_loss=319.10540771 time/batch=0.58s
20867/10943 (epoch 171.612) train_loss=389.45031738 time/batch=0.64s
20868/10943 (epoch 171.621) train_loss=569.55151367 time/batch=0.94s
20869/10943 (epoch 171.629) train_loss=193.92919922 time/batch=0.39s
20870/10943 (epoch 171.637) train_loss=354.05517578 time/batch=0.60s
20871/10943 (epoch 171.645) train_loss=449.70169067 time/batch=0.80s
20872/10943 (epoch 171.654) train_loss=335.68450928 time/batch=0.64s
20873/10943 (epoch 171.662) train_loss=172.97460938 time/batch=0.34s
20874/10943 (epoch 171.670) train_loss=537.40148926 time/batch=0.89s
20875/10943 (epoch 171.678) train_loss=419.67803955 time/batch=0.70s
20876/10943 (epoch 171.686) train_loss=434.03982544 time/batch=0.78s
20877/10943 (epoch 171.695) train_loss=507.21957397 time/batch=0.87s
20878/10943 (epoch 171.703) train_loss=353.83233643 time/batch=0.61s
20879/10943 (epoch 171.711) train_loss=506.33380127 time/batch=0.85s
20880/10943 (epoch 171.719) train_loss=282.40747070 time/batch=0.54s
20881/10943 (epoch 171.728) train_loss=401.41693115 time/batch=0.67s
20882/10943 (epoch 171.736) train_loss=204.93261719 time/batch=0.37s
20883/10943 (epoch 171.744) train_loss=373.65322876 time/batch=0.61s
20884/10943 (epoch 171.752) train_loss=403.33697510 time/batch=0.67s
20885/10943 (epoch 171.760) train_loss=400.16644287 time/batch=0.68s
20886/10943 (epoch 171.769) train_loss=371.95745850 time/batch=0.66s
20887/10943 (epoch 171.777) train_loss=390.07608032 time/batch=0.70s
20888/10943 (epoch 171.785) train_loss=503.59735107 time/batch=0.88s
20889/10943 (epoch 171.793) train_loss=297.47058105 time/batch=0.59s
20890/10943 (epoch 171.802) train_loss=565.59301758 time/batch=0.96s
20891/10943 (epoch 171.810) train_loss=333.24526978 time/batch=0.64s
20892/10943 (epoch 171.818) train_loss=473.54138184 time/batch=0.81s
20893/10943 (epoch 171.826) train_loss=493.36993408 time/batch=1.08s
20894/10943 (epoch 171.834) train_loss=488.21447754 time/batch=0.85s
20895/10943 (epoch 171.843) train_loss=318.90078735 time/batch=0.61s
20896/10943 (epoch 171.851) train_loss=337.20959473 time/batch=0.59s
20897/10943 (epoch 171.859) train_loss=462.08966064 time/batch=0.80s
20898/10943 (epoch 171.867) train_loss=424.29281616 time/batch=0.73s
20899/10943 (epoch 171.876) train_loss=442.03253174 time/batch=0.81s
20900/10943 (epoch 171.884) train_loss=252.45497131 time/batch=0.63s
20901/10943 (epoch 171.892) train_loss=344.53555298 time/batch=0.63s
20902/10943 (epoch 171.900) train_loss=362.78039551 time/batch=0.71s
setting learning rate to 0.0008605
20903/10943 (epoch 171.909) train_loss=683.03918457 time/batch=1.10s
20904/10943 (epoch 171.917) train_loss=849.94738770 time/batch=1.47s
20905/10943 (epoch 171.925) train_loss=704.20507812 time/batch=1.08s
20906/10943 (epoch 171.933) train_loss=883.42822266 time/batch=1.34s
20907/10943 (epoch 171.941) train_loss=1410.24121094 time/batch=3.17s
20908/10943 (epoch 171.950) train_loss=301.04333496 time/batch=0.80s
20909/10943 (epoch 171.958) train_loss=328.06454468 time/batch=0.55s
20910/10943 (epoch 171.966) train_loss=135.50183105 time/batch=0.27s
20911/10943 (epoch 171.974) train_loss=676.88195801 time/batch=1.11s
20912/10943 (epoch 171.983) train_loss=232.10409546 time/batch=0.49s
20913/10943 (epoch 171.991) train_loss=449.22943115 time/batch=0.72s
20914/10943 (epoch 171.999) train_loss=450.98263550 time/batch=0.80s
20915/10943 (epoch 172.007) train_loss=1022.91241455 time/batch=1.68s
20916/10943 (epoch 172.015) train_loss=207.68679810 time/batch=0.51s
20917/10943 (epoch 172.024) train_loss=289.41339111 time/batch=0.50s
20918/10943 (epoch 172.032) train_loss=257.35946655 time/batch=0.45s
20919/10943 (epoch 172.040) train_loss=717.04309082 time/batch=1.20s
20920/10943 (epoch 172.048) train_loss=931.05682373 time/batch=1.60s
20921/10943 (epoch 172.057) train_loss=223.69689941 time/batch=0.52s
20922/10943 (epoch 172.065) train_loss=637.54553223 time/batch=1.04s
20923/10943 (epoch 172.073) train_loss=227.53475952 time/batch=0.46s
20924/10943 (epoch 172.081) train_loss=288.52435303 time/batch=0.50s
20925/10943 (epoch 172.089) train_loss=459.81753540 time/batch=0.80s
20926/10943 (epoch 172.098) train_loss=337.07141113 time/batch=0.62s
20927/10943 (epoch 172.106) train_loss=443.54156494 time/batch=0.75s
20928/10943 (epoch 172.114) train_loss=821.41320801 time/batch=1.36s
20929/10943 (epoch 172.122) train_loss=589.18701172 time/batch=1.07s
20930/10943 (epoch 172.131) train_loss=647.98382568 time/batch=1.05s
20931/10943 (epoch 172.139) train_loss=407.73724365 time/batch=0.71s
20932/10943 (epoch 172.147) train_loss=193.64266968 time/batch=0.36s
20933/10943 (epoch 172.155) train_loss=643.74017334 time/batch=1.05s
20934/10943 (epoch 172.163) train_loss=353.13909912 time/batch=0.68s
20935/10943 (epoch 172.172) train_loss=561.19860840 time/batch=0.96s
20936/10943 (epoch 172.180) train_loss=158.95846558 time/batch=0.35s
20937/10943 (epoch 172.188) train_loss=160.02468872 time/batch=0.30s
20938/10943 (epoch 172.196) train_loss=239.95788574 time/batch=0.42s
20939/10943 (epoch 172.205) train_loss=279.28842163 time/batch=0.48s
20940/10943 (epoch 172.213) train_loss=254.14544678 time/batch=0.46s
20941/10943 (epoch 172.221) train_loss=261.33410645 time/batch=0.47s
20942/10943 (epoch 172.229) train_loss=666.26049805 time/batch=1.12s
20943/10943 (epoch 172.237) train_loss=282.87783813 time/batch=0.54s
20944/10943 (epoch 172.246) train_loss=176.18667603 time/batch=0.32s
20945/10943 (epoch 172.254) train_loss=177.67094421 time/batch=0.33s
20946/10943 (epoch 172.262) train_loss=578.12542725 time/batch=0.92s
20947/10943 (epoch 172.270) train_loss=327.96112061 time/batch=0.62s
20948/10943 (epoch 172.279) train_loss=219.52093506 time/batch=0.39s
20949/10943 (epoch 172.287) train_loss=244.97769165 time/batch=0.44s
20950/10943 (epoch 172.295) train_loss=202.37918091 time/batch=0.37s
20951/10943 (epoch 172.303) train_loss=431.79998779 time/batch=0.69s
20952/10943 (epoch 172.311) train_loss=408.34387207 time/batch=0.70s
20953/10943 (epoch 172.320) train_loss=473.10723877 time/batch=0.78s
20954/10943 (epoch 172.328) train_loss=644.29315186 time/batch=1.05s
20955/10943 (epoch 172.336) train_loss=427.51498413 time/batch=0.71s
20956/10943 (epoch 172.344) train_loss=278.15338135 time/batch=0.50s
20957/10943 (epoch 172.353) train_loss=368.44409180 time/batch=0.62s
20958/10943 (epoch 172.361) train_loss=276.72964478 time/batch=0.51s
20959/10943 (epoch 172.369) train_loss=326.73864746 time/batch=0.56s
20960/10943 (epoch 172.377) train_loss=690.34210205 time/batch=1.16s
20961/10943 (epoch 172.386) train_loss=307.13046265 time/batch=0.61s
20962/10943 (epoch 172.394) train_loss=442.02703857 time/batch=0.72s
20963/10943 (epoch 172.402) train_loss=503.72817993 time/batch=0.86s
20964/10943 (epoch 172.410) train_loss=175.96894836 time/batch=0.35s
20965/10943 (epoch 172.418) train_loss=398.46609497 time/batch=0.64s
20966/10943 (epoch 172.427) train_loss=425.24847412 time/batch=0.75s
20967/10943 (epoch 172.435) train_loss=510.50839233 time/batch=0.88s
20968/10943 (epoch 172.443) train_loss=447.65063477 time/batch=0.78s
20969/10943 (epoch 172.451) train_loss=203.84167480 time/batch=0.40s
20970/10943 (epoch 172.460) train_loss=187.93208313 time/batch=0.37s
20971/10943 (epoch 172.468) train_loss=242.80570984 time/batch=0.49s
20972/10943 (epoch 172.476) train_loss=223.79681396 time/batch=0.42s
20973/10943 (epoch 172.484) train_loss=274.78088379 time/batch=0.51s
20974/10943 (epoch 172.492) train_loss=387.48556519 time/batch=0.67s
20975/10943 (epoch 172.501) train_loss=346.99954224 time/batch=0.63s
20976/10943 (epoch 172.509) train_loss=431.41180420 time/batch=0.77s
20977/10943 (epoch 172.517) train_loss=294.32971191 time/batch=0.57s
20978/10943 (epoch 172.525) train_loss=527.25067139 time/batch=0.87s
20979/10943 (epoch 172.534) train_loss=505.04135132 time/batch=0.87s
20980/10943 (epoch 172.542) train_loss=385.76019287 time/batch=0.68s
20981/10943 (epoch 172.550) train_loss=422.16384888 time/batch=0.71s
20982/10943 (epoch 172.558) train_loss=321.48333740 time/batch=0.60s
20983/10943 (epoch 172.566) train_loss=534.87585449 time/batch=0.89s
20984/10943 (epoch 172.575) train_loss=579.83868408 time/batch=0.97s
20985/10943 (epoch 172.583) train_loss=665.75683594 time/batch=1.22s
20986/10943 (epoch 172.591) train_loss=503.65374756 time/batch=0.89s
20987/10943 (epoch 172.599) train_loss=363.18145752 time/batch=0.66s
20988/10943 (epoch 172.608) train_loss=706.65563965 time/batch=1.19s
20989/10943 (epoch 172.616) train_loss=417.55859375 time/batch=0.74s
20990/10943 (epoch 172.624) train_loss=553.05889893 time/batch=0.94s
20991/10943 (epoch 172.632) train_loss=493.75781250 time/batch=0.85s
20992/10943 (epoch 172.640) train_loss=488.59118652 time/batch=0.81s
20993/10943 (epoch 172.649) train_loss=389.44860840 time/batch=0.67s
20994/10943 (epoch 172.657) train_loss=349.11761475 time/batch=0.61s
20995/10943 (epoch 172.665) train_loss=357.62902832 time/batch=0.63s
20996/10943 (epoch 172.673) train_loss=540.43627930 time/batch=0.96s
20997/10943 (epoch 172.682) train_loss=538.19519043 time/batch=0.93s
20998/10943 (epoch 172.690) train_loss=443.16177368 time/batch=0.74s
20999/10943 (epoch 172.698) train_loss=388.39093018 time/batch=0.66s
Validating
    loss:	406.801168

21000/10943 (epoch 172.706) train_loss=539.30993652 time/batch=2.74s
21001/10943 (epoch 172.714) train_loss=322.79986572 time/batch=0.58s
21002/10943 (epoch 172.723) train_loss=419.55303955 time/batch=0.68s
21003/10943 (epoch 172.731) train_loss=470.37536621 time/batch=0.80s
21004/10943 (epoch 172.739) train_loss=484.84088135 time/batch=0.84s
21005/10943 (epoch 172.747) train_loss=461.04733276 time/batch=0.81s
21006/10943 (epoch 172.756) train_loss=442.75723267 time/batch=0.79s
21007/10943 (epoch 172.764) train_loss=483.13943481 time/batch=0.84s
21008/10943 (epoch 172.772) train_loss=335.69750977 time/batch=0.62s
21009/10943 (epoch 172.780) train_loss=330.45065308 time/batch=0.58s
21010/10943 (epoch 172.788) train_loss=499.39648438 time/batch=0.83s
21011/10943 (epoch 172.797) train_loss=464.18164062 time/batch=0.82s
21012/10943 (epoch 172.805) train_loss=312.05404663 time/batch=0.58s
21013/10943 (epoch 172.813) train_loss=339.76452637 time/batch=0.59s
21014/10943 (epoch 172.821) train_loss=513.13867188 time/batch=0.87s
21015/10943 (epoch 172.830) train_loss=368.09851074 time/batch=0.64s
21016/10943 (epoch 172.838) train_loss=459.58041382 time/batch=0.82s
21017/10943 (epoch 172.846) train_loss=426.10516357 time/batch=0.71s
21018/10943 (epoch 172.854) train_loss=407.22430420 time/batch=0.70s
21019/10943 (epoch 172.863) train_loss=430.95654297 time/batch=0.83s
21020/10943 (epoch 172.871) train_loss=337.74417114 time/batch=0.62s
21021/10943 (epoch 172.879) train_loss=367.68582153 time/batch=0.64s
21022/10943 (epoch 172.887) train_loss=411.80078125 time/batch=0.71s
21023/10943 (epoch 172.895) train_loss=340.26086426 time/batch=0.61s
setting learning rate to 0.0008347
21024/10943 (epoch 172.904) train_loss=244.89094543 time/batch=0.44s
21025/10943 (epoch 172.912) train_loss=455.35565186 time/batch=0.78s
21026/10943 (epoch 172.920) train_loss=1048.14013672 time/batch=1.67s
21027/10943 (epoch 172.928) train_loss=466.60357666 time/batch=0.83s
21028/10943 (epoch 172.937) train_loss=642.02563477 time/batch=1.00s
21029/10943 (epoch 172.945) train_loss=191.75033569 time/batch=0.39s
21030/10943 (epoch 172.953) train_loss=827.34069824 time/batch=1.24s
21031/10943 (epoch 172.961) train_loss=718.95166016 time/batch=1.21s
21032/10943 (epoch 172.969) train_loss=166.87643433 time/batch=0.37s
21033/10943 (epoch 172.978) train_loss=181.51174927 time/batch=0.32s
21034/10943 (epoch 172.986) train_loss=260.44311523 time/batch=0.43s
21035/10943 (epoch 172.994) train_loss=497.84991455 time/batch=0.83s
21036/10943 (epoch 173.002) train_loss=1054.74047852 time/batch=1.95s
21037/10943 (epoch 173.011) train_loss=917.09191895 time/batch=1.59s
21038/10943 (epoch 173.019) train_loss=433.43249512 time/batch=0.77s
21039/10943 (epoch 173.027) train_loss=889.36065674 time/batch=2.02s
21040/10943 (epoch 173.035) train_loss=768.95312500 time/batch=1.36s
21041/10943 (epoch 173.043) train_loss=405.28762817 time/batch=0.75s
21042/10943 (epoch 173.052) train_loss=382.53817749 time/batch=0.66s
21043/10943 (epoch 173.060) train_loss=151.19982910 time/batch=0.32s
21044/10943 (epoch 173.068) train_loss=220.95518494 time/batch=0.39s
21045/10943 (epoch 173.076) train_loss=389.45886230 time/batch=0.63s
21046/10943 (epoch 173.085) train_loss=251.60180664 time/batch=0.47s
21047/10943 (epoch 173.093) train_loss=663.58142090 time/batch=1.07s
21048/10943 (epoch 173.101) train_loss=223.55622864 time/batch=0.47s
21049/10943 (epoch 173.109) train_loss=637.38525391 time/batch=1.03s
21050/10943 (epoch 173.117) train_loss=718.20959473 time/batch=1.27s
21051/10943 (epoch 173.126) train_loss=175.77612305 time/batch=0.41s
21052/10943 (epoch 173.134) train_loss=427.11691284 time/batch=0.67s
21053/10943 (epoch 173.142) train_loss=290.19891357 time/batch=0.52s
21054/10943 (epoch 173.150) train_loss=494.49124146 time/batch=0.83s
21055/10943 (epoch 173.159) train_loss=580.72216797 time/batch=0.96s
21056/10943 (epoch 173.167) train_loss=1160.69116211 time/batch=3.11s
21057/10943 (epoch 173.175) train_loss=432.49218750 time/batch=0.93s
21058/10943 (epoch 173.183) train_loss=225.01776123 time/batch=0.40s
21059/10943 (epoch 173.191) train_loss=462.29351807 time/batch=0.74s
21060/10943 (epoch 173.200) train_loss=540.39514160 time/batch=0.93s
21061/10943 (epoch 173.208) train_loss=434.70196533 time/batch=0.75s
21062/10943 (epoch 173.216) train_loss=512.72192383 time/batch=0.86s
21063/10943 (epoch 173.224) train_loss=274.12380981 time/batch=0.51s
21064/10943 (epoch 173.233) train_loss=365.06585693 time/batch=0.62s
21065/10943 (epoch 173.241) train_loss=397.80664062 time/batch=0.68s
21066/10943 (epoch 173.249) train_loss=648.26123047 time/batch=1.07s
21067/10943 (epoch 173.257) train_loss=709.33752441 time/batch=1.27s
21068/10943 (epoch 173.265) train_loss=707.15686035 time/batch=1.18s
21069/10943 (epoch 173.274) train_loss=345.75720215 time/batch=0.64s
21070/10943 (epoch 173.282) train_loss=228.99023438 time/batch=0.43s
21071/10943 (epoch 173.290) train_loss=420.30108643 time/batch=0.66s
21072/10943 (epoch 173.298) train_loss=200.03594971 time/batch=0.39s
21073/10943 (epoch 173.307) train_loss=543.37048340 time/batch=0.91s
21074/10943 (epoch 173.315) train_loss=492.23831177 time/batch=0.89s
21075/10943 (epoch 173.323) train_loss=194.68577576 time/batch=0.40s
21076/10943 (epoch 173.331) train_loss=253.38897705 time/batch=0.44s
21077/10943 (epoch 173.340) train_loss=294.35134888 time/batch=0.52s
21078/10943 (epoch 173.348) train_loss=479.23635864 time/batch=0.80s
21079/10943 (epoch 173.356) train_loss=355.34341431 time/batch=0.64s
21080/10943 (epoch 173.364) train_loss=284.28680420 time/batch=0.52s
21081/10943 (epoch 173.372) train_loss=576.79693604 time/batch=0.93s
21082/10943 (epoch 173.381) train_loss=466.52471924 time/batch=0.84s
21083/10943 (epoch 173.389) train_loss=440.83782959 time/batch=0.78s
21084/10943 (epoch 173.397) train_loss=284.10125732 time/batch=0.52s
21085/10943 (epoch 173.405) train_loss=521.65039062 time/batch=0.87s
21086/10943 (epoch 173.414) train_loss=223.28950500 time/batch=0.44s
21087/10943 (epoch 173.422) train_loss=260.95065308 time/batch=0.47s
21088/10943 (epoch 173.430) train_loss=463.39666748 time/batch=0.81s
21089/10943 (epoch 173.438) train_loss=457.94433594 time/batch=0.80s
21090/10943 (epoch 173.446) train_loss=570.50769043 time/batch=0.98s
21091/10943 (epoch 173.455) train_loss=658.30743408 time/batch=1.16s
21092/10943 (epoch 173.463) train_loss=372.18707275 time/batch=0.68s
21093/10943 (epoch 173.471) train_loss=316.60241699 time/batch=0.56s
21094/10943 (epoch 173.479) train_loss=305.64526367 time/batch=0.55s
21095/10943 (epoch 173.488) train_loss=258.80044556 time/batch=0.48s
21096/10943 (epoch 173.496) train_loss=618.35955811 time/batch=0.99s
21097/10943 (epoch 173.504) train_loss=531.73663330 time/batch=0.95s
21098/10943 (epoch 173.512) train_loss=468.07867432 time/batch=0.85s
21099/10943 (epoch 173.520) train_loss=187.23995972 time/batch=0.38s
21100/10943 (epoch 173.529) train_loss=326.87789917 time/batch=0.56s
21101/10943 (epoch 173.537) train_loss=274.89862061 time/batch=0.50s
21102/10943 (epoch 173.545) train_loss=415.08285522 time/batch=0.70s
21103/10943 (epoch 173.553) train_loss=295.62338257 time/batch=0.56s
21104/10943 (epoch 173.562) train_loss=284.15911865 time/batch=0.53s
21105/10943 (epoch 173.570) train_loss=246.80856323 time/batch=0.48s
21106/10943 (epoch 173.578) train_loss=295.01638794 time/batch=0.53s
21107/10943 (epoch 173.586) train_loss=153.42150879 time/batch=0.32s
21108/10943 (epoch 173.594) train_loss=390.03149414 time/batch=0.65s
21109/10943 (epoch 173.603) train_loss=452.35906982 time/batch=0.79s
21110/10943 (epoch 173.611) train_loss=337.94882202 time/batch=0.63s
21111/10943 (epoch 173.619) train_loss=428.65447998 time/batch=0.74s
21112/10943 (epoch 173.627) train_loss=410.31460571 time/batch=0.72s
21113/10943 (epoch 173.636) train_loss=410.08453369 time/batch=0.72s
21114/10943 (epoch 173.644) train_loss=535.76135254 time/batch=0.91s
21115/10943 (epoch 173.652) train_loss=493.88592529 time/batch=0.85s
21116/10943 (epoch 173.660) train_loss=575.90740967 time/batch=1.01s
21117/10943 (epoch 173.668) train_loss=381.04150391 time/batch=0.69s
21118/10943 (epoch 173.677) train_loss=209.30505371 time/batch=0.43s
21119/10943 (epoch 173.685) train_loss=325.45217896 time/batch=0.58s
21120/10943 (epoch 173.693) train_loss=564.13220215 time/batch=1.00s
21121/10943 (epoch 173.701) train_loss=438.41253662 time/batch=0.80s
21122/10943 (epoch 173.710) train_loss=437.43554688 time/batch=0.75s
21123/10943 (epoch 173.718) train_loss=322.82183838 time/batch=0.60s
21124/10943 (epoch 173.726) train_loss=340.96276855 time/batch=0.62s
21125/10943 (epoch 173.734) train_loss=424.43777466 time/batch=0.74s
21126/10943 (epoch 173.742) train_loss=336.41436768 time/batch=0.60s
21127/10943 (epoch 173.751) train_loss=496.45812988 time/batch=0.86s
21128/10943 (epoch 173.759) train_loss=355.01153564 time/batch=0.64s
21129/10943 (epoch 173.767) train_loss=451.67166138 time/batch=0.83s
21130/10943 (epoch 173.775) train_loss=325.89624023 time/batch=0.63s
21131/10943 (epoch 173.784) train_loss=384.54632568 time/batch=0.68s
21132/10943 (epoch 173.792) train_loss=254.80676270 time/batch=0.50s
21133/10943 (epoch 173.800) train_loss=463.09869385 time/batch=0.84s
21134/10943 (epoch 173.808) train_loss=387.42007446 time/batch=0.74s
21135/10943 (epoch 173.816) train_loss=246.29357910 time/batch=0.56s
21136/10943 (epoch 173.825) train_loss=538.44555664 time/batch=0.99s
21137/10943 (epoch 173.833) train_loss=388.19027710 time/batch=0.69s
21138/10943 (epoch 173.841) train_loss=313.65444946 time/batch=0.56s
21139/10943 (epoch 173.849) train_loss=506.04455566 time/batch=1.00s
21140/10943 (epoch 173.858) train_loss=345.87988281 time/batch=0.66s
21141/10943 (epoch 173.866) train_loss=425.00213623 time/batch=0.76s
21142/10943 (epoch 173.874) train_loss=430.36419678 time/batch=0.80s
21143/10943 (epoch 173.882) train_loss=345.04180908 time/batch=0.65s
21144/10943 (epoch 173.891) train_loss=364.59869385 time/batch=0.77s
setting learning rate to 0.0008097
21145/10943 (epoch 173.899) train_loss=774.74340820 time/batch=1.26s
21146/10943 (epoch 173.907) train_loss=1217.32421875 time/batch=2.23s
21147/10943 (epoch 173.915) train_loss=153.16412354 time/batch=0.46s
21148/10943 (epoch 173.923) train_loss=168.84381104 time/batch=0.29s
21149/10943 (epoch 173.932) train_loss=467.71453857 time/batch=0.74s
21150/10943 (epoch 173.940) train_loss=285.61276245 time/batch=0.54s
21151/10943 (epoch 173.948) train_loss=224.30172729 time/batch=0.41s
21152/10943 (epoch 173.956) train_loss=803.69738770 time/batch=1.26s
21153/10943 (epoch 173.965) train_loss=641.91381836 time/batch=1.06s
21154/10943 (epoch 173.973) train_loss=693.68261719 time/batch=1.17s
21155/10943 (epoch 173.981) train_loss=474.90209961 time/batch=0.85s
21156/10943 (epoch 173.989) train_loss=946.43743896 time/batch=1.57s
21157/10943 (epoch 173.997) train_loss=369.00485229 time/batch=0.73s
21158/10943 (epoch 174.006) train_loss=553.03491211 time/batch=0.95s
21159/10943 (epoch 174.014) train_loss=381.03472900 time/batch=0.69s
21160/10943 (epoch 174.022) train_loss=441.32192993 time/batch=0.74s
21161/10943 (epoch 174.030) train_loss=454.06646729 time/batch=0.81s
21162/10943 (epoch 174.039) train_loss=656.29449463 time/batch=1.11s
21163/10943 (epoch 174.047) train_loss=206.43182373 time/batch=0.43s
21164/10943 (epoch 174.055) train_loss=426.10821533 time/batch=0.70s
21165/10943 (epoch 174.063) train_loss=479.26660156 time/batch=0.82s
21166/10943 (epoch 174.071) train_loss=209.63574219 time/batch=0.44s
21167/10943 (epoch 174.080) train_loss=407.74481201 time/batch=0.65s
21168/10943 (epoch 174.088) train_loss=290.77658081 time/batch=0.54s
21169/10943 (epoch 174.096) train_loss=810.99658203 time/batch=1.35s
21170/10943 (epoch 174.104) train_loss=427.04312134 time/batch=0.82s
21171/10943 (epoch 174.113) train_loss=466.28744507 time/batch=0.82s
21172/10943 (epoch 174.121) train_loss=593.40197754 time/batch=0.97s
21173/10943 (epoch 174.129) train_loss=1078.27880859 time/batch=2.32s
21174/10943 (epoch 174.137) train_loss=306.93695068 time/batch=0.69s
21175/10943 (epoch 174.145) train_loss=815.33172607 time/batch=1.28s
21176/10943 (epoch 174.154) train_loss=248.95507812 time/batch=0.54s
21177/10943 (epoch 174.162) train_loss=159.46188354 time/batch=0.31s
21178/10943 (epoch 174.170) train_loss=627.24951172 time/batch=1.04s
21179/10943 (epoch 174.178) train_loss=568.65795898 time/batch=1.04s
21180/10943 (epoch 174.187) train_loss=417.28604126 time/batch=0.75s
21181/10943 (epoch 174.195) train_loss=705.48931885 time/batch=1.19s
21182/10943 (epoch 174.203) train_loss=620.94683838 time/batch=1.10s
21183/10943 (epoch 174.211) train_loss=622.61242676 time/batch=1.05s
21184/10943 (epoch 174.219) train_loss=198.52355957 time/batch=0.41s
21185/10943 (epoch 174.228) train_loss=217.25216675 time/batch=0.37s
21186/10943 (epoch 174.236) train_loss=675.99267578 time/batch=1.11s
21187/10943 (epoch 174.244) train_loss=525.16699219 time/batch=0.92s
21188/10943 (epoch 174.252) train_loss=195.03086853 time/batch=0.40s
21189/10943 (epoch 174.261) train_loss=294.06253052 time/batch=0.50s
21190/10943 (epoch 174.269) train_loss=395.10565186 time/batch=0.67s
21191/10943 (epoch 174.277) train_loss=873.59771729 time/batch=3.09s
21192/10943 (epoch 174.285) train_loss=451.39624023 time/batch=0.99s
21193/10943 (epoch 174.293) train_loss=395.99462891 time/batch=0.66s
21194/10943 (epoch 174.302) train_loss=311.22705078 time/batch=0.56s
21195/10943 (epoch 174.310) train_loss=420.66461182 time/batch=0.68s
21196/10943 (epoch 174.318) train_loss=316.40454102 time/batch=0.56s
21197/10943 (epoch 174.326) train_loss=358.14007568 time/batch=0.62s
21198/10943 (epoch 174.335) train_loss=543.54321289 time/batch=0.91s
21199/10943 (epoch 174.343) train_loss=340.92993164 time/batch=0.62s
21200/10943 (epoch 174.351) train_loss=252.61114502 time/batch=0.44s
21201/10943 (epoch 174.359) train_loss=349.11804199 time/batch=0.60s
21202/10943 (epoch 174.368) train_loss=343.97924805 time/batch=0.61s
21203/10943 (epoch 174.376) train_loss=194.80995178 time/batch=0.38s
21204/10943 (epoch 174.384) train_loss=457.30181885 time/batch=0.74s
21205/10943 (epoch 174.392) train_loss=356.82452393 time/batch=0.65s
21206/10943 (epoch 174.400) train_loss=446.37826538 time/batch=0.75s
21207/10943 (epoch 174.409) train_loss=376.82833862 time/batch=0.66s
21208/10943 (epoch 174.417) train_loss=589.13507080 time/batch=0.99s
21209/10943 (epoch 174.425) train_loss=474.33343506 time/batch=0.84s
21210/10943 (epoch 174.433) train_loss=350.38818359 time/batch=0.64s
21211/10943 (epoch 174.442) train_loss=222.27502441 time/batch=0.42s
21212/10943 (epoch 174.450) train_loss=220.64340210 time/batch=0.41s
21213/10943 (epoch 174.458) train_loss=395.34881592 time/batch=0.66s
21214/10943 (epoch 174.466) train_loss=494.82272339 time/batch=0.84s
21215/10943 (epoch 174.474) train_loss=401.32788086 time/batch=0.68s
21216/10943 (epoch 174.483) train_loss=652.01672363 time/batch=1.06s
21217/10943 (epoch 174.491) train_loss=357.19732666 time/batch=0.67s
21218/10943 (epoch 174.499) train_loss=322.26892090 time/batch=0.57s
21219/10943 (epoch 174.507) train_loss=172.66549683 time/batch=0.33s
21220/10943 (epoch 174.516) train_loss=530.05120850 time/batch=0.86s
21221/10943 (epoch 174.524) train_loss=443.46252441 time/batch=0.79s
21222/10943 (epoch 174.532) train_loss=286.44055176 time/batch=0.56s
21223/10943 (epoch 174.540) train_loss=523.42065430 time/batch=0.87s
21224/10943 (epoch 174.548) train_loss=320.79840088 time/batch=0.58s
21225/10943 (epoch 174.557) train_loss=488.15893555 time/batch=0.83s
21226/10943 (epoch 174.565) train_loss=337.13928223 time/batch=0.61s
21227/10943 (epoch 174.573) train_loss=262.87265015 time/batch=0.46s
21228/10943 (epoch 174.581) train_loss=396.27749634 time/batch=0.67s
21229/10943 (epoch 174.590) train_loss=382.74337769 time/batch=0.65s
21230/10943 (epoch 174.598) train_loss=186.70608521 time/batch=0.39s
21231/10943 (epoch 174.606) train_loss=265.38861084 time/batch=0.46s
21232/10943 (epoch 174.614) train_loss=259.16082764 time/batch=0.48s
21233/10943 (epoch 174.622) train_loss=454.25256348 time/batch=0.77s
21234/10943 (epoch 174.631) train_loss=536.08630371 time/batch=0.88s
21235/10943 (epoch 174.639) train_loss=541.80999756 time/batch=0.89s
21236/10943 (epoch 174.647) train_loss=183.77069092 time/batch=0.36s
21237/10943 (epoch 174.655) train_loss=493.08926392 time/batch=0.81s
21238/10943 (epoch 174.664) train_loss=215.22880554 time/batch=0.46s
21239/10943 (epoch 174.672) train_loss=337.12307739 time/batch=0.57s
21240/10943 (epoch 174.680) train_loss=539.60906982 time/batch=0.89s
21241/10943 (epoch 174.688) train_loss=572.76391602 time/batch=0.96s
21242/10943 (epoch 174.696) train_loss=611.68243408 time/batch=1.11s
21243/10943 (epoch 174.705) train_loss=423.42950439 time/batch=0.76s
21244/10943 (epoch 174.713) train_loss=582.34307861 time/batch=1.10s
21245/10943 (epoch 174.721) train_loss=468.36111450 time/batch=0.87s
21246/10943 (epoch 174.729) train_loss=440.45678711 time/batch=0.76s
21247/10943 (epoch 174.738) train_loss=326.70910645 time/batch=0.59s
21248/10943 (epoch 174.746) train_loss=347.90582275 time/batch=0.60s
21249/10943 (epoch 174.754) train_loss=353.13534546 time/batch=0.64s
21250/10943 (epoch 174.762) train_loss=478.20715332 time/batch=0.82s
21251/10943 (epoch 174.770) train_loss=321.89227295 time/batch=0.61s
21252/10943 (epoch 174.779) train_loss=405.26116943 time/batch=0.69s
21253/10943 (epoch 174.787) train_loss=279.52389526 time/batch=0.50s
21254/10943 (epoch 174.795) train_loss=240.13919067 time/batch=0.45s
21255/10943 (epoch 174.803) train_loss=454.90386963 time/batch=0.79s
21256/10943 (epoch 174.812) train_loss=405.85083008 time/batch=0.71s
21257/10943 (epoch 174.820) train_loss=283.10400391 time/batch=0.51s
21258/10943 (epoch 174.828) train_loss=336.69293213 time/batch=0.58s
21259/10943 (epoch 174.836) train_loss=434.98931885 time/batch=0.75s
21260/10943 (epoch 174.845) train_loss=344.55212402 time/batch=0.62s
21261/10943 (epoch 174.853) train_loss=484.39736938 time/batch=0.81s
21262/10943 (epoch 174.861) train_loss=262.21444702 time/batch=0.50s
21263/10943 (epoch 174.869) train_loss=281.75463867 time/batch=0.48s
21264/10943 (epoch 174.877) train_loss=398.31948853 time/batch=0.69s
21265/10943 (epoch 174.886) train_loss=382.82681274 time/batch=0.75s
setting learning rate to 0.0007854
  saved to metadata/gru_dropout-9_nov_folkwiki-20181115-204407_epoch64.pkl
21266/10943 (epoch 174.894) train_loss=590.40667725 time/batch=1.01s
21267/10943 (epoch 174.902) train_loss=1091.88195801 time/batch=1.70s
21268/10943 (epoch 174.910) train_loss=752.18811035 time/batch=1.21s
21269/10943 (epoch 174.919) train_loss=1408.12255859 time/batch=3.12s
21270/10943 (epoch 174.927) train_loss=421.94708252 time/batch=0.93s
21271/10943 (epoch 174.935) train_loss=836.81011963 time/batch=1.27s
21272/10943 (epoch 174.943) train_loss=872.10473633 time/batch=1.54s
21273/10943 (epoch 174.951) train_loss=161.56353760 time/batch=0.41s
21274/10943 (epoch 174.960) train_loss=400.83050537 time/batch=0.65s
21275/10943 (epoch 174.968) train_loss=173.35092163 time/batch=0.33s
21276/10943 (epoch 174.976) train_loss=355.48950195 time/batch=0.60s
21277/10943 (epoch 174.984) train_loss=627.86590576 time/batch=1.04s
21278/10943 (epoch 174.993) train_loss=397.57910156 time/batch=0.76s
21279/10943 (epoch 175.001) train_loss=181.62541199 time/batch=0.36s
21280/10943 (epoch 175.009) train_loss=408.02252197 time/batch=0.66s
21281/10943 (epoch 175.017) train_loss=528.25134277 time/batch=0.88s
21282/10943 (epoch 175.025) train_loss=444.20520020 time/batch=0.79s
21283/10943 (epoch 175.034) train_loss=515.46386719 time/batch=0.87s
21284/10943 (epoch 175.042) train_loss=676.45642090 time/batch=1.17s
21285/10943 (epoch 175.050) train_loss=630.98608398 time/batch=1.11s
21286/10943 (epoch 175.058) train_loss=231.71929932 time/batch=0.49s
21287/10943 (epoch 175.067) train_loss=731.14227295 time/batch=1.20s
21288/10943 (epoch 175.075) train_loss=405.47180176 time/batch=0.74s
21289/10943 (epoch 175.083) train_loss=877.18981934 time/batch=1.53s
21290/10943 (epoch 175.091) train_loss=294.31420898 time/batch=0.61s
21291/10943 (epoch 175.099) train_loss=429.69879150 time/batch=0.69s
21292/10943 (epoch 175.108) train_loss=733.69799805 time/batch=1.19s
21293/10943 (epoch 175.116) train_loss=426.36987305 time/batch=0.77s
21294/10943 (epoch 175.124) train_loss=163.27313232 time/batch=0.34s
21295/10943 (epoch 175.132) train_loss=190.28521729 time/batch=0.33s
21296/10943 (epoch 175.141) train_loss=683.94134521 time/batch=1.11s
21297/10943 (epoch 175.149) train_loss=239.72190857 time/batch=0.49s
21298/10943 (epoch 175.157) train_loss=833.09375000 time/batch=1.50s
21299/10943 (epoch 175.165) train_loss=372.78454590 time/batch=0.71s
21300/10943 (epoch 175.173) train_loss=576.41210938 time/batch=0.96s
21301/10943 (epoch 175.182) train_loss=478.31854248 time/batch=0.85s
21302/10943 (epoch 175.190) train_loss=327.34698486 time/batch=0.58s
21303/10943 (epoch 175.198) train_loss=274.51770020 time/batch=0.48s
21304/10943 (epoch 175.206) train_loss=429.43325806 time/batch=0.72s
21305/10943 (epoch 175.215) train_loss=639.22973633 time/batch=1.08s
21306/10943 (epoch 175.223) train_loss=438.79577637 time/batch=0.75s
21307/10943 (epoch 175.231) train_loss=698.67529297 time/batch=1.14s
21308/10943 (epoch 175.239) train_loss=262.95611572 time/batch=0.52s
21309/10943 (epoch 175.247) train_loss=135.42341614 time/batch=0.32s
21310/10943 (epoch 175.256) train_loss=432.06954956 time/batch=0.73s
21311/10943 (epoch 175.264) train_loss=339.70959473 time/batch=0.63s
21312/10943 (epoch 175.272) train_loss=164.67120361 time/batch=0.33s
21313/10943 (epoch 175.280) train_loss=503.76959229 time/batch=0.81s
21314/10943 (epoch 175.289) train_loss=418.21975708 time/batch=0.74s
21315/10943 (epoch 175.297) train_loss=577.81835938 time/batch=0.98s
21316/10943 (epoch 175.305) train_loss=245.05426025 time/batch=0.48s
21317/10943 (epoch 175.313) train_loss=362.87783813 time/batch=0.62s
21318/10943 (epoch 175.322) train_loss=239.87414551 time/batch=0.45s
21319/10943 (epoch 175.330) train_loss=538.40435791 time/batch=0.89s
21320/10943 (epoch 175.338) train_loss=467.17108154 time/batch=0.82s
21321/10943 (epoch 175.346) train_loss=390.53012085 time/batch=0.67s
21322/10943 (epoch 175.354) train_loss=442.69216919 time/batch=0.73s
21323/10943 (epoch 175.363) train_loss=287.99008179 time/batch=0.54s
21324/10943 (epoch 175.371) train_loss=210.78546143 time/batch=0.39s
21325/10943 (epoch 175.379) train_loss=246.40322876 time/batch=0.44s
21326/10943 (epoch 175.387) train_loss=369.47201538 time/batch=0.62s
21327/10943 (epoch 175.396) train_loss=541.55816650 time/batch=0.91s
21328/10943 (epoch 175.404) train_loss=504.14947510 time/batch=0.86s
21329/10943 (epoch 175.412) train_loss=643.36242676 time/batch=1.03s
21330/10943 (epoch 175.420) train_loss=490.37969971 time/batch=0.90s
21331/10943 (epoch 175.428) train_loss=336.83618164 time/batch=0.60s
21332/10943 (epoch 175.437) train_loss=487.89373779 time/batch=0.81s
21333/10943 (epoch 175.445) train_loss=200.76142883 time/batch=0.40s
21334/10943 (epoch 175.453) train_loss=559.82666016 time/batch=0.94s
21335/10943 (epoch 175.461) train_loss=263.28726196 time/batch=0.52s
21336/10943 (epoch 175.470) train_loss=350.48446655 time/batch=0.61s
21337/10943 (epoch 175.478) train_loss=193.34165955 time/batch=0.36s
21338/10943 (epoch 175.486) train_loss=297.73504639 time/batch=0.53s
21339/10943 (epoch 175.494) train_loss=639.93896484 time/batch=1.21s
21340/10943 (epoch 175.502) train_loss=340.68572998 time/batch=0.67s
21341/10943 (epoch 175.511) train_loss=316.16442871 time/batch=0.55s
21342/10943 (epoch 175.519) train_loss=352.24093628 time/batch=0.62s
21343/10943 (epoch 175.527) train_loss=290.23712158 time/batch=0.54s
21344/10943 (epoch 175.535) train_loss=397.96118164 time/batch=0.71s
21345/10943 (epoch 175.544) train_loss=418.58758545 time/batch=0.73s
21346/10943 (epoch 175.552) train_loss=326.94421387 time/batch=0.59s
21347/10943 (epoch 175.560) train_loss=382.59963989 time/batch=0.64s
21348/10943 (epoch 175.568) train_loss=481.33831787 time/batch=0.81s
21349/10943 (epoch 175.576) train_loss=276.93353271 time/batch=0.50s
21350/10943 (epoch 175.585) train_loss=210.82743835 time/batch=0.37s
21351/10943 (epoch 175.593) train_loss=270.23535156 time/batch=0.48s
21352/10943 (epoch 175.601) train_loss=454.16009521 time/batch=0.77s
21353/10943 (epoch 175.609) train_loss=433.35195923 time/batch=0.75s
21354/10943 (epoch 175.618) train_loss=466.37124634 time/batch=0.79s
21355/10943 (epoch 175.626) train_loss=416.85400391 time/batch=0.69s
21356/10943 (epoch 175.634) train_loss=434.97686768 time/batch=0.76s
21357/10943 (epoch 175.642) train_loss=298.77749634 time/batch=0.54s
21358/10943 (epoch 175.650) train_loss=414.08248901 time/batch=0.73s
21359/10943 (epoch 175.659) train_loss=216.50585938 time/batch=0.43s
21360/10943 (epoch 175.667) train_loss=343.58160400 time/batch=0.59s
21361/10943 (epoch 175.675) train_loss=609.31579590 time/batch=0.97s
21362/10943 (epoch 175.683) train_loss=379.77999878 time/batch=0.70s
21363/10943 (epoch 175.692) train_loss=332.28887939 time/batch=0.62s
21364/10943 (epoch 175.700) train_loss=281.26895142 time/batch=0.50s
21365/10943 (epoch 175.708) train_loss=518.98266602 time/batch=0.87s
21366/10943 (epoch 175.716) train_loss=312.83706665 time/batch=0.59s
21367/10943 (epoch 175.724) train_loss=456.90734863 time/batch=0.78s
21368/10943 (epoch 175.733) train_loss=552.43298340 time/batch=0.94s
21369/10943 (epoch 175.741) train_loss=544.35681152 time/batch=0.93s
21370/10943 (epoch 175.749) train_loss=497.67413330 time/batch=0.85s
21371/10943 (epoch 175.757) train_loss=537.96990967 time/batch=0.94s
21372/10943 (epoch 175.766) train_loss=196.08435059 time/batch=0.41s
21373/10943 (epoch 175.774) train_loss=455.17745972 time/batch=0.75s
21374/10943 (epoch 175.782) train_loss=486.00820923 time/batch=0.86s
21375/10943 (epoch 175.790) train_loss=220.91268921 time/batch=0.47s
21376/10943 (epoch 175.799) train_loss=280.72137451 time/batch=0.51s
21377/10943 (epoch 175.807) train_loss=341.30993652 time/batch=0.61s
21378/10943 (epoch 175.815) train_loss=443.75317383 time/batch=0.79s
21379/10943 (epoch 175.823) train_loss=496.02758789 time/batch=0.99s
21380/10943 (epoch 175.831) train_loss=337.60986328 time/batch=0.71s
21381/10943 (epoch 175.840) train_loss=328.01452637 time/batch=0.59s
21382/10943 (epoch 175.848) train_loss=454.74810791 time/batch=0.77s
21383/10943 (epoch 175.856) train_loss=265.38693237 time/batch=0.55s
21384/10943 (epoch 175.864) train_loss=395.20138550 time/batch=0.66s
21385/10943 (epoch 175.873) train_loss=339.58035278 time/batch=0.58s
21386/10943 (epoch 175.881) train_loss=361.65774536 time/batch=0.75s
setting learning rate to 0.0007618
21387/10943 (epoch 175.889) train_loss=385.52120972 time/batch=0.70s
21388/10943 (epoch 175.897) train_loss=316.24896240 time/batch=0.60s
21389/10943 (epoch 175.905) train_loss=833.93072510 time/batch=1.28s
21390/10943 (epoch 175.914) train_loss=1417.98986816 time/batch=3.15s
21391/10943 (epoch 175.922) train_loss=739.18164062 time/batch=1.39s
21392/10943 (epoch 175.930) train_loss=1049.03027344 time/batch=1.72s
21393/10943 (epoch 175.938) train_loss=591.11297607 time/batch=1.07s
21394/10943 (epoch 175.947) train_loss=395.30499268 time/batch=0.70s
21395/10943 (epoch 175.955) train_loss=146.60736084 time/batch=0.31s
21396/10943 (epoch 175.963) train_loss=818.32403564 time/batch=1.30s
21397/10943 (epoch 175.971) train_loss=565.97180176 time/batch=1.05s
21398/10943 (epoch 175.979) train_loss=148.20486450 time/batch=0.35s
21399/10943 (epoch 175.988) train_loss=255.72683716 time/batch=0.45s
21400/10943 (epoch 175.996) train_loss=661.75292969 time/batch=1.11s
21401/10943 (epoch 176.004) train_loss=551.67492676 time/batch=0.97s
21402/10943 (epoch 176.012) train_loss=908.67077637 time/batch=1.55s
21403/10943 (epoch 176.021) train_loss=641.12042236 time/batch=1.14s
21404/10943 (epoch 176.029) train_loss=455.71307373 time/batch=0.84s
21405/10943 (epoch 176.037) train_loss=240.20753479 time/batch=0.47s
21406/10943 (epoch 176.045) train_loss=392.80133057 time/batch=0.64s
21407/10943 (epoch 176.053) train_loss=678.39245605 time/batch=1.15s
21408/10943 (epoch 176.062) train_loss=428.29858398 time/batch=0.79s
21409/10943 (epoch 176.070) train_loss=822.76501465 time/batch=1.67s
21410/10943 (epoch 176.078) train_loss=178.96087646 time/batch=0.46s
21411/10943 (epoch 176.086) train_loss=246.81809998 time/batch=0.41s
21412/10943 (epoch 176.095) train_loss=382.35165405 time/batch=0.63s
21413/10943 (epoch 176.103) train_loss=527.08117676 time/batch=0.88s
21414/10943 (epoch 176.111) train_loss=521.76226807 time/batch=0.89s
21415/10943 (epoch 176.119) train_loss=371.68936157 time/batch=0.68s
21416/10943 (epoch 176.127) train_loss=577.94366455 time/batch=0.99s
21417/10943 (epoch 176.136) train_loss=657.03735352 time/batch=1.13s
21418/10943 (epoch 176.144) train_loss=261.67816162 time/batch=0.52s
21419/10943 (epoch 176.152) train_loss=269.43893433 time/batch=0.47s
21420/10943 (epoch 176.160) train_loss=735.46966553 time/batch=1.17s
21421/10943 (epoch 176.169) train_loss=507.54421997 time/batch=0.91s
21422/10943 (epoch 176.177) train_loss=328.24807739 time/batch=0.60s
21423/10943 (epoch 176.185) train_loss=189.70593262 time/batch=0.36s
21424/10943 (epoch 176.193) train_loss=386.68798828 time/batch=0.67s
21425/10943 (epoch 176.201) train_loss=279.15744019 time/batch=0.51s
21426/10943 (epoch 176.210) train_loss=448.24481201 time/batch=0.80s
21427/10943 (epoch 176.218) train_loss=350.14944458 time/batch=0.64s
21428/10943 (epoch 176.226) train_loss=566.71447754 time/batch=0.96s
21429/10943 (epoch 176.234) train_loss=434.81881714 time/batch=0.75s
21430/10943 (epoch 176.243) train_loss=382.25473022 time/batch=0.64s
21431/10943 (epoch 176.251) train_loss=336.18716431 time/batch=0.58s
21432/10943 (epoch 176.259) train_loss=681.26055908 time/batch=1.15s
21433/10943 (epoch 176.267) train_loss=456.95779419 time/batch=0.81s
21434/10943 (epoch 176.276) train_loss=469.24752808 time/batch=0.80s
21435/10943 (epoch 176.284) train_loss=204.03190613 time/batch=0.39s
21436/10943 (epoch 176.292) train_loss=646.75622559 time/batch=1.16s
21437/10943 (epoch 176.300) train_loss=619.37030029 time/batch=1.08s
21438/10943 (epoch 176.308) train_loss=442.14031982 time/batch=0.79s
21439/10943 (epoch 176.317) train_loss=644.83062744 time/batch=1.21s
21440/10943 (epoch 176.325) train_loss=231.89978027 time/batch=0.49s
21441/10943 (epoch 176.333) train_loss=275.00439453 time/batch=0.48s
21442/10943 (epoch 176.341) train_loss=271.19958496 time/batch=0.50s
21443/10943 (epoch 176.350) train_loss=347.07089233 time/batch=0.62s
21444/10943 (epoch 176.358) train_loss=688.86975098 time/batch=1.23s
21445/10943 (epoch 176.366) train_loss=478.87835693 time/batch=0.85s
21446/10943 (epoch 176.374) train_loss=345.52380371 time/batch=0.63s
21447/10943 (epoch 176.382) train_loss=576.30700684 time/batch=0.93s
21448/10943 (epoch 176.391) train_loss=287.56048584 time/batch=0.57s
21449/10943 (epoch 176.399) train_loss=382.33862305 time/batch=0.64s
21450/10943 (epoch 176.407) train_loss=386.31127930 time/batch=0.68s
21451/10943 (epoch 176.415) train_loss=242.42713928 time/batch=0.47s
21452/10943 (epoch 176.424) train_loss=526.17517090 time/batch=0.86s
21453/10943 (epoch 176.432) train_loss=312.35379028 time/batch=0.60s
21454/10943 (epoch 176.440) train_loss=256.54598999 time/batch=0.47s
21455/10943 (epoch 176.448) train_loss=375.96575928 time/batch=0.64s
21456/10943 (epoch 176.456) train_loss=287.76757812 time/batch=0.54s
21457/10943 (epoch 176.465) train_loss=167.51049805 time/batch=0.33s
21458/10943 (epoch 176.473) train_loss=513.29705811 time/batch=0.88s
21459/10943 (epoch 176.481) train_loss=424.30383301 time/batch=0.74s
21460/10943 (epoch 176.489) train_loss=195.02185059 time/batch=0.39s
21461/10943 (epoch 176.498) train_loss=440.54187012 time/batch=0.75s
21462/10943 (epoch 176.506) train_loss=425.46112061 time/batch=0.71s
21463/10943 (epoch 176.514) train_loss=463.56079102 time/batch=0.81s
21464/10943 (epoch 176.522) train_loss=523.12951660 time/batch=0.89s
21465/10943 (epoch 176.530) train_loss=308.61422729 time/batch=0.57s
21466/10943 (epoch 176.539) train_loss=356.22579956 time/batch=0.60s
21467/10943 (epoch 176.547) train_loss=287.14315796 time/batch=0.51s
21468/10943 (epoch 176.555) train_loss=209.17214966 time/batch=0.39s
21469/10943 (epoch 176.563) train_loss=311.94085693 time/batch=0.53s
21470/10943 (epoch 176.572) train_loss=327.37588501 time/batch=0.57s
21471/10943 (epoch 176.580) train_loss=180.72349548 time/batch=0.34s
21472/10943 (epoch 176.588) train_loss=175.57873535 time/batch=0.35s
21473/10943 (epoch 176.596) train_loss=349.95806885 time/batch=0.60s
21474/10943 (epoch 176.604) train_loss=170.80120850 time/batch=0.38s
21475/10943 (epoch 176.613) train_loss=276.65020752 time/batch=0.49s
21476/10943 (epoch 176.621) train_loss=549.31494141 time/batch=0.96s
21477/10943 (epoch 176.629) train_loss=229.70602417 time/batch=0.47s
21478/10943 (epoch 176.637) train_loss=328.08749390 time/batch=0.56s
21479/10943 (epoch 176.646) train_loss=340.26705933 time/batch=0.61s
21480/10943 (epoch 176.654) train_loss=487.84869385 time/batch=0.82s
21481/10943 (epoch 176.662) train_loss=224.28305054 time/batch=0.45s
21482/10943 (epoch 176.670) train_loss=443.70422363 time/batch=0.74s
21483/10943 (epoch 176.678) train_loss=429.71142578 time/batch=0.74s
21484/10943 (epoch 176.687) train_loss=360.62322998 time/batch=0.65s
21485/10943 (epoch 176.695) train_loss=528.83471680 time/batch=0.92s
21486/10943 (epoch 176.703) train_loss=304.99395752 time/batch=0.58s
21487/10943 (epoch 176.711) train_loss=470.78558350 time/batch=0.80s
21488/10943 (epoch 176.720) train_loss=329.18545532 time/batch=0.64s
21489/10943 (epoch 176.728) train_loss=336.60128784 time/batch=0.63s
21490/10943 (epoch 176.736) train_loss=211.71842957 time/batch=0.39s
21491/10943 (epoch 176.744) train_loss=436.18710327 time/batch=0.75s
21492/10943 (epoch 176.753) train_loss=492.96569824 time/batch=0.85s
21493/10943 (epoch 176.761) train_loss=498.59497070 time/batch=0.89s
21494/10943 (epoch 176.769) train_loss=433.37835693 time/batch=0.74s
21495/10943 (epoch 176.777) train_loss=222.67315674 time/batch=0.46s
21496/10943 (epoch 176.785) train_loss=422.46026611 time/batch=0.72s
21497/10943 (epoch 176.794) train_loss=461.58825684 time/batch=0.82s
21498/10943 (epoch 176.802) train_loss=450.55969238 time/batch=0.81s
21499/10943 (epoch 176.810) train_loss=477.32562256 time/batch=0.84s
21500/10943 (epoch 176.818) train_loss=417.91693115 time/batch=0.71s
21501/10943 (epoch 176.827) train_loss=331.37979126 time/batch=0.60s
21502/10943 (epoch 176.835) train_loss=388.62744141 time/batch=0.68s
21503/10943 (epoch 176.843) train_loss=320.41799927 time/batch=0.69s
21504/10943 (epoch 176.851) train_loss=317.21936035 time/batch=0.72s
21505/10943 (epoch 176.859) train_loss=446.20404053 time/batch=0.79s
21506/10943 (epoch 176.868) train_loss=480.66140747 time/batch=0.85s
21507/10943 (epoch 176.876) train_loss=413.28656006 time/batch=0.84s
setting learning rate to 0.0007390
21508/10943 (epoch 176.884) train_loss=257.24938965 time/batch=0.49s
21509/10943 (epoch 176.892) train_loss=489.07504272 time/batch=0.79s
21510/10943 (epoch 176.901) train_loss=537.22064209 time/batch=0.90s
21511/10943 (epoch 176.909) train_loss=184.73300171 time/batch=0.38s
21512/10943 (epoch 176.917) train_loss=686.24334717 time/batch=1.06s
21513/10943 (epoch 176.925) train_loss=496.93890381 time/batch=0.90s
21514/10943 (epoch 176.933) train_loss=775.01342773 time/batch=1.26s
21515/10943 (epoch 176.942) train_loss=1424.17871094 time/batch=3.15s
21516/10943 (epoch 176.950) train_loss=301.19842529 time/batch=0.79s
21517/10943 (epoch 176.958) train_loss=439.84143066 time/batch=0.71s
21518/10943 (epoch 176.966) train_loss=261.88137817 time/batch=0.48s
21519/10943 (epoch 176.975) train_loss=662.42718506 time/batch=1.11s
21520/10943 (epoch 176.983) train_loss=290.04486084 time/batch=0.59s
21521/10943 (epoch 176.991) train_loss=929.55615234 time/batch=1.53s
21522/10943 (epoch 176.999) train_loss=354.52041626 time/batch=0.70s
21523/10943 (epoch 177.007) train_loss=431.43817139 time/batch=0.74s
21524/10943 (epoch 177.016) train_loss=442.33050537 time/batch=0.77s
21525/10943 (epoch 177.024) train_loss=821.35046387 time/batch=1.39s
21526/10943 (epoch 177.032) train_loss=444.85324097 time/batch=0.83s
21527/10943 (epoch 177.040) train_loss=832.96911621 time/batch=1.32s
21528/10943 (epoch 177.049) train_loss=360.88327026 time/batch=0.71s
21529/10943 (epoch 177.057) train_loss=391.01147461 time/batch=0.66s
21530/10943 (epoch 177.065) train_loss=642.95104980 time/batch=1.09s
21531/10943 (epoch 177.073) train_loss=625.86193848 time/batch=1.03s
21532/10943 (epoch 177.081) train_loss=395.92053223 time/batch=0.73s
21533/10943 (epoch 177.090) train_loss=165.81001282 time/batch=0.33s
21534/10943 (epoch 177.098) train_loss=396.85241699 time/batch=0.66s
21535/10943 (epoch 177.106) train_loss=614.27893066 time/batch=1.04s
21536/10943 (epoch 177.114) train_loss=419.73217773 time/batch=0.77s
21537/10943 (epoch 177.123) train_loss=200.66204834 time/batch=0.39s
21538/10943 (epoch 177.131) train_loss=330.42016602 time/batch=0.56s
21539/10943 (epoch 177.139) train_loss=199.25788879 time/batch=0.38s
21540/10943 (epoch 177.147) train_loss=378.92108154 time/batch=0.62s
21541/10943 (epoch 177.155) train_loss=374.33032227 time/batch=0.64s
21542/10943 (epoch 177.164) train_loss=492.12933350 time/batch=0.84s
21543/10943 (epoch 177.172) train_loss=537.23577881 time/batch=0.93s
21544/10943 (epoch 177.180) train_loss=176.82138062 time/batch=0.36s
21545/10943 (epoch 177.188) train_loss=511.61364746 time/batch=0.83s
21546/10943 (epoch 177.197) train_loss=883.84625244 time/batch=1.63s
21547/10943 (epoch 177.205) train_loss=211.69190979 time/batch=0.48s
21548/10943 (epoch 177.213) train_loss=300.31707764 time/batch=0.51s
21549/10943 (epoch 177.221) train_loss=631.21923828 time/batch=1.09s
21550/10943 (epoch 177.230) train_loss=555.44525146 time/batch=0.97s
21551/10943 (epoch 177.238) train_loss=165.62411499 time/batch=0.37s
21552/10943 (epoch 177.246) train_loss=518.17590332 time/batch=0.88s
21553/10943 (epoch 177.254) train_loss=290.28912354 time/batch=0.56s
21554/10943 (epoch 177.262) train_loss=224.75570679 time/batch=0.42s
21555/10943 (epoch 177.271) train_loss=246.85359192 time/batch=0.42s
21556/10943 (epoch 177.279) train_loss=578.25927734 time/batch=0.98s
21557/10943 (epoch 177.287) train_loss=420.78405762 time/batch=0.77s
21558/10943 (epoch 177.295) train_loss=528.32318115 time/batch=0.90s
21559/10943 (epoch 177.304) train_loss=522.54040527 time/batch=0.91s
21560/10943 (epoch 177.312) train_loss=335.66116333 time/batch=0.61s
21561/10943 (epoch 177.320) train_loss=442.30828857 time/batch=0.75s
21562/10943 (epoch 177.328) train_loss=149.25517273 time/batch=0.35s
21563/10943 (epoch 177.336) train_loss=565.60021973 time/batch=0.92s
21564/10943 (epoch 177.345) train_loss=288.94888306 time/batch=0.55s
21565/10943 (epoch 177.353) train_loss=188.81362915 time/batch=0.34s
21566/10943 (epoch 177.361) train_loss=557.75207520 time/batch=0.93s
21567/10943 (epoch 177.369) train_loss=762.10375977 time/batch=1.27s
21568/10943 (epoch 177.378) train_loss=324.97885132 time/batch=0.63s
21569/10943 (epoch 177.386) train_loss=619.32635498 time/batch=1.00s
21570/10943 (epoch 177.394) train_loss=460.45086670 time/batch=0.85s
21571/10943 (epoch 177.402) train_loss=486.00640869 time/batch=0.85s
21572/10943 (epoch 177.410) train_loss=387.97402954 time/batch=0.71s
21573/10943 (epoch 177.419) train_loss=661.45178223 time/batch=1.15s
21574/10943 (epoch 177.427) train_loss=462.53851318 time/batch=0.87s
21575/10943 (epoch 177.435) train_loss=297.48358154 time/batch=0.57s
21576/10943 (epoch 177.443) train_loss=449.94430542 time/batch=0.79s
21577/10943 (epoch 177.452) train_loss=656.66088867 time/batch=1.17s
21578/10943 (epoch 177.460) train_loss=355.71847534 time/batch=0.68s
21579/10943 (epoch 177.468) train_loss=450.68536377 time/batch=0.77s
21580/10943 (epoch 177.476) train_loss=190.82516479 time/batch=0.39s
21581/10943 (epoch 177.484) train_loss=474.01574707 time/batch=0.79s
21582/10943 (epoch 177.493) train_loss=893.62628174 time/batch=1.68s
21583/10943 (epoch 177.501) train_loss=489.13122559 time/batch=0.93s
21584/10943 (epoch 177.509) train_loss=381.20797729 time/batch=0.67s
21585/10943 (epoch 177.517) train_loss=299.43908691 time/batch=0.55s
21586/10943 (epoch 177.526) train_loss=500.53845215 time/batch=0.85s
21587/10943 (epoch 177.534) train_loss=544.21643066 time/batch=0.96s
21588/10943 (epoch 177.542) train_loss=296.06710815 time/batch=0.59s
21589/10943 (epoch 177.550) train_loss=205.17071533 time/batch=0.39s
21590/10943 (epoch 177.558) train_loss=217.56405640 time/batch=0.39s
21591/10943 (epoch 177.567) train_loss=433.85107422 time/batch=0.72s
21592/10943 (epoch 177.575) train_loss=561.57440186 time/batch=0.96s
21593/10943 (epoch 177.583) train_loss=320.67996216 time/batch=0.62s
21594/10943 (epoch 177.591) train_loss=357.95922852 time/batch=0.63s
21595/10943 (epoch 177.600) train_loss=322.57330322 time/batch=0.58s
21596/10943 (epoch 177.608) train_loss=342.06393433 time/batch=0.62s
21597/10943 (epoch 177.616) train_loss=158.81459045 time/batch=0.39s
21598/10943 (epoch 177.624) train_loss=315.53741455 time/batch=0.58s
21599/10943 (epoch 177.632) train_loss=274.56542969 time/batch=0.50s
21600/10943 (epoch 177.641) train_loss=352.14276123 time/batch=0.61s
21601/10943 (epoch 177.649) train_loss=217.34378052 time/batch=0.41s
21602/10943 (epoch 177.657) train_loss=397.03686523 time/batch=0.67s
21603/10943 (epoch 177.665) train_loss=456.99877930 time/batch=0.80s
21604/10943 (epoch 177.674) train_loss=348.07464600 time/batch=0.63s
21605/10943 (epoch 177.682) train_loss=317.20056152 time/batch=0.59s
21606/10943 (epoch 177.690) train_loss=259.65826416 time/batch=0.47s
21607/10943 (epoch 177.698) train_loss=329.74481201 time/batch=0.59s
21608/10943 (epoch 177.707) train_loss=215.43338013 time/batch=0.44s
21609/10943 (epoch 177.715) train_loss=231.87750244 time/batch=0.44s
21610/10943 (epoch 177.723) train_loss=258.36163330 time/batch=0.46s
21611/10943 (epoch 177.731) train_loss=564.35192871 time/batch=1.15s
21612/10943 (epoch 177.739) train_loss=317.40008545 time/batch=0.67s
21613/10943 (epoch 177.748) train_loss=488.47113037 time/batch=0.92s
21614/10943 (epoch 177.756) train_loss=456.81082153 time/batch=0.80s
21615/10943 (epoch 177.764) train_loss=428.08700562 time/batch=0.72s
21616/10943 (epoch 177.772) train_loss=405.50750732 time/batch=0.68s
21617/10943 (epoch 177.781) train_loss=491.89831543 time/batch=1.67s
21618/10943 (epoch 177.789) train_loss=338.95471191 time/batch=0.73s
21619/10943 (epoch 177.797) train_loss=325.47583008 time/batch=0.60s
21620/10943 (epoch 177.805) train_loss=451.19854736 time/batch=0.77s
21621/10943 (epoch 177.813) train_loss=430.04382324 time/batch=0.72s
21622/10943 (epoch 177.822) train_loss=270.50576782 time/batch=0.51s
21623/10943 (epoch 177.830) train_loss=385.12100220 time/batch=0.64s
21624/10943 (epoch 177.838) train_loss=402.79071045 time/batch=0.71s
21625/10943 (epoch 177.846) train_loss=265.80380249 time/batch=0.65s
21626/10943 (epoch 177.855) train_loss=378.64172363 time/batch=0.66s
21627/10943 (epoch 177.863) train_loss=454.01666260 time/batch=0.79s
21628/10943 (epoch 177.871) train_loss=421.74279785 time/batch=0.71s
setting learning rate to 0.0007168
21629/10943 (epoch 177.879) train_loss=464.33544922 time/batch=0.81s
21630/10943 (epoch 177.887) train_loss=847.79724121 time/batch=1.37s
21631/10943 (epoch 177.896) train_loss=532.78192139 time/batch=0.89s
21632/10943 (epoch 177.904) train_loss=685.61248779 time/batch=1.13s
21633/10943 (epoch 177.912) train_loss=884.05676270 time/batch=1.54s
21634/10943 (epoch 177.920) train_loss=650.06323242 time/batch=1.14s
21635/10943 (epoch 177.929) train_loss=411.01184082 time/batch=0.74s
21636/10943 (epoch 177.937) train_loss=778.04370117 time/batch=1.25s
21637/10943 (epoch 177.945) train_loss=622.73205566 time/batch=1.11s
21638/10943 (epoch 177.953) train_loss=639.63635254 time/batch=1.11s
21639/10943 (epoch 177.961) train_loss=257.95492554 time/batch=0.51s
21640/10943 (epoch 177.970) train_loss=735.14111328 time/batch=1.22s
21641/10943 (epoch 177.978) train_loss=226.99743652 time/batch=0.49s
21642/10943 (epoch 177.986) train_loss=831.46252441 time/batch=1.34s
21643/10943 (epoch 177.994) train_loss=1108.64892578 time/batch=2.03s
21644/10943 (epoch 178.003) train_loss=712.33117676 time/batch=1.23s
21645/10943 (epoch 178.011) train_loss=342.07934570 time/batch=0.63s
21646/10943 (epoch 178.019) train_loss=518.82244873 time/batch=0.86s
21647/10943 (epoch 178.027) train_loss=446.52972412 time/batch=0.79s
21648/10943 (epoch 178.035) train_loss=174.69683838 time/batch=0.36s
21649/10943 (epoch 178.044) train_loss=264.38418579 time/batch=0.44s
21650/10943 (epoch 178.052) train_loss=241.54141235 time/batch=0.44s
21651/10943 (epoch 178.060) train_loss=618.64233398 time/batch=0.96s
21652/10943 (epoch 178.068) train_loss=390.30377197 time/batch=0.70s
21653/10943 (epoch 178.077) train_loss=634.17907715 time/batch=1.07s
21654/10943 (epoch 178.085) train_loss=778.25634766 time/batch=1.56s
21655/10943 (epoch 178.093) train_loss=593.26049805 time/batch=1.06s
21656/10943 (epoch 178.101) train_loss=1022.66156006 time/batch=2.11s
21657/10943 (epoch 178.109) train_loss=144.45208740 time/batch=0.44s
21658/10943 (epoch 178.118) train_loss=167.66020203 time/batch=0.30s
21659/10943 (epoch 178.126) train_loss=462.87759399 time/batch=0.73s
21660/10943 (epoch 178.134) train_loss=336.70166016 time/batch=0.62s
21661/10943 (epoch 178.142) train_loss=493.50628662 time/batch=0.84s
21662/10943 (epoch 178.151) train_loss=307.22024536 time/batch=0.60s
21663/10943 (epoch 178.159) train_loss=543.52722168 time/batch=0.91s
21664/10943 (epoch 178.167) train_loss=168.18710327 time/batch=0.36s
21665/10943 (epoch 178.175) train_loss=692.75451660 time/batch=1.12s
21666/10943 (epoch 178.184) train_loss=362.41021729 time/batch=0.71s
21667/10943 (epoch 178.192) train_loss=249.21765137 time/batch=0.46s
21668/10943 (epoch 178.200) train_loss=505.02343750 time/batch=0.83s
21669/10943 (epoch 178.208) train_loss=193.09980774 time/batch=0.39s
21670/10943 (epoch 178.216) train_loss=286.30068970 time/batch=0.51s
21671/10943 (epoch 178.225) train_loss=518.21337891 time/batch=0.86s
21672/10943 (epoch 178.233) train_loss=418.03155518 time/batch=0.73s
21673/10943 (epoch 178.241) train_loss=575.05767822 time/batch=0.99s
21674/10943 (epoch 178.249) train_loss=752.57330322 time/batch=2.20s
21675/10943 (epoch 178.258) train_loss=414.51940918 time/batch=0.86s
21676/10943 (epoch 178.266) train_loss=432.65136719 time/batch=0.74s
21677/10943 (epoch 178.274) train_loss=347.24072266 time/batch=0.64s
21678/10943 (epoch 178.282) train_loss=448.87738037 time/batch=0.79s
21679/10943 (epoch 178.290) train_loss=204.91007996 time/batch=0.41s
21680/10943 (epoch 178.299) train_loss=267.15490723 time/batch=0.46s
21681/10943 (epoch 178.307) train_loss=417.93115234 time/batch=0.69s
21682/10943 (epoch 178.315) train_loss=297.38070679 time/batch=0.55s
21683/10943 (epoch 178.323) train_loss=372.25091553 time/batch=0.64s
21684/10943 (epoch 178.332) train_loss=161.31846619 time/batch=0.34s
21685/10943 (epoch 178.340) train_loss=571.59912109 time/batch=0.93s
21686/10943 (epoch 178.348) train_loss=220.59095764 time/batch=0.46s
21687/10943 (epoch 178.356) train_loss=397.96466064 time/batch=0.64s
21688/10943 (epoch 178.364) train_loss=385.70968628 time/batch=0.69s
21689/10943 (epoch 178.373) train_loss=315.52709961 time/batch=0.57s
21690/10943 (epoch 178.381) train_loss=218.47673035 time/batch=0.41s
21691/10943 (epoch 178.389) train_loss=392.84576416 time/batch=0.65s
21692/10943 (epoch 178.397) train_loss=485.02764893 time/batch=0.84s
21693/10943 (epoch 178.406) train_loss=575.47039795 time/batch=0.99s
21694/10943 (epoch 178.414) train_loss=590.73211670 time/batch=1.03s
21695/10943 (epoch 178.422) train_loss=355.39932251 time/batch=0.65s
21696/10943 (epoch 178.430) train_loss=367.26391602 time/batch=0.64s
21697/10943 (epoch 178.438) train_loss=184.45761108 time/batch=0.37s
21698/10943 (epoch 178.447) train_loss=255.22155762 time/batch=0.45s
21699/10943 (epoch 178.455) train_loss=459.70599365 time/batch=0.78s
21700/10943 (epoch 178.463) train_loss=453.87579346 time/batch=0.82s
21701/10943 (epoch 178.471) train_loss=456.13290405 time/batch=0.80s
21702/10943 (epoch 178.480) train_loss=370.90118408 time/batch=0.66s
21703/10943 (epoch 178.488) train_loss=517.37902832 time/batch=0.92s
21704/10943 (epoch 178.496) train_loss=286.96353149 time/batch=0.56s
21705/10943 (epoch 178.504) train_loss=874.43920898 time/batch=3.07s
21706/10943 (epoch 178.512) train_loss=434.61419678 time/batch=0.98s
21707/10943 (epoch 178.521) train_loss=482.21099854 time/batch=0.83s
21708/10943 (epoch 178.529) train_loss=425.96163940 time/batch=0.75s
21709/10943 (epoch 178.537) train_loss=185.99055481 time/batch=0.38s
21710/10943 (epoch 178.545) train_loss=291.67044067 time/batch=0.51s
21711/10943 (epoch 178.554) train_loss=461.74041748 time/batch=0.80s
21712/10943 (epoch 178.562) train_loss=218.61856079 time/batch=0.45s
21713/10943 (epoch 178.570) train_loss=503.13031006 time/batch=0.85s
21714/10943 (epoch 178.578) train_loss=449.32604980 time/batch=0.82s
21715/10943 (epoch 178.586) train_loss=353.79968262 time/batch=0.63s
21716/10943 (epoch 178.595) train_loss=304.32711792 time/batch=0.55s
21717/10943 (epoch 178.603) train_loss=201.25430298 time/batch=0.42s
21718/10943 (epoch 178.611) train_loss=323.04864502 time/batch=0.56s
21719/10943 (epoch 178.619) train_loss=246.33766174 time/batch=0.48s
21720/10943 (epoch 178.628) train_loss=475.33850098 time/batch=0.83s
21721/10943 (epoch 178.636) train_loss=468.82977295 time/batch=0.85s
21722/10943 (epoch 178.644) train_loss=534.21643066 time/batch=0.94s
21723/10943 (epoch 178.652) train_loss=294.21209717 time/batch=0.57s
21724/10943 (epoch 178.660) train_loss=479.84741211 time/batch=0.86s
21725/10943 (epoch 178.669) train_loss=353.09051514 time/batch=0.66s
21726/10943 (epoch 178.677) train_loss=217.61463928 time/batch=0.43s
21727/10943 (epoch 178.685) train_loss=354.89016724 time/batch=0.61s
21728/10943 (epoch 178.693) train_loss=287.81811523 time/batch=0.55s
21729/10943 (epoch 178.702) train_loss=384.40820312 time/batch=0.67s
21730/10943 (epoch 178.710) train_loss=279.31597900 time/batch=0.51s
21731/10943 (epoch 178.718) train_loss=260.70452881 time/batch=0.48s
21732/10943 (epoch 178.726) train_loss=431.04095459 time/batch=0.74s
21733/10943 (epoch 178.735) train_loss=278.38717651 time/batch=0.53s
21734/10943 (epoch 178.743) train_loss=228.30908203 time/batch=0.46s
21735/10943 (epoch 178.751) train_loss=342.76977539 time/batch=0.60s
21736/10943 (epoch 178.759) train_loss=339.93359375 time/batch=0.60s
21737/10943 (epoch 178.767) train_loss=324.16006470 time/batch=0.58s
21738/10943 (epoch 178.776) train_loss=336.19815063 time/batch=0.63s
21739/10943 (epoch 178.784) train_loss=426.88442993 time/batch=0.72s
21740/10943 (epoch 178.792) train_loss=438.05981445 time/batch=0.78s
21741/10943 (epoch 178.800) train_loss=374.67779541 time/batch=0.67s
21742/10943 (epoch 178.809) train_loss=420.86993408 time/batch=0.71s
21743/10943 (epoch 178.817) train_loss=418.95806885 time/batch=0.72s
21744/10943 (epoch 178.825) train_loss=491.08105469 time/batch=0.91s
21745/10943 (epoch 178.833) train_loss=443.17187500 time/batch=0.81s
21746/10943 (epoch 178.841) train_loss=335.25146484 time/batch=0.60s
21747/10943 (epoch 178.850) train_loss=307.42593384 time/batch=0.59s
21748/10943 (epoch 178.858) train_loss=413.42175293 time/batch=0.72s
21749/10943 (epoch 178.866) train_loss=278.30126953 time/batch=0.70s
setting learning rate to 0.0006953
21750/10943 (epoch 178.874) train_loss=829.23425293 time/batch=1.42s
21751/10943 (epoch 178.883) train_loss=243.98948669 time/batch=0.53s
21752/10943 (epoch 178.891) train_loss=175.54135132 time/batch=0.32s
21753/10943 (epoch 178.899) train_loss=618.42187500 time/batch=1.01s
21754/10943 (epoch 178.907) train_loss=868.38378906 time/batch=1.53s
21755/10943 (epoch 178.915) train_loss=467.60162354 time/batch=0.84s
21756/10943 (epoch 178.924) train_loss=311.81732178 time/batch=0.58s
21757/10943 (epoch 178.932) train_loss=294.59057617 time/batch=0.53s
21758/10943 (epoch 178.940) train_loss=415.43029785 time/batch=0.69s
21759/10943 (epoch 178.948) train_loss=496.18032837 time/batch=0.86s
21760/10943 (epoch 178.957) train_loss=712.64758301 time/batch=1.21s
21761/10943 (epoch 178.965) train_loss=857.17755127 time/batch=1.56s
21762/10943 (epoch 178.973) train_loss=1384.31567383 time/batch=3.17s
21763/10943 (epoch 178.981) train_loss=591.51531982 time/batch=1.20s
21764/10943 (epoch 178.989) train_loss=459.40283203 time/batch=0.83s
21765/10943 (epoch 178.998) train_loss=512.09442139 time/batch=0.89s
21766/10943 (epoch 179.006) train_loss=667.89587402 time/batch=1.16s
21767/10943 (epoch 179.014) train_loss=735.53723145 time/batch=1.26s
21768/10943 (epoch 179.022) train_loss=404.62753296 time/batch=0.74s
21769/10943 (epoch 179.031) train_loss=1014.24517822 time/batch=1.68s
21770/10943 (epoch 179.039) train_loss=622.85363770 time/batch=1.12s
21771/10943 (epoch 179.047) train_loss=217.77853394 time/batch=0.45s
21772/10943 (epoch 179.055) train_loss=612.67907715 time/batch=1.00s
21773/10943 (epoch 179.063) train_loss=245.97294617 time/batch=0.49s
21774/10943 (epoch 179.072) train_loss=570.78466797 time/batch=0.94s
21775/10943 (epoch 179.080) train_loss=631.36224365 time/batch=1.11s
21776/10943 (epoch 179.088) train_loss=373.42721558 time/batch=0.71s
21777/10943 (epoch 179.096) train_loss=510.50860596 time/batch=0.87s
21778/10943 (epoch 179.105) train_loss=410.21176147 time/batch=0.76s
21779/10943 (epoch 179.113) train_loss=226.59793091 time/batch=0.44s
21780/10943 (epoch 179.121) train_loss=131.18579102 time/batch=0.26s
21781/10943 (epoch 179.129) train_loss=263.91629028 time/batch=0.46s
21782/10943 (epoch 179.137) train_loss=255.15592957 time/batch=0.45s
21783/10943 (epoch 179.146) train_loss=642.41687012 time/batch=1.08s
21784/10943 (epoch 179.154) train_loss=799.14074707 time/batch=1.33s
21785/10943 (epoch 179.162) train_loss=704.58459473 time/batch=1.29s
21786/10943 (epoch 179.170) train_loss=285.24194336 time/batch=0.56s
21787/10943 (epoch 179.179) train_loss=669.38525391 time/batch=1.07s
21788/10943 (epoch 179.187) train_loss=522.31756592 time/batch=0.95s
21789/10943 (epoch 179.195) train_loss=371.32531738 time/batch=0.69s
21790/10943 (epoch 179.203) train_loss=160.56716919 time/batch=0.32s
21791/10943 (epoch 179.212) train_loss=471.96835327 time/batch=0.79s
21792/10943 (epoch 179.220) train_loss=561.48309326 time/batch=0.96s
21793/10943 (epoch 179.228) train_loss=154.40563965 time/batch=0.37s
21794/10943 (epoch 179.236) train_loss=548.24407959 time/batch=0.92s
21795/10943 (epoch 179.244) train_loss=409.10577393 time/batch=0.71s
21796/10943 (epoch 179.253) train_loss=327.58807373 time/batch=0.60s
21797/10943 (epoch 179.261) train_loss=423.53485107 time/batch=0.70s
21798/10943 (epoch 179.269) train_loss=238.45791626 time/batch=0.45s
21799/10943 (epoch 179.277) train_loss=179.24545288 time/batch=0.33s
21800/10943 (epoch 179.286) train_loss=675.27587891 time/batch=1.49s
21801/10943 (epoch 179.294) train_loss=434.83831787 time/batch=0.84s
21802/10943 (epoch 179.302) train_loss=418.88903809 time/batch=0.73s
21803/10943 (epoch 179.310) train_loss=394.46356201 time/batch=0.67s
21804/10943 (epoch 179.318) train_loss=191.25344849 time/batch=0.36s
21805/10943 (epoch 179.327) train_loss=168.89147949 time/batch=0.31s
21806/10943 (epoch 179.335) train_loss=397.88900757 time/batch=0.65s
21807/10943 (epoch 179.343) train_loss=509.57043457 time/batch=0.88s
21808/10943 (epoch 179.351) train_loss=514.60827637 time/batch=0.87s
21809/10943 (epoch 179.360) train_loss=580.88146973 time/batch=0.98s
21810/10943 (epoch 179.368) train_loss=361.24896240 time/batch=0.66s
21811/10943 (epoch 179.376) train_loss=562.17883301 time/batch=0.96s
21812/10943 (epoch 179.384) train_loss=450.40222168 time/batch=0.81s
21813/10943 (epoch 179.392) train_loss=486.29132080 time/batch=0.89s
21814/10943 (epoch 179.401) train_loss=340.62469482 time/batch=0.64s
21815/10943 (epoch 179.409) train_loss=448.14880371 time/batch=0.77s
21816/10943 (epoch 179.417) train_loss=520.81738281 time/batch=0.91s
21817/10943 (epoch 179.425) train_loss=393.30310059 time/batch=0.73s
21818/10943 (epoch 179.434) train_loss=277.66790771 time/batch=0.51s
21819/10943 (epoch 179.442) train_loss=456.51116943 time/batch=0.77s
21820/10943 (epoch 179.450) train_loss=313.32226562 time/batch=0.59s
21821/10943 (epoch 179.458) train_loss=269.31896973 time/batch=0.50s
21822/10943 (epoch 179.466) train_loss=343.50021362 time/batch=0.60s
21823/10943 (epoch 179.475) train_loss=437.25579834 time/batch=0.74s
21824/10943 (epoch 179.483) train_loss=259.66909790 time/batch=0.49s
21825/10943 (epoch 179.491) train_loss=316.98254395 time/batch=0.56s
21826/10943 (epoch 179.499) train_loss=445.59375000 time/batch=0.79s
21827/10943 (epoch 179.508) train_loss=325.81652832 time/batch=0.61s
21828/10943 (epoch 179.516) train_loss=264.97329712 time/batch=0.48s
21829/10943 (epoch 179.524) train_loss=347.76934814 time/batch=0.60s
21830/10943 (epoch 179.532) train_loss=385.98828125 time/batch=0.68s
21831/10943 (epoch 179.540) train_loss=452.60598755 time/batch=0.82s
21832/10943 (epoch 179.549) train_loss=334.27709961 time/batch=0.62s
21833/10943 (epoch 179.557) train_loss=324.44570923 time/batch=0.59s
21834/10943 (epoch 179.565) train_loss=345.89465332 time/batch=0.61s
21835/10943 (epoch 179.573) train_loss=285.37246704 time/batch=0.54s
21836/10943 (epoch 179.582) train_loss=618.38671875 time/batch=0.98s
21837/10943 (epoch 179.590) train_loss=315.96905518 time/batch=0.60s
21838/10943 (epoch 179.598) train_loss=225.04994202 time/batch=0.45s
21839/10943 (epoch 179.606) train_loss=280.49105835 time/batch=0.51s
21840/10943 (epoch 179.614) train_loss=519.51135254 time/batch=0.98s
21841/10943 (epoch 179.623) train_loss=407.24282837 time/batch=0.74s
21842/10943 (epoch 179.631) train_loss=301.61395264 time/batch=0.56s
21843/10943 (epoch 179.639) train_loss=371.43353271 time/batch=0.63s
21844/10943 (epoch 179.647) train_loss=330.65591431 time/batch=0.61s
21845/10943 (epoch 179.656) train_loss=340.25585938 time/batch=0.63s
21846/10943 (epoch 179.664) train_loss=191.78289795 time/batch=0.37s
21847/10943 (epoch 179.672) train_loss=446.95611572 time/batch=0.77s
21848/10943 (epoch 179.680) train_loss=353.47830200 time/batch=0.65s
21849/10943 (epoch 179.689) train_loss=217.47708130 time/batch=0.40s
21850/10943 (epoch 179.697) train_loss=430.83944702 time/batch=0.74s
21851/10943 (epoch 179.705) train_loss=203.00802612 time/batch=0.42s
21852/10943 (epoch 179.713) train_loss=421.87765503 time/batch=0.73s
21853/10943 (epoch 179.721) train_loss=189.43298340 time/batch=0.39s
21854/10943 (epoch 179.730) train_loss=418.26632690 time/batch=0.70s
21855/10943 (epoch 179.738) train_loss=199.95518494 time/batch=0.46s
21856/10943 (epoch 179.746) train_loss=305.17877197 time/batch=0.56s
21857/10943 (epoch 179.754) train_loss=436.37265015 time/batch=0.76s
21858/10943 (epoch 179.763) train_loss=482.72833252 time/batch=0.84s
21859/10943 (epoch 179.771) train_loss=292.65802002 time/batch=0.54s
21860/10943 (epoch 179.779) train_loss=490.81655884 time/batch=0.82s
21861/10943 (epoch 179.787) train_loss=463.76623535 time/batch=0.81s
21862/10943 (epoch 179.795) train_loss=470.86248779 time/batch=0.82s
21863/10943 (epoch 179.804) train_loss=424.31173706 time/batch=0.79s
21864/10943 (epoch 179.812) train_loss=435.36508179 time/batch=0.83s
21865/10943 (epoch 179.820) train_loss=224.08332825 time/batch=0.48s
21866/10943 (epoch 179.828) train_loss=281.89270020 time/batch=0.50s
21867/10943 (epoch 179.837) train_loss=327.83779907 time/batch=0.58s
21868/10943 (epoch 179.845) train_loss=379.17297363 time/batch=0.69s
21869/10943 (epoch 179.853) train_loss=313.61352539 time/batch=0.65s
21870/10943 (epoch 179.861) train_loss=380.21545410 time/batch=0.65s
setting learning rate to 0.0006744
  saved to metadata/gru_dropout-9_nov_folkwiki-20181115-204407_epoch69.pkl
21871/10943 (epoch 179.869) train_loss=979.98065186 time/batch=1.66s
21872/10943 (epoch 179.878) train_loss=293.24545288 time/batch=0.63s
21873/10943 (epoch 179.886) train_loss=447.94702148 time/batch=0.77s
21874/10943 (epoch 179.894) train_loss=697.33929443 time/batch=1.20s
21875/10943 (epoch 179.902) train_loss=219.45440674 time/batch=0.48s
21876/10943 (epoch 179.911) train_loss=822.48364258 time/batch=1.28s
21877/10943 (epoch 179.919) train_loss=688.99243164 time/batch=1.20s
21878/10943 (epoch 179.927) train_loss=424.52655029 time/batch=0.79s
21879/10943 (epoch 179.935) train_loss=532.79980469 time/batch=0.93s
21880/10943 (epoch 179.943) train_loss=502.66055298 time/batch=0.90s
21881/10943 (epoch 179.952) train_loss=636.26989746 time/batch=1.10s
21882/10943 (epoch 179.960) train_loss=276.69470215 time/batch=0.56s
21883/10943 (epoch 179.968) train_loss=470.59906006 time/batch=0.80s
21884/10943 (epoch 179.976) train_loss=416.56365967 time/batch=0.73s
21885/10943 (epoch 179.985) train_loss=660.36364746 time/batch=1.09s
21886/10943 (epoch 179.993) train_loss=195.72637939 time/batch=0.43s
21887/10943 (epoch 180.001) train_loss=907.74200439 time/batch=1.59s
21888/10943 (epoch 180.009) train_loss=351.85839844 time/batch=0.75s
21889/10943 (epoch 180.017) train_loss=491.89874268 time/batch=0.84s
21890/10943 (epoch 180.026) train_loss=190.10144043 time/batch=0.39s
21891/10943 (epoch 180.034) train_loss=382.92974854 time/batch=0.64s
21892/10943 (epoch 180.042) train_loss=375.26016235 time/batch=0.66s
21893/10943 (epoch 180.050) train_loss=359.37066650 time/batch=0.64s
21894/10943 (epoch 180.059) train_loss=205.34745789 time/batch=0.39s
21895/10943 (epoch 180.067) train_loss=604.27148438 time/batch=1.03s
21896/10943 (epoch 180.075) train_loss=800.52111816 time/batch=1.39s
21897/10943 (epoch 180.083) train_loss=609.23962402 time/batch=1.03s
21898/10943 (epoch 180.091) train_loss=684.95849609 time/batch=1.17s
21899/10943 (epoch 180.100) train_loss=455.63092041 time/batch=0.84s
21900/10943 (epoch 180.108) train_loss=1297.85913086 time/batch=3.11s
21901/10943 (epoch 180.116) train_loss=230.10783386 time/batch=0.71s
21902/10943 (epoch 180.124) train_loss=252.29838562 time/batch=0.43s
21903/10943 (epoch 180.133) train_loss=512.06011963 time/batch=0.86s
21904/10943 (epoch 180.141) train_loss=567.50488281 time/batch=1.03s
21905/10943 (epoch 180.149) train_loss=444.23413086 time/batch=0.81s
21906/10943 (epoch 180.157) train_loss=615.52386475 time/batch=1.16s
21907/10943 (epoch 180.166) train_loss=405.34414673 time/batch=0.73s
21908/10943 (epoch 180.174) train_loss=765.95666504 time/batch=1.36s
21909/10943 (epoch 180.182) train_loss=153.76464844 time/batch=0.39s
21910/10943 (epoch 180.190) train_loss=254.96447754 time/batch=0.44s
21911/10943 (epoch 180.198) train_loss=340.35794067 time/batch=0.59s
21912/10943 (epoch 180.207) train_loss=605.40808105 time/batch=1.00s
21913/10943 (epoch 180.215) train_loss=460.07666016 time/batch=0.84s
21914/10943 (epoch 180.223) train_loss=452.94998169 time/batch=0.81s
21915/10943 (epoch 180.231) train_loss=546.62042236 time/batch=0.96s
21916/10943 (epoch 180.240) train_loss=174.16499329 time/batch=0.38s
21917/10943 (epoch 180.248) train_loss=250.88038635 time/batch=0.45s
21918/10943 (epoch 180.256) train_loss=516.67926025 time/batch=0.86s
21919/10943 (epoch 180.264) train_loss=458.90841675 time/batch=0.84s
21920/10943 (epoch 180.272) train_loss=387.39068604 time/batch=0.70s
21921/10943 (epoch 180.281) train_loss=375.08340454 time/batch=0.65s
21922/10943 (epoch 180.289) train_loss=266.60156250 time/batch=0.50s
21923/10943 (epoch 180.297) train_loss=334.69421387 time/batch=0.56s
21924/10943 (epoch 180.305) train_loss=343.72659302 time/batch=0.63s
21925/10943 (epoch 180.314) train_loss=281.58041382 time/batch=0.54s
21926/10943 (epoch 180.322) train_loss=521.34442139 time/batch=0.88s
21927/10943 (epoch 180.330) train_loss=209.88742065 time/batch=0.45s
21928/10943 (epoch 180.338) train_loss=385.65014648 time/batch=0.65s
21929/10943 (epoch 180.346) train_loss=189.72958374 time/batch=0.38s
21930/10943 (epoch 180.355) train_loss=218.00024414 time/batch=0.39s
21931/10943 (epoch 180.363) train_loss=443.21200562 time/batch=0.79s
21932/10943 (epoch 180.371) train_loss=432.23535156 time/batch=0.77s
21933/10943 (epoch 180.379) train_loss=414.89587402 time/batch=0.74s
21934/10943 (epoch 180.388) train_loss=390.39901733 time/batch=0.66s
21935/10943 (epoch 180.396) train_loss=248.46942139 time/batch=0.47s
21936/10943 (epoch 180.404) train_loss=418.57885742 time/batch=0.73s
21937/10943 (epoch 180.412) train_loss=510.16601562 time/batch=0.86s
21938/10943 (epoch 180.420) train_loss=316.70562744 time/batch=0.61s
21939/10943 (epoch 180.429) train_loss=759.53063965 time/batch=1.62s
21940/10943 (epoch 180.437) train_loss=350.12515259 time/batch=0.72s
21941/10943 (epoch 180.445) train_loss=423.86810303 time/batch=0.72s
21942/10943 (epoch 180.453) train_loss=339.84149170 time/batch=0.60s
21943/10943 (epoch 180.462) train_loss=552.63171387 time/batch=0.96s
21944/10943 (epoch 180.470) train_loss=429.63046265 time/batch=0.78s
21945/10943 (epoch 180.478) train_loss=345.47375488 time/batch=0.64s
21946/10943 (epoch 180.486) train_loss=495.13528442 time/batch=0.89s
21947/10943 (epoch 180.494) train_loss=592.91369629 time/batch=1.02s
21948/10943 (epoch 180.503) train_loss=137.77203369 time/batch=0.35s
21949/10943 (epoch 180.511) train_loss=437.02868652 time/batch=0.76s
21950/10943 (epoch 180.519) train_loss=724.71856689 time/batch=1.69s
21951/10943 (epoch 180.527) train_loss=607.98791504 time/batch=1.10s
21952/10943 (epoch 180.536) train_loss=419.93820190 time/batch=0.76s
21953/10943 (epoch 180.544) train_loss=221.86280823 time/batch=0.44s
21954/10943 (epoch 180.552) train_loss=338.46963501 time/batch=0.61s
21955/10943 (epoch 180.560) train_loss=220.82849121 time/batch=0.43s
21956/10943 (epoch 180.568) train_loss=478.05227661 time/batch=0.87s
21957/10943 (epoch 180.577) train_loss=174.68554688 time/batch=0.37s
21958/10943 (epoch 180.585) train_loss=177.30673218 time/batch=0.35s
21959/10943 (epoch 180.593) train_loss=422.99398804 time/batch=0.72s
21960/10943 (epoch 180.601) train_loss=320.44067383 time/batch=0.60s
21961/10943 (epoch 180.610) train_loss=255.18795776 time/batch=0.48s
21962/10943 (epoch 180.618) train_loss=282.32952881 time/batch=0.52s
21963/10943 (epoch 180.626) train_loss=379.11120605 time/batch=0.66s
21964/10943 (epoch 180.634) train_loss=306.73742676 time/batch=0.58s
21965/10943 (epoch 180.643) train_loss=297.86077881 time/batch=0.54s
21966/10943 (epoch 180.651) train_loss=252.49200439 time/batch=0.47s
21967/10943 (epoch 180.659) train_loss=294.46063232 time/batch=0.53s
21968/10943 (epoch 180.667) train_loss=432.93261719 time/batch=0.76s
21969/10943 (epoch 180.675) train_loss=504.64813232 time/batch=0.84s
21970/10943 (epoch 180.684) train_loss=421.32788086 time/batch=0.71s
21971/10943 (epoch 180.692) train_loss=464.49035645 time/batch=0.81s
21972/10943 (epoch 180.700) train_loss=385.00012207 time/batch=0.70s
21973/10943 (epoch 180.708) train_loss=302.43792725 time/batch=0.57s
21974/10943 (epoch 180.717) train_loss=431.78256226 time/batch=0.75s
21975/10943 (epoch 180.725) train_loss=276.84930420 time/batch=0.51s
21976/10943 (epoch 180.733) train_loss=449.98687744 time/batch=0.79s
21977/10943 (epoch 180.741) train_loss=284.63519287 time/batch=0.54s
21978/10943 (epoch 180.749) train_loss=375.01437378 time/batch=0.67s
21979/10943 (epoch 180.758) train_loss=395.51269531 time/batch=0.71s
21980/10943 (epoch 180.766) train_loss=293.96154785 time/batch=0.56s
21981/10943 (epoch 180.774) train_loss=457.75109863 time/batch=0.83s
21982/10943 (epoch 180.782) train_loss=327.25433350 time/batch=0.62s
21983/10943 (epoch 180.791) train_loss=585.37341309 time/batch=1.00s
21984/10943 (epoch 180.799) train_loss=314.05947876 time/batch=0.63s
21985/10943 (epoch 180.807) train_loss=349.72134399 time/batch=0.62s
21986/10943 (epoch 180.815) train_loss=159.18908691 time/batch=0.32s
21987/10943 (epoch 180.823) train_loss=488.84753418 time/batch=0.88s
21988/10943 (epoch 180.832) train_loss=434.66015625 time/batch=0.86s
21989/10943 (epoch 180.840) train_loss=239.45976257 time/batch=0.62s
21990/10943 (epoch 180.848) train_loss=351.16140747 time/batch=0.69s
21991/10943 (epoch 180.856) train_loss=324.19940186 time/batch=0.61s
setting learning rate to 0.0006542
21992/10943 (epoch 180.865) train_loss=320.06759644 time/batch=0.60s
21993/10943 (epoch 180.873) train_loss=206.49520874 time/batch=0.39s
21994/10943 (epoch 180.881) train_loss=610.94226074 time/batch=0.99s
21995/10943 (epoch 180.889) train_loss=681.85278320 time/batch=1.19s
21996/10943 (epoch 180.897) train_loss=482.09515381 time/batch=0.84s
21997/10943 (epoch 180.906) train_loss=132.85641479 time/batch=0.30s
21998/10943 (epoch 180.914) train_loss=666.24029541 time/batch=1.04s
21999/10943 (epoch 180.922) train_loss=824.45471191 time/batch=1.47s
Validating
    loss:	418.103358

22000/10943 (epoch 180.930) train_loss=181.15457153 time/batch=2.09s
22001/10943 (epoch 180.939) train_loss=573.52050781 time/batch=0.93s
22002/10943 (epoch 180.947) train_loss=1084.66284180 time/batch=1.79s
22003/10943 (epoch 180.955) train_loss=1035.18554688 time/batch=1.68s
22004/10943 (epoch 180.963) train_loss=879.03515625 time/batch=1.38s
22005/10943 (epoch 180.971) train_loss=723.93920898 time/batch=1.26s
22006/10943 (epoch 180.980) train_loss=641.02142334 time/batch=1.17s
22007/10943 (epoch 180.988) train_loss=641.06188965 time/batch=1.17s
22008/10943 (epoch 180.996) train_loss=572.61157227 time/batch=1.00s
22009/10943 (epoch 181.004) train_loss=527.07513428 time/batch=0.95s
22010/10943 (epoch 181.013) train_loss=1254.45727539 time/batch=3.13s
22011/10943 (epoch 181.021) train_loss=658.64611816 time/batch=1.40s
22012/10943 (epoch 181.029) train_loss=221.05987549 time/batch=0.46s
22013/10943 (epoch 181.037) train_loss=388.33288574 time/batch=0.65s
22014/10943 (epoch 181.045) train_loss=242.45794678 time/batch=0.46s
22015/10943 (epoch 181.054) train_loss=272.83691406 time/batch=0.46s
22016/10943 (epoch 181.062) train_loss=492.97125244 time/batch=0.84s
22017/10943 (epoch 181.070) train_loss=189.71514893 time/batch=0.38s
22018/10943 (epoch 181.078) train_loss=254.90353394 time/batch=0.44s
22019/10943 (epoch 181.087) train_loss=397.41400146 time/batch=0.69s
22020/10943 (epoch 181.095) train_loss=396.15496826 time/batch=0.68s
22021/10943 (epoch 181.103) train_loss=448.69238281 time/batch=0.79s
22022/10943 (epoch 181.111) train_loss=537.27392578 time/batch=0.92s
22023/10943 (epoch 181.120) train_loss=338.39657593 time/batch=0.65s
22024/10943 (epoch 181.128) train_loss=431.13262939 time/batch=0.74s
22025/10943 (epoch 181.136) train_loss=232.25665283 time/batch=0.46s
22026/10943 (epoch 181.144) train_loss=637.60595703 time/batch=1.15s
22027/10943 (epoch 181.152) train_loss=343.87075806 time/batch=0.67s
22028/10943 (epoch 181.161) train_loss=154.99305725 time/batch=0.30s
22029/10943 (epoch 181.169) train_loss=454.22650146 time/batch=0.77s
22030/10943 (epoch 181.177) train_loss=311.77337646 time/batch=0.57s
22031/10943 (epoch 181.185) train_loss=561.24462891 time/batch=0.95s
22032/10943 (epoch 181.194) train_loss=250.94409180 time/batch=0.49s
22033/10943 (epoch 181.202) train_loss=401.78244019 time/batch=0.66s
22034/10943 (epoch 181.210) train_loss=828.14086914 time/batch=1.33s
22035/10943 (epoch 181.218) train_loss=444.17462158 time/batch=0.76s
22036/10943 (epoch 181.226) train_loss=586.96844482 time/batch=0.93s
22037/10943 (epoch 181.235) train_loss=477.80798340 time/batch=0.84s
22038/10943 (epoch 181.243) train_loss=626.90734863 time/batch=1.05s
22039/10943 (epoch 181.251) train_loss=553.78015137 time/batch=0.98s
22040/10943 (epoch 181.259) train_loss=175.70574951 time/batch=0.37s
22041/10943 (epoch 181.268) train_loss=217.14649963 time/batch=0.39s
22042/10943 (epoch 181.276) train_loss=731.57904053 time/batch=1.31s
22043/10943 (epoch 181.284) train_loss=483.07617188 time/batch=0.91s
22044/10943 (epoch 181.292) train_loss=431.71228027 time/batch=0.78s
22045/10943 (epoch 181.300) train_loss=520.26928711 time/batch=0.88s
22046/10943 (epoch 181.309) train_loss=399.91848755 time/batch=0.69s
22047/10943 (epoch 181.317) train_loss=257.26760864 time/batch=0.48s
22048/10943 (epoch 181.325) train_loss=299.47308350 time/batch=0.53s
22049/10943 (epoch 181.333) train_loss=257.46813965 time/batch=0.47s
22050/10943 (epoch 181.342) train_loss=200.73036194 time/batch=0.36s
22051/10943 (epoch 181.350) train_loss=400.08721924 time/batch=0.68s
22052/10943 (epoch 181.358) train_loss=448.98144531 time/batch=0.74s
22053/10943 (epoch 181.366) train_loss=297.86068726 time/batch=0.55s
22054/10943 (epoch 181.374) train_loss=527.19689941 time/batch=0.87s
22055/10943 (epoch 181.383) train_loss=519.54260254 time/batch=0.89s
22056/10943 (epoch 181.391) train_loss=322.82260132 time/batch=0.59s
22057/10943 (epoch 181.399) train_loss=413.02078247 time/batch=0.70s
22058/10943 (epoch 181.407) train_loss=327.96087646 time/batch=0.58s
22059/10943 (epoch 181.416) train_loss=382.67349243 time/batch=0.64s
22060/10943 (epoch 181.424) train_loss=421.36993408 time/batch=0.72s
22061/10943 (epoch 181.432) train_loss=316.77526855 time/batch=0.58s
22062/10943 (epoch 181.440) train_loss=396.31781006 time/batch=0.65s
22063/10943 (epoch 181.448) train_loss=381.48651123 time/batch=0.66s
22064/10943 (epoch 181.457) train_loss=271.95458984 time/batch=0.50s
22065/10943 (epoch 181.465) train_loss=423.26278687 time/batch=0.71s
22066/10943 (epoch 181.473) train_loss=450.90335083 time/batch=0.77s
22067/10943 (epoch 181.481) train_loss=472.94171143 time/batch=0.85s
22068/10943 (epoch 181.490) train_loss=323.35733032 time/batch=0.61s
22069/10943 (epoch 181.498) train_loss=247.45364380 time/batch=0.48s
22070/10943 (epoch 181.506) train_loss=283.91754150 time/batch=0.50s
22071/10943 (epoch 181.514) train_loss=430.83145142 time/batch=0.73s
22072/10943 (epoch 181.522) train_loss=163.49195862 time/batch=0.35s
22073/10943 (epoch 181.531) train_loss=426.79541016 time/batch=0.69s
22074/10943 (epoch 181.539) train_loss=580.28814697 time/batch=1.01s
22075/10943 (epoch 181.547) train_loss=185.65594482 time/batch=0.39s
22076/10943 (epoch 181.555) train_loss=236.78765869 time/batch=0.46s
22077/10943 (epoch 181.564) train_loss=621.53100586 time/batch=0.98s
22078/10943 (epoch 181.572) train_loss=435.84899902 time/batch=0.75s
22079/10943 (epoch 181.580) train_loss=344.14416504 time/batch=0.61s
22080/10943 (epoch 181.588) train_loss=443.82232666 time/batch=0.77s
22081/10943 (epoch 181.597) train_loss=260.39892578 time/batch=0.51s
22082/10943 (epoch 181.605) train_loss=565.62658691 time/batch=1.18s
22083/10943 (epoch 181.613) train_loss=349.56311035 time/batch=0.70s
22084/10943 (epoch 181.621) train_loss=414.77508545 time/batch=0.72s
22085/10943 (epoch 181.629) train_loss=501.01525879 time/batch=0.87s
22086/10943 (epoch 181.638) train_loss=193.08618164 time/batch=0.40s
22087/10943 (epoch 181.646) train_loss=354.55740356 time/batch=0.60s
22088/10943 (epoch 181.654) train_loss=568.20404053 time/batch=1.21s
22089/10943 (epoch 181.662) train_loss=266.27230835 time/batch=0.57s
22090/10943 (epoch 181.671) train_loss=332.19155884 time/batch=0.59s
22091/10943 (epoch 181.679) train_loss=345.97976685 time/batch=0.62s
22092/10943 (epoch 181.687) train_loss=298.23242188 time/batch=0.52s
22093/10943 (epoch 181.695) train_loss=241.38104248 time/batch=0.49s
22094/10943 (epoch 181.703) train_loss=431.45489502 time/batch=0.76s
22095/10943 (epoch 181.712) train_loss=353.83728027 time/batch=0.64s
22096/10943 (epoch 181.720) train_loss=461.06039429 time/batch=0.79s
22097/10943 (epoch 181.728) train_loss=467.87689209 time/batch=0.84s
22098/10943 (epoch 181.736) train_loss=415.88302612 time/batch=0.79s
22099/10943 (epoch 181.745) train_loss=501.84429932 time/batch=0.84s
22100/10943 (epoch 181.753) train_loss=298.09774780 time/batch=0.57s
22101/10943 (epoch 181.761) train_loss=483.28900146 time/batch=0.83s
22102/10943 (epoch 181.769) train_loss=284.72750854 time/batch=0.55s
22103/10943 (epoch 181.777) train_loss=456.44223022 time/batch=0.80s
22104/10943 (epoch 181.786) train_loss=199.64590454 time/batch=0.41s
22105/10943 (epoch 181.794) train_loss=352.50424194 time/batch=0.60s
22106/10943 (epoch 181.802) train_loss=330.98458862 time/batch=0.57s
22107/10943 (epoch 181.810) train_loss=456.75244141 time/batch=0.80s
22108/10943 (epoch 181.819) train_loss=350.57739258 time/batch=0.65s
22109/10943 (epoch 181.827) train_loss=343.82244873 time/batch=0.59s
22110/10943 (epoch 181.835) train_loss=315.57064819 time/batch=0.63s
22111/10943 (epoch 181.843) train_loss=404.23779297 time/batch=0.80s
22112/10943 (epoch 181.851) train_loss=375.86407471 time/batch=0.67s
setting learning rate to 0.0006346
22113/10943 (epoch 181.860) train_loss=815.76562500 time/batch=1.27s
22114/10943 (epoch 181.868) train_loss=1419.53198242 time/batch=3.17s
22115/10943 (epoch 181.876) train_loss=745.49597168 time/batch=1.31s
22116/10943 (epoch 181.884) train_loss=190.70721436 time/batch=0.40s
22117/10943 (epoch 181.893) train_loss=303.06527710 time/batch=0.52s
22118/10943 (epoch 181.901) train_loss=490.15106201 time/batch=0.83s
22119/10943 (epoch 181.909) train_loss=587.59368896 time/batch=1.01s
22120/10943 (epoch 181.917) train_loss=683.95629883 time/batch=1.19s
22121/10943 (epoch 181.925) train_loss=149.19708252 time/batch=0.37s
22122/10943 (epoch 181.934) train_loss=578.49670410 time/batch=0.91s
22123/10943 (epoch 181.942) train_loss=226.82807922 time/batch=0.48s
22124/10943 (epoch 181.950) train_loss=530.91174316 time/batch=0.88s
22125/10943 (epoch 181.958) train_loss=435.85675049 time/batch=0.77s
22126/10943 (epoch 181.967) train_loss=668.83551025 time/batch=1.09s
22127/10943 (epoch 181.975) train_loss=438.87414551 time/batch=0.81s
22128/10943 (epoch 181.983) train_loss=326.05325317 time/batch=0.61s
22129/10943 (epoch 181.991) train_loss=398.25054932 time/batch=0.67s
22130/10943 (epoch 181.999) train_loss=526.70178223 time/batch=0.89s
22131/10943 (epoch 182.008) train_loss=227.56153870 time/batch=0.45s
22132/10943 (epoch 182.016) train_loss=737.81469727 time/batch=1.17s
22133/10943 (epoch 182.024) train_loss=831.51220703 time/batch=1.44s
22134/10943 (epoch 182.032) train_loss=378.72314453 time/batch=0.72s
22135/10943 (epoch 182.041) train_loss=483.01397705 time/batch=0.83s
22136/10943 (epoch 182.049) train_loss=1040.35156250 time/batch=1.69s
22137/10943 (epoch 182.057) train_loss=295.96542358 time/batch=0.61s
22138/10943 (epoch 182.065) train_loss=922.42211914 time/batch=1.52s
22139/10943 (epoch 182.074) train_loss=783.77282715 time/batch=1.37s
22140/10943 (epoch 182.082) train_loss=390.10137939 time/batch=0.72s
22141/10943 (epoch 182.090) train_loss=337.05944824 time/batch=0.60s
22142/10943 (epoch 182.098) train_loss=246.21479797 time/batch=0.44s
22143/10943 (epoch 182.106) train_loss=718.32458496 time/batch=1.26s
22144/10943 (epoch 182.115) train_loss=370.68481445 time/batch=0.70s
22145/10943 (epoch 182.123) train_loss=764.59497070 time/batch=1.41s
22146/10943 (epoch 182.131) train_loss=643.14660645 time/batch=1.13s
22147/10943 (epoch 182.139) train_loss=297.14730835 time/batch=0.56s
22148/10943 (epoch 182.148) train_loss=654.71899414 time/batch=1.10s
22149/10943 (epoch 182.156) train_loss=453.22021484 time/batch=0.85s
22150/10943 (epoch 182.164) train_loss=244.32762146 time/batch=0.47s
22151/10943 (epoch 182.172) train_loss=515.62207031 time/batch=0.85s
22152/10943 (epoch 182.180) train_loss=337.72210693 time/batch=0.63s
22153/10943 (epoch 182.189) train_loss=635.75274658 time/batch=1.06s
22154/10943 (epoch 182.197) train_loss=289.83462524 time/batch=0.57s
22155/10943 (epoch 182.205) train_loss=604.89489746 time/batch=0.98s
22156/10943 (epoch 182.213) train_loss=177.53804016 time/batch=0.39s
22157/10943 (epoch 182.222) train_loss=449.68896484 time/batch=0.74s
22158/10943 (epoch 182.230) train_loss=194.30540466 time/batch=0.38s
22159/10943 (epoch 182.238) train_loss=644.23785400 time/batch=1.05s
22160/10943 (epoch 182.246) train_loss=449.35577393 time/batch=0.86s
22161/10943 (epoch 182.254) train_loss=564.33508301 time/batch=0.97s
22162/10943 (epoch 182.263) train_loss=469.88269043 time/batch=0.85s
22163/10943 (epoch 182.271) train_loss=425.38629150 time/batch=0.75s
22164/10943 (epoch 182.279) train_loss=353.34667969 time/batch=0.63s
22165/10943 (epoch 182.287) train_loss=408.63919067 time/batch=0.67s
22166/10943 (epoch 182.296) train_loss=312.58093262 time/batch=0.57s
22167/10943 (epoch 182.304) train_loss=305.55880737 time/batch=0.54s
22168/10943 (epoch 182.312) train_loss=319.65658569 time/batch=0.56s
22169/10943 (epoch 182.320) train_loss=436.54006958 time/batch=0.72s
22170/10943 (epoch 182.328) train_loss=431.58456421 time/batch=0.71s
22171/10943 (epoch 182.337) train_loss=208.43238831 time/batch=0.41s
22172/10943 (epoch 182.345) train_loss=413.83819580 time/batch=0.67s
22173/10943 (epoch 182.353) train_loss=460.02770996 time/batch=0.79s
22174/10943 (epoch 182.361) train_loss=487.93292236 time/batch=0.87s
22175/10943 (epoch 182.370) train_loss=571.42883301 time/batch=0.95s
22176/10943 (epoch 182.378) train_loss=312.40490723 time/batch=0.57s
22177/10943 (epoch 182.386) train_loss=566.30444336 time/batch=0.92s
22178/10943 (epoch 182.394) train_loss=162.10205078 time/batch=0.35s
22179/10943 (epoch 182.402) train_loss=197.58518982 time/batch=0.34s
22180/10943 (epoch 182.411) train_loss=239.61035156 time/batch=0.44s
22181/10943 (epoch 182.419) train_loss=461.67446899 time/batch=0.76s
22182/10943 (epoch 182.427) train_loss=352.43927002 time/batch=0.65s
22183/10943 (epoch 182.435) train_loss=584.67999268 time/batch=0.97s
22184/10943 (epoch 182.444) train_loss=181.14753723 time/batch=0.36s
22185/10943 (epoch 182.452) train_loss=437.40802002 time/batch=0.72s
22186/10943 (epoch 182.460) train_loss=287.15771484 time/batch=0.54s
22187/10943 (epoch 182.468) train_loss=537.41516113 time/batch=0.95s
22188/10943 (epoch 182.476) train_loss=317.81402588 time/batch=0.59s
22189/10943 (epoch 182.485) train_loss=420.50604248 time/batch=0.71s
22190/10943 (epoch 182.493) train_loss=364.44378662 time/batch=0.64s
22191/10943 (epoch 182.501) train_loss=460.49005127 time/batch=0.78s
22192/10943 (epoch 182.509) train_loss=547.82366943 time/batch=0.98s
22193/10943 (epoch 182.518) train_loss=412.43640137 time/batch=0.71s
22194/10943 (epoch 182.526) train_loss=402.42431641 time/batch=0.66s
22195/10943 (epoch 182.534) train_loss=393.86047363 time/batch=0.66s
22196/10943 (epoch 182.542) train_loss=261.56484985 time/batch=0.48s
22197/10943 (epoch 182.551) train_loss=279.86444092 time/batch=0.49s
22198/10943 (epoch 182.559) train_loss=204.25741577 time/batch=0.36s
22199/10943 (epoch 182.567) train_loss=497.81042480 time/batch=0.83s
22200/10943 (epoch 182.575) train_loss=186.74905396 time/batch=0.40s
22201/10943 (epoch 182.583) train_loss=268.25067139 time/batch=0.46s
22202/10943 (epoch 182.592) train_loss=376.77795410 time/batch=0.62s
22203/10943 (epoch 182.600) train_loss=335.51171875 time/batch=0.61s
22204/10943 (epoch 182.608) train_loss=452.82360840 time/batch=0.79s
22205/10943 (epoch 182.616) train_loss=334.79034424 time/batch=0.59s
22206/10943 (epoch 182.625) train_loss=314.18206787 time/batch=0.57s
22207/10943 (epoch 182.633) train_loss=520.27905273 time/batch=0.85s
22208/10943 (epoch 182.641) train_loss=414.38302612 time/batch=0.72s
22209/10943 (epoch 182.649) train_loss=522.91076660 time/batch=0.86s
22210/10943 (epoch 182.657) train_loss=280.54159546 time/batch=0.52s
22211/10943 (epoch 182.666) train_loss=157.96072388 time/batch=0.36s
22212/10943 (epoch 182.674) train_loss=482.72790527 time/batch=0.86s
22213/10943 (epoch 182.682) train_loss=466.96618652 time/batch=0.85s
22214/10943 (epoch 182.690) train_loss=434.48590088 time/batch=0.75s
22215/10943 (epoch 182.699) train_loss=351.07336426 time/batch=0.66s
22216/10943 (epoch 182.707) train_loss=382.89642334 time/batch=0.65s
22217/10943 (epoch 182.715) train_loss=352.02108765 time/batch=0.61s
22218/10943 (epoch 182.723) train_loss=335.94711304 time/batch=0.61s
22219/10943 (epoch 182.731) train_loss=274.40625000 time/batch=0.50s
22220/10943 (epoch 182.740) train_loss=378.31997681 time/batch=0.65s
22221/10943 (epoch 182.748) train_loss=216.85166931 time/batch=0.40s
22222/10943 (epoch 182.756) train_loss=464.42437744 time/batch=0.78s
22223/10943 (epoch 182.764) train_loss=291.56427002 time/batch=0.60s
22224/10943 (epoch 182.773) train_loss=430.78005981 time/batch=0.74s
22225/10943 (epoch 182.781) train_loss=268.68917847 time/batch=0.59s
22226/10943 (epoch 182.789) train_loss=468.98944092 time/batch=0.80s
22227/10943 (epoch 182.797) train_loss=471.95294189 time/batch=0.84s
22228/10943 (epoch 182.805) train_loss=221.66824341 time/batch=0.44s
22229/10943 (epoch 182.814) train_loss=434.08459473 time/batch=0.68s
22230/10943 (epoch 182.822) train_loss=255.55674744 time/batch=0.59s
22231/10943 (epoch 182.830) train_loss=380.78643799 time/batch=0.67s
22232/10943 (epoch 182.838) train_loss=328.90472412 time/batch=0.59s
22233/10943 (epoch 182.847) train_loss=371.84072876 time/batch=0.69s
setting learning rate to 0.0006155
22234/10943 (epoch 182.855) train_loss=542.67858887 time/batch=0.91s
22235/10943 (epoch 182.863) train_loss=730.69299316 time/batch=1.12s
22236/10943 (epoch 182.871) train_loss=1191.31567383 time/batch=1.95s
22237/10943 (epoch 182.879) train_loss=478.32965088 time/batch=0.92s
22238/10943 (epoch 182.888) train_loss=530.08508301 time/batch=0.90s
22239/10943 (epoch 182.896) train_loss=765.21655273 time/batch=1.27s
22240/10943 (epoch 182.904) train_loss=834.55621338 time/batch=1.39s
22241/10943 (epoch 182.912) train_loss=698.00183105 time/batch=1.25s
22242/10943 (epoch 182.921) train_loss=827.78833008 time/batch=1.42s
22243/10943 (epoch 182.929) train_loss=473.57778931 time/batch=0.87s
22244/10943 (epoch 182.937) train_loss=150.40820312 time/batch=0.32s
22245/10943 (epoch 182.945) train_loss=640.40289307 time/batch=1.03s
22246/10943 (epoch 182.953) train_loss=681.09167480 time/batch=1.19s
22247/10943 (epoch 182.962) train_loss=871.24597168 time/batch=1.54s
22248/10943 (epoch 182.970) train_loss=613.55438232 time/batch=1.08s
22249/10943 (epoch 182.978) train_loss=751.79541016 time/batch=1.23s
22250/10943 (epoch 182.986) train_loss=406.40454102 time/batch=0.71s
22251/10943 (epoch 182.995) train_loss=233.27597046 time/batch=0.44s
22252/10943 (epoch 183.003) train_loss=204.26571655 time/batch=0.36s
22253/10943 (epoch 183.011) train_loss=401.65319824 time/batch=0.64s
22254/10943 (epoch 183.019) train_loss=1257.09204102 time/batch=3.10s
22255/10943 (epoch 183.027) train_loss=201.07575989 time/batch=0.65s
22256/10943 (epoch 183.036) train_loss=425.49261475 time/batch=0.68s
22257/10943 (epoch 183.044) train_loss=199.72543335 time/batch=0.38s
22258/10943 (epoch 183.052) train_loss=553.73889160 time/batch=0.93s
22259/10943 (epoch 183.060) train_loss=276.13906860 time/batch=0.54s
22260/10943 (epoch 183.069) train_loss=377.85992432 time/batch=0.65s
22261/10943 (epoch 183.077) train_loss=388.58154297 time/batch=0.68s
22262/10943 (epoch 183.085) train_loss=807.10711670 time/batch=1.54s
22263/10943 (epoch 183.093) train_loss=595.01892090 time/batch=1.07s
22264/10943 (epoch 183.102) train_loss=543.31921387 time/batch=0.90s
22265/10943 (epoch 183.110) train_loss=393.94061279 time/batch=0.69s
22266/10943 (epoch 183.118) train_loss=423.88067627 time/batch=0.74s
22267/10943 (epoch 183.126) train_loss=340.10571289 time/batch=0.59s
22268/10943 (epoch 183.134) train_loss=406.44531250 time/batch=0.71s
22269/10943 (epoch 183.143) train_loss=642.64880371 time/batch=1.11s
22270/10943 (epoch 183.151) train_loss=509.74926758 time/batch=0.90s
22271/10943 (epoch 183.159) train_loss=342.97070312 time/batch=0.63s
22272/10943 (epoch 183.167) train_loss=396.47235107 time/batch=0.67s
22273/10943 (epoch 183.176) train_loss=287.67575073 time/batch=0.52s
22274/10943 (epoch 183.184) train_loss=170.03198242 time/batch=0.31s
22275/10943 (epoch 183.192) train_loss=252.51052856 time/batch=0.43s
22276/10943 (epoch 183.200) train_loss=427.85516357 time/batch=0.73s
22277/10943 (epoch 183.208) train_loss=651.03881836 time/batch=1.12s
22278/10943 (epoch 183.217) train_loss=299.51654053 time/batch=0.59s
22279/10943 (epoch 183.225) train_loss=275.16619873 time/batch=0.49s
22280/10943 (epoch 183.233) train_loss=227.02041626 time/batch=0.43s
22281/10943 (epoch 183.241) train_loss=416.30462646 time/batch=0.67s
22282/10943 (epoch 183.250) train_loss=335.20428467 time/batch=0.59s
22283/10943 (epoch 183.258) train_loss=250.72047424 time/batch=0.46s
22284/10943 (epoch 183.266) train_loss=333.54046631 time/batch=0.56s
22285/10943 (epoch 183.274) train_loss=561.49121094 time/batch=0.92s
22286/10943 (epoch 183.282) train_loss=617.16711426 time/batch=1.02s
22287/10943 (epoch 183.291) train_loss=419.20123291 time/batch=0.75s
22288/10943 (epoch 183.299) train_loss=642.36315918 time/batch=1.01s
22289/10943 (epoch 183.307) train_loss=347.31289673 time/batch=0.63s
22290/10943 (epoch 183.315) train_loss=293.25128174 time/batch=0.53s
22291/10943 (epoch 183.324) train_loss=452.17749023 time/batch=0.77s
22292/10943 (epoch 183.332) train_loss=264.85778809 time/batch=0.49s
22293/10943 (epoch 183.340) train_loss=457.97885132 time/batch=0.78s
22294/10943 (epoch 183.348) train_loss=157.62060547 time/batch=0.34s
22295/10943 (epoch 183.356) train_loss=452.19812012 time/batch=0.75s
22296/10943 (epoch 183.365) train_loss=443.51605225 time/batch=0.77s
22297/10943 (epoch 183.373) train_loss=472.23358154 time/batch=0.85s
22298/10943 (epoch 183.381) train_loss=459.51470947 time/batch=0.79s
22299/10943 (epoch 183.389) train_loss=175.67687988 time/batch=0.35s
22300/10943 (epoch 183.398) train_loss=611.75103760 time/batch=0.97s
22301/10943 (epoch 183.406) train_loss=280.27392578 time/batch=0.54s
22302/10943 (epoch 183.414) train_loss=613.80126953 time/batch=1.01s
22303/10943 (epoch 183.422) train_loss=493.19973755 time/batch=0.87s
22304/10943 (epoch 183.430) train_loss=445.26666260 time/batch=0.73s
22305/10943 (epoch 183.439) train_loss=208.73669434 time/batch=0.39s
22306/10943 (epoch 183.447) train_loss=152.89651489 time/batch=0.32s
22307/10943 (epoch 183.455) train_loss=285.64904785 time/batch=0.49s
22308/10943 (epoch 183.463) train_loss=330.05606079 time/batch=0.59s
22309/10943 (epoch 183.472) train_loss=571.60400391 time/batch=0.92s
22310/10943 (epoch 183.480) train_loss=340.85888672 time/batch=0.63s
22311/10943 (epoch 183.488) train_loss=565.17016602 time/batch=0.94s
22312/10943 (epoch 183.496) train_loss=413.16992188 time/batch=0.73s
22313/10943 (epoch 183.504) train_loss=397.19934082 time/batch=0.67s
22314/10943 (epoch 183.513) train_loss=196.21160889 time/batch=0.37s
22315/10943 (epoch 183.521) train_loss=263.19403076 time/batch=0.45s
22316/10943 (epoch 183.529) train_loss=246.96488953 time/batch=0.43s
22317/10943 (epoch 183.537) train_loss=415.75671387 time/batch=0.67s
22318/10943 (epoch 183.546) train_loss=188.53051758 time/batch=0.38s
22319/10943 (epoch 183.554) train_loss=357.88970947 time/batch=0.59s
22320/10943 (epoch 183.562) train_loss=541.89074707 time/batch=0.87s
22321/10943 (epoch 183.570) train_loss=375.32904053 time/batch=0.67s
22322/10943 (epoch 183.579) train_loss=449.64556885 time/batch=0.74s
22323/10943 (epoch 183.587) train_loss=270.89367676 time/batch=0.50s
22324/10943 (epoch 183.595) train_loss=383.27453613 time/batch=0.62s
22325/10943 (epoch 183.603) train_loss=354.74169922 time/batch=0.62s
22326/10943 (epoch 183.611) train_loss=249.00018311 time/batch=0.48s
22327/10943 (epoch 183.620) train_loss=514.51892090 time/batch=0.86s
22328/10943 (epoch 183.628) train_loss=296.07342529 time/batch=0.56s
22329/10943 (epoch 183.636) train_loss=428.99328613 time/batch=0.71s
22330/10943 (epoch 183.644) train_loss=363.61065674 time/batch=0.63s
22331/10943 (epoch 183.653) train_loss=435.72592163 time/batch=0.72s
22332/10943 (epoch 183.661) train_loss=358.16412354 time/batch=0.63s
22333/10943 (epoch 183.669) train_loss=286.48532104 time/batch=0.54s
22334/10943 (epoch 183.677) train_loss=472.36224365 time/batch=0.78s
22335/10943 (epoch 183.685) train_loss=390.73928833 time/batch=0.69s
22336/10943 (epoch 183.694) train_loss=314.58541870 time/batch=0.56s
22337/10943 (epoch 183.702) train_loss=445.43945312 time/batch=0.78s
22338/10943 (epoch 183.710) train_loss=316.32775879 time/batch=0.59s
22339/10943 (epoch 183.718) train_loss=214.26075745 time/batch=0.41s
22340/10943 (epoch 183.727) train_loss=492.50994873 time/batch=0.81s
22341/10943 (epoch 183.735) train_loss=328.64727783 time/batch=0.59s
22342/10943 (epoch 183.743) train_loss=461.60925293 time/batch=0.79s
22343/10943 (epoch 183.751) train_loss=348.50677490 time/batch=0.63s
22344/10943 (epoch 183.759) train_loss=525.87829590 time/batch=0.89s
22345/10943 (epoch 183.768) train_loss=481.21325684 time/batch=0.84s
22346/10943 (epoch 183.776) train_loss=224.35910034 time/batch=0.42s
22347/10943 (epoch 183.784) train_loss=240.47946167 time/batch=0.53s
22348/10943 (epoch 183.792) train_loss=492.23797607 time/batch=0.82s
22349/10943 (epoch 183.801) train_loss=498.37426758 time/batch=0.86s
22350/10943 (epoch 183.809) train_loss=489.60577393 time/batch=0.83s
22351/10943 (epoch 183.817) train_loss=511.17498779 time/batch=0.89s
22352/10943 (epoch 183.825) train_loss=319.41082764 time/batch=0.62s
22353/10943 (epoch 183.833) train_loss=341.53170776 time/batch=0.61s
22354/10943 (epoch 183.842) train_loss=357.63269043 time/batch=0.64s
setting learning rate to 0.0005971
22355/10943 (epoch 183.850) train_loss=224.79760742 time/batch=0.41s
22356/10943 (epoch 183.858) train_loss=499.32275391 time/batch=0.80s
22357/10943 (epoch 183.866) train_loss=848.14617920 time/batch=1.35s
22358/10943 (epoch 183.875) train_loss=1496.43872070 time/batch=3.16s
22359/10943 (epoch 183.883) train_loss=1015.97143555 time/batch=1.75s
22360/10943 (epoch 183.891) train_loss=645.36145020 time/batch=1.09s
22361/10943 (epoch 183.899) train_loss=173.17449951 time/batch=0.37s
22362/10943 (epoch 183.907) train_loss=742.58129883 time/batch=1.18s
22363/10943 (epoch 183.916) train_loss=808.67559814 time/batch=1.54s
22364/10943 (epoch 183.924) train_loss=257.04986572 time/batch=0.58s
22365/10943 (epoch 183.932) train_loss=624.76239014 time/batch=1.02s
22366/10943 (epoch 183.940) train_loss=135.98643494 time/batch=0.33s
22367/10943 (epoch 183.949) train_loss=707.52410889 time/batch=1.15s
22368/10943 (epoch 183.957) train_loss=520.67407227 time/batch=0.93s
22369/10943 (epoch 183.965) train_loss=687.58911133 time/batch=1.18s
22370/10943 (epoch 183.973) train_loss=211.49249268 time/batch=0.46s
22371/10943 (epoch 183.981) train_loss=242.12715149 time/batch=0.43s
22372/10943 (epoch 183.990) train_loss=603.45965576 time/batch=0.98s
22373/10943 (epoch 183.998) train_loss=415.28637695 time/batch=0.77s
22374/10943 (epoch 184.006) train_loss=1039.76647949 time/batch=1.67s
22375/10943 (epoch 184.014) train_loss=436.94189453 time/batch=0.82s
22376/10943 (epoch 184.023) train_loss=178.67770386 time/batch=0.35s
22377/10943 (epoch 184.031) train_loss=322.64016724 time/batch=0.53s
22378/10943 (epoch 184.039) train_loss=519.32360840 time/batch=0.87s
22379/10943 (epoch 184.047) train_loss=279.41720581 time/batch=0.53s
22380/10943 (epoch 184.056) train_loss=392.47375488 time/batch=0.67s
22381/10943 (epoch 184.064) train_loss=572.32556152 time/batch=0.95s
22382/10943 (epoch 184.072) train_loss=568.27697754 time/batch=1.00s
22383/10943 (epoch 184.080) train_loss=156.35287476 time/batch=0.34s
22384/10943 (epoch 184.088) train_loss=671.59423828 time/batch=1.06s
22385/10943 (epoch 184.097) train_loss=433.90948486 time/batch=0.76s
22386/10943 (epoch 184.105) train_loss=296.59448242 time/batch=0.54s
22387/10943 (epoch 184.113) train_loss=536.51373291 time/batch=0.89s
22388/10943 (epoch 184.121) train_loss=586.67871094 time/batch=1.00s
22389/10943 (epoch 184.130) train_loss=310.25924683 time/batch=0.58s
22390/10943 (epoch 184.138) train_loss=656.26721191 time/batch=1.09s
22391/10943 (epoch 184.146) train_loss=451.07263184 time/batch=0.82s
22392/10943 (epoch 184.154) train_loss=900.75830078 time/batch=1.55s
22393/10943 (epoch 184.162) train_loss=706.41455078 time/batch=1.23s
22394/10943 (epoch 184.171) train_loss=466.04992676 time/batch=0.80s
22395/10943 (epoch 184.179) train_loss=294.64282227 time/batch=0.55s
22396/10943 (epoch 184.187) train_loss=305.97622681 time/batch=0.56s
22397/10943 (epoch 184.195) train_loss=638.06982422 time/batch=1.15s
22398/10943 (epoch 184.204) train_loss=235.10711670 time/batch=0.49s
22399/10943 (epoch 184.212) train_loss=456.29937744 time/batch=0.77s
22400/10943 (epoch 184.220) train_loss=392.78741455 time/batch=0.69s
22401/10943 (epoch 184.228) train_loss=172.39587402 time/batch=0.34s
22402/10943 (epoch 184.236) train_loss=331.51196289 time/batch=0.56s
22403/10943 (epoch 184.245) train_loss=467.94006348 time/batch=0.82s
22404/10943 (epoch 184.253) train_loss=482.88027954 time/batch=0.84s
22405/10943 (epoch 184.261) train_loss=545.75927734 time/batch=0.91s
22406/10943 (epoch 184.269) train_loss=504.38580322 time/batch=0.86s
22407/10943 (epoch 184.278) train_loss=457.92303467 time/batch=0.79s
22408/10943 (epoch 184.286) train_loss=457.97488403 time/batch=0.81s
22409/10943 (epoch 184.294) train_loss=236.90927124 time/batch=0.45s
22410/10943 (epoch 184.302) train_loss=451.01055908 time/batch=0.78s
22411/10943 (epoch 184.310) train_loss=175.26704407 time/batch=0.37s
22412/10943 (epoch 184.319) train_loss=353.23126221 time/batch=0.58s
22413/10943 (epoch 184.327) train_loss=257.41006470 time/batch=0.48s
22414/10943 (epoch 184.335) train_loss=358.36645508 time/batch=0.61s
22415/10943 (epoch 184.343) train_loss=329.05468750 time/batch=0.59s
22416/10943 (epoch 184.352) train_loss=275.98126221 time/batch=0.49s
22417/10943 (epoch 184.360) train_loss=470.23400879 time/batch=0.77s
22418/10943 (epoch 184.368) train_loss=498.54190063 time/batch=0.86s
22419/10943 (epoch 184.376) train_loss=214.37261963 time/batch=0.42s
22420/10943 (epoch 184.384) train_loss=280.75030518 time/batch=0.48s
22421/10943 (epoch 184.393) train_loss=395.04687500 time/batch=0.66s
22422/10943 (epoch 184.401) train_loss=213.11349487 time/batch=0.40s
22423/10943 (epoch 184.409) train_loss=463.61495972 time/batch=0.74s
22424/10943 (epoch 184.417) train_loss=545.90783691 time/batch=0.96s
22425/10943 (epoch 184.426) train_loss=674.24908447 time/batch=1.06s
22426/10943 (epoch 184.434) train_loss=640.32641602 time/batch=1.05s
22427/10943 (epoch 184.442) train_loss=449.10821533 time/batch=0.79s
22428/10943 (epoch 184.450) train_loss=656.16613770 time/batch=1.19s
22429/10943 (epoch 184.458) train_loss=611.36584473 time/batch=1.28s
22430/10943 (epoch 184.467) train_loss=467.80111694 time/batch=0.85s
22431/10943 (epoch 184.475) train_loss=455.45947266 time/batch=0.80s
22432/10943 (epoch 184.483) train_loss=349.98156738 time/batch=0.64s
22433/10943 (epoch 184.491) train_loss=253.80371094 time/batch=0.46s
22434/10943 (epoch 184.500) train_loss=275.14233398 time/batch=0.46s
22435/10943 (epoch 184.508) train_loss=192.76034546 time/batch=0.35s
22436/10943 (epoch 184.516) train_loss=407.71826172 time/batch=0.64s
22437/10943 (epoch 184.524) train_loss=359.84463501 time/batch=0.64s
22438/10943 (epoch 184.533) train_loss=375.32373047 time/batch=0.64s
22439/10943 (epoch 184.541) train_loss=455.67419434 time/batch=0.80s
22440/10943 (epoch 184.549) train_loss=421.86108398 time/batch=0.72s
22441/10943 (epoch 184.557) train_loss=437.63937378 time/batch=0.73s
22442/10943 (epoch 184.565) train_loss=279.28198242 time/batch=0.52s
22443/10943 (epoch 184.574) train_loss=505.56896973 time/batch=0.82s
22444/10943 (epoch 184.582) train_loss=191.20610046 time/batch=0.39s
22445/10943 (epoch 184.590) train_loss=311.56430054 time/batch=0.52s
22446/10943 (epoch 184.598) train_loss=377.47662354 time/batch=0.63s
22447/10943 (epoch 184.607) train_loss=312.47738647 time/batch=0.55s
22448/10943 (epoch 184.615) train_loss=300.69079590 time/batch=0.55s
22449/10943 (epoch 184.623) train_loss=532.04284668 time/batch=0.88s
22450/10943 (epoch 184.631) train_loss=286.52783203 time/batch=0.54s
22451/10943 (epoch 184.639) train_loss=519.88000488 time/batch=0.83s
22452/10943 (epoch 184.648) train_loss=359.16561890 time/batch=0.64s
22453/10943 (epoch 184.656) train_loss=203.78207397 time/batch=0.37s
22454/10943 (epoch 184.664) train_loss=386.45806885 time/batch=0.62s
22455/10943 (epoch 184.672) train_loss=494.57507324 time/batch=0.84s
22456/10943 (epoch 184.681) train_loss=301.13598633 time/batch=0.55s
22457/10943 (epoch 184.689) train_loss=443.92572021 time/batch=0.69s
22458/10943 (epoch 184.697) train_loss=431.21795654 time/batch=0.77s
22459/10943 (epoch 184.705) train_loss=346.14508057 time/batch=0.60s
22460/10943 (epoch 184.713) train_loss=425.52029419 time/batch=0.70s
22461/10943 (epoch 184.722) train_loss=298.53302002 time/batch=0.58s
22462/10943 (epoch 184.730) train_loss=338.17370605 time/batch=0.59s
22463/10943 (epoch 184.738) train_loss=456.23599243 time/batch=0.79s
22464/10943 (epoch 184.746) train_loss=404.02032471 time/batch=0.72s
22465/10943 (epoch 184.755) train_loss=440.03192139 time/batch=0.74s
22466/10943 (epoch 184.763) train_loss=394.35131836 time/batch=0.68s
22467/10943 (epoch 184.771) train_loss=422.03549194 time/batch=0.73s
22468/10943 (epoch 184.779) train_loss=462.27355957 time/batch=0.87s
22469/10943 (epoch 184.787) train_loss=351.28070068 time/batch=0.62s
22470/10943 (epoch 184.796) train_loss=226.92073059 time/batch=0.57s
22471/10943 (epoch 184.804) train_loss=370.06762695 time/batch=0.66s
22472/10943 (epoch 184.812) train_loss=327.54879761 time/batch=0.58s
22473/10943 (epoch 184.820) train_loss=319.21615601 time/batch=0.59s
22474/10943 (epoch 184.829) train_loss=243.90251160 time/batch=0.61s
22475/10943 (epoch 184.837) train_loss=344.58276367 time/batch=0.60s
setting learning rate to 0.0005792
  saved to metadata/gru_dropout-9_nov_folkwiki-20181115-204407_epoch74.pkl
22476/10943 (epoch 184.845) train_loss=248.67663574 time/batch=0.53s
22477/10943 (epoch 184.853) train_loss=189.57575989 time/batch=0.34s
22478/10943 (epoch 184.861) train_loss=486.14297485 time/batch=0.79s
22479/10943 (epoch 184.870) train_loss=645.85961914 time/batch=1.07s
22480/10943 (epoch 184.878) train_loss=469.13485718 time/batch=0.81s
22481/10943 (epoch 184.886) train_loss=542.63500977 time/batch=0.89s
22482/10943 (epoch 184.894) train_loss=453.75863647 time/batch=0.74s
22483/10943 (epoch 184.903) train_loss=251.88375854 time/batch=0.45s
22484/10943 (epoch 184.911) train_loss=1371.57141113 time/batch=3.06s
22485/10943 (epoch 184.919) train_loss=1111.48681641 time/batch=1.87s
22486/10943 (epoch 184.927) train_loss=239.13131714 time/batch=0.52s
22487/10943 (epoch 184.935) train_loss=588.43481445 time/batch=0.89s
22488/10943 (epoch 184.944) train_loss=203.67492676 time/batch=0.40s
22489/10943 (epoch 184.952) train_loss=796.85662842 time/batch=1.23s
22490/10943 (epoch 184.960) train_loss=652.04028320 time/batch=1.14s
22491/10943 (epoch 184.968) train_loss=960.03039551 time/batch=1.65s
22492/10943 (epoch 184.977) train_loss=515.47991943 time/batch=0.97s
22493/10943 (epoch 184.985) train_loss=548.54339600 time/batch=0.95s
22494/10943 (epoch 184.993) train_loss=226.25262451 time/batch=0.46s
22495/10943 (epoch 185.001) train_loss=432.42120361 time/batch=0.69s
22496/10943 (epoch 185.010) train_loss=678.43640137 time/batch=1.12s
22497/10943 (epoch 185.018) train_loss=174.82110596 time/batch=0.39s
22498/10943 (epoch 185.026) train_loss=540.24017334 time/batch=0.84s
22499/10943 (epoch 185.034) train_loss=465.49618530 time/batch=0.83s
22500/10943 (epoch 185.042) train_loss=585.79937744 time/batch=1.02s
22501/10943 (epoch 185.051) train_loss=877.92993164 time/batch=1.71s
22502/10943 (epoch 185.059) train_loss=359.08236694 time/batch=0.71s
22503/10943 (epoch 185.067) train_loss=138.90859985 time/batch=0.28s
22504/10943 (epoch 185.075) train_loss=209.82989502 time/batch=0.38s
22505/10943 (epoch 185.084) train_loss=353.09188843 time/batch=0.60s
22506/10943 (epoch 185.092) train_loss=324.91137695 time/batch=0.57s
22507/10943 (epoch 185.100) train_loss=154.03433228 time/batch=0.30s
22508/10943 (epoch 185.108) train_loss=487.93957520 time/batch=0.80s
22509/10943 (epoch 185.116) train_loss=709.21545410 time/batch=1.18s
22510/10943 (epoch 185.125) train_loss=607.00549316 time/batch=1.02s
22511/10943 (epoch 185.133) train_loss=290.17309570 time/batch=0.53s
22512/10943 (epoch 185.141) train_loss=582.53704834 time/batch=0.95s
22513/10943 (epoch 185.149) train_loss=691.78118896 time/batch=1.19s
22514/10943 (epoch 185.158) train_loss=200.78767395 time/batch=0.41s
22515/10943 (epoch 185.166) train_loss=227.30984497 time/batch=0.40s
22516/10943 (epoch 185.174) train_loss=389.04907227 time/batch=0.66s
22517/10943 (epoch 185.182) train_loss=345.21862793 time/batch=0.60s
22518/10943 (epoch 185.190) train_loss=455.93002319 time/batch=0.76s
22519/10943 (epoch 185.199) train_loss=537.89056396 time/batch=0.91s
22520/10943 (epoch 185.207) train_loss=303.37661743 time/batch=0.57s
22521/10943 (epoch 185.215) train_loss=659.71435547 time/batch=1.06s
22522/10943 (epoch 185.223) train_loss=305.63000488 time/batch=0.59s
22523/10943 (epoch 185.232) train_loss=308.23937988 time/batch=0.54s
22524/10943 (epoch 185.240) train_loss=454.32525635 time/batch=0.76s
22525/10943 (epoch 185.248) train_loss=463.77343750 time/batch=0.83s
22526/10943 (epoch 185.256) train_loss=825.85998535 time/batch=1.30s
22527/10943 (epoch 185.264) train_loss=875.25512695 time/batch=1.41s
22528/10943 (epoch 185.273) train_loss=521.62829590 time/batch=0.90s
22529/10943 (epoch 185.281) train_loss=464.82073975 time/batch=0.81s
22530/10943 (epoch 185.289) train_loss=464.00585938 time/batch=0.79s
22531/10943 (epoch 185.297) train_loss=468.39523315 time/batch=0.83s
22532/10943 (epoch 185.306) train_loss=284.34680176 time/batch=0.54s
22533/10943 (epoch 185.314) train_loss=646.89685059 time/batch=0.99s
22534/10943 (epoch 185.322) train_loss=360.50512695 time/batch=0.67s
22535/10943 (epoch 185.330) train_loss=762.24926758 time/batch=1.18s
22536/10943 (epoch 185.338) train_loss=257.07702637 time/batch=0.52s
22537/10943 (epoch 185.347) train_loss=255.88288879 time/batch=0.44s
22538/10943 (epoch 185.355) train_loss=460.87695312 time/batch=0.77s
22539/10943 (epoch 185.363) train_loss=681.45483398 time/batch=1.22s
22540/10943 (epoch 185.371) train_loss=425.59613037 time/batch=0.75s
22541/10943 (epoch 185.380) train_loss=578.16601562 time/batch=0.95s
22542/10943 (epoch 185.388) train_loss=211.31379700 time/batch=0.42s
22543/10943 (epoch 185.396) train_loss=411.08953857 time/batch=0.65s
22544/10943 (epoch 185.404) train_loss=360.65582275 time/batch=0.64s
22545/10943 (epoch 185.412) train_loss=413.24426270 time/batch=0.72s
22546/10943 (epoch 185.421) train_loss=509.27932739 time/batch=0.84s
22547/10943 (epoch 185.429) train_loss=376.04580688 time/batch=0.66s
22548/10943 (epoch 185.437) train_loss=493.04638672 time/batch=0.84s
22549/10943 (epoch 185.445) train_loss=442.83862305 time/batch=0.74s
22550/10943 (epoch 185.454) train_loss=453.17840576 time/batch=0.74s
22551/10943 (epoch 185.462) train_loss=370.87054443 time/batch=0.63s
22552/10943 (epoch 185.470) train_loss=443.00399780 time/batch=0.78s
22553/10943 (epoch 185.478) train_loss=380.06756592 time/batch=0.65s
22554/10943 (epoch 185.487) train_loss=174.53253174 time/batch=0.35s
22555/10943 (epoch 185.495) train_loss=176.98886108 time/batch=0.34s
22556/10943 (epoch 185.503) train_loss=178.99694824 time/batch=0.36s
22557/10943 (epoch 185.511) train_loss=536.10607910 time/batch=0.85s
22558/10943 (epoch 185.519) train_loss=288.96514893 time/batch=0.53s
22559/10943 (epoch 185.528) train_loss=444.41885376 time/batch=0.71s
22560/10943 (epoch 185.536) train_loss=470.60882568 time/batch=0.80s
22561/10943 (epoch 185.544) train_loss=235.65031433 time/batch=0.45s
22562/10943 (epoch 185.552) train_loss=312.96020508 time/batch=0.53s
22563/10943 (epoch 185.561) train_loss=314.89733887 time/batch=0.55s
22564/10943 (epoch 185.569) train_loss=262.59436035 time/batch=0.46s
22565/10943 (epoch 185.577) train_loss=345.42037964 time/batch=0.58s
22566/10943 (epoch 185.585) train_loss=530.52124023 time/batch=0.86s
22567/10943 (epoch 185.593) train_loss=394.44030762 time/batch=0.68s
22568/10943 (epoch 185.602) train_loss=399.03604126 time/batch=0.65s
22569/10943 (epoch 185.610) train_loss=522.23663330 time/batch=0.85s
22570/10943 (epoch 185.618) train_loss=287.68206787 time/batch=0.52s
22571/10943 (epoch 185.626) train_loss=316.64233398 time/batch=0.55s
22572/10943 (epoch 185.635) train_loss=493.14392090 time/batch=0.88s
22573/10943 (epoch 185.643) train_loss=320.63241577 time/batch=0.62s
22574/10943 (epoch 185.651) train_loss=266.33398438 time/batch=0.49s
22575/10943 (epoch 185.659) train_loss=291.84082031 time/batch=0.50s
22576/10943 (epoch 185.667) train_loss=261.58621216 time/batch=0.48s
22577/10943 (epoch 185.676) train_loss=369.96218872 time/batch=0.64s
22578/10943 (epoch 185.684) train_loss=590.52532959 time/batch=1.00s
22579/10943 (epoch 185.692) train_loss=447.23220825 time/batch=0.79s
22580/10943 (epoch 185.700) train_loss=435.01071167 time/batch=0.71s
22581/10943 (epoch 185.709) train_loss=339.51522827 time/batch=0.60s
22582/10943 (epoch 185.717) train_loss=327.93035889 time/batch=0.59s
22583/10943 (epoch 185.725) train_loss=253.88555908 time/batch=0.49s
22584/10943 (epoch 185.733) train_loss=406.04418945 time/batch=0.66s
22585/10943 (epoch 185.741) train_loss=422.61242676 time/batch=0.74s
22586/10943 (epoch 185.750) train_loss=479.14886475 time/batch=0.92s
22587/10943 (epoch 185.758) train_loss=348.98626709 time/batch=0.63s
22588/10943 (epoch 185.766) train_loss=400.20571899 time/batch=0.73s
22589/10943 (epoch 185.774) train_loss=378.98004150 time/batch=0.67s
22590/10943 (epoch 185.783) train_loss=501.49295044 time/batch=1.00s
22591/10943 (epoch 185.791) train_loss=336.05651855 time/batch=0.64s
22592/10943 (epoch 185.799) train_loss=286.69998169 time/batch=0.52s
22593/10943 (epoch 185.807) train_loss=585.06738281 time/batch=0.99s
22594/10943 (epoch 185.815) train_loss=341.61846924 time/batch=0.66s
22595/10943 (epoch 185.824) train_loss=400.53985596 time/batch=0.65s
22596/10943 (epoch 185.832) train_loss=398.51165771 time/batch=0.68s
setting learning rate to 0.0005618
22597/10943 (epoch 185.840) train_loss=972.41802979 time/batch=1.59s
22598/10943 (epoch 185.848) train_loss=364.91519165 time/batch=0.71s
22599/10943 (epoch 185.857) train_loss=832.37207031 time/batch=1.27s
22600/10943 (epoch 185.865) train_loss=978.63964844 time/batch=1.66s
22601/10943 (epoch 185.873) train_loss=192.80355835 time/batch=0.44s
22602/10943 (epoch 185.881) train_loss=141.35198975 time/batch=0.26s
22603/10943 (epoch 185.889) train_loss=605.80297852 time/batch=0.95s
22604/10943 (epoch 185.898) train_loss=833.73742676 time/batch=1.38s
22605/10943 (epoch 185.906) train_loss=660.97564697 time/batch=1.07s
22606/10943 (epoch 185.914) train_loss=515.95019531 time/batch=0.88s
22607/10943 (epoch 185.922) train_loss=241.86805725 time/batch=0.46s
22608/10943 (epoch 185.931) train_loss=365.12252808 time/batch=0.59s
22609/10943 (epoch 185.939) train_loss=1347.58996582 time/batch=3.07s
22610/10943 (epoch 185.947) train_loss=477.73236084 time/batch=1.04s
22611/10943 (epoch 185.955) train_loss=501.49334717 time/batch=0.84s
22612/10943 (epoch 185.964) train_loss=195.41400146 time/batch=0.39s
22613/10943 (epoch 185.972) train_loss=189.61378479 time/batch=0.34s
22614/10943 (epoch 185.980) train_loss=323.51458740 time/batch=0.55s
22615/10943 (epoch 185.988) train_loss=585.18640137 time/batch=0.96s
22616/10943 (epoch 185.996) train_loss=164.35275269 time/batch=0.36s
22617/10943 (epoch 186.005) train_loss=496.35418701 time/batch=0.80s
22618/10943 (epoch 186.013) train_loss=178.59468079 time/batch=0.35s
22619/10943 (epoch 186.021) train_loss=341.85174561 time/batch=0.56s
22620/10943 (epoch 186.029) train_loss=542.26116943 time/batch=0.92s
22621/10943 (epoch 186.038) train_loss=388.67202759 time/batch=0.68s
22622/10943 (epoch 186.046) train_loss=715.12866211 time/batch=1.17s
22623/10943 (epoch 186.054) train_loss=452.06842041 time/batch=0.79s
22624/10943 (epoch 186.062) train_loss=589.72961426 time/batch=0.94s
22625/10943 (epoch 186.070) train_loss=357.05664062 time/batch=0.64s
22626/10943 (epoch 186.079) train_loss=493.00903320 time/batch=0.82s
22627/10943 (epoch 186.087) train_loss=705.25805664 time/batch=1.15s
22628/10943 (epoch 186.095) train_loss=285.86892700 time/batch=0.54s
22629/10943 (epoch 186.103) train_loss=671.11633301 time/batch=1.04s
22630/10943 (epoch 186.112) train_loss=208.75653076 time/batch=0.43s
22631/10943 (epoch 186.120) train_loss=408.54687500 time/batch=0.67s
22632/10943 (epoch 186.128) train_loss=212.28045654 time/batch=0.39s
22633/10943 (epoch 186.136) train_loss=300.49011230 time/batch=0.51s
22634/10943 (epoch 186.144) train_loss=667.57250977 time/batch=1.08s
22635/10943 (epoch 186.153) train_loss=826.78186035 time/batch=1.42s
22636/10943 (epoch 186.161) train_loss=460.48303223 time/batch=0.79s
22637/10943 (epoch 186.169) train_loss=329.98486328 time/batch=0.57s
22638/10943 (epoch 186.177) train_loss=350.63421631 time/batch=0.59s
22639/10943 (epoch 186.186) train_loss=494.49212646 time/batch=0.85s
22640/10943 (epoch 186.194) train_loss=400.83206177 time/batch=0.71s
22641/10943 (epoch 186.202) train_loss=223.33203125 time/batch=0.42s
22642/10943 (epoch 186.210) train_loss=164.61090088 time/batch=0.31s
22643/10943 (epoch 186.218) train_loss=447.92321777 time/batch=0.73s
22644/10943 (epoch 186.227) train_loss=363.03021240 time/batch=0.66s
22645/10943 (epoch 186.235) train_loss=211.56484985 time/batch=0.40s
22646/10943 (epoch 186.243) train_loss=371.22085571 time/batch=0.62s
22647/10943 (epoch 186.251) train_loss=312.53436279 time/batch=0.55s
22648/10943 (epoch 186.260) train_loss=538.48779297 time/batch=0.86s
22649/10943 (epoch 186.268) train_loss=285.83068848 time/batch=0.51s
22650/10943 (epoch 186.276) train_loss=408.79681396 time/batch=0.67s
22651/10943 (epoch 186.284) train_loss=538.12231445 time/batch=0.89s
22652/10943 (epoch 186.292) train_loss=906.57366943 time/batch=1.69s
22653/10943 (epoch 186.301) train_loss=523.30999756 time/batch=0.91s
22654/10943 (epoch 186.309) train_loss=606.02221680 time/batch=1.03s
22655/10943 (epoch 186.317) train_loss=248.12232971 time/batch=0.50s
22656/10943 (epoch 186.325) train_loss=351.39862061 time/batch=0.60s
22657/10943 (epoch 186.334) train_loss=455.77947998 time/batch=0.77s
22658/10943 (epoch 186.342) train_loss=638.99133301 time/batch=1.07s
22659/10943 (epoch 186.350) train_loss=414.40924072 time/batch=0.72s
22660/10943 (epoch 186.358) train_loss=437.51043701 time/batch=0.75s
22661/10943 (epoch 186.366) train_loss=323.50949097 time/batch=0.60s
22662/10943 (epoch 186.375) train_loss=289.67895508 time/batch=0.53s
22663/10943 (epoch 186.383) train_loss=228.55535889 time/batch=0.40s
22664/10943 (epoch 186.391) train_loss=424.51531982 time/batch=0.69s
22665/10943 (epoch 186.399) train_loss=194.19349670 time/batch=0.38s
22666/10943 (epoch 186.408) train_loss=232.15069580 time/batch=0.41s
22667/10943 (epoch 186.416) train_loss=249.61737061 time/batch=0.43s
22668/10943 (epoch 186.424) train_loss=454.39916992 time/batch=0.73s
22669/10943 (epoch 186.432) train_loss=308.70513916 time/batch=0.56s
22670/10943 (epoch 186.441) train_loss=284.16766357 time/batch=0.50s
22671/10943 (epoch 186.449) train_loss=200.94810486 time/batch=0.36s
22672/10943 (epoch 186.457) train_loss=258.71585083 time/batch=0.44s
22673/10943 (epoch 186.465) train_loss=481.11361694 time/batch=0.81s
22674/10943 (epoch 186.473) train_loss=547.51696777 time/batch=0.89s
22675/10943 (epoch 186.482) train_loss=478.69812012 time/batch=0.81s
22676/10943 (epoch 186.490) train_loss=483.30145264 time/batch=0.80s
22677/10943 (epoch 186.498) train_loss=665.66992188 time/batch=1.04s
22678/10943 (epoch 186.506) train_loss=783.05822754 time/batch=1.23s
22679/10943 (epoch 186.515) train_loss=310.66946411 time/batch=0.58s
22680/10943 (epoch 186.523) train_loss=618.86096191 time/batch=1.02s
22681/10943 (epoch 186.531) train_loss=610.79846191 time/batch=1.12s
22682/10943 (epoch 186.539) train_loss=348.46984863 time/batch=0.64s
22683/10943 (epoch 186.547) train_loss=357.78295898 time/batch=0.62s
22684/10943 (epoch 186.556) train_loss=258.31109619 time/batch=0.46s
22685/10943 (epoch 186.564) train_loss=576.81201172 time/batch=0.92s
22686/10943 (epoch 186.572) train_loss=417.80062866 time/batch=0.71s
22687/10943 (epoch 186.580) train_loss=422.46432495 time/batch=0.70s
22688/10943 (epoch 186.589) train_loss=342.72448730 time/batch=0.60s
22689/10943 (epoch 186.597) train_loss=486.81185913 time/batch=0.84s
22690/10943 (epoch 186.605) train_loss=379.21557617 time/batch=0.67s
22691/10943 (epoch 186.613) train_loss=399.50524902 time/batch=0.66s
22692/10943 (epoch 186.621) train_loss=524.06066895 time/batch=0.88s
22693/10943 (epoch 186.630) train_loss=651.05456543 time/batch=1.13s
22694/10943 (epoch 186.638) train_loss=639.51293945 time/batch=1.25s
22695/10943 (epoch 186.646) train_loss=493.28118896 time/batch=0.87s
22696/10943 (epoch 186.654) train_loss=361.38140869 time/batch=0.65s
22697/10943 (epoch 186.663) train_loss=251.37481689 time/batch=0.48s
22698/10943 (epoch 186.671) train_loss=282.20159912 time/batch=0.48s
22699/10943 (epoch 186.679) train_loss=441.87237549 time/batch=0.71s
22700/10943 (epoch 186.687) train_loss=383.74285889 time/batch=0.67s
22701/10943 (epoch 186.695) train_loss=314.33862305 time/batch=0.56s
22702/10943 (epoch 186.704) train_loss=419.70593262 time/batch=0.69s
22703/10943 (epoch 186.712) train_loss=290.76220703 time/batch=0.50s
22704/10943 (epoch 186.720) train_loss=298.13299561 time/batch=0.50s
22705/10943 (epoch 186.728) train_loss=397.57897949 time/batch=0.69s
22706/10943 (epoch 186.737) train_loss=260.70858765 time/batch=0.58s
22707/10943 (epoch 186.745) train_loss=427.63665771 time/batch=0.70s
22708/10943 (epoch 186.753) train_loss=334.33911133 time/batch=0.60s
22709/10943 (epoch 186.761) train_loss=539.62963867 time/batch=0.88s
22710/10943 (epoch 186.769) train_loss=420.24084473 time/batch=0.75s
22711/10943 (epoch 186.778) train_loss=386.61373901 time/batch=0.66s
22712/10943 (epoch 186.786) train_loss=465.02600098 time/batch=0.78s
22713/10943 (epoch 186.794) train_loss=466.82727051 time/batch=0.91s
22714/10943 (epoch 186.802) train_loss=461.90869141 time/batch=0.84s
22715/10943 (epoch 186.811) train_loss=444.14831543 time/batch=0.76s
22716/10943 (epoch 186.819) train_loss=464.63900757 time/batch=0.81s
22717/10943 (epoch 186.827) train_loss=347.60568237 time/batch=0.76s
setting learning rate to 0.0005449
22718/10943 (epoch 186.835) train_loss=633.56774902 time/batch=1.01s
22719/10943 (epoch 186.843) train_loss=595.51501465 time/batch=0.97s
22720/10943 (epoch 186.852) train_loss=1405.39697266 time/batch=3.10s
22721/10943 (epoch 186.860) train_loss=313.50183105 time/batch=0.79s
22722/10943 (epoch 186.868) train_loss=464.30572510 time/batch=0.74s
22723/10943 (epoch 186.876) train_loss=329.06338501 time/batch=0.58s
22724/10943 (epoch 186.885) train_loss=675.59973145 time/batch=1.10s
22725/10943 (epoch 186.893) train_loss=836.92028809 time/batch=1.40s
22726/10943 (epoch 186.901) train_loss=711.16687012 time/batch=1.17s
22727/10943 (epoch 186.909) train_loss=597.02215576 time/batch=1.02s
22728/10943 (epoch 186.918) train_loss=340.94781494 time/batch=0.61s
22729/10943 (epoch 186.926) train_loss=496.61666870 time/batch=0.82s
22730/10943 (epoch 186.934) train_loss=433.63220215 time/batch=0.74s
22731/10943 (epoch 186.942) train_loss=461.25347900 time/batch=0.79s
22732/10943 (epoch 186.950) train_loss=529.01269531 time/batch=0.91s
22733/10943 (epoch 186.959) train_loss=445.09289551 time/batch=0.80s
22734/10943 (epoch 186.967) train_loss=577.81170654 time/batch=0.97s
22735/10943 (epoch 186.975) train_loss=284.42245483 time/batch=0.54s
22736/10943 (epoch 186.983) train_loss=438.06835938 time/batch=0.74s
22737/10943 (epoch 186.992) train_loss=911.83276367 time/batch=1.52s
22738/10943 (epoch 187.000) train_loss=362.34707642 time/batch=0.72s
22739/10943 (epoch 187.008) train_loss=434.97131348 time/batch=0.70s
22740/10943 (epoch 187.016) train_loss=461.38500977 time/batch=0.82s
22741/10943 (epoch 187.024) train_loss=317.72961426 time/batch=0.58s
22742/10943 (epoch 187.033) train_loss=684.39196777 time/batch=1.14s
22743/10943 (epoch 187.041) train_loss=339.29089355 time/batch=0.67s
22744/10943 (epoch 187.049) train_loss=604.52868652 time/batch=0.96s
22745/10943 (epoch 187.057) train_loss=414.49014282 time/batch=0.71s
22746/10943 (epoch 187.066) train_loss=400.39508057 time/batch=0.67s
22747/10943 (epoch 187.074) train_loss=233.59309387 time/batch=0.43s
22748/10943 (epoch 187.082) train_loss=604.14587402 time/batch=0.96s
22749/10943 (epoch 187.090) train_loss=772.17657471 time/batch=1.24s
22750/10943 (epoch 187.098) train_loss=514.30273438 time/batch=0.89s
22751/10943 (epoch 187.107) train_loss=621.14178467 time/batch=1.02s
22752/10943 (epoch 187.115) train_loss=334.49728394 time/batch=0.61s
22753/10943 (epoch 187.123) train_loss=309.11877441 time/batch=0.54s
22754/10943 (epoch 187.131) train_loss=157.87966919 time/batch=0.30s
22755/10943 (epoch 187.140) train_loss=340.43038940 time/batch=0.58s
22756/10943 (epoch 187.148) train_loss=513.32202148 time/batch=0.85s
22757/10943 (epoch 187.156) train_loss=634.16357422 time/batch=1.08s
22758/10943 (epoch 187.164) train_loss=139.27209473 time/batch=0.33s
22759/10943 (epoch 187.172) train_loss=227.51358032 time/batch=0.40s
22760/10943 (epoch 187.181) train_loss=348.50366211 time/batch=0.58s
22761/10943 (epoch 187.189) train_loss=181.77638245 time/batch=0.35s
22762/10943 (epoch 187.197) train_loss=686.63311768 time/batch=1.12s
22763/10943 (epoch 187.205) train_loss=416.77655029 time/batch=0.73s
22764/10943 (epoch 187.214) train_loss=167.10644531 time/batch=0.33s
22765/10943 (epoch 187.222) train_loss=923.01391602 time/batch=1.55s
22766/10943 (epoch 187.230) train_loss=389.32275391 time/batch=0.73s
22767/10943 (epoch 187.238) train_loss=541.26379395 time/batch=0.89s
22768/10943 (epoch 187.246) train_loss=175.18988037 time/batch=0.37s
22769/10943 (epoch 187.255) train_loss=464.39743042 time/batch=0.78s
22770/10943 (epoch 187.263) train_loss=833.67199707 time/batch=1.30s
22771/10943 (epoch 187.271) train_loss=551.53344727 time/batch=0.95s
22772/10943 (epoch 187.279) train_loss=250.85571289 time/batch=0.49s
22773/10943 (epoch 187.288) train_loss=204.21734619 time/batch=0.36s
22774/10943 (epoch 187.296) train_loss=274.58886719 time/batch=0.48s
22775/10943 (epoch 187.304) train_loss=279.95980835 time/batch=0.50s
22776/10943 (epoch 187.312) train_loss=357.37423706 time/batch=0.62s
22777/10943 (epoch 187.320) train_loss=967.50952148 time/batch=1.66s
22778/10943 (epoch 187.329) train_loss=275.72399902 time/batch=0.58s
22779/10943 (epoch 187.337) train_loss=739.21252441 time/batch=1.20s
22780/10943 (epoch 187.345) train_loss=571.98004150 time/batch=1.00s
22781/10943 (epoch 187.353) train_loss=470.44689941 time/batch=0.82s
22782/10943 (epoch 187.362) train_loss=441.39459229 time/batch=0.74s
22783/10943 (epoch 187.370) train_loss=532.82995605 time/batch=0.89s
22784/10943 (epoch 187.378) train_loss=468.24822998 time/batch=0.81s
22785/10943 (epoch 187.386) train_loss=261.52032471 time/batch=0.48s
22786/10943 (epoch 187.395) train_loss=398.71786499 time/batch=0.64s
22787/10943 (epoch 187.403) train_loss=403.44503784 time/batch=0.70s
22788/10943 (epoch 187.411) train_loss=660.06311035 time/batch=1.16s
22789/10943 (epoch 187.419) train_loss=574.44836426 time/batch=1.06s
22790/10943 (epoch 187.427) train_loss=638.40966797 time/batch=1.10s
22791/10943 (epoch 187.436) train_loss=305.38885498 time/batch=0.58s
22792/10943 (epoch 187.444) train_loss=331.37670898 time/batch=0.57s
22793/10943 (epoch 187.452) train_loss=511.99334717 time/batch=0.86s
22794/10943 (epoch 187.460) train_loss=437.68450928 time/batch=0.76s
22795/10943 (epoch 187.469) train_loss=289.18792725 time/batch=0.53s
22796/10943 (epoch 187.477) train_loss=458.87463379 time/batch=0.78s
22797/10943 (epoch 187.485) train_loss=509.95150757 time/batch=0.87s
22798/10943 (epoch 187.493) train_loss=357.31298828 time/batch=0.61s
22799/10943 (epoch 187.501) train_loss=345.80181885 time/batch=0.61s
22800/10943 (epoch 187.510) train_loss=199.58685303 time/batch=0.38s
22801/10943 (epoch 187.518) train_loss=456.66497803 time/batch=0.78s
22802/10943 (epoch 187.526) train_loss=375.74694824 time/batch=0.66s
22803/10943 (epoch 187.534) train_loss=173.10737610 time/batch=0.33s
22804/10943 (epoch 187.543) train_loss=425.80072021 time/batch=0.71s
22805/10943 (epoch 187.551) train_loss=388.79891968 time/batch=0.67s
22806/10943 (epoch 187.559) train_loss=328.68270874 time/batch=0.59s
22807/10943 (epoch 187.567) train_loss=425.90478516 time/batch=0.76s
22808/10943 (epoch 187.575) train_loss=473.88311768 time/batch=0.84s
22809/10943 (epoch 187.584) train_loss=276.38500977 time/batch=0.51s
22810/10943 (epoch 187.592) train_loss=487.80230713 time/batch=0.83s
22811/10943 (epoch 187.600) train_loss=291.19793701 time/batch=0.55s
22812/10943 (epoch 187.608) train_loss=189.54718018 time/batch=0.36s
22813/10943 (epoch 187.617) train_loss=420.05795288 time/batch=0.71s
22814/10943 (epoch 187.625) train_loss=346.59301758 time/batch=0.64s
22815/10943 (epoch 187.633) train_loss=212.44018555 time/batch=0.40s
22816/10943 (epoch 187.641) train_loss=217.57627869 time/batch=0.39s
22817/10943 (epoch 187.649) train_loss=289.19598389 time/batch=0.51s
22818/10943 (epoch 187.658) train_loss=414.53662109 time/batch=0.69s
22819/10943 (epoch 187.666) train_loss=399.96270752 time/batch=0.69s
22820/10943 (epoch 187.674) train_loss=484.02359009 time/batch=0.81s
22821/10943 (epoch 187.682) train_loss=362.44100952 time/batch=0.65s
22822/10943 (epoch 187.691) train_loss=386.19006348 time/batch=0.65s
22823/10943 (epoch 187.699) train_loss=394.41101074 time/batch=0.69s
22824/10943 (epoch 187.707) train_loss=195.90631104 time/batch=0.38s
22825/10943 (epoch 187.715) train_loss=191.84649658 time/batch=0.36s
22826/10943 (epoch 187.723) train_loss=328.01495361 time/batch=0.57s
22827/10943 (epoch 187.732) train_loss=221.23590088 time/batch=0.44s
22828/10943 (epoch 187.740) train_loss=485.21697998 time/batch=0.79s
22829/10943 (epoch 187.748) train_loss=411.08972168 time/batch=0.71s
22830/10943 (epoch 187.756) train_loss=262.39617920 time/batch=0.48s
22831/10943 (epoch 187.765) train_loss=503.23898315 time/batch=0.99s
22832/10943 (epoch 187.773) train_loss=307.70947266 time/batch=0.62s
22833/10943 (epoch 187.781) train_loss=412.30621338 time/batch=0.71s
22834/10943 (epoch 187.789) train_loss=372.42517090 time/batch=0.64s
22835/10943 (epoch 187.797) train_loss=456.79132080 time/batch=0.82s
22836/10943 (epoch 187.806) train_loss=286.25906372 time/batch=0.66s
22837/10943 (epoch 187.814) train_loss=240.06860352 time/batch=0.44s
22838/10943 (epoch 187.822) train_loss=365.18093872 time/batch=0.67s
setting learning rate to 0.0005286
22839/10943 (epoch 187.830) train_loss=192.18177795 time/batch=0.37s
22840/10943 (epoch 187.839) train_loss=658.84338379 time/batch=1.09s
22841/10943 (epoch 187.847) train_loss=184.40647888 time/batch=0.40s
22842/10943 (epoch 187.855) train_loss=646.62268066 time/batch=1.04s
22843/10943 (epoch 187.863) train_loss=339.27008057 time/batch=0.66s
22844/10943 (epoch 187.871) train_loss=352.10189819 time/batch=0.60s
22845/10943 (epoch 187.880) train_loss=843.22674561 time/batch=1.42s
22846/10943 (epoch 187.888) train_loss=514.98345947 time/batch=0.90s
22847/10943 (epoch 187.896) train_loss=596.79071045 time/batch=0.97s
22848/10943 (epoch 187.904) train_loss=567.74719238 time/batch=0.99s
22849/10943 (epoch 187.913) train_loss=676.31237793 time/batch=1.16s
22850/10943 (epoch 187.921) train_loss=381.41204834 time/batch=0.70s
22851/10943 (epoch 187.929) train_loss=737.01403809 time/batch=1.20s
22852/10943 (epoch 187.937) train_loss=834.61035156 time/batch=1.35s
22853/10943 (epoch 187.946) train_loss=921.77844238 time/batch=1.60s
22854/10943 (epoch 187.954) train_loss=592.46368408 time/batch=1.07s
22855/10943 (epoch 187.962) train_loss=629.92431641 time/batch=1.09s
22856/10943 (epoch 187.970) train_loss=856.79577637 time/batch=1.61s
22857/10943 (epoch 187.978) train_loss=162.35499573 time/batch=0.42s
22858/10943 (epoch 187.987) train_loss=1098.09716797 time/batch=1.87s
22859/10943 (epoch 187.995) train_loss=217.57656860 time/batch=0.54s
22860/10943 (epoch 188.003) train_loss=402.05148315 time/batch=0.66s
22861/10943 (epoch 188.011) train_loss=257.37911987 time/batch=0.46s
22862/10943 (epoch 188.020) train_loss=1233.27014160 time/batch=3.08s
22863/10943 (epoch 188.028) train_loss=450.93258667 time/batch=1.00s
22864/10943 (epoch 188.036) train_loss=328.06420898 time/batch=0.58s
22865/10943 (epoch 188.044) train_loss=410.89111328 time/batch=0.69s
22866/10943 (epoch 188.052) train_loss=455.32910156 time/batch=0.79s
22867/10943 (epoch 188.061) train_loss=588.20715332 time/batch=1.01s
22868/10943 (epoch 188.069) train_loss=196.88737488 time/batch=0.41s
22869/10943 (epoch 188.077) train_loss=453.79977417 time/batch=0.72s
22870/10943 (epoch 188.085) train_loss=219.58584595 time/batch=0.43s
22871/10943 (epoch 188.094) train_loss=438.49505615 time/batch=0.71s
22872/10943 (epoch 188.102) train_loss=302.21539307 time/batch=0.56s
22873/10943 (epoch 188.110) train_loss=210.42153931 time/batch=0.37s
22874/10943 (epoch 188.118) train_loss=383.63146973 time/batch=0.63s
22875/10943 (epoch 188.126) train_loss=311.04501343 time/batch=0.55s
22876/10943 (epoch 188.135) train_loss=138.70239258 time/batch=0.30s
22877/10943 (epoch 188.143) train_loss=545.62615967 time/batch=0.87s
22878/10943 (epoch 188.151) train_loss=643.96679688 time/batch=1.01s
22879/10943 (epoch 188.159) train_loss=261.30114746 time/batch=0.50s
22880/10943 (epoch 188.168) train_loss=335.60885620 time/batch=0.58s
22881/10943 (epoch 188.176) train_loss=256.89178467 time/batch=0.46s
22882/10943 (epoch 188.184) train_loss=213.74911499 time/batch=0.39s
22883/10943 (epoch 188.192) train_loss=670.73962402 time/batch=1.05s
22884/10943 (epoch 188.200) train_loss=237.49349976 time/batch=0.49s
22885/10943 (epoch 188.209) train_loss=327.08261108 time/batch=0.55s
22886/10943 (epoch 188.217) train_loss=358.14044189 time/batch=0.62s
22887/10943 (epoch 188.225) train_loss=200.58732605 time/batch=0.38s
22888/10943 (epoch 188.233) train_loss=713.95489502 time/batch=1.18s
22889/10943 (epoch 188.242) train_loss=513.93737793 time/batch=0.89s
22890/10943 (epoch 188.250) train_loss=511.36145020 time/batch=0.86s
22891/10943 (epoch 188.258) train_loss=327.79882812 time/batch=0.59s
22892/10943 (epoch 188.266) train_loss=156.14913940 time/batch=0.32s
22893/10943 (epoch 188.274) train_loss=512.97155762 time/batch=0.83s
22894/10943 (epoch 188.283) train_loss=478.26391602 time/batch=0.85s
22895/10943 (epoch 188.291) train_loss=266.76132202 time/batch=0.50s
22896/10943 (epoch 188.299) train_loss=502.36877441 time/batch=0.82s
22897/10943 (epoch 188.307) train_loss=598.60174561 time/batch=1.03s
22898/10943 (epoch 188.316) train_loss=425.46429443 time/batch=0.74s
22899/10943 (epoch 188.324) train_loss=701.28363037 time/batch=1.23s
22900/10943 (epoch 188.332) train_loss=417.11355591 time/batch=0.73s
22901/10943 (epoch 188.340) train_loss=323.22503662 time/batch=0.58s
22902/10943 (epoch 188.348) train_loss=466.61004639 time/batch=0.80s
22903/10943 (epoch 188.357) train_loss=646.93518066 time/batch=1.11s
22904/10943 (epoch 188.365) train_loss=314.07192993 time/batch=0.61s
22905/10943 (epoch 188.373) train_loss=507.28860474 time/batch=0.86s
22906/10943 (epoch 188.381) train_loss=281.45306396 time/batch=0.54s
22907/10943 (epoch 188.390) train_loss=466.90328979 time/batch=0.77s
22908/10943 (epoch 188.398) train_loss=586.11480713 time/batch=1.02s
22909/10943 (epoch 188.406) train_loss=341.42312622 time/batch=0.63s
22910/10943 (epoch 188.414) train_loss=390.51367188 time/batch=0.64s
22911/10943 (epoch 188.423) train_loss=239.17248535 time/batch=0.44s
22912/10943 (epoch 188.431) train_loss=286.78686523 time/batch=0.50s
22913/10943 (epoch 188.439) train_loss=537.52923584 time/batch=0.90s
22914/10943 (epoch 188.447) train_loss=290.23242188 time/batch=0.53s
22915/10943 (epoch 188.455) train_loss=479.46206665 time/batch=0.80s
22916/10943 (epoch 188.464) train_loss=437.97424316 time/batch=0.79s
22917/10943 (epoch 188.472) train_loss=175.31712341 time/batch=0.35s
22918/10943 (epoch 188.480) train_loss=285.33084106 time/batch=0.50s
22919/10943 (epoch 188.488) train_loss=216.13793945 time/batch=0.41s
22920/10943 (epoch 188.497) train_loss=424.21771240 time/batch=0.72s
22921/10943 (epoch 188.505) train_loss=291.11474609 time/batch=0.53s
22922/10943 (epoch 188.513) train_loss=336.66412354 time/batch=0.59s
22923/10943 (epoch 188.521) train_loss=417.68078613 time/batch=0.72s
22924/10943 (epoch 188.529) train_loss=371.76062012 time/batch=0.64s
22925/10943 (epoch 188.538) train_loss=384.25311279 time/batch=0.64s
22926/10943 (epoch 188.546) train_loss=408.20697021 time/batch=0.68s
22927/10943 (epoch 188.554) train_loss=306.04193115 time/batch=0.58s
22928/10943 (epoch 188.562) train_loss=279.46777344 time/batch=0.50s
22929/10943 (epoch 188.571) train_loss=421.76174927 time/batch=0.69s
22930/10943 (epoch 188.579) train_loss=607.41674805 time/batch=1.02s
22931/10943 (epoch 188.587) train_loss=482.41656494 time/batch=0.83s
22932/10943 (epoch 188.595) train_loss=435.56225586 time/batch=0.72s
22933/10943 (epoch 188.603) train_loss=464.51062012 time/batch=0.78s
22934/10943 (epoch 188.612) train_loss=364.86572266 time/batch=0.66s
22935/10943 (epoch 188.620) train_loss=257.88513184 time/batch=0.48s
22936/10943 (epoch 188.628) train_loss=528.63714600 time/batch=0.87s
22937/10943 (epoch 188.636) train_loss=487.12036133 time/batch=0.89s
22938/10943 (epoch 188.645) train_loss=409.28808594 time/batch=0.72s
22939/10943 (epoch 188.653) train_loss=451.27050781 time/batch=0.76s
22940/10943 (epoch 188.661) train_loss=537.67181396 time/batch=0.93s
22941/10943 (epoch 188.669) train_loss=542.87109375 time/batch=0.90s
22942/10943 (epoch 188.677) train_loss=278.48074341 time/batch=0.52s
22943/10943 (epoch 188.686) train_loss=342.57208252 time/batch=0.59s
22944/10943 (epoch 188.694) train_loss=356.81213379 time/batch=0.61s
22945/10943 (epoch 188.702) train_loss=302.12744141 time/batch=0.57s
22946/10943 (epoch 188.710) train_loss=242.68077087 time/batch=0.47s
22947/10943 (epoch 188.719) train_loss=488.46881104 time/batch=0.83s
22948/10943 (epoch 188.727) train_loss=354.06689453 time/batch=0.67s
22949/10943 (epoch 188.735) train_loss=185.74401855 time/batch=0.34s
22950/10943 (epoch 188.743) train_loss=430.68087769 time/batch=0.69s
22951/10943 (epoch 188.751) train_loss=394.38632202 time/batch=0.69s
22952/10943 (epoch 188.760) train_loss=320.95562744 time/batch=0.61s
22953/10943 (epoch 188.768) train_loss=422.61065674 time/batch=0.71s
22954/10943 (epoch 188.776) train_loss=472.05603027 time/batch=0.81s
22955/10943 (epoch 188.784) train_loss=405.34020996 time/batch=0.68s
22956/10943 (epoch 188.793) train_loss=440.14050293 time/batch=0.77s
22957/10943 (epoch 188.801) train_loss=472.77545166 time/batch=0.82s
22958/10943 (epoch 188.809) train_loss=387.24664307 time/batch=0.74s
22959/10943 (epoch 188.817) train_loss=449.05499268 time/batch=0.81s
setting learning rate to 0.0005127
22960/10943 (epoch 188.825) train_loss=771.15197754 time/batch=1.26s
22961/10943 (epoch 188.834) train_loss=1001.13519287 time/batch=1.62s
22962/10943 (epoch 188.842) train_loss=480.38964844 time/batch=0.88s
22963/10943 (epoch 188.850) train_loss=485.17395020 time/batch=0.83s
22964/10943 (epoch 188.858) train_loss=140.22607422 time/batch=0.32s
22965/10943 (epoch 188.867) train_loss=769.24530029 time/batch=1.21s
22966/10943 (epoch 188.875) train_loss=711.03295898 time/batch=1.24s
22967/10943 (epoch 188.883) train_loss=556.17895508 time/batch=0.96s
22968/10943 (epoch 188.891) train_loss=1057.71435547 time/batch=1.78s
22969/10943 (epoch 188.900) train_loss=1340.20373535 time/batch=3.21s
22970/10943 (epoch 188.908) train_loss=323.46917725 time/batch=0.83s
22971/10943 (epoch 188.916) train_loss=852.09411621 time/batch=1.30s
22972/10943 (epoch 188.924) train_loss=333.76153564 time/batch=0.67s
22973/10943 (epoch 188.932) train_loss=177.46112061 time/batch=0.33s
22974/10943 (epoch 188.941) train_loss=818.01037598 time/batch=1.38s
22975/10943 (epoch 188.949) train_loss=228.13659668 time/batch=0.49s
22976/10943 (epoch 188.957) train_loss=558.49768066 time/batch=0.90s
22977/10943 (epoch 188.965) train_loss=613.59863281 time/batch=1.03s
22978/10943 (epoch 188.974) train_loss=328.40435791 time/batch=0.61s
22979/10943 (epoch 188.982) train_loss=205.32713318 time/batch=0.36s
22980/10943 (epoch 188.990) train_loss=160.38095093 time/batch=0.30s
22981/10943 (epoch 188.998) train_loss=288.24606323 time/batch=0.48s
22982/10943 (epoch 189.006) train_loss=543.49517822 time/batch=0.90s
22983/10943 (epoch 189.015) train_loss=227.66687012 time/batch=0.46s
22984/10943 (epoch 189.023) train_loss=443.17764282 time/batch=0.74s
22985/10943 (epoch 189.031) train_loss=605.67065430 time/batch=0.98s
22986/10943 (epoch 189.039) train_loss=276.41809082 time/batch=0.54s
22987/10943 (epoch 189.048) train_loss=594.49401855 time/batch=0.96s
22988/10943 (epoch 189.056) train_loss=579.41906738 time/batch=1.00s
22989/10943 (epoch 189.064) train_loss=260.67224121 time/batch=0.49s
22990/10943 (epoch 189.072) train_loss=303.77603149 time/batch=0.54s
22991/10943 (epoch 189.080) train_loss=767.86230469 time/batch=1.34s
22992/10943 (epoch 189.089) train_loss=332.48956299 time/batch=0.65s
22993/10943 (epoch 189.097) train_loss=579.12786865 time/batch=0.93s
22994/10943 (epoch 189.105) train_loss=460.60644531 time/batch=0.76s
22995/10943 (epoch 189.113) train_loss=673.72192383 time/batch=1.10s
22996/10943 (epoch 189.122) train_loss=684.01794434 time/batch=1.16s
22997/10943 (epoch 189.130) train_loss=709.28411865 time/batch=1.18s
22998/10943 (epoch 189.138) train_loss=340.79400635 time/batch=0.64s
22999/10943 (epoch 189.146) train_loss=438.82797241 time/batch=0.74s
Validating
    loss:	408.421659

23000/10943 (epoch 189.154) train_loss=619.50067139 time/batch=2.90s
23001/10943 (epoch 189.163) train_loss=480.26727295 time/batch=0.87s
23002/10943 (epoch 189.171) train_loss=525.34515381 time/batch=0.88s
23003/10943 (epoch 189.179) train_loss=529.43811035 time/batch=0.94s
23004/10943 (epoch 189.187) train_loss=642.30017090 time/batch=1.11s
23005/10943 (epoch 189.196) train_loss=303.42837524 time/batch=0.57s
23006/10943 (epoch 189.204) train_loss=159.68978882 time/batch=0.31s
23007/10943 (epoch 189.212) train_loss=391.10528564 time/batch=0.62s
23008/10943 (epoch 189.220) train_loss=461.94995117 time/batch=0.79s
23009/10943 (epoch 189.228) train_loss=611.93322754 time/batch=1.05s
23010/10943 (epoch 189.237) train_loss=569.54089355 time/batch=0.99s
23011/10943 (epoch 189.245) train_loss=235.21228027 time/batch=0.47s
23012/10943 (epoch 189.253) train_loss=428.08813477 time/batch=0.71s
23013/10943 (epoch 189.261) train_loss=356.78894043 time/batch=0.64s
23014/10943 (epoch 189.270) train_loss=417.40301514 time/batch=0.69s
23015/10943 (epoch 189.278) train_loss=493.90802002 time/batch=0.86s
23016/10943 (epoch 189.286) train_loss=448.41967773 time/batch=0.77s
23017/10943 (epoch 189.294) train_loss=346.36950684 time/batch=0.61s
23018/10943 (epoch 189.302) train_loss=524.23846436 time/batch=0.85s
23019/10943 (epoch 189.311) train_loss=216.90969849 time/batch=0.44s
23020/10943 (epoch 189.319) train_loss=240.52401733 time/batch=0.44s
23021/10943 (epoch 189.327) train_loss=259.30545044 time/batch=0.44s
23022/10943 (epoch 189.335) train_loss=461.97381592 time/batch=0.76s
23023/10943 (epoch 189.344) train_loss=226.17623901 time/batch=0.45s
23024/10943 (epoch 189.352) train_loss=394.48373413 time/batch=0.66s
23025/10943 (epoch 189.360) train_loss=654.43273926 time/batch=1.07s
23026/10943 (epoch 189.368) train_loss=433.89959717 time/batch=0.77s
23027/10943 (epoch 189.377) train_loss=468.18765259 time/batch=0.82s
23028/10943 (epoch 189.385) train_loss=309.21325684 time/batch=0.57s
23029/10943 (epoch 189.393) train_loss=183.74589539 time/batch=0.34s
23030/10943 (epoch 189.401) train_loss=423.12704468 time/batch=0.73s
23031/10943 (epoch 189.409) train_loss=312.28790283 time/batch=0.58s
23032/10943 (epoch 189.418) train_loss=172.76959229 time/batch=0.33s
23033/10943 (epoch 189.426) train_loss=457.38623047 time/batch=0.75s
23034/10943 (epoch 189.434) train_loss=203.20619202 time/batch=0.40s
23035/10943 (epoch 189.442) train_loss=343.07864380 time/batch=0.59s
23036/10943 (epoch 189.451) train_loss=277.23797607 time/batch=0.51s
23037/10943 (epoch 189.459) train_loss=267.38250732 time/batch=0.48s
23038/10943 (epoch 189.467) train_loss=504.24087524 time/batch=0.84s
23039/10943 (epoch 189.475) train_loss=353.01574707 time/batch=0.63s
23040/10943 (epoch 189.483) train_loss=413.26541138 time/batch=0.67s
23041/10943 (epoch 189.492) train_loss=456.32031250 time/batch=0.79s
23042/10943 (epoch 189.500) train_loss=458.24822998 time/batch=0.78s
23043/10943 (epoch 189.508) train_loss=288.56210327 time/batch=0.52s
23044/10943 (epoch 189.516) train_loss=553.01293945 time/batch=0.96s
23045/10943 (epoch 189.525) train_loss=358.84146118 time/batch=0.68s
23046/10943 (epoch 189.533) train_loss=422.36010742 time/batch=0.71s
23047/10943 (epoch 189.541) train_loss=417.36190796 time/batch=0.71s
23048/10943 (epoch 189.549) train_loss=387.65188599 time/batch=0.66s
23049/10943 (epoch 189.557) train_loss=319.30383301 time/batch=0.57s
23050/10943 (epoch 189.566) train_loss=448.44812012 time/batch=0.78s
23051/10943 (epoch 189.574) train_loss=199.67468262 time/batch=0.40s
23052/10943 (epoch 189.582) train_loss=179.76904297 time/batch=0.33s
23053/10943 (epoch 189.590) train_loss=214.49267578 time/batch=0.41s
23054/10943 (epoch 189.599) train_loss=520.62207031 time/batch=0.84s
23055/10943 (epoch 189.607) train_loss=502.66033936 time/batch=0.84s
23056/10943 (epoch 189.615) train_loss=349.05291748 time/batch=0.62s
23057/10943 (epoch 189.623) train_loss=253.48968506 time/batch=0.46s
23058/10943 (epoch 189.631) train_loss=399.59121704 time/batch=0.65s
23059/10943 (epoch 189.640) train_loss=357.92248535 time/batch=0.63s
23060/10943 (epoch 189.648) train_loss=233.13293457 time/batch=0.47s
23061/10943 (epoch 189.656) train_loss=332.74945068 time/batch=0.58s
23062/10943 (epoch 189.664) train_loss=372.21411133 time/batch=0.64s
23063/10943 (epoch 189.673) train_loss=370.67254639 time/batch=0.65s
23064/10943 (epoch 189.681) train_loss=290.35247803 time/batch=0.53s
23065/10943 (epoch 189.689) train_loss=359.42135620 time/batch=0.62s
23066/10943 (epoch 189.697) train_loss=395.35382080 time/batch=0.66s
23067/10943 (epoch 189.705) train_loss=277.33853149 time/batch=0.51s
23068/10943 (epoch 189.714) train_loss=455.77819824 time/batch=0.78s
23069/10943 (epoch 189.722) train_loss=401.29501343 time/batch=0.68s
23070/10943 (epoch 189.730) train_loss=469.71392822 time/batch=0.80s
23071/10943 (epoch 189.738) train_loss=399.69451904 time/batch=0.71s
23072/10943 (epoch 189.747) train_loss=307.44213867 time/batch=0.59s
23073/10943 (epoch 189.755) train_loss=459.14596558 time/batch=0.80s
23074/10943 (epoch 189.763) train_loss=394.07540894 time/batch=0.70s
23075/10943 (epoch 189.771) train_loss=431.88928223 time/batch=0.83s
23076/10943 (epoch 189.779) train_loss=490.74749756 time/batch=0.86s
23077/10943 (epoch 189.788) train_loss=339.76226807 time/batch=0.63s
23078/10943 (epoch 189.796) train_loss=352.48989868 time/batch=0.67s
23079/10943 (epoch 189.804) train_loss=415.10638428 time/batch=0.70s
23080/10943 (epoch 189.812) train_loss=398.63073730 time/batch=0.72s
setting learning rate to 0.0004973
  saved to metadata/gru_dropout-9_nov_folkwiki-20181115-204407_epoch79.pkl
23081/10943 (epoch 189.821) train_loss=281.77960205 time/batch=0.58s
23082/10943 (epoch 189.829) train_loss=494.10421753 time/batch=0.82s
23083/10943 (epoch 189.837) train_loss=542.67004395 time/batch=0.92s
23084/10943 (epoch 189.845) train_loss=1217.78454590 time/batch=2.11s
23085/10943 (epoch 189.854) train_loss=264.55850220 time/batch=0.61s
23086/10943 (epoch 189.862) train_loss=162.15185547 time/batch=0.29s
23087/10943 (epoch 189.870) train_loss=824.94299316 time/batch=1.23s
23088/10943 (epoch 189.878) train_loss=195.49719238 time/batch=0.44s
23089/10943 (epoch 189.886) train_loss=563.14978027 time/batch=0.90s
23090/10943 (epoch 189.895) train_loss=391.69628906 time/batch=0.72s
23091/10943 (epoch 189.903) train_loss=217.38406372 time/batch=0.41s
23092/10943 (epoch 189.911) train_loss=626.23498535 time/batch=1.04s
23093/10943 (epoch 189.919) train_loss=852.53344727 time/batch=1.52s
23094/10943 (epoch 189.928) train_loss=435.20349121 time/batch=0.81s
23095/10943 (epoch 189.936) train_loss=661.57678223 time/batch=1.13s
23096/10943 (epoch 189.944) train_loss=772.58703613 time/batch=1.34s
23097/10943 (epoch 189.952) train_loss=655.61492920 time/batch=1.09s
23098/10943 (epoch 189.960) train_loss=344.81634521 time/batch=0.64s
23099/10943 (epoch 189.969) train_loss=456.41680908 time/batch=0.80s
23100/10943 (epoch 189.977) train_loss=429.95382690 time/batch=0.77s
23101/10943 (epoch 189.985) train_loss=528.94134521 time/batch=0.90s
23102/10943 (epoch 189.993) train_loss=663.40032959 time/batch=1.11s
23103/10943 (epoch 190.002) train_loss=289.55236816 time/batch=0.59s
23104/10943 (epoch 190.010) train_loss=922.03613281 time/batch=1.55s
23105/10943 (epoch 190.018) train_loss=492.53900146 time/batch=0.93s
23106/10943 (epoch 190.026) train_loss=677.96594238 time/batch=1.11s
23107/10943 (epoch 190.034) train_loss=221.96304321 time/batch=0.46s
23108/10943 (epoch 190.043) train_loss=451.69232178 time/batch=0.73s
23109/10943 (epoch 190.051) train_loss=381.84924316 time/batch=0.68s
23110/10943 (epoch 190.059) train_loss=410.44976807 time/batch=0.69s
23111/10943 (epoch 190.067) train_loss=434.74908447 time/batch=0.73s
23112/10943 (epoch 190.076) train_loss=454.97863770 time/batch=0.79s
23113/10943 (epoch 190.084) train_loss=167.43215942 time/batch=0.35s
23114/10943 (epoch 190.092) train_loss=422.96472168 time/batch=0.71s
23115/10943 (epoch 190.100) train_loss=425.48376465 time/batch=0.76s
23116/10943 (epoch 190.108) train_loss=512.54498291 time/batch=0.86s
23117/10943 (epoch 190.117) train_loss=323.25018311 time/batch=0.60s
23118/10943 (epoch 190.125) train_loss=245.18041992 time/batch=0.45s
23119/10943 (epoch 190.133) train_loss=804.17236328 time/batch=1.31s
23120/10943 (epoch 190.141) train_loss=678.22436523 time/batch=1.21s
23121/10943 (epoch 190.150) train_loss=715.47302246 time/batch=1.21s
23122/10943 (epoch 190.158) train_loss=264.61486816 time/batch=0.51s
23123/10943 (epoch 190.166) train_loss=700.27008057 time/batch=1.16s
23124/10943 (epoch 190.174) train_loss=178.84655762 time/batch=0.40s
23125/10943 (epoch 190.182) train_loss=288.13702393 time/batch=0.49s
23126/10943 (epoch 190.191) train_loss=569.08325195 time/batch=0.94s
23127/10943 (epoch 190.199) train_loss=349.54083252 time/batch=0.65s
23128/10943 (epoch 190.207) train_loss=350.16754150 time/batch=0.62s
23129/10943 (epoch 190.215) train_loss=453.61608887 time/batch=0.77s
23130/10943 (epoch 190.224) train_loss=609.28894043 time/batch=1.02s
23131/10943 (epoch 190.232) train_loss=614.19726562 time/batch=1.04s
23132/10943 (epoch 190.240) train_loss=341.74343872 time/batch=0.64s
23133/10943 (epoch 190.248) train_loss=289.06439209 time/batch=0.54s
23134/10943 (epoch 190.256) train_loss=229.61161804 time/batch=0.44s
23135/10943 (epoch 190.265) train_loss=492.57232666 time/batch=0.82s
23136/10943 (epoch 190.273) train_loss=315.03778076 time/batch=0.59s
23137/10943 (epoch 190.281) train_loss=270.99389648 time/batch=0.49s
23138/10943 (epoch 190.289) train_loss=1176.78784180 time/batch=3.06s
23139/10943 (epoch 190.298) train_loss=458.28601074 time/batch=0.95s
23140/10943 (epoch 190.306) train_loss=493.57537842 time/batch=0.86s
23141/10943 (epoch 190.314) train_loss=332.68161011 time/batch=0.62s
23142/10943 (epoch 190.322) train_loss=570.80999756 time/batch=0.96s
23143/10943 (epoch 190.331) train_loss=218.38763428 time/batch=0.42s
23144/10943 (epoch 190.339) train_loss=693.06298828 time/batch=1.17s
23145/10943 (epoch 190.347) train_loss=408.98016357 time/batch=0.73s
23146/10943 (epoch 190.355) train_loss=548.93267822 time/batch=0.92s
23147/10943 (epoch 190.363) train_loss=293.27349854 time/batch=0.57s
23148/10943 (epoch 190.372) train_loss=511.29687500 time/batch=0.83s
23149/10943 (epoch 190.380) train_loss=349.79669189 time/batch=0.66s
23150/10943 (epoch 190.388) train_loss=412.55737305 time/batch=0.72s
23151/10943 (epoch 190.396) train_loss=497.32235718 time/batch=0.87s
23152/10943 (epoch 190.405) train_loss=233.92941284 time/batch=0.45s
23153/10943 (epoch 190.413) train_loss=321.38549805 time/batch=0.57s
23154/10943 (epoch 190.421) train_loss=133.31668091 time/batch=0.28s
23155/10943 (epoch 190.429) train_loss=450.95062256 time/batch=0.75s
23156/10943 (epoch 190.437) train_loss=401.00115967 time/batch=0.69s
23157/10943 (epoch 190.446) train_loss=531.87402344 time/batch=0.90s
23158/10943 (epoch 190.454) train_loss=273.62014771 time/batch=0.50s
23159/10943 (epoch 190.462) train_loss=309.23864746 time/batch=0.54s
23160/10943 (epoch 190.470) train_loss=273.26599121 time/batch=0.50s
23161/10943 (epoch 190.479) train_loss=394.92861938 time/batch=0.68s
23162/10943 (epoch 190.487) train_loss=387.07418823 time/batch=0.69s
23163/10943 (epoch 190.495) train_loss=579.69458008 time/batch=0.95s
23164/10943 (epoch 190.503) train_loss=459.11965942 time/batch=0.79s
23165/10943 (epoch 190.511) train_loss=535.90966797 time/batch=0.93s
23166/10943 (epoch 190.520) train_loss=478.40148926 time/batch=0.83s
23167/10943 (epoch 190.528) train_loss=405.31109619 time/batch=0.72s
23168/10943 (epoch 190.536) train_loss=371.39215088 time/batch=0.65s
23169/10943 (epoch 190.544) train_loss=363.29901123 time/batch=0.64s
23170/10943 (epoch 190.553) train_loss=170.80050659 time/batch=0.34s
23171/10943 (epoch 190.561) train_loss=390.72308350 time/batch=0.64s
23172/10943 (epoch 190.569) train_loss=463.28561401 time/batch=0.80s
23173/10943 (epoch 190.577) train_loss=202.49533081 time/batch=0.40s
23174/10943 (epoch 190.585) train_loss=342.28088379 time/batch=0.60s
23175/10943 (epoch 190.594) train_loss=329.18225098 time/batch=0.60s
23176/10943 (epoch 190.602) train_loss=301.29953003 time/batch=0.54s
23177/10943 (epoch 190.610) train_loss=230.10021973 time/batch=0.45s
23178/10943 (epoch 190.618) train_loss=380.59552002 time/batch=0.67s
23179/10943 (epoch 190.627) train_loss=358.04956055 time/batch=0.64s
23180/10943 (epoch 190.635) train_loss=262.99392700 time/batch=0.48s
23181/10943 (epoch 190.643) train_loss=172.02328491 time/batch=0.33s
23182/10943 (epoch 190.651) train_loss=287.80746460 time/batch=0.50s
23183/10943 (epoch 190.659) train_loss=326.92590332 time/batch=0.57s
23184/10943 (epoch 190.668) train_loss=270.54760742 time/batch=0.50s
23185/10943 (epoch 190.676) train_loss=488.47705078 time/batch=0.80s
23186/10943 (epoch 190.684) train_loss=295.77960205 time/batch=0.57s
23187/10943 (epoch 190.692) train_loss=532.03485107 time/batch=0.96s
23188/10943 (epoch 190.701) train_loss=447.24099731 time/batch=0.83s
23189/10943 (epoch 190.709) train_loss=503.69528198 time/batch=0.83s
23190/10943 (epoch 190.717) train_loss=381.92968750 time/batch=0.66s
23191/10943 (epoch 190.725) train_loss=250.10980225 time/batch=0.47s
23192/10943 (epoch 190.733) train_loss=445.81155396 time/batch=0.77s
23193/10943 (epoch 190.742) train_loss=424.89215088 time/batch=0.73s
23194/10943 (epoch 190.750) train_loss=279.40792847 time/batch=0.56s
23195/10943 (epoch 190.758) train_loss=458.65097046 time/batch=0.79s
23196/10943 (epoch 190.766) train_loss=427.28497314 time/batch=0.73s
23197/10943 (epoch 190.775) train_loss=334.34567261 time/batch=0.61s
23198/10943 (epoch 190.783) train_loss=189.93908691 time/batch=0.39s
23199/10943 (epoch 190.791) train_loss=231.44763184 time/batch=0.59s
23200/10943 (epoch 190.799) train_loss=375.32476807 time/batch=0.72s
23201/10943 (epoch 190.808) train_loss=392.08901978 time/batch=0.80s
setting learning rate to 0.0004824
23202/10943 (epoch 190.816) train_loss=819.25427246 time/batch=1.30s
23203/10943 (epoch 190.824) train_loss=602.81781006 time/batch=1.01s
23204/10943 (epoch 190.832) train_loss=595.25354004 time/batch=0.96s
23205/10943 (epoch 190.840) train_loss=850.14801025 time/batch=1.39s
23206/10943 (epoch 190.849) train_loss=491.75592041 time/batch=0.86s
23207/10943 (epoch 190.857) train_loss=521.16137695 time/batch=0.93s
23208/10943 (epoch 190.865) train_loss=905.94409180 time/batch=1.58s
23209/10943 (epoch 190.873) train_loss=650.64941406 time/batch=1.17s
23210/10943 (epoch 190.882) train_loss=300.94265747 time/batch=0.60s
23211/10943 (epoch 190.890) train_loss=290.19482422 time/batch=0.52s
23212/10943 (epoch 190.898) train_loss=691.98669434 time/batch=1.17s
23213/10943 (epoch 190.906) train_loss=223.75152588 time/batch=0.46s
23214/10943 (epoch 190.914) train_loss=348.38662720 time/batch=0.61s
23215/10943 (epoch 190.923) train_loss=445.81869507 time/batch=0.76s
23216/10943 (epoch 190.931) train_loss=350.76519775 time/batch=0.64s
23217/10943 (epoch 190.939) train_loss=558.85870361 time/batch=0.94s
23218/10943 (epoch 190.947) train_loss=147.35060120 time/batch=0.33s
23219/10943 (epoch 190.956) train_loss=1179.54223633 time/batch=2.15s
23220/10943 (epoch 190.964) train_loss=458.34124756 time/batch=0.90s
23221/10943 (epoch 190.972) train_loss=1183.40942383 time/batch=3.09s
23222/10943 (epoch 190.980) train_loss=762.11340332 time/batch=1.45s
23223/10943 (epoch 190.988) train_loss=519.46044922 time/batch=0.91s
23224/10943 (epoch 190.997) train_loss=761.31323242 time/batch=1.22s
23225/10943 (epoch 191.005) train_loss=645.57946777 time/batch=1.08s
23226/10943 (epoch 191.013) train_loss=806.54638672 time/batch=1.43s
23227/10943 (epoch 191.021) train_loss=329.82000732 time/batch=0.67s
23228/10943 (epoch 191.030) train_loss=654.85839844 time/batch=1.07s
23229/10943 (epoch 191.038) train_loss=294.77593994 time/batch=0.60s
23230/10943 (epoch 191.046) train_loss=612.97802734 time/batch=0.97s
23231/10943 (epoch 191.054) train_loss=228.39248657 time/batch=0.48s
23232/10943 (epoch 191.062) train_loss=643.32958984 time/batch=1.08s
23233/10943 (epoch 191.071) train_loss=611.57971191 time/batch=1.06s
23234/10943 (epoch 191.079) train_loss=342.78216553 time/batch=0.62s
23235/10943 (epoch 191.087) train_loss=406.42889404 time/batch=0.66s
23236/10943 (epoch 191.095) train_loss=425.94583130 time/batch=0.73s
23237/10943 (epoch 191.104) train_loss=201.52679443 time/batch=0.40s
23238/10943 (epoch 191.112) train_loss=144.48590088 time/batch=0.29s
23239/10943 (epoch 191.120) train_loss=505.54177856 time/batch=0.83s
23240/10943 (epoch 191.128) train_loss=481.45721436 time/batch=0.84s
23241/10943 (epoch 191.136) train_loss=493.77886963 time/batch=0.88s
23242/10943 (epoch 191.145) train_loss=739.98962402 time/batch=1.44s
23243/10943 (epoch 191.153) train_loss=415.20278931 time/batch=0.75s
23244/10943 (epoch 191.161) train_loss=173.61701965 time/batch=0.33s
23245/10943 (epoch 191.169) train_loss=373.93743896 time/batch=0.62s
23246/10943 (epoch 191.178) train_loss=662.17236328 time/batch=1.11s
23247/10943 (epoch 191.186) train_loss=177.79542542 time/batch=0.40s
23248/10943 (epoch 191.194) train_loss=474.45581055 time/batch=0.80s
23249/10943 (epoch 191.202) train_loss=321.20666504 time/batch=0.58s
23250/10943 (epoch 191.210) train_loss=279.07043457 time/batch=0.49s
23251/10943 (epoch 191.219) train_loss=247.57604980 time/batch=0.43s
23252/10943 (epoch 191.227) train_loss=328.37109375 time/batch=0.57s
23253/10943 (epoch 191.235) train_loss=575.35021973 time/batch=1.02s
23254/10943 (epoch 191.243) train_loss=561.83776855 time/batch=1.01s
23255/10943 (epoch 191.252) train_loss=395.35095215 time/batch=0.71s
23256/10943 (epoch 191.260) train_loss=163.71670532 time/batch=0.33s
23257/10943 (epoch 191.268) train_loss=198.09489441 time/batch=0.35s
23258/10943 (epoch 191.276) train_loss=527.35290527 time/batch=0.85s
23259/10943 (epoch 191.285) train_loss=529.57836914 time/batch=0.92s
23260/10943 (epoch 191.293) train_loss=442.61145020 time/batch=0.79s
23261/10943 (epoch 191.301) train_loss=538.11633301 time/batch=0.92s
23262/10943 (epoch 191.309) train_loss=293.50088501 time/batch=0.56s
23263/10943 (epoch 191.317) train_loss=206.14395142 time/batch=0.39s
23264/10943 (epoch 191.326) train_loss=251.88084412 time/batch=0.44s
23265/10943 (epoch 191.334) train_loss=575.61767578 time/batch=0.94s
23266/10943 (epoch 191.342) train_loss=488.32983398 time/batch=0.86s
23267/10943 (epoch 191.350) train_loss=523.78356934 time/batch=0.89s
23268/10943 (epoch 191.359) train_loss=376.25262451 time/batch=0.67s
23269/10943 (epoch 191.367) train_loss=580.73138428 time/batch=1.03s
23270/10943 (epoch 191.375) train_loss=439.74908447 time/batch=0.79s
23271/10943 (epoch 191.383) train_loss=185.45288086 time/batch=0.37s
23272/10943 (epoch 191.391) train_loss=405.68572998 time/batch=0.66s
23273/10943 (epoch 191.400) train_loss=218.30343628 time/batch=0.44s
23274/10943 (epoch 191.408) train_loss=288.93591309 time/batch=0.53s
23275/10943 (epoch 191.416) train_loss=325.81268311 time/batch=0.59s
23276/10943 (epoch 191.424) train_loss=304.66027832 time/batch=0.56s
23277/10943 (epoch 191.433) train_loss=451.35565186 time/batch=0.79s
23278/10943 (epoch 191.441) train_loss=234.64242554 time/batch=0.47s
23279/10943 (epoch 191.449) train_loss=222.54843140 time/batch=0.42s
23280/10943 (epoch 191.457) train_loss=425.09570312 time/batch=0.72s
23281/10943 (epoch 191.465) train_loss=435.59982300 time/batch=0.74s
23282/10943 (epoch 191.474) train_loss=455.19531250 time/batch=0.82s
23283/10943 (epoch 191.482) train_loss=350.22164917 time/batch=0.64s
23284/10943 (epoch 191.490) train_loss=325.78369141 time/batch=0.59s
23285/10943 (epoch 191.498) train_loss=372.10485840 time/batch=0.64s
23286/10943 (epoch 191.507) train_loss=450.33609009 time/batch=0.77s
23287/10943 (epoch 191.515) train_loss=248.11241150 time/batch=0.47s
23288/10943 (epoch 191.523) train_loss=483.58697510 time/batch=0.83s
23289/10943 (epoch 191.531) train_loss=426.02648926 time/batch=0.77s
23290/10943 (epoch 191.539) train_loss=474.18041992 time/batch=0.82s
23291/10943 (epoch 191.548) train_loss=274.98635864 time/batch=0.52s
23292/10943 (epoch 191.556) train_loss=446.56958008 time/batch=0.81s
23293/10943 (epoch 191.564) train_loss=352.32028198 time/batch=0.66s
23294/10943 (epoch 191.572) train_loss=325.66442871 time/batch=0.57s
23295/10943 (epoch 191.581) train_loss=456.50991821 time/batch=0.79s
23296/10943 (epoch 191.589) train_loss=392.23474121 time/batch=0.71s
23297/10943 (epoch 191.597) train_loss=256.14749146 time/batch=0.48s
23298/10943 (epoch 191.605) train_loss=202.81420898 time/batch=0.43s
23299/10943 (epoch 191.613) train_loss=292.54266357 time/batch=0.52s
23300/10943 (epoch 191.622) train_loss=268.68768311 time/batch=0.49s
23301/10943 (epoch 191.630) train_loss=333.58038330 time/batch=0.58s
23302/10943 (epoch 191.638) train_loss=445.68457031 time/batch=0.79s
23303/10943 (epoch 191.646) train_loss=399.32580566 time/batch=0.69s
23304/10943 (epoch 191.655) train_loss=412.60870361 time/batch=0.71s
23305/10943 (epoch 191.663) train_loss=267.44772339 time/batch=0.50s
23306/10943 (epoch 191.671) train_loss=345.18533325 time/batch=0.60s
23307/10943 (epoch 191.679) train_loss=403.22726440 time/batch=0.70s
23308/10943 (epoch 191.687) train_loss=459.13598633 time/batch=0.79s
23309/10943 (epoch 191.696) train_loss=453.42852783 time/batch=0.80s
23310/10943 (epoch 191.704) train_loss=304.35031128 time/batch=0.57s
23311/10943 (epoch 191.712) train_loss=404.42950439 time/batch=0.71s
23312/10943 (epoch 191.720) train_loss=276.39489746 time/batch=0.51s
23313/10943 (epoch 191.729) train_loss=175.59750366 time/batch=0.34s
23314/10943 (epoch 191.737) train_loss=315.91448975 time/batch=0.57s
23315/10943 (epoch 191.745) train_loss=379.01971436 time/batch=0.68s
23316/10943 (epoch 191.753) train_loss=416.85092163 time/batch=0.73s
23317/10943 (epoch 191.762) train_loss=198.46282959 time/batch=0.47s
23318/10943 (epoch 191.770) train_loss=389.36141968 time/batch=0.66s
23319/10943 (epoch 191.778) train_loss=375.37692261 time/batch=0.69s
23320/10943 (epoch 191.786) train_loss=411.45733643 time/batch=0.79s
23321/10943 (epoch 191.794) train_loss=282.58642578 time/batch=0.63s
23322/10943 (epoch 191.803) train_loss=341.22622681 time/batch=0.61s
setting learning rate to 0.0004679
23323/10943 (epoch 191.811) train_loss=962.46966553 time/batch=1.58s
23324/10943 (epoch 191.819) train_loss=219.31495667 time/batch=0.50s
23325/10943 (epoch 191.827) train_loss=418.89520264 time/batch=0.67s
23326/10943 (epoch 191.836) train_loss=331.05938721 time/batch=0.60s
23327/10943 (epoch 191.844) train_loss=153.81228638 time/batch=0.31s
23328/10943 (epoch 191.852) train_loss=269.92272949 time/batch=0.47s
23329/10943 (epoch 191.860) train_loss=528.03131104 time/batch=0.90s
23330/10943 (epoch 191.868) train_loss=701.47033691 time/batch=1.21s
23331/10943 (epoch 191.877) train_loss=348.74774170 time/batch=0.65s
23332/10943 (epoch 191.885) train_loss=812.50146484 time/batch=1.39s
23333/10943 (epoch 191.893) train_loss=551.79266357 time/batch=1.01s
23334/10943 (epoch 191.901) train_loss=679.24871826 time/batch=1.12s
23335/10943 (epoch 191.910) train_loss=489.07464600 time/batch=0.90s
23336/10943 (epoch 191.918) train_loss=644.61694336 time/batch=1.13s
23337/10943 (epoch 191.926) train_loss=772.26257324 time/batch=1.30s
23338/10943 (epoch 191.934) train_loss=194.19650269 time/batch=0.43s
23339/10943 (epoch 191.942) train_loss=512.00476074 time/batch=0.82s
23340/10943 (epoch 191.951) train_loss=372.33770752 time/batch=0.67s
23341/10943 (epoch 191.959) train_loss=423.72814941 time/batch=0.75s
23342/10943 (epoch 191.967) train_loss=561.63763428 time/batch=0.99s
23343/10943 (epoch 191.975) train_loss=652.88854980 time/batch=1.16s
23344/10943 (epoch 191.984) train_loss=455.41030884 time/batch=0.85s
23345/10943 (epoch 191.992) train_loss=374.38452148 time/batch=0.67s
23346/10943 (epoch 192.000) train_loss=375.28619385 time/batch=0.65s
23347/10943 (epoch 192.008) train_loss=605.66369629 time/batch=1.02s
23348/10943 (epoch 192.016) train_loss=258.27066040 time/batch=0.52s
23349/10943 (epoch 192.025) train_loss=690.77441406 time/batch=1.16s
23350/10943 (epoch 192.033) train_loss=636.40136719 time/batch=1.19s
23351/10943 (epoch 192.041) train_loss=229.40942383 time/batch=0.48s
23352/10943 (epoch 192.049) train_loss=207.20031738 time/batch=0.39s
23353/10943 (epoch 192.058) train_loss=813.40588379 time/batch=1.28s
23354/10943 (epoch 192.066) train_loss=287.69506836 time/batch=0.59s
23355/10943 (epoch 192.074) train_loss=502.57376099 time/batch=0.85s
23356/10943 (epoch 192.082) train_loss=241.39474487 time/batch=0.49s
23357/10943 (epoch 192.090) train_loss=326.16476440 time/batch=0.56s
23358/10943 (epoch 192.099) train_loss=552.39007568 time/batch=0.93s
23359/10943 (epoch 192.107) train_loss=618.48400879 time/batch=1.07s
23360/10943 (epoch 192.115) train_loss=960.95928955 time/batch=1.66s
23361/10943 (epoch 192.123) train_loss=498.53808594 time/batch=0.92s
23362/10943 (epoch 192.132) train_loss=527.73730469 time/batch=0.91s
23363/10943 (epoch 192.140) train_loss=1135.61059570 time/batch=2.11s
23364/10943 (epoch 192.148) train_loss=232.75630188 time/batch=0.59s
23365/10943 (epoch 192.156) train_loss=426.36968994 time/batch=0.68s
23366/10943 (epoch 192.164) train_loss=454.22189331 time/batch=0.81s
23367/10943 (epoch 192.173) train_loss=346.52612305 time/batch=0.65s
23368/10943 (epoch 192.181) train_loss=523.05041504 time/batch=0.86s
23369/10943 (epoch 192.189) train_loss=471.56170654 time/batch=0.85s
23370/10943 (epoch 192.197) train_loss=287.84820557 time/batch=0.55s
23371/10943 (epoch 192.206) train_loss=285.08367920 time/batch=0.53s
23372/10943 (epoch 192.214) train_loss=384.49798584 time/batch=0.65s
23373/10943 (epoch 192.222) train_loss=529.47869873 time/batch=0.92s
23374/10943 (epoch 192.230) train_loss=149.66082764 time/batch=0.36s
23375/10943 (epoch 192.238) train_loss=602.76782227 time/batch=1.02s
23376/10943 (epoch 192.247) train_loss=306.60699463 time/batch=0.61s
23377/10943 (epoch 192.255) train_loss=653.99340820 time/batch=1.18s
23378/10943 (epoch 192.263) train_loss=498.82177734 time/batch=0.93s
23379/10943 (epoch 192.271) train_loss=170.19583130 time/batch=0.37s
23380/10943 (epoch 192.280) train_loss=416.78897095 time/batch=0.70s
23381/10943 (epoch 192.288) train_loss=607.21453857 time/batch=0.99s
23382/10943 (epoch 192.296) train_loss=207.91738892 time/batch=0.43s
23383/10943 (epoch 192.304) train_loss=283.28945923 time/batch=0.50s
23384/10943 (epoch 192.313) train_loss=263.73663330 time/batch=0.46s
23385/10943 (epoch 192.321) train_loss=329.24786377 time/batch=0.58s
23386/10943 (epoch 192.329) train_loss=567.93328857 time/batch=0.94s
23387/10943 (epoch 192.337) train_loss=267.72814941 time/batch=0.53s
23388/10943 (epoch 192.345) train_loss=479.27450562 time/batch=0.83s
23389/10943 (epoch 192.354) train_loss=558.35736084 time/batch=1.00s
23390/10943 (epoch 192.362) train_loss=226.43928528 time/batch=0.47s
23391/10943 (epoch 192.370) train_loss=306.37078857 time/batch=0.53s
23392/10943 (epoch 192.378) train_loss=174.47361755 time/batch=0.35s
23393/10943 (epoch 192.387) train_loss=842.01287842 time/batch=2.27s
23394/10943 (epoch 192.395) train_loss=246.16934204 time/batch=0.62s
23395/10943 (epoch 192.403) train_loss=427.49444580 time/batch=0.72s
23396/10943 (epoch 192.411) train_loss=340.54956055 time/batch=0.59s
23397/10943 (epoch 192.419) train_loss=524.00244141 time/batch=0.96s
23398/10943 (epoch 192.428) train_loss=401.91442871 time/batch=0.70s
23399/10943 (epoch 192.436) train_loss=404.25378418 time/batch=0.66s
23400/10943 (epoch 192.444) train_loss=149.38034058 time/batch=0.33s
23401/10943 (epoch 192.452) train_loss=390.87835693 time/batch=0.63s
23402/10943 (epoch 192.461) train_loss=454.82107544 time/batch=0.79s
23403/10943 (epoch 192.469) train_loss=397.23529053 time/batch=0.71s
23404/10943 (epoch 192.477) train_loss=324.40399170 time/batch=0.58s
23405/10943 (epoch 192.485) train_loss=348.03704834 time/batch=0.61s
23406/10943 (epoch 192.493) train_loss=162.59074402 time/batch=0.33s
23407/10943 (epoch 192.502) train_loss=437.89105225 time/batch=0.73s
23408/10943 (epoch 192.510) train_loss=386.30688477 time/batch=0.69s
23409/10943 (epoch 192.518) train_loss=259.61932373 time/batch=0.50s
23410/10943 (epoch 192.526) train_loss=286.73077393 time/batch=0.50s
23411/10943 (epoch 192.535) train_loss=410.18640137 time/batch=0.70s
23412/10943 (epoch 192.543) train_loss=348.22277832 time/batch=0.63s
23413/10943 (epoch 192.551) train_loss=204.06677246 time/batch=0.43s
23414/10943 (epoch 192.559) train_loss=422.00625610 time/batch=0.69s
23415/10943 (epoch 192.567) train_loss=296.98388672 time/batch=0.57s
23416/10943 (epoch 192.576) train_loss=327.52819824 time/batch=0.59s
23417/10943 (epoch 192.584) train_loss=355.23184204 time/batch=0.63s
23418/10943 (epoch 192.592) train_loss=185.67857361 time/batch=0.36s
23419/10943 (epoch 192.600) train_loss=275.85949707 time/batch=0.47s
23420/10943 (epoch 192.609) train_loss=445.21240234 time/batch=0.79s
23421/10943 (epoch 192.617) train_loss=252.07907104 time/batch=0.47s
23422/10943 (epoch 192.625) train_loss=281.52838135 time/batch=0.54s
23423/10943 (epoch 192.633) train_loss=357.80679321 time/batch=0.64s
23424/10943 (epoch 192.641) train_loss=386.48077393 time/batch=0.69s
23425/10943 (epoch 192.650) train_loss=692.32147217 time/batch=3.11s
23426/10943 (epoch 192.658) train_loss=456.96832275 time/batch=1.01s
23427/10943 (epoch 192.666) train_loss=474.69329834 time/batch=0.83s
23428/10943 (epoch 192.674) train_loss=236.17829895 time/batch=0.48s
23429/10943 (epoch 192.683) train_loss=426.40814209 time/batch=0.71s
23430/10943 (epoch 192.691) train_loss=442.02139282 time/batch=0.77s
23431/10943 (epoch 192.699) train_loss=452.90374756 time/batch=0.79s
23432/10943 (epoch 192.707) train_loss=303.54504395 time/batch=0.59s
23433/10943 (epoch 192.715) train_loss=397.59500122 time/batch=0.68s
23434/10943 (epoch 192.724) train_loss=439.88861084 time/batch=0.79s
23435/10943 (epoch 192.732) train_loss=472.61566162 time/batch=0.86s
23436/10943 (epoch 192.740) train_loss=420.19653320 time/batch=0.76s
23437/10943 (epoch 192.748) train_loss=474.21093750 time/batch=0.82s
23438/10943 (epoch 192.757) train_loss=418.75396729 time/batch=0.79s
23439/10943 (epoch 192.765) train_loss=344.91876221 time/batch=0.61s
23440/10943 (epoch 192.773) train_loss=367.04473877 time/batch=0.76s
23441/10943 (epoch 192.781) train_loss=273.71347046 time/batch=0.59s
23442/10943 (epoch 192.790) train_loss=345.48327637 time/batch=0.61s
23443/10943 (epoch 192.798) train_loss=406.68762207 time/batch=0.78s
setting learning rate to 0.0004539
23444/10943 (epoch 192.806) train_loss=277.63104248 time/batch=0.51s
23445/10943 (epoch 192.814) train_loss=957.99493408 time/batch=1.57s
23446/10943 (epoch 192.822) train_loss=1415.95727539 time/batch=3.21s
23447/10943 (epoch 192.831) train_loss=172.45037842 time/batch=0.62s
23448/10943 (epoch 192.839) train_loss=205.52851868 time/batch=0.36s
23449/10943 (epoch 192.847) train_loss=546.45373535 time/batch=0.89s
23450/10943 (epoch 192.855) train_loss=902.30407715 time/batch=1.64s
23451/10943 (epoch 192.864) train_loss=542.68939209 time/batch=1.00s
23452/10943 (epoch 192.872) train_loss=398.77929688 time/batch=0.70s
23453/10943 (epoch 192.880) train_loss=552.23999023 time/batch=0.96s
23454/10943 (epoch 192.888) train_loss=293.41171265 time/batch=0.56s
23455/10943 (epoch 192.896) train_loss=151.26953125 time/batch=0.31s
23456/10943 (epoch 192.905) train_loss=574.39331055 time/batch=0.96s
23457/10943 (epoch 192.913) train_loss=749.65313721 time/batch=1.28s
23458/10943 (epoch 192.921) train_loss=535.42810059 time/batch=0.94s
23459/10943 (epoch 192.929) train_loss=816.60296631 time/batch=1.40s
23460/10943 (epoch 192.938) train_loss=355.36254883 time/batch=0.69s
23461/10943 (epoch 192.946) train_loss=292.73196411 time/batch=0.53s
23462/10943 (epoch 192.954) train_loss=436.26034546 time/batch=0.78s
23463/10943 (epoch 192.962) train_loss=625.46514893 time/batch=1.09s
23464/10943 (epoch 192.970) train_loss=419.38735962 time/batch=0.80s
23465/10943 (epoch 192.979) train_loss=333.44219971 time/batch=0.60s
23466/10943 (epoch 192.987) train_loss=138.11967468 time/batch=0.32s
23467/10943 (epoch 192.995) train_loss=238.90484619 time/batch=0.41s
23468/10943 (epoch 193.003) train_loss=443.70812988 time/batch=0.77s
23469/10943 (epoch 193.012) train_loss=221.92135620 time/batch=0.44s
23470/10943 (epoch 193.020) train_loss=794.12097168 time/batch=1.25s
23471/10943 (epoch 193.028) train_loss=450.62078857 time/batch=0.81s
23472/10943 (epoch 193.036) train_loss=200.47644043 time/batch=0.39s
23473/10943 (epoch 193.044) train_loss=473.49566650 time/batch=0.79s
23474/10943 (epoch 193.053) train_loss=635.26611328 time/batch=1.10s
23475/10943 (epoch 193.061) train_loss=827.45629883 time/batch=1.68s
23476/10943 (epoch 193.069) train_loss=536.25195312 time/batch=0.96s
23477/10943 (epoch 193.077) train_loss=395.01397705 time/batch=0.71s
23478/10943 (epoch 193.086) train_loss=510.56958008 time/batch=0.88s
23479/10943 (epoch 193.094) train_loss=391.88226318 time/batch=0.68s
23480/10943 (epoch 193.102) train_loss=185.00674438 time/batch=0.36s
23481/10943 (epoch 193.110) train_loss=499.40026855 time/batch=0.83s
23482/10943 (epoch 193.118) train_loss=386.66668701 time/batch=0.71s
23483/10943 (epoch 193.127) train_loss=668.19616699 time/batch=1.08s
23484/10943 (epoch 193.135) train_loss=206.78823853 time/batch=0.44s
23485/10943 (epoch 193.143) train_loss=644.10168457 time/batch=1.08s
23486/10943 (epoch 193.151) train_loss=425.83184814 time/batch=0.76s
23487/10943 (epoch 193.160) train_loss=225.04113770 time/batch=0.44s
23488/10943 (epoch 193.168) train_loss=259.35272217 time/batch=0.46s
23489/10943 (epoch 193.176) train_loss=605.39184570 time/batch=0.96s
23490/10943 (epoch 193.184) train_loss=289.28100586 time/batch=0.58s
23491/10943 (epoch 193.192) train_loss=348.42889404 time/batch=0.60s
23492/10943 (epoch 193.201) train_loss=254.00656128 time/batch=0.46s
23493/10943 (epoch 193.209) train_loss=683.24780273 time/batch=1.15s
23494/10943 (epoch 193.217) train_loss=730.83923340 time/batch=1.25s
23495/10943 (epoch 193.225) train_loss=331.55465698 time/batch=0.63s
23496/10943 (epoch 193.234) train_loss=421.41098022 time/batch=0.70s
23497/10943 (epoch 193.242) train_loss=333.16259766 time/batch=0.60s
23498/10943 (epoch 193.250) train_loss=398.16516113 time/batch=0.70s
23499/10943 (epoch 193.258) train_loss=615.78302002 time/batch=1.03s
23500/10943 (epoch 193.267) train_loss=375.06246948 time/batch=0.69s
23501/10943 (epoch 193.275) train_loss=237.63528442 time/batch=0.46s
23502/10943 (epoch 193.283) train_loss=163.42468262 time/batch=0.32s
23503/10943 (epoch 193.291) train_loss=315.56060791 time/batch=0.56s
23504/10943 (epoch 193.299) train_loss=569.69726562 time/batch=0.95s
23505/10943 (epoch 193.308) train_loss=761.33996582 time/batch=1.72s
23506/10943 (epoch 193.316) train_loss=291.63027954 time/batch=0.63s
23507/10943 (epoch 193.324) train_loss=279.86920166 time/batch=0.50s
23508/10943 (epoch 193.332) train_loss=403.28082275 time/batch=0.71s
23509/10943 (epoch 193.341) train_loss=168.74075317 time/batch=0.35s
23510/10943 (epoch 193.349) train_loss=475.30590820 time/batch=0.79s
23511/10943 (epoch 193.357) train_loss=268.04791260 time/batch=0.52s
23512/10943 (epoch 193.365) train_loss=406.58319092 time/batch=0.71s
23513/10943 (epoch 193.373) train_loss=208.90661621 time/batch=0.42s
23514/10943 (epoch 193.382) train_loss=211.95649719 time/batch=0.39s
23515/10943 (epoch 193.390) train_loss=591.52209473 time/batch=1.08s
23516/10943 (epoch 193.398) train_loss=513.89196777 time/batch=0.92s
23517/10943 (epoch 193.406) train_loss=278.88739014 time/batch=0.53s
23518/10943 (epoch 193.415) train_loss=435.60531616 time/batch=0.74s
23519/10943 (epoch 193.423) train_loss=335.30395508 time/batch=0.62s
23520/10943 (epoch 193.431) train_loss=512.40686035 time/batch=0.89s
23521/10943 (epoch 193.439) train_loss=430.51504517 time/batch=0.73s
23522/10943 (epoch 193.447) train_loss=523.93041992 time/batch=0.91s
23523/10943 (epoch 193.456) train_loss=262.15036011 time/batch=0.50s
23524/10943 (epoch 193.464) train_loss=176.82351685 time/batch=0.33s
23525/10943 (epoch 193.472) train_loss=412.70367432 time/batch=0.70s
23526/10943 (epoch 193.480) train_loss=428.93457031 time/batch=0.77s
23527/10943 (epoch 193.489) train_loss=512.82336426 time/batch=0.93s
23528/10943 (epoch 193.497) train_loss=193.08898926 time/batch=0.42s
23529/10943 (epoch 193.505) train_loss=216.19566345 time/batch=0.41s
23530/10943 (epoch 193.513) train_loss=596.57275391 time/batch=0.98s
23531/10943 (epoch 193.521) train_loss=472.86862183 time/batch=0.87s
23532/10943 (epoch 193.530) train_loss=302.76629639 time/batch=0.57s
23533/10943 (epoch 193.538) train_loss=450.36514282 time/batch=0.76s
23534/10943 (epoch 193.546) train_loss=305.40817261 time/batch=0.58s
23535/10943 (epoch 193.554) train_loss=438.92156982 time/batch=0.76s
23536/10943 (epoch 193.563) train_loss=267.44506836 time/batch=0.51s
23537/10943 (epoch 193.571) train_loss=325.14559937 time/batch=0.57s
23538/10943 (epoch 193.579) train_loss=552.45483398 time/batch=0.96s
23539/10943 (epoch 193.587) train_loss=331.71865845 time/batch=0.61s
23540/10943 (epoch 193.595) train_loss=462.68197632 time/batch=0.78s
23541/10943 (epoch 193.604) train_loss=419.32394409 time/batch=0.69s
23542/10943 (epoch 193.612) train_loss=537.85131836 time/batch=0.93s
23543/10943 (epoch 193.620) train_loss=273.22729492 time/batch=0.56s
23544/10943 (epoch 193.628) train_loss=284.74645996 time/batch=0.54s
23545/10943 (epoch 193.637) train_loss=366.94119263 time/batch=0.65s
23546/10943 (epoch 193.645) train_loss=448.10681152 time/batch=0.81s
23547/10943 (epoch 193.653) train_loss=375.65588379 time/batch=0.68s
23548/10943 (epoch 193.661) train_loss=364.04602051 time/batch=0.64s
23549/10943 (epoch 193.669) train_loss=403.55603027 time/batch=0.73s
23550/10943 (epoch 193.678) train_loss=412.79678345 time/batch=0.76s
23551/10943 (epoch 193.686) train_loss=322.51770020 time/batch=0.61s
23552/10943 (epoch 193.694) train_loss=356.29864502 time/batch=0.63s
23553/10943 (epoch 193.702) train_loss=352.91696167 time/batch=0.63s
23554/10943 (epoch 193.711) train_loss=371.42395020 time/batch=0.67s
23555/10943 (epoch 193.719) train_loss=455.27951050 time/batch=0.80s
23556/10943 (epoch 193.727) train_loss=346.16659546 time/batch=0.64s
23557/10943 (epoch 193.735) train_loss=350.67715454 time/batch=0.62s
23558/10943 (epoch 193.744) train_loss=453.70568848 time/batch=0.80s
23559/10943 (epoch 193.752) train_loss=320.83984375 time/batch=0.59s
23560/10943 (epoch 193.760) train_loss=438.15197754 time/batch=0.76s
23561/10943 (epoch 193.768) train_loss=337.94598389 time/batch=0.69s
23562/10943 (epoch 193.776) train_loss=474.82080078 time/batch=0.82s
23563/10943 (epoch 193.785) train_loss=440.99090576 time/batch=0.84s
23564/10943 (epoch 193.793) train_loss=368.77276611 time/batch=0.69s
setting learning rate to 0.0004403
23565/10943 (epoch 193.801) train_loss=747.60882568 time/batch=1.21s
23566/10943 (epoch 193.809) train_loss=218.39892578 time/batch=0.44s
23567/10943 (epoch 193.818) train_loss=230.51307678 time/batch=0.40s
23568/10943 (epoch 193.826) train_loss=940.72473145 time/batch=1.58s
23569/10943 (epoch 193.834) train_loss=563.98962402 time/batch=1.03s
23570/10943 (epoch 193.842) train_loss=834.56970215 time/batch=1.32s
23571/10943 (epoch 193.850) train_loss=605.14770508 time/batch=1.02s
23572/10943 (epoch 193.859) train_loss=279.45916748 time/batch=0.52s
23573/10943 (epoch 193.867) train_loss=804.45916748 time/batch=1.32s
23574/10943 (epoch 193.875) train_loss=795.05139160 time/batch=1.43s
23575/10943 (epoch 193.883) train_loss=627.64587402 time/batch=1.09s
23576/10943 (epoch 193.892) train_loss=477.65509033 time/batch=0.87s
23577/10943 (epoch 193.900) train_loss=152.34426880 time/batch=0.33s
23578/10943 (epoch 193.908) train_loss=686.99523926 time/batch=1.32s
23579/10943 (epoch 193.916) train_loss=307.51638794 time/batch=0.64s
23580/10943 (epoch 193.924) train_loss=512.68041992 time/batch=0.88s
23581/10943 (epoch 193.933) train_loss=780.49017334 time/batch=1.46s
23582/10943 (epoch 193.941) train_loss=355.54125977 time/batch=0.71s
23583/10943 (epoch 193.949) train_loss=345.63894653 time/batch=0.62s
23584/10943 (epoch 193.957) train_loss=1030.24145508 time/batch=1.84s
23585/10943 (epoch 193.966) train_loss=529.17352295 time/batch=1.00s
23586/10943 (epoch 193.974) train_loss=460.08209229 time/batch=0.83s
23587/10943 (epoch 193.982) train_loss=301.62261963 time/batch=0.57s
23588/10943 (epoch 193.990) train_loss=187.64959717 time/batch=0.34s
23589/10943 (epoch 193.998) train_loss=270.29440308 time/batch=0.48s
23590/10943 (epoch 194.007) train_loss=351.55148315 time/batch=0.62s
23591/10943 (epoch 194.015) train_loss=247.06889343 time/batch=0.44s
23592/10943 (epoch 194.023) train_loss=521.89916992 time/batch=0.86s
23593/10943 (epoch 194.031) train_loss=239.31915283 time/batch=0.48s
23594/10943 (epoch 194.040) train_loss=1219.94250488 time/batch=3.05s
23595/10943 (epoch 194.048) train_loss=537.42395020 time/batch=1.14s
23596/10943 (epoch 194.056) train_loss=433.38504028 time/batch=0.74s
23597/10943 (epoch 194.064) train_loss=388.25366211 time/batch=0.69s
23598/10943 (epoch 194.072) train_loss=417.27212524 time/batch=0.72s
23599/10943 (epoch 194.081) train_loss=293.45162964 time/batch=0.54s
23600/10943 (epoch 194.089) train_loss=386.35534668 time/batch=0.67s
23601/10943 (epoch 194.097) train_loss=375.80288696 time/batch=0.66s
23602/10943 (epoch 194.105) train_loss=447.10324097 time/batch=0.78s
23603/10943 (epoch 194.114) train_loss=614.24774170 time/batch=1.04s
23604/10943 (epoch 194.122) train_loss=149.49496460 time/batch=0.36s
23605/10943 (epoch 194.130) train_loss=445.88439941 time/batch=0.76s
23606/10943 (epoch 194.138) train_loss=266.80813599 time/batch=0.52s
23607/10943 (epoch 194.146) train_loss=396.45397949 time/batch=0.68s
23608/10943 (epoch 194.155) train_loss=254.73318481 time/batch=0.49s
23609/10943 (epoch 194.163) train_loss=428.17105103 time/batch=0.74s
23610/10943 (epoch 194.171) train_loss=286.79373169 time/batch=0.55s
23611/10943 (epoch 194.179) train_loss=354.81542969 time/batch=0.63s
23612/10943 (epoch 194.188) train_loss=441.55227661 time/batch=0.77s
23613/10943 (epoch 194.196) train_loss=388.87503052 time/batch=0.68s
23614/10943 (epoch 194.204) train_loss=308.99566650 time/batch=0.56s
23615/10943 (epoch 194.212) train_loss=414.94314575 time/batch=0.72s
23616/10943 (epoch 194.221) train_loss=637.85284424 time/batch=1.07s
23617/10943 (epoch 194.229) train_loss=684.09960938 time/batch=1.12s
23618/10943 (epoch 194.237) train_loss=277.51477051 time/batch=0.55s
23619/10943 (epoch 194.245) train_loss=452.26419067 time/batch=0.79s
23620/10943 (epoch 194.253) train_loss=652.75756836 time/batch=1.14s
23621/10943 (epoch 194.262) train_loss=623.68347168 time/batch=1.05s
23622/10943 (epoch 194.270) train_loss=343.39901733 time/batch=0.64s
23623/10943 (epoch 194.278) train_loss=220.69165039 time/batch=0.43s
23624/10943 (epoch 194.286) train_loss=325.39221191 time/batch=0.59s
23625/10943 (epoch 194.295) train_loss=280.77276611 time/batch=0.51s
23626/10943 (epoch 194.303) train_loss=547.27783203 time/batch=0.95s
23627/10943 (epoch 194.311) train_loss=551.45214844 time/batch=1.00s
23628/10943 (epoch 194.319) train_loss=295.96362305 time/batch=0.60s
23629/10943 (epoch 194.327) train_loss=535.66650391 time/batch=0.92s
23630/10943 (epoch 194.336) train_loss=342.49774170 time/batch=0.64s
23631/10943 (epoch 194.344) train_loss=260.05984497 time/batch=0.48s
23632/10943 (epoch 194.352) train_loss=311.35791016 time/batch=0.55s
23633/10943 (epoch 194.360) train_loss=312.23175049 time/batch=0.58s
23634/10943 (epoch 194.369) train_loss=433.96044922 time/batch=0.75s
23635/10943 (epoch 194.377) train_loss=404.06561279 time/batch=0.73s
23636/10943 (epoch 194.385) train_loss=232.58999634 time/batch=0.47s
23637/10943 (epoch 194.393) train_loss=505.19149780 time/batch=0.84s
23638/10943 (epoch 194.401) train_loss=327.47692871 time/batch=0.60s
23639/10943 (epoch 194.410) train_loss=386.44189453 time/batch=0.66s
23640/10943 (epoch 194.418) train_loss=652.43292236 time/batch=1.10s
23641/10943 (epoch 194.426) train_loss=671.27722168 time/batch=1.18s
23642/10943 (epoch 194.434) train_loss=229.24191284 time/batch=0.46s
23643/10943 (epoch 194.443) train_loss=488.18569946 time/batch=0.87s
23644/10943 (epoch 194.451) train_loss=284.61291504 time/batch=0.56s
23645/10943 (epoch 194.459) train_loss=194.15423584 time/batch=0.37s
23646/10943 (epoch 194.467) train_loss=165.54861450 time/batch=0.31s
23647/10943 (epoch 194.475) train_loss=443.99053955 time/batch=0.76s
23648/10943 (epoch 194.484) train_loss=564.18377686 time/batch=1.01s
23649/10943 (epoch 194.492) train_loss=577.22045898 time/batch=1.06s
23650/10943 (epoch 194.500) train_loss=516.90747070 time/batch=0.93s
23651/10943 (epoch 194.508) train_loss=436.04296875 time/batch=0.77s
23652/10943 (epoch 194.517) train_loss=330.75933838 time/batch=0.61s
23653/10943 (epoch 194.525) train_loss=443.82171631 time/batch=0.77s
23654/10943 (epoch 194.533) train_loss=419.80029297 time/batch=0.77s
23655/10943 (epoch 194.541) train_loss=426.27593994 time/batch=0.77s
23656/10943 (epoch 194.549) train_loss=410.80084229 time/batch=0.75s
23657/10943 (epoch 194.558) train_loss=198.76112366 time/batch=0.40s
23658/10943 (epoch 194.566) train_loss=396.34506226 time/batch=0.65s
23659/10943 (epoch 194.574) train_loss=331.33300781 time/batch=0.64s
23660/10943 (epoch 194.582) train_loss=358.57046509 time/batch=0.64s
23661/10943 (epoch 194.591) train_loss=398.56298828 time/batch=0.70s
23662/10943 (epoch 194.599) train_loss=522.18395996 time/batch=1.13s
23663/10943 (epoch 194.607) train_loss=474.22930908 time/batch=0.88s
23664/10943 (epoch 194.615) train_loss=348.44592285 time/batch=0.61s
23665/10943 (epoch 194.623) train_loss=188.50947571 time/batch=0.38s
23666/10943 (epoch 194.632) train_loss=318.02883911 time/batch=0.58s
23667/10943 (epoch 194.640) train_loss=363.34320068 time/batch=0.63s
23668/10943 (epoch 194.648) train_loss=154.57220459 time/batch=0.33s
23669/10943 (epoch 194.656) train_loss=467.04113770 time/batch=0.80s
23670/10943 (epoch 194.665) train_loss=395.47879028 time/batch=0.70s
23671/10943 (epoch 194.673) train_loss=321.77355957 time/batch=0.60s
23672/10943 (epoch 194.681) train_loss=474.93240356 time/batch=0.83s
23673/10943 (epoch 194.689) train_loss=466.87921143 time/batch=0.82s
23674/10943 (epoch 194.698) train_loss=446.54040527 time/batch=0.81s
23675/10943 (epoch 194.706) train_loss=493.30328369 time/batch=0.84s
23676/10943 (epoch 194.714) train_loss=390.95654297 time/batch=0.72s
23677/10943 (epoch 194.722) train_loss=511.62640381 time/batch=1.13s
23678/10943 (epoch 194.730) train_loss=378.62762451 time/batch=0.70s
23679/10943 (epoch 194.739) train_loss=178.67132568 time/batch=0.35s
23680/10943 (epoch 194.747) train_loss=265.22467041 time/batch=0.47s
23681/10943 (epoch 194.755) train_loss=271.08312988 time/batch=0.49s
23682/10943 (epoch 194.763) train_loss=170.20825195 time/batch=0.37s
23683/10943 (epoch 194.772) train_loss=216.17576599 time/batch=0.50s
23684/10943 (epoch 194.780) train_loss=218.45693970 time/batch=0.52s
23685/10943 (epoch 194.788) train_loss=382.64624023 time/batch=0.72s
setting learning rate to 0.0004271
  saved to metadata/gru_dropout-9_nov_folkwiki-20181115-204407_epoch84.pkl
23686/10943 (epoch 194.796) train_loss=260.46188354 time/batch=0.56s
23687/10943 (epoch 194.804) train_loss=667.86059570 time/batch=1.13s
23688/10943 (epoch 194.813) train_loss=236.69659424 time/batch=0.50s
23689/10943 (epoch 194.821) train_loss=440.27319336 time/batch=0.73s
23690/10943 (epoch 194.829) train_loss=327.21401978 time/batch=0.60s
23691/10943 (epoch 194.837) train_loss=427.73287964 time/batch=0.73s
23692/10943 (epoch 194.846) train_loss=443.47528076 time/batch=0.74s
23693/10943 (epoch 194.854) train_loss=1031.58666992 time/batch=1.66s
23694/10943 (epoch 194.862) train_loss=910.16650391 time/batch=1.46s
23695/10943 (epoch 194.870) train_loss=165.75360107 time/batch=0.39s
23696/10943 (epoch 194.878) train_loss=639.31811523 time/batch=0.96s
23697/10943 (epoch 194.887) train_loss=386.80413818 time/batch=0.70s
23698/10943 (epoch 194.895) train_loss=670.95605469 time/batch=1.09s
23699/10943 (epoch 194.903) train_loss=634.37292480 time/batch=1.11s
23700/10943 (epoch 194.911) train_loss=562.36633301 time/batch=1.01s
23701/10943 (epoch 194.920) train_loss=821.97631836 time/batch=1.41s
23702/10943 (epoch 194.928) train_loss=645.65319824 time/batch=1.18s
23703/10943 (epoch 194.936) train_loss=1332.15136719 time/batch=3.11s
23704/10943 (epoch 194.944) train_loss=453.40069580 time/batch=0.96s
23705/10943 (epoch 194.952) train_loss=888.64074707 time/batch=1.66s
23706/10943 (epoch 194.961) train_loss=622.18737793 time/batch=1.16s
23707/10943 (epoch 194.969) train_loss=249.58779907 time/batch=0.50s
23708/10943 (epoch 194.977) train_loss=734.18420410 time/batch=1.21s
23709/10943 (epoch 194.985) train_loss=805.35327148 time/batch=1.73s
23710/10943 (epoch 194.994) train_loss=576.64160156 time/batch=1.08s
23711/10943 (epoch 195.002) train_loss=731.76000977 time/batch=1.24s
23712/10943 (epoch 195.010) train_loss=446.01437378 time/batch=0.83s
23713/10943 (epoch 195.018) train_loss=214.34365845 time/batch=0.43s
23714/10943 (epoch 195.026) train_loss=407.66021729 time/batch=0.70s
23715/10943 (epoch 195.035) train_loss=446.88931274 time/batch=0.80s
23716/10943 (epoch 195.043) train_loss=514.83166504 time/batch=0.92s
23717/10943 (epoch 195.051) train_loss=343.11694336 time/batch=0.61s
23718/10943 (epoch 195.059) train_loss=668.85821533 time/batch=1.14s
23719/10943 (epoch 195.068) train_loss=362.13604736 time/batch=0.68s
23720/10943 (epoch 195.076) train_loss=216.68719482 time/batch=0.40s
23721/10943 (epoch 195.084) train_loss=639.61193848 time/batch=1.13s
23722/10943 (epoch 195.092) train_loss=447.09973145 time/batch=0.80s
23723/10943 (epoch 195.100) train_loss=486.39630127 time/batch=0.82s
23724/10943 (epoch 195.109) train_loss=428.14431763 time/batch=0.76s
23725/10943 (epoch 195.117) train_loss=407.58386230 time/batch=0.71s
23726/10943 (epoch 195.125) train_loss=272.30578613 time/batch=0.49s
23727/10943 (epoch 195.133) train_loss=135.70782471 time/batch=0.30s
23728/10943 (epoch 195.142) train_loss=510.14007568 time/batch=0.83s
23729/10943 (epoch 195.150) train_loss=610.47216797 time/batch=1.02s
23730/10943 (epoch 195.158) train_loss=487.44000244 time/batch=0.82s
23731/10943 (epoch 195.166) train_loss=180.53704834 time/batch=0.35s
23732/10943 (epoch 195.175) train_loss=172.02458191 time/batch=0.30s
23733/10943 (epoch 195.183) train_loss=202.00090027 time/batch=0.36s
23734/10943 (epoch 195.191) train_loss=200.93254089 time/batch=0.34s
23735/10943 (epoch 195.199) train_loss=366.56173706 time/batch=0.61s
23736/10943 (epoch 195.207) train_loss=266.82333374 time/batch=0.48s
23737/10943 (epoch 195.216) train_loss=428.90762329 time/batch=0.69s
23738/10943 (epoch 195.224) train_loss=420.04992676 time/batch=0.71s
23739/10943 (epoch 195.232) train_loss=364.76629639 time/batch=0.62s
23740/10943 (epoch 195.240) train_loss=185.42669678 time/batch=0.34s
23741/10943 (epoch 195.249) train_loss=257.11749268 time/batch=0.46s
23742/10943 (epoch 195.257) train_loss=412.32434082 time/batch=0.72s
23743/10943 (epoch 195.265) train_loss=231.39080811 time/batch=0.44s
23744/10943 (epoch 195.273) train_loss=386.20098877 time/batch=0.64s
23745/10943 (epoch 195.281) train_loss=353.72637939 time/batch=0.63s
23746/10943 (epoch 195.290) train_loss=514.27502441 time/batch=0.86s
23747/10943 (epoch 195.298) train_loss=587.45629883 time/batch=0.97s
23748/10943 (epoch 195.306) train_loss=335.66381836 time/batch=0.60s
23749/10943 (epoch 195.314) train_loss=349.96197510 time/batch=0.62s
23750/10943 (epoch 195.323) train_loss=465.50927734 time/batch=0.80s
23751/10943 (epoch 195.331) train_loss=265.32504272 time/batch=0.49s
23752/10943 (epoch 195.339) train_loss=490.47949219 time/batch=0.83s
23753/10943 (epoch 195.347) train_loss=304.77749634 time/batch=0.55s
23754/10943 (epoch 195.355) train_loss=285.75439453 time/batch=0.50s
23755/10943 (epoch 195.364) train_loss=491.06796265 time/batch=0.82s
23756/10943 (epoch 195.372) train_loss=490.37939453 time/batch=0.86s
23757/10943 (epoch 195.380) train_loss=340.64706421 time/batch=0.61s
23758/10943 (epoch 195.388) train_loss=383.17749023 time/batch=0.65s
23759/10943 (epoch 195.397) train_loss=426.54721069 time/batch=0.76s
23760/10943 (epoch 195.405) train_loss=535.19213867 time/batch=0.89s
23761/10943 (epoch 195.413) train_loss=232.96759033 time/batch=0.47s
23762/10943 (epoch 195.421) train_loss=302.27078247 time/batch=0.54s
23763/10943 (epoch 195.429) train_loss=164.03875732 time/batch=0.33s
23764/10943 (epoch 195.438) train_loss=391.38607788 time/batch=0.68s
23765/10943 (epoch 195.446) train_loss=266.15319824 time/batch=0.50s
23766/10943 (epoch 195.454) train_loss=344.14678955 time/batch=0.61s
23767/10943 (epoch 195.462) train_loss=417.77185059 time/batch=0.74s
23768/10943 (epoch 195.471) train_loss=531.78735352 time/batch=0.92s
23769/10943 (epoch 195.479) train_loss=385.39764404 time/batch=0.68s
23770/10943 (epoch 195.487) train_loss=650.93341064 time/batch=1.20s
23771/10943 (epoch 195.495) train_loss=240.41482544 time/batch=0.51s
23772/10943 (epoch 195.503) train_loss=343.49798584 time/batch=0.58s
23773/10943 (epoch 195.512) train_loss=288.58422852 time/batch=0.52s
23774/10943 (epoch 195.520) train_loss=287.08630371 time/batch=0.52s
23775/10943 (epoch 195.528) train_loss=464.34323120 time/batch=0.77s
23776/10943 (epoch 195.536) train_loss=459.87014771 time/batch=0.82s
23777/10943 (epoch 195.545) train_loss=541.66729736 time/batch=0.93s
23778/10943 (epoch 195.553) train_loss=334.24383545 time/batch=0.63s
23779/10943 (epoch 195.561) train_loss=318.91925049 time/batch=0.58s
23780/10943 (epoch 195.569) train_loss=187.19540405 time/batch=0.35s
23781/10943 (epoch 195.577) train_loss=188.22296143 time/batch=0.34s
23782/10943 (epoch 195.586) train_loss=369.62139893 time/batch=0.62s
23783/10943 (epoch 195.594) train_loss=328.90979004 time/batch=0.60s
23784/10943 (epoch 195.602) train_loss=311.87774658 time/batch=0.58s
23785/10943 (epoch 195.610) train_loss=244.78543091 time/batch=0.49s
23786/10943 (epoch 195.619) train_loss=503.53826904 time/batch=0.88s
23787/10943 (epoch 195.627) train_loss=349.01452637 time/batch=0.64s
23788/10943 (epoch 195.635) train_loss=310.85293579 time/batch=0.55s
23789/10943 (epoch 195.643) train_loss=578.99072266 time/batch=0.92s
23790/10943 (epoch 195.652) train_loss=236.30166626 time/batch=0.54s
23791/10943 (epoch 195.660) train_loss=394.41217041 time/batch=0.66s
23792/10943 (epoch 195.668) train_loss=391.16754150 time/batch=0.67s
23793/10943 (epoch 195.676) train_loss=468.68563843 time/batch=0.80s
23794/10943 (epoch 195.684) train_loss=502.18939209 time/batch=0.84s
23795/10943 (epoch 195.693) train_loss=467.45434570 time/batch=0.78s
23796/10943 (epoch 195.701) train_loss=450.74276733 time/batch=0.79s
23797/10943 (epoch 195.709) train_loss=495.22888184 time/batch=0.92s
23798/10943 (epoch 195.717) train_loss=395.13177490 time/batch=0.71s
23799/10943 (epoch 195.726) train_loss=575.85131836 time/batch=0.98s
23800/10943 (epoch 195.734) train_loss=452.30255127 time/batch=0.85s
23801/10943 (epoch 195.742) train_loss=407.97167969 time/batch=0.83s
23802/10943 (epoch 195.750) train_loss=496.81021118 time/batch=0.94s
23803/10943 (epoch 195.758) train_loss=288.30865479 time/batch=0.54s
23804/10943 (epoch 195.767) train_loss=290.12631226 time/batch=0.53s
23805/10943 (epoch 195.775) train_loss=355.78411865 time/batch=0.66s
23806/10943 (epoch 195.783) train_loss=279.81289673 time/batch=0.58s
setting learning rate to 0.0004143
23807/10943 (epoch 195.791) train_loss=451.12982178 time/batch=0.80s
23808/10943 (epoch 195.800) train_loss=466.61346436 time/batch=0.82s
23809/10943 (epoch 195.808) train_loss=549.08807373 time/batch=0.93s
23810/10943 (epoch 195.816) train_loss=485.78979492 time/batch=0.89s
23811/10943 (epoch 195.824) train_loss=620.32238770 time/batch=1.04s
23812/10943 (epoch 195.832) train_loss=1278.55273438 time/batch=2.39s
23813/10943 (epoch 195.841) train_loss=292.35333252 time/batch=0.69s
23814/10943 (epoch 195.849) train_loss=339.56994629 time/batch=0.58s
23815/10943 (epoch 195.857) train_loss=570.34460449 time/batch=0.95s
23816/10943 (epoch 195.865) train_loss=430.42034912 time/batch=0.78s
23817/10943 (epoch 195.874) train_loss=353.03851318 time/batch=0.64s
23818/10943 (epoch 195.882) train_loss=398.14987183 time/batch=0.69s
23819/10943 (epoch 195.890) train_loss=625.57763672 time/batch=1.03s
23820/10943 (epoch 195.898) train_loss=593.34130859 time/batch=1.08s
23821/10943 (epoch 195.906) train_loss=542.46899414 time/batch=0.93s
23822/10943 (epoch 195.915) train_loss=523.75146484 time/batch=0.89s
23823/10943 (epoch 195.923) train_loss=831.42749023 time/batch=1.35s
23824/10943 (epoch 195.931) train_loss=653.25323486 time/batch=1.14s
23825/10943 (epoch 195.939) train_loss=778.48327637 time/batch=1.30s
23826/10943 (epoch 195.948) train_loss=376.06298828 time/batch=0.71s
23827/10943 (epoch 195.956) train_loss=133.44143677 time/batch=0.28s
23828/10943 (epoch 195.964) train_loss=664.83239746 time/batch=1.07s
23829/10943 (epoch 195.972) train_loss=487.15716553 time/batch=0.88s
23830/10943 (epoch 195.980) train_loss=574.44677734 time/batch=1.00s
23831/10943 (epoch 195.989) train_loss=346.23406982 time/batch=0.63s
23832/10943 (epoch 195.997) train_loss=865.00518799 time/batch=1.48s
23833/10943 (epoch 196.005) train_loss=487.13681030 time/batch=0.88s
23834/10943 (epoch 196.013) train_loss=394.12469482 time/batch=0.70s
23835/10943 (epoch 196.022) train_loss=329.87814331 time/batch=0.60s
23836/10943 (epoch 196.030) train_loss=470.69583130 time/batch=0.81s
23837/10943 (epoch 196.038) train_loss=708.18090820 time/batch=1.20s
23838/10943 (epoch 196.046) train_loss=275.33459473 time/batch=0.54s
23839/10943 (epoch 196.054) train_loss=168.32656860 time/batch=0.31s
23840/10943 (epoch 196.063) train_loss=187.46554565 time/batch=0.33s
23841/10943 (epoch 196.071) train_loss=226.14785767 time/batch=0.41s
23842/10943 (epoch 196.079) train_loss=294.99475098 time/batch=0.52s
23843/10943 (epoch 196.087) train_loss=495.20776367 time/batch=0.83s
23844/10943 (epoch 196.096) train_loss=216.27835083 time/batch=0.41s
23845/10943 (epoch 196.104) train_loss=310.94833374 time/batch=0.54s
23846/10943 (epoch 196.112) train_loss=184.34674072 time/batch=0.36s
23847/10943 (epoch 196.120) train_loss=216.77806091 time/batch=0.37s
23848/10943 (epoch 196.129) train_loss=605.30792236 time/batch=0.95s
23849/10943 (epoch 196.137) train_loss=408.81695557 time/batch=0.73s
23850/10943 (epoch 196.145) train_loss=687.97583008 time/batch=1.15s
23851/10943 (epoch 196.153) train_loss=598.60583496 time/batch=0.99s
23852/10943 (epoch 196.161) train_loss=600.64514160 time/batch=1.07s
23853/10943 (epoch 196.170) train_loss=588.17407227 time/batch=1.00s
23854/10943 (epoch 196.178) train_loss=435.92758179 time/batch=0.76s
23855/10943 (epoch 196.186) train_loss=261.78759766 time/batch=0.50s
23856/10943 (epoch 196.194) train_loss=243.84048462 time/batch=0.45s
23857/10943 (epoch 196.203) train_loss=154.46148682 time/batch=0.29s
23858/10943 (epoch 196.211) train_loss=322.38412476 time/batch=0.55s
23859/10943 (epoch 196.219) train_loss=386.00439453 time/batch=0.68s
23860/10943 (epoch 196.227) train_loss=807.72186279 time/batch=1.37s
23861/10943 (epoch 196.235) train_loss=237.60147095 time/batch=0.52s
23862/10943 (epoch 196.244) train_loss=399.65704346 time/batch=0.64s
23863/10943 (epoch 196.252) train_loss=1122.13134766 time/batch=3.10s
23864/10943 (epoch 196.260) train_loss=320.72216797 time/batch=0.82s
23865/10943 (epoch 196.268) train_loss=442.92773438 time/batch=0.76s
23866/10943 (epoch 196.277) train_loss=257.69485474 time/batch=0.50s
23867/10943 (epoch 196.285) train_loss=523.51593018 time/batch=0.87s
23868/10943 (epoch 196.293) train_loss=208.42820740 time/batch=0.41s
23869/10943 (epoch 196.301) train_loss=460.48883057 time/batch=0.76s
23870/10943 (epoch 196.309) train_loss=754.98712158 time/batch=1.40s
23871/10943 (epoch 196.318) train_loss=203.93389893 time/batch=0.46s
23872/10943 (epoch 196.326) train_loss=788.22631836 time/batch=1.50s
23873/10943 (epoch 196.334) train_loss=706.52703857 time/batch=1.19s
23874/10943 (epoch 196.342) train_loss=371.06579590 time/batch=0.67s
23875/10943 (epoch 196.351) train_loss=410.99835205 time/batch=0.67s
23876/10943 (epoch 196.359) train_loss=331.97296143 time/batch=0.61s
23877/10943 (epoch 196.367) train_loss=362.73968506 time/batch=0.63s
23878/10943 (epoch 196.375) train_loss=212.77616882 time/batch=0.41s
23879/10943 (epoch 196.383) train_loss=297.95098877 time/batch=0.52s
23880/10943 (epoch 196.392) train_loss=639.40612793 time/batch=1.07s
23881/10943 (epoch 196.400) train_loss=344.95568848 time/batch=0.64s
23882/10943 (epoch 196.408) train_loss=287.33386230 time/batch=0.49s
23883/10943 (epoch 196.416) train_loss=508.53619385 time/batch=0.88s
23884/10943 (epoch 196.425) train_loss=397.81561279 time/batch=0.68s
23885/10943 (epoch 196.433) train_loss=289.43951416 time/batch=0.53s
23886/10943 (epoch 196.441) train_loss=426.25469971 time/batch=0.69s
23887/10943 (epoch 196.449) train_loss=430.13049316 time/batch=0.74s
23888/10943 (epoch 196.457) train_loss=173.23930359 time/batch=0.35s
23889/10943 (epoch 196.466) train_loss=413.69610596 time/batch=0.67s
23890/10943 (epoch 196.474) train_loss=215.30621338 time/batch=0.42s
23891/10943 (epoch 196.482) train_loss=434.32012939 time/batch=0.72s
23892/10943 (epoch 196.490) train_loss=573.97241211 time/batch=1.04s
23893/10943 (epoch 196.499) train_loss=570.56793213 time/batch=0.94s
23894/10943 (epoch 196.507) train_loss=479.40158081 time/batch=0.78s
23895/10943 (epoch 196.515) train_loss=338.34234619 time/batch=0.60s
23896/10943 (epoch 196.523) train_loss=456.83859253 time/batch=0.77s
23897/10943 (epoch 196.531) train_loss=306.78369141 time/batch=0.57s
23898/10943 (epoch 196.540) train_loss=166.03723145 time/batch=0.33s
23899/10943 (epoch 196.548) train_loss=427.87274170 time/batch=0.68s
23900/10943 (epoch 196.556) train_loss=448.09500122 time/batch=0.76s
23901/10943 (epoch 196.564) train_loss=355.29534912 time/batch=0.63s
23902/10943 (epoch 196.573) train_loss=330.55041504 time/batch=0.59s
23903/10943 (epoch 196.581) train_loss=388.62609863 time/batch=0.65s
23904/10943 (epoch 196.589) train_loss=276.59783936 time/batch=0.51s
23905/10943 (epoch 196.597) train_loss=461.94641113 time/batch=0.79s
23906/10943 (epoch 196.605) train_loss=278.97470093 time/batch=0.53s
23907/10943 (epoch 196.614) train_loss=272.20993042 time/batch=0.49s
23908/10943 (epoch 196.622) train_loss=382.65832520 time/batch=0.66s
23909/10943 (epoch 196.630) train_loss=424.84454346 time/batch=0.71s
23910/10943 (epoch 196.638) train_loss=250.88552856 time/batch=0.45s
23911/10943 (epoch 196.647) train_loss=465.78106689 time/batch=0.77s
23912/10943 (epoch 196.655) train_loss=307.63610840 time/batch=0.53s
23913/10943 (epoch 196.663) train_loss=383.05853271 time/batch=0.63s
23914/10943 (epoch 196.671) train_loss=478.38098145 time/batch=0.81s
23915/10943 (epoch 196.680) train_loss=543.66381836 time/batch=0.87s
23916/10943 (epoch 196.688) train_loss=368.56198120 time/batch=0.65s
23917/10943 (epoch 196.696) train_loss=417.79681396 time/batch=0.72s
23918/10943 (epoch 196.704) train_loss=330.69439697 time/batch=0.62s
23919/10943 (epoch 196.712) train_loss=329.10208130 time/batch=0.60s
23920/10943 (epoch 196.721) train_loss=479.14486694 time/batch=0.83s
23921/10943 (epoch 196.729) train_loss=205.08874512 time/batch=0.46s
23922/10943 (epoch 196.737) train_loss=484.90075684 time/batch=0.81s
23923/10943 (epoch 196.745) train_loss=281.03015137 time/batch=0.53s
23924/10943 (epoch 196.754) train_loss=460.05841064 time/batch=0.78s
23925/10943 (epoch 196.762) train_loss=301.63394165 time/batch=0.64s
23926/10943 (epoch 196.770) train_loss=347.97567749 time/batch=0.64s
23927/10943 (epoch 196.778) train_loss=403.75494385 time/batch=0.71s
setting learning rate to 0.0004018
23928/10943 (epoch 196.786) train_loss=578.42590332 time/batch=0.96s
23929/10943 (epoch 196.795) train_loss=352.71197510 time/batch=0.64s
23930/10943 (epoch 196.803) train_loss=407.82080078 time/batch=0.66s
23931/10943 (epoch 196.811) train_loss=771.90344238 time/batch=1.20s
23932/10943 (epoch 196.819) train_loss=758.00854492 time/batch=1.13s
23933/10943 (epoch 196.828) train_loss=699.10614014 time/batch=1.15s
23934/10943 (epoch 196.836) train_loss=409.76559448 time/batch=0.70s
23935/10943 (epoch 196.844) train_loss=647.04370117 time/batch=1.06s
23936/10943 (epoch 196.852) train_loss=277.18280029 time/batch=0.52s
23937/10943 (epoch 196.860) train_loss=239.46498108 time/batch=0.41s
23938/10943 (epoch 196.869) train_loss=706.68786621 time/batch=1.15s
23939/10943 (epoch 196.877) train_loss=855.59851074 time/batch=1.41s
23940/10943 (epoch 196.885) train_loss=216.56582642 time/batch=0.47s
23941/10943 (epoch 196.893) train_loss=880.51977539 time/batch=1.44s
23942/10943 (epoch 196.902) train_loss=616.35931396 time/batch=1.06s
23943/10943 (epoch 196.910) train_loss=222.85966492 time/batch=0.42s
23944/10943 (epoch 196.918) train_loss=441.05319214 time/batch=0.72s
23945/10943 (epoch 196.926) train_loss=978.55676270 time/batch=1.59s
23946/10943 (epoch 196.934) train_loss=369.69345093 time/batch=0.73s
23947/10943 (epoch 196.943) train_loss=614.93310547 time/batch=0.98s
23948/10943 (epoch 196.951) train_loss=183.05786133 time/batch=0.37s
23949/10943 (epoch 196.959) train_loss=1354.43725586 time/batch=3.07s
23950/10943 (epoch 196.967) train_loss=182.48233032 time/batch=0.61s
23951/10943 (epoch 196.976) train_loss=740.64746094 time/batch=1.19s
23952/10943 (epoch 196.984) train_loss=992.95855713 time/batch=1.73s
23953/10943 (epoch 196.992) train_loss=559.87176514 time/batch=0.99s
23954/10943 (epoch 197.000) train_loss=472.79373169 time/batch=0.82s
23955/10943 (epoch 197.008) train_loss=283.04919434 time/batch=0.51s
23956/10943 (epoch 197.017) train_loss=349.26739502 time/batch=0.57s
23957/10943 (epoch 197.025) train_loss=447.61846924 time/batch=0.73s
23958/10943 (epoch 197.033) train_loss=403.15576172 time/batch=0.68s
23959/10943 (epoch 197.041) train_loss=602.73516846 time/batch=0.99s
23960/10943 (epoch 197.050) train_loss=440.41390991 time/batch=0.76s
23961/10943 (epoch 197.058) train_loss=223.18432617 time/batch=0.41s
23962/10943 (epoch 197.066) train_loss=467.06762695 time/batch=0.75s
23963/10943 (epoch 197.074) train_loss=510.36676025 time/batch=0.86s
23964/10943 (epoch 197.082) train_loss=291.06381226 time/batch=0.54s
23965/10943 (epoch 197.091) train_loss=544.29284668 time/batch=0.85s
23966/10943 (epoch 197.099) train_loss=849.87536621 time/batch=1.30s
23967/10943 (epoch 197.107) train_loss=343.03915405 time/batch=0.64s
23968/10943 (epoch 197.115) train_loss=690.52526855 time/batch=1.26s
23969/10943 (epoch 197.124) train_loss=646.12451172 time/batch=1.14s
23970/10943 (epoch 197.132) train_loss=448.24688721 time/batch=0.80s
23971/10943 (epoch 197.140) train_loss=424.36773682 time/batch=0.75s
23972/10943 (epoch 197.148) train_loss=669.42944336 time/batch=1.13s
23973/10943 (epoch 197.157) train_loss=477.08026123 time/batch=0.83s
23974/10943 (epoch 197.165) train_loss=269.40423584 time/batch=0.48s
23975/10943 (epoch 197.173) train_loss=298.46734619 time/batch=0.51s
23976/10943 (epoch 197.181) train_loss=532.05908203 time/batch=0.88s
23977/10943 (epoch 197.189) train_loss=303.69595337 time/batch=0.55s
23978/10943 (epoch 197.198) train_loss=223.91790771 time/batch=0.40s
23979/10943 (epoch 197.206) train_loss=562.33282471 time/batch=0.91s
23980/10943 (epoch 197.214) train_loss=446.18432617 time/batch=0.79s
23981/10943 (epoch 197.222) train_loss=359.55419922 time/batch=0.64s
23982/10943 (epoch 197.231) train_loss=567.00195312 time/batch=0.93s
23983/10943 (epoch 197.239) train_loss=429.61004639 time/batch=0.74s
23984/10943 (epoch 197.247) train_loss=232.75988770 time/batch=0.45s
23985/10943 (epoch 197.255) train_loss=361.50952148 time/batch=0.61s
23986/10943 (epoch 197.263) train_loss=547.62731934 time/batch=0.91s
23987/10943 (epoch 197.272) train_loss=387.94757080 time/batch=0.69s
23988/10943 (epoch 197.280) train_loss=406.12759399 time/batch=0.68s
23989/10943 (epoch 197.288) train_loss=351.26995850 time/batch=0.61s
23990/10943 (epoch 197.296) train_loss=314.93774414 time/batch=0.55s
23991/10943 (epoch 197.305) train_loss=161.62512207 time/batch=0.32s
23992/10943 (epoch 197.313) train_loss=419.19659424 time/batch=0.68s
23993/10943 (epoch 197.321) train_loss=578.71374512 time/batch=1.00s
23994/10943 (epoch 197.329) train_loss=269.47338867 time/batch=0.51s
23995/10943 (epoch 197.337) train_loss=374.24981689 time/batch=0.62s
23996/10943 (epoch 197.346) train_loss=606.04296875 time/batch=1.00s
23997/10943 (epoch 197.354) train_loss=437.58770752 time/batch=0.76s
23998/10943 (epoch 197.362) train_loss=396.72668457 time/batch=0.68s
23999/10943 (epoch 197.370) train_loss=291.50363159 time/batch=0.53s
Validating
    loss:	403.249105

24000/10943 (epoch 197.379) train_loss=529.85815430 time/batch=2.88s
24001/10943 (epoch 197.387) train_loss=417.67388916 time/batch=0.74s
24002/10943 (epoch 197.395) train_loss=362.28210449 time/batch=0.64s
24003/10943 (epoch 197.403) train_loss=432.77539062 time/batch=0.76s
24004/10943 (epoch 197.411) train_loss=190.84719849 time/batch=0.36s
24005/10943 (epoch 197.420) train_loss=190.19079590 time/batch=0.33s
24006/10943 (epoch 197.428) train_loss=205.94743347 time/batch=0.38s
24007/10943 (epoch 197.436) train_loss=452.01501465 time/batch=0.74s
24008/10943 (epoch 197.444) train_loss=219.37576294 time/batch=0.43s
24009/10943 (epoch 197.453) train_loss=466.51861572 time/batch=0.80s
24010/10943 (epoch 197.461) train_loss=309.07922363 time/batch=0.57s
24011/10943 (epoch 197.469) train_loss=194.08959961 time/batch=0.36s
24012/10943 (epoch 197.477) train_loss=454.88790894 time/batch=0.74s
24013/10943 (epoch 197.485) train_loss=148.95216370 time/batch=0.35s
24014/10943 (epoch 197.494) train_loss=490.07751465 time/batch=0.79s
24015/10943 (epoch 197.502) train_loss=466.37908936 time/batch=0.84s
24016/10943 (epoch 197.510) train_loss=486.38854980 time/batch=0.80s
24017/10943 (epoch 197.518) train_loss=633.44689941 time/batch=1.03s
24018/10943 (epoch 197.527) train_loss=284.13357544 time/batch=0.53s
24019/10943 (epoch 197.535) train_loss=331.96774292 time/batch=0.58s
24020/10943 (epoch 197.543) train_loss=181.70967102 time/batch=0.41s
24021/10943 (epoch 197.551) train_loss=331.74981689 time/batch=0.56s
24022/10943 (epoch 197.559) train_loss=317.99392700 time/batch=0.57s
24023/10943 (epoch 197.568) train_loss=323.80331421 time/batch=0.56s
24024/10943 (epoch 197.576) train_loss=243.97735596 time/batch=0.45s
24025/10943 (epoch 197.584) train_loss=486.27572632 time/batch=0.80s
24026/10943 (epoch 197.592) train_loss=217.87150574 time/batch=0.47s
24027/10943 (epoch 197.601) train_loss=462.65899658 time/batch=0.77s
24028/10943 (epoch 197.609) train_loss=466.87591553 time/batch=0.81s
24029/10943 (epoch 197.617) train_loss=322.73785400 time/batch=0.57s
24030/10943 (epoch 197.625) train_loss=520.74932861 time/batch=0.84s
24031/10943 (epoch 197.634) train_loss=295.57086182 time/batch=0.53s
24032/10943 (epoch 197.642) train_loss=397.48181152 time/batch=0.67s
24033/10943 (epoch 197.650) train_loss=351.35534668 time/batch=0.60s
24034/10943 (epoch 197.658) train_loss=488.52404785 time/batch=0.83s
24035/10943 (epoch 197.666) train_loss=296.91455078 time/batch=0.55s
24036/10943 (epoch 197.675) train_loss=518.17614746 time/batch=0.83s
24037/10943 (epoch 197.683) train_loss=267.54388428 time/batch=0.53s
24038/10943 (epoch 197.691) train_loss=389.19628906 time/batch=0.66s
24039/10943 (epoch 197.699) train_loss=425.12966919 time/batch=0.70s
24040/10943 (epoch 197.708) train_loss=400.67941284 time/batch=0.68s
24041/10943 (epoch 197.716) train_loss=495.36425781 time/batch=0.83s
24042/10943 (epoch 197.724) train_loss=420.18362427 time/batch=0.81s
24043/10943 (epoch 197.732) train_loss=313.75192261 time/batch=0.59s
24044/10943 (epoch 197.740) train_loss=393.08068848 time/batch=0.67s
24045/10943 (epoch 197.749) train_loss=352.61846924 time/batch=0.61s
24046/10943 (epoch 197.757) train_loss=479.61541748 time/batch=0.85s
24047/10943 (epoch 197.765) train_loss=373.40936279 time/batch=0.64s
24048/10943 (epoch 197.773) train_loss=349.99423218 time/batch=0.60s
setting learning rate to 0.0003898
24049/10943 (epoch 197.782) train_loss=219.15728760 time/batch=0.41s
24050/10943 (epoch 197.790) train_loss=638.04364014 time/batch=1.01s
24051/10943 (epoch 197.798) train_loss=517.04077148 time/batch=0.91s
24052/10943 (epoch 197.806) train_loss=171.81707764 time/batch=0.35s
24053/10943 (epoch 197.814) train_loss=584.83673096 time/batch=0.90s
24054/10943 (epoch 197.823) train_loss=874.04260254 time/batch=1.34s
24055/10943 (epoch 197.831) train_loss=375.01898193 time/batch=0.67s
24056/10943 (epoch 197.839) train_loss=407.91430664 time/batch=0.67s
24057/10943 (epoch 197.847) train_loss=672.56018066 time/batch=1.07s
24058/10943 (epoch 197.856) train_loss=340.09060669 time/batch=0.62s
24059/10943 (epoch 197.864) train_loss=292.50686646 time/batch=0.50s
24060/10943 (epoch 197.872) train_loss=450.73474121 time/batch=0.75s
24061/10943 (epoch 197.880) train_loss=1387.96557617 time/batch=3.10s
24062/10943 (epoch 197.888) train_loss=762.46466064 time/batch=1.35s
24063/10943 (epoch 197.897) train_loss=459.77233887 time/batch=0.75s
24064/10943 (epoch 197.905) train_loss=446.36132812 time/batch=0.74s
24065/10943 (epoch 197.913) train_loss=234.35577393 time/batch=0.44s
24066/10943 (epoch 197.921) train_loss=147.60771179 time/batch=0.30s
24067/10943 (epoch 197.930) train_loss=393.22290039 time/batch=0.62s
24068/10943 (epoch 197.938) train_loss=1068.08789062 time/batch=1.66s
24069/10943 (epoch 197.946) train_loss=169.21008301 time/batch=0.44s
24070/10943 (epoch 197.954) train_loss=802.86596680 time/batch=1.20s
24071/10943 (epoch 197.962) train_loss=340.82348633 time/batch=0.63s
24072/10943 (epoch 197.971) train_loss=436.75405884 time/batch=0.72s
24073/10943 (epoch 197.979) train_loss=695.83557129 time/batch=1.14s
24074/10943 (epoch 197.987) train_loss=488.49594116 time/batch=0.82s
24075/10943 (epoch 197.995) train_loss=376.86386108 time/batch=0.64s
24076/10943 (epoch 198.004) train_loss=221.88415527 time/batch=0.40s
24077/10943 (epoch 198.012) train_loss=945.89001465 time/batch=1.50s
24078/10943 (epoch 198.020) train_loss=836.41064453 time/batch=1.42s
24079/10943 (epoch 198.028) train_loss=713.09619141 time/batch=1.17s
24080/10943 (epoch 198.036) train_loss=258.48873901 time/batch=0.51s
24081/10943 (epoch 198.045) train_loss=455.15374756 time/batch=0.72s
24082/10943 (epoch 198.053) train_loss=271.52975464 time/batch=0.49s
24083/10943 (epoch 198.061) train_loss=725.51873779 time/batch=1.16s
24084/10943 (epoch 198.069) train_loss=735.54974365 time/batch=1.41s
24085/10943 (epoch 198.078) train_loss=484.41876221 time/batch=0.87s
24086/10943 (epoch 198.086) train_loss=586.07373047 time/batch=0.99s
24087/10943 (epoch 198.094) train_loss=281.12554932 time/batch=0.53s
24088/10943 (epoch 198.102) train_loss=296.74893188 time/batch=0.50s
24089/10943 (epoch 198.111) train_loss=182.73330688 time/batch=0.33s
24090/10943 (epoch 198.119) train_loss=525.23968506 time/batch=0.83s
24091/10943 (epoch 198.127) train_loss=585.62719727 time/batch=0.98s
24092/10943 (epoch 198.135) train_loss=301.29699707 time/batch=0.59s
24093/10943 (epoch 198.143) train_loss=465.67007446 time/batch=0.77s
24094/10943 (epoch 198.152) train_loss=623.19665527 time/batch=1.00s
24095/10943 (epoch 198.160) train_loss=558.84436035 time/batch=0.92s
24096/10943 (epoch 198.168) train_loss=874.77502441 time/batch=1.45s
24097/10943 (epoch 198.176) train_loss=221.56427002 time/batch=0.47s
24098/10943 (epoch 198.185) train_loss=344.91070557 time/batch=0.56s
24099/10943 (epoch 198.193) train_loss=435.58584595 time/batch=0.70s
24100/10943 (epoch 198.201) train_loss=651.72540283 time/batch=1.09s
24101/10943 (epoch 198.209) train_loss=263.69982910 time/batch=0.51s
24102/10943 (epoch 198.217) train_loss=451.72958374 time/batch=0.72s
24103/10943 (epoch 198.226) train_loss=502.05554199 time/batch=0.83s
24104/10943 (epoch 198.234) train_loss=294.13232422 time/batch=0.54s
24105/10943 (epoch 198.242) train_loss=480.45788574 time/batch=0.80s
24106/10943 (epoch 198.250) train_loss=435.51049805 time/batch=0.72s
24107/10943 (epoch 198.259) train_loss=626.34857178 time/batch=0.99s
24108/10943 (epoch 198.267) train_loss=346.03085327 time/batch=0.62s
24109/10943 (epoch 198.275) train_loss=547.26007080 time/batch=0.91s
24110/10943 (epoch 198.283) train_loss=487.81738281 time/batch=0.82s
24111/10943 (epoch 198.291) train_loss=569.11334229 time/batch=0.96s
24112/10943 (epoch 198.300) train_loss=683.65106201 time/batch=1.14s
24113/10943 (epoch 198.308) train_loss=256.00463867 time/batch=0.49s
24114/10943 (epoch 198.316) train_loss=294.70739746 time/batch=0.50s
24115/10943 (epoch 198.324) train_loss=459.49252319 time/batch=0.79s
24116/10943 (epoch 198.333) train_loss=174.35942078 time/batch=0.36s
24117/10943 (epoch 198.341) train_loss=374.70147705 time/batch=0.61s
24118/10943 (epoch 198.349) train_loss=231.99230957 time/batch=0.44s
24119/10943 (epoch 198.357) train_loss=393.67593384 time/batch=0.63s
24120/10943 (epoch 198.365) train_loss=542.04278564 time/batch=0.88s
24121/10943 (epoch 198.374) train_loss=415.72683716 time/batch=0.72s
24122/10943 (epoch 198.382) train_loss=460.65661621 time/batch=0.77s
24123/10943 (epoch 198.390) train_loss=288.51556396 time/batch=0.52s
24124/10943 (epoch 198.398) train_loss=445.24798584 time/batch=0.72s
24125/10943 (epoch 198.407) train_loss=358.83160400 time/batch=0.59s
24126/10943 (epoch 198.415) train_loss=585.29656982 time/batch=0.99s
24127/10943 (epoch 198.423) train_loss=207.04229736 time/batch=0.41s
24128/10943 (epoch 198.431) train_loss=543.98626709 time/batch=0.87s
24129/10943 (epoch 198.439) train_loss=349.48886108 time/batch=0.64s
24130/10943 (epoch 198.448) train_loss=443.24374390 time/batch=0.70s
24131/10943 (epoch 198.456) train_loss=397.83636475 time/batch=0.66s
24132/10943 (epoch 198.464) train_loss=313.83267212 time/batch=0.54s
24133/10943 (epoch 198.472) train_loss=510.72610474 time/batch=0.83s
24134/10943 (epoch 198.481) train_loss=297.13125610 time/batch=0.53s
24135/10943 (epoch 198.489) train_loss=582.08038330 time/batch=0.98s
24136/10943 (epoch 198.497) train_loss=401.87707520 time/batch=0.70s
24137/10943 (epoch 198.505) train_loss=515.81799316 time/batch=0.85s
24138/10943 (epoch 198.513) train_loss=417.50732422 time/batch=0.73s
24139/10943 (epoch 198.522) train_loss=304.34570312 time/batch=0.55s
24140/10943 (epoch 198.530) train_loss=195.25498962 time/batch=0.36s
24141/10943 (epoch 198.538) train_loss=346.97467041 time/batch=0.58s
24142/10943 (epoch 198.546) train_loss=471.51446533 time/batch=0.81s
24143/10943 (epoch 198.555) train_loss=442.76571655 time/batch=0.73s
24144/10943 (epoch 198.563) train_loss=340.79760742 time/batch=0.60s
24145/10943 (epoch 198.571) train_loss=262.68402100 time/batch=0.45s
24146/10943 (epoch 198.579) train_loss=282.50881958 time/batch=0.50s
24147/10943 (epoch 198.588) train_loss=255.14465332 time/batch=0.45s
24148/10943 (epoch 198.596) train_loss=367.01257324 time/batch=0.61s
24149/10943 (epoch 198.604) train_loss=349.88183594 time/batch=0.61s
24150/10943 (epoch 198.612) train_loss=399.71026611 time/batch=0.66s
24151/10943 (epoch 198.620) train_loss=377.18444824 time/batch=0.66s
24152/10943 (epoch 198.629) train_loss=188.15251160 time/batch=0.38s
24153/10943 (epoch 198.637) train_loss=499.95007324 time/batch=0.80s
24154/10943 (epoch 198.645) train_loss=370.43145752 time/batch=0.65s
24155/10943 (epoch 198.653) train_loss=223.72012329 time/batch=0.39s
24156/10943 (epoch 198.662) train_loss=523.18334961 time/batch=0.86s
24157/10943 (epoch 198.670) train_loss=323.04498291 time/batch=0.59s
24158/10943 (epoch 198.678) train_loss=415.02917480 time/batch=0.68s
24159/10943 (epoch 198.686) train_loss=476.78729248 time/batch=0.78s
24160/10943 (epoch 198.694) train_loss=485.05532837 time/batch=0.82s
24161/10943 (epoch 198.703) train_loss=361.15786743 time/batch=0.61s
24162/10943 (epoch 198.711) train_loss=463.98880005 time/batch=0.79s
24163/10943 (epoch 198.719) train_loss=425.51004028 time/batch=0.69s
24164/10943 (epoch 198.727) train_loss=339.38677979 time/batch=0.62s
24165/10943 (epoch 198.736) train_loss=365.52731323 time/batch=0.62s
24166/10943 (epoch 198.744) train_loss=490.27032471 time/batch=0.81s
24167/10943 (epoch 198.752) train_loss=424.05432129 time/batch=0.75s
24168/10943 (epoch 198.760) train_loss=199.93539429 time/batch=0.40s
24169/10943 (epoch 198.768) train_loss=273.88851929 time/batch=0.59s
setting learning rate to 0.0003781
24170/10943 (epoch 198.777) train_loss=160.82765198 time/batch=0.31s
24171/10943 (epoch 198.785) train_loss=602.51776123 time/batch=0.90s
24172/10943 (epoch 198.793) train_loss=539.66198730 time/batch=0.90s
24173/10943 (epoch 198.801) train_loss=365.22436523 time/batch=0.62s
24174/10943 (epoch 198.810) train_loss=690.27758789 time/batch=1.12s
24175/10943 (epoch 198.818) train_loss=143.37197876 time/batch=0.34s
24176/10943 (epoch 198.826) train_loss=227.21298218 time/batch=0.38s
24177/10943 (epoch 198.834) train_loss=1394.52441406 time/batch=3.07s
24178/10943 (epoch 198.842) train_loss=771.58166504 time/batch=1.38s
24179/10943 (epoch 198.851) train_loss=251.94314575 time/batch=0.50s
24180/10943 (epoch 198.859) train_loss=276.96603394 time/batch=0.47s
24181/10943 (epoch 198.867) train_loss=451.05706787 time/batch=0.76s
24182/10943 (epoch 198.875) train_loss=843.15960693 time/batch=1.41s
24183/10943 (epoch 198.884) train_loss=586.29223633 time/batch=0.99s
24184/10943 (epoch 198.892) train_loss=868.78509521 time/batch=1.33s
24185/10943 (epoch 198.900) train_loss=468.56631470 time/batch=0.80s
24186/10943 (epoch 198.908) train_loss=651.24035645 time/batch=1.00s
24187/10943 (epoch 198.916) train_loss=361.84149170 time/batch=0.66s
24188/10943 (epoch 198.925) train_loss=574.82666016 time/batch=0.98s
24189/10943 (epoch 198.933) train_loss=464.23437500 time/batch=0.82s
24190/10943 (epoch 198.941) train_loss=757.63806152 time/batch=1.22s
24191/10943 (epoch 198.949) train_loss=722.94018555 time/batch=1.16s
24192/10943 (epoch 198.958) train_loss=352.00946045 time/batch=0.65s
24193/10943 (epoch 198.966) train_loss=932.55364990 time/batch=1.51s
24194/10943 (epoch 198.974) train_loss=733.58886719 time/batch=1.26s
24195/10943 (epoch 198.982) train_loss=491.21047974 time/batch=0.84s
24196/10943 (epoch 198.990) train_loss=475.64715576 time/batch=0.81s
24197/10943 (epoch 198.999) train_loss=291.02352905 time/batch=0.54s
24198/10943 (epoch 199.007) train_loss=1016.59350586 time/batch=1.61s
24199/10943 (epoch 199.015) train_loss=296.60317993 time/batch=0.63s
24200/10943 (epoch 199.023) train_loss=713.65185547 time/batch=1.16s
24201/10943 (epoch 199.032) train_loss=431.55926514 time/batch=0.78s
24202/10943 (epoch 199.040) train_loss=206.44560242 time/batch=0.41s
24203/10943 (epoch 199.048) train_loss=192.82943726 time/batch=0.34s
24204/10943 (epoch 199.056) train_loss=524.54589844 time/batch=0.86s
24205/10943 (epoch 199.065) train_loss=388.62707520 time/batch=0.68s
24206/10943 (epoch 199.073) train_loss=693.99835205 time/batch=1.24s
24207/10943 (epoch 199.081) train_loss=353.04943848 time/batch=0.66s
24208/10943 (epoch 199.089) train_loss=278.72534180 time/batch=0.49s
24209/10943 (epoch 199.097) train_loss=618.17932129 time/batch=0.99s
24210/10943 (epoch 199.106) train_loss=291.88867188 time/batch=0.53s
24211/10943 (epoch 199.114) train_loss=343.79528809 time/batch=0.59s
24212/10943 (epoch 199.122) train_loss=587.80230713 time/batch=0.94s
24213/10943 (epoch 199.130) train_loss=175.22874451 time/batch=0.37s
24214/10943 (epoch 199.139) train_loss=664.02014160 time/batch=1.20s
24215/10943 (epoch 199.147) train_loss=175.16043091 time/batch=0.40s
24216/10943 (epoch 199.155) train_loss=230.98829651 time/batch=0.40s
24217/10943 (epoch 199.163) train_loss=398.41857910 time/batch=0.66s
24218/10943 (epoch 199.171) train_loss=412.58874512 time/batch=0.67s
24219/10943 (epoch 199.180) train_loss=699.30664062 time/batch=1.26s
24220/10943 (epoch 199.188) train_loss=213.92646790 time/batch=0.44s
24221/10943 (epoch 199.196) train_loss=305.46514893 time/batch=0.49s
24222/10943 (epoch 199.204) train_loss=409.90798950 time/batch=0.67s
24223/10943 (epoch 199.213) train_loss=413.71038818 time/batch=0.72s
24224/10943 (epoch 199.221) train_loss=296.54507446 time/batch=0.54s
24225/10943 (epoch 199.229) train_loss=328.22442627 time/batch=0.58s
24226/10943 (epoch 199.237) train_loss=462.35836792 time/batch=0.78s
24227/10943 (epoch 199.245) train_loss=538.47985840 time/batch=0.88s
24228/10943 (epoch 199.254) train_loss=233.80947876 time/batch=0.43s
24229/10943 (epoch 199.262) train_loss=476.22717285 time/batch=0.79s
24230/10943 (epoch 199.270) train_loss=658.39501953 time/batch=1.04s
24231/10943 (epoch 199.278) train_loss=451.84677124 time/batch=0.74s
24232/10943 (epoch 199.287) train_loss=398.96270752 time/batch=0.66s
24233/10943 (epoch 199.295) train_loss=180.13284302 time/batch=0.35s
24234/10943 (epoch 199.303) train_loss=492.58489990 time/batch=0.82s
24235/10943 (epoch 199.311) train_loss=200.50387573 time/batch=0.40s
24236/10943 (epoch 199.319) train_loss=528.19244385 time/batch=0.82s
24237/10943 (epoch 199.328) train_loss=259.09893799 time/batch=0.49s
24238/10943 (epoch 199.336) train_loss=540.44897461 time/batch=0.85s
24239/10943 (epoch 199.344) train_loss=794.75158691 time/batch=1.70s
24240/10943 (epoch 199.352) train_loss=488.01348877 time/batch=0.86s
24241/10943 (epoch 199.361) train_loss=371.70925903 time/batch=0.63s
24242/10943 (epoch 199.369) train_loss=370.44055176 time/batch=0.64s
24243/10943 (epoch 199.377) train_loss=229.47731018 time/batch=0.43s
24244/10943 (epoch 199.385) train_loss=574.90447998 time/batch=0.96s
24245/10943 (epoch 199.393) train_loss=441.93511963 time/batch=0.77s
24246/10943 (epoch 199.402) train_loss=233.95330811 time/batch=0.45s
24247/10943 (epoch 199.410) train_loss=498.81268311 time/batch=0.80s
24248/10943 (epoch 199.418) train_loss=371.21783447 time/batch=0.66s
24249/10943 (epoch 199.426) train_loss=549.80175781 time/batch=0.92s
24250/10943 (epoch 199.435) train_loss=568.46472168 time/batch=0.94s
24251/10943 (epoch 199.443) train_loss=384.10726929 time/batch=0.67s
24252/10943 (epoch 199.451) train_loss=341.78741455 time/batch=0.60s
24253/10943 (epoch 199.459) train_loss=425.21618652 time/batch=0.70s
24254/10943 (epoch 199.467) train_loss=468.90185547 time/batch=0.80s
24255/10943 (epoch 199.476) train_loss=353.78936768 time/batch=0.62s
24256/10943 (epoch 199.484) train_loss=331.26220703 time/batch=0.59s
24257/10943 (epoch 199.492) train_loss=224.63465881 time/batch=0.44s
24258/10943 (epoch 199.500) train_loss=446.57135010 time/batch=0.73s
24259/10943 (epoch 199.509) train_loss=559.41564941 time/batch=0.96s
24260/10943 (epoch 199.517) train_loss=449.44671631 time/batch=0.77s
24261/10943 (epoch 199.525) train_loss=519.55938721 time/batch=0.92s
24262/10943 (epoch 199.533) train_loss=268.01275635 time/batch=0.50s
24263/10943 (epoch 199.542) train_loss=327.96350098 time/batch=0.57s
24264/10943 (epoch 199.550) train_loss=400.15283203 time/batch=0.68s
24265/10943 (epoch 199.558) train_loss=313.71258545 time/batch=0.55s
24266/10943 (epoch 199.566) train_loss=307.92306519 time/batch=0.53s
24267/10943 (epoch 199.574) train_loss=258.14270020 time/batch=0.46s
24268/10943 (epoch 199.583) train_loss=379.87484741 time/batch=0.62s
24269/10943 (epoch 199.591) train_loss=227.30769348 time/batch=0.44s
24270/10943 (epoch 199.599) train_loss=320.97589111 time/batch=0.53s
24271/10943 (epoch 199.607) train_loss=315.77722168 time/batch=0.56s
24272/10943 (epoch 199.616) train_loss=362.45013428 time/batch=0.60s
24273/10943 (epoch 199.624) train_loss=223.16323853 time/batch=0.47s
24274/10943 (epoch 199.632) train_loss=443.33880615 time/batch=0.69s
24275/10943 (epoch 199.640) train_loss=470.55169678 time/batch=0.79s
24276/10943 (epoch 199.648) train_loss=515.04388428 time/batch=0.85s
24277/10943 (epoch 199.657) train_loss=510.42147827 time/batch=0.81s
24278/10943 (epoch 199.665) train_loss=295.79888916 time/batch=0.52s
24279/10943 (epoch 199.673) train_loss=438.62463379 time/batch=0.72s
24280/10943 (epoch 199.681) train_loss=391.52941895 time/batch=0.67s
24281/10943 (epoch 199.690) train_loss=402.59817505 time/batch=0.70s
24282/10943 (epoch 199.698) train_loss=301.12500000 time/batch=0.54s
24283/10943 (epoch 199.706) train_loss=440.98959351 time/batch=0.79s
24284/10943 (epoch 199.714) train_loss=480.05505371 time/batch=0.83s
24285/10943 (epoch 199.722) train_loss=297.91250610 time/batch=0.53s
24286/10943 (epoch 199.731) train_loss=329.41925049 time/batch=0.60s
24287/10943 (epoch 199.739) train_loss=424.00665283 time/batch=0.73s
24288/10943 (epoch 199.747) train_loss=501.96893311 time/batch=0.85s
24289/10943 (epoch 199.755) train_loss=405.96350098 time/batch=0.69s
24290/10943 (epoch 199.764) train_loss=471.54409790 time/batch=0.81s
setting learning rate to 0.0003668
  saved to metadata/gru_dropout-9_nov_folkwiki-20181115-204407_epoch89.pkl
